{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 13 - Using Our Pre-Trained Models\n",
    "This notebook shows how users can use our pretrained models for both Narrowband and Wideband.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Information\n",
    "We have two Narrowband Models, and two Wideband models. See the below table for info.\n",
    "\n",
    "| Name | Filename  | Dataset | Description | Input Data | Input Shape |\n",
    "| ---- | --------  | ------- | ----------- | ---------- | ----------- |\n",
    "| ConVit | convit_narrowband.pth | Narrowband | test | IQ | (2, 4096) |\n",
    "| XCiT | xcit_narrowband.ckpt | Narrowband | test | IQ | (2, 4096) |\n",
    "| YOLO Detect | yolo_detect.pt | Wideband | YOLO model trained for energy detection (drawing bounding boxes). | Spectrogram | (1024, 1024) |\n",
    "| YOLO Classify | yolo_classify.pt | Wideband | YOLO model that can classify signals into their respective signal families. | Spectrogra, | (1024, 1024) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TorchSig\n",
    "from torchsig.datasets.signal_classes import torchsig_signals\n",
    "from torchsig.transforms.target_transforms import DescToClassIndex, DescToBBoxFamilyDict, DescToBBoxDict\n",
    "from torchsig.transforms.transforms import (\n",
    "    RandomPhaseShift,\n",
    "    Normalize,\n",
    "    Compose,  \n",
    "    ComplexTo2D,\n",
    "    Spectrogram,\n",
    "    SpectrogramImage\n",
    ")\n",
    "from torchsig.datasets.modulations import ModulationsDataset\n",
    "from torchsig.datasets.wideband import WidebandModulationsDataset\n",
    "from torchsig.utils.writer import DatasetCreator\n",
    "from torchsig.datasets.torchsig_narrowband import TorchSigNarrowband\n",
    "from torchsig.datasets.torchsig_wideband import TorchSigWideband\n",
    "\n",
    "# Third Party\n",
    "import torch\n",
    "from torchinfo import summary\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import cv2\n",
    "\n",
    "# Built-In\n",
    "import os\n",
    "\n",
    "print(\"Imports Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Narrowband Models\n",
    "We have two pretrained models for Narrowband: ConVit and XCiT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Test Narrowband Dataset\n",
    "First create and save the dataset to disk. Then load it in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(0)\n",
    "root = \"./datasets/13_example\"\n",
    "num_workers = 8\n",
    "seed = 1234567890\n",
    "class_list = torchsig_signals.class_list\n",
    "num_classes = len(class_list)\n",
    "\n",
    "ds = ModulationsDataset(\n",
    "    level = 2,\n",
    "    num_samples = num_classes,\n",
    "    num_iq_samples = 4096,\n",
    "    eb_no = False,\n",
    "    use_class_idx = True,\n",
    "    include_snr = True\n",
    ")\n",
    "\n",
    "os.makedirs(root, exist_ok=True)\n",
    "\n",
    "creator = DatasetCreator(\n",
    "    ds,\n",
    "    seed = seed,\n",
    "    path = f\"{root}/narrowband_impaired_val\",\n",
    "    num_workers = num_workers,\n",
    ")\n",
    "\n",
    "creator.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose([\n",
    "    RandomPhaseShift(phase_offset=(-1, 1)),\n",
    "    Normalize(norm=np.inf),\n",
    "    ComplexTo2D(),\n",
    "])\n",
    "\n",
    "target_transform = DescToClassIndex(class_list=class_list)\n",
    "\n",
    "\n",
    "test_narrowband = TorchSigNarrowband(\n",
    "    root,\n",
    "    train = False,\n",
    "    impaired = True,\n",
    "    transform = transform,\n",
    "    target_transform = target_transform,\n",
    "    use_signal_data = True,\n",
    ")\n",
    "\n",
    "test_data_numpy, test_target = test_narrowband[0]\n",
    "figure = plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 1, 1)\n",
    "plt.plot(test_data_numpy[0][:100])\n",
    "plt.plot(test_data_numpy[1][:100])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title(f\"Class Index: {test_target}, Class Name: {class_list[test_target]}\")\n",
    "print(f\"Class Name: {class_list[test_target]}\")\n",
    "\n",
    "# convert data as tensor, and put on same device as model, add batch dimension\n",
    "test_data = torch.from_numpy(test_data_numpy).to(device).unsqueeze(0)\n",
    "test_data = test_data.to(torch.float32)\n",
    "print(f\"Data Shape: {test_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConVit Model\n",
    "We can download the model from our hosted servers on via the release package (see release v0.6.1 attached files). The file will be stored under the examples/ directory. The following lines check to see if the file exists, and if not, it is downloaded. Therefore if you have a partial download or want a fresh copy of the file you will need to delete it manually before rerunning the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (not(os.path.isfile('convit_narrowband.pth'))):\n",
    "    download_command = 'curl -L -o \"convit_narrowband.pth\" \"https://bucket.ltsnet.net/torchsig/models/convit_narrowband.pth\"'\n",
    "    os.system(download_command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsig.models.iq_models.convit import ConVit1DLightning\n",
    "\n",
    "convit_model = ConVit1DLightning.load_from_checkpoint(\"convit_narrowband.pth\")\n",
    "summary(convit_model)\n",
    "\n",
    "# set model in evaluation mode\n",
    "convit_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data with model\n",
    "test_data\n",
    "pred = convit_model(test_data)\n",
    "result = torch.argmax(pred, dim=1).cpu().item()\n",
    "\n",
    "# compare results\n",
    "print(f\"Model Prediction = {result} | {class_list[result]}\")\n",
    "print(f\"Actual = {test_target} | {class_list[test_target]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XCiT Model\n",
    "We can download the model from our hosted servers on via the release package (see release v0.6.1 attached files). The file will be stored under the examples/ directory. The following lines check to see if the file exists, and if not, it is downloaded. Therefore if you have a partial download or want a fresh copy of the file you will need to delete it manually before rerunning the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (not(os.path.isfile('xcit_narrowband.ckpt'))):\n",
    "    download_command = 'curl -L -o \"xcit_narrowband.ckpt\" \"https://bucket.ltsnet.net/torchsig/models/xcit_narrowband.ckpt\"'\n",
    "    os.system(download_command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsig.models.iq_models.xcit import XCiTClassifier\n",
    "\n",
    "xcit_model = XCiTClassifier.load_from_checkpoint(\"xcit_narrowband.ckpt\")\n",
    "summary(xcit_model)\n",
    "\n",
    "xcit_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data with model\n",
    "pred = xcit_model(test_data)\n",
    "result = torch.argmax(pred, dim=1).cpu().item()\n",
    "\n",
    "# compare results\n",
    "print(f\"Model Prediction = {result} | {class_list[result]}\")\n",
    "print(f\"Actual = {test_target} | {class_list[test_target]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wideband Models\n",
    "We have two YOLO models trained on wideband spectrograms. `yolo_detect.pt` performs energy detection, while `yolo_classify.pt` performs family classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Test Wideband Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"./datasets/13_example\"\n",
    "overlap_prob = 0.1\n",
    "num_workers = 8\n",
    "batch_size = 8\n",
    "seed = 1234567891\n",
    "class_list = torchsig_signals.class_list\n",
    "num_classes = len(class_list)\n",
    "fft_size = 512\n",
    "\n",
    "ds = WidebandModulationsDataset(\n",
    "    level = 2,\n",
    "    num_samples = num_classes,\n",
    "    num_iq_samples = 512**2,\n",
    "    seed = seed,\n",
    "    overlap_prob = overlap_prob\n",
    ")\n",
    "os.makedirs(root, exist_ok=True)\n",
    "\n",
    "creator = DatasetCreator(\n",
    "    ds,\n",
    "    seed = seed,\n",
    "    path = f\"{root}/wideband_impaired_val\",\n",
    "    num_workers = num_workers,\n",
    ")\n",
    "\n",
    "creator.create()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLO Detection Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we set up the dataset to transform the data into spectrograms, and labels as bounding box information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose([\n",
    "    Spectrogram(nperseg=512, noverlap=0, nfft=512, mode='psd'),\n",
    "    Normalize(norm=np.inf, flatten=True),\n",
    "    SpectrogramImage(), \n",
    "])\n",
    "\n",
    "target_transform = DescToBBoxDict(\n",
    "    class_list = class_list\n",
    ")\n",
    "\n",
    "test_detect_wideband = TorchSigWideband(\n",
    "    root,\n",
    "    train = False,\n",
    "    impaired = True,\n",
    "    transform = transform,\n",
    "    target_transform = target_transform\n",
    ")\n",
    "\n",
    "test_data, test_target = test_detect_wideband[0]\n",
    "print(f\"Spectrogram: {test_data.shape}\")\n",
    "print(f\"Class Name Indicies: {test_target['labels']}\")\n",
    "print(f\"Bounding Boxes (xmin, ymin, width, height):\\n {test_target['boxes']}\")\n",
    "\n",
    "full_width, full_height, _ = test_data.shape\n",
    "figure = plt.figure(figsize=(9, 9))\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "ax.imshow(test_data)\n",
    "for i,l in enumerate(test_target['labels']):\n",
    "    norm_xstart, norm_ystart, norm_width, norm_height = test_target['boxes'][i]\n",
    "    rect = patches.Rectangle(\n",
    "        (norm_xstart*full_width, norm_ystart*full_height),\n",
    "        norm_width * full_width,\n",
    "        norm_height * full_height,\n",
    "        linewidth = 2,\n",
    "        edgecolor = \"r\",\n",
    "        facecolor = \"none\"\n",
    "    )\n",
    "    ax.add_patch(rect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can download the model from our hosted servers on via the release package (see release v0.6.1 attached files). The file will be stored under the examples/ directory. The following lines check to see if the file exists, and if not, it is downloaded. Therefore if you have a partial download or want a fresh copy of the file you will need to delete it manually before rerunning the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (not(os.path.isfile('yolo_detect.pt'))):\n",
    "    download_command = 'curl -L -o \"yolo_detect.pt\" \"https://bucket.ltsnet.net/torchsig/models/yolo_detect.pt\"'\n",
    "    os.system(download_command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "yolo_detect_model = YOLO(\"yolo_detect.pt\")\n",
    "summary(yolo_detect_model)\n",
    "\n",
    "yolo_detect_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data with model\n",
    "results = yolo_detect_model.predict(test_data, save=True, imgsz=512, conf=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare results\n",
    "results_dir = results[0].save_dir\n",
    "imgpath = os.path.join(results_dir, \"image\" + str(0) + \".jpg\")\n",
    "\n",
    "figure, ax = plt.subplots(1, 1, figsize=(9, 9))\n",
    "figure.suptitle(\"test_data\")\n",
    "\n",
    "# plot predicted bonding boxes\n",
    "img = cv2.imread(imgpath)\n",
    "ax.imshow(img)\n",
    "\n",
    "# plot actual bounding boxes\n",
    "full_width, full_height, _ = test_data.shape\n",
    "for i,l in enumerate(test_target['labels']):\n",
    "    norm_xstart, norm_ystart, norm_width, norm_height = test_target['boxes'][i]\n",
    "    rect = patches.Rectangle(\n",
    "        (norm_xstart*full_width, norm_ystart*full_height),\n",
    "        norm_width * full_width,\n",
    "        norm_height * full_height,\n",
    "        linewidth = 2,\n",
    "        edgecolor = \"b\",\n",
    "        facecolor = \"none\"\n",
    "    )\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "ax.legend([\"Actual\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLO Family Classification Model\n",
    "Below, we set up the dataset to transform the data into spectrograms, and labels as family name and bounding box information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target_transform = DescToBBoxFamilyDict(\n",
    "    class_family_dict = torchsig_signals.family_dict\n",
    ")\n",
    "family_list = target_transform.family_list\n",
    "\n",
    "test_detect_wideband = TorchSigWideband(\n",
    "    root,\n",
    "    train = False,\n",
    "    impaired = True,\n",
    "    transform = transform,\n",
    "    target_transform = target_transform\n",
    ")\n",
    "\n",
    "test_data, test_target = test_detect_wideband[0]\n",
    "print(f\"Spectrogram: {test_data.shape}\")\n",
    "print(f\"Family Class Indicies: {test_target['labels']}\")\n",
    "print(f\"Bounding Boxes (xcenter, ycenter, width, height):\\n {test_target['boxes']}\")\n",
    "\n",
    "full_width, full_height, _ = test_data.shape\n",
    "figure = plt.figure(figsize=(9, 9))\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "ax.imshow(test_data)\n",
    "for i,l in enumerate(test_target['labels']):\n",
    "    norm_xcenter, norm_ycenter, norm_width, norm_height = test_target['boxes'][i]\n",
    "    width = norm_width * full_width\n",
    "    height = norm_height * full_height\n",
    "    xcenter = norm_xcenter * full_width\n",
    "    ycenter = norm_ycenter * full_height\n",
    "    xstart = xcenter - (width / 2)\n",
    "    ystart = ycenter - (height / 2)\n",
    "    rect = patches.Rectangle(\n",
    "        (xstart, ystart),\n",
    "        width,\n",
    "        height,\n",
    "        linewidth = 2,\n",
    "        edgecolor = \"r\",\n",
    "        facecolor = \"none\"\n",
    "    )\n",
    "    ax.add_patch(rect)\n",
    "    ax.text(xcenter - 1, ycenter - 1, f\"{family_list[l]}\", backgroundcolor = 'gray', color = 'b', fontsize='small')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can download the model from our hosted servers on via the release package (see release v0.6.1 attached files). The file will be stored under the examples/ directory. The following lines check to see if the file exists, and if not, it is downloaded. Therefore if you have a partial download or want a fresh copy of the file you will need to delete it manually before rerunning the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (not(os.path.isfile('yolo_classify.pt'))):\n",
    "    download_command = 'curl -L -o \"yolo_classify.pt\" \"https://bucket.ltsnet.net/torchsig/models/yolo_classify.pt\"'\n",
    "    os.system(download_command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "yolo_detect_model = YOLO(\"yolo_classify.pt\")\n",
    "summary(yolo_detect_model)\n",
    "\n",
    "yolo_detect_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data with model\n",
    "results = yolo_detect_model.predict(test_data, save=True, imgsz=512, conf=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare results\n",
    "results_dir = results[0].save_dir\n",
    "imgpath = os.path.join(results_dir, \"image\" + str(0) + \".jpg\")\n",
    "\n",
    "figure, ax = plt.subplots(1, 1, figsize=(9, 9))\n",
    "figure.suptitle(\"test_data\")\n",
    "\n",
    "# plot predicted bonding boxes\n",
    "img = cv2.imread(imgpath)\n",
    "ax.imshow(img)\n",
    "\n",
    "full_width, full_height, _ = test_data.shape\n",
    "for i,l in enumerate(test_target['labels']):\n",
    "    norm_xcenter, norm_ycenter, norm_width, norm_height = test_target['boxes'][i]\n",
    "    width = norm_width * full_width\n",
    "    height = norm_height * full_height\n",
    "    xcenter = norm_xcenter * full_width\n",
    "    ycenter = norm_ycenter * full_height\n",
    "    xstart = xcenter - (width / 2)\n",
    "    ystart = ycenter - (height / 2)\n",
    "    rect = patches.Rectangle(\n",
    "        (xstart, ystart),\n",
    "        width,\n",
    "        height,\n",
    "        linewidth = 2,\n",
    "        edgecolor = \"r\",\n",
    "        facecolor = \"none\"\n",
    "    )\n",
    "    ax.add_patch(rect)\n",
    "    ax.text(xcenter - 1, ycenter - 1, f\"{family_list[l]}\", backgroundcolor = 'gray', color = 'b', fontsize='small')\n",
    "\n",
    "ax.legend([\"Actual\"], bbox_to_anchor = (0, 1.02, 1, 0.2), loc ='lower left', mode = 'expand')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
