{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TorchSig Iterable Dataset Example\n",
    "This notebook showcases the TorchSigIterableDataset dataset.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Variables\n",
    "num_signals_max = 5\n",
    "num_signals_min = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Metadata\n",
    "In order to create a TorchSigIterableDataset, you must define parameters for any signals included in the dataset. Different signal types may require different parameters, however most will require a sample_rate, bandwidth_min/bandwidth_max, and frequency_min/frequency_max.\n",
    "\n",
    "Here we are importing and using default parameters from TorchSig's defaults module. These default parameters are intended to allow users to quickly make reasonable looking signal data, and should correspond to the default parameters used in previous TorchSig versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsig.utils.defaults import TorchSigDefaults\n",
    "\n",
    "dataset_metadata = TorchSigDefaults().default_dataset_metadata\n",
    "dataset_metadata[\"num_signals_min\"] = num_signals_min\n",
    "dataset_metadata[\"num_signals_max\"] = num_signals_max\n",
    "print(dataset_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic Dataset\n",
    "To create a new dataset, simply instantiate a TorchSigIterableDataset object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsig.datasets.datasets import TorchSigIterableDataset\n",
    "from torchsig.transforms.transforms import Spectrogram\n",
    "\n",
    "# Without target_labels, returns Signal objects with rich metadata\n",
    "dataset = TorchSigIterableDataset(\n",
    "    metadata=dataset_metadata,\n",
    "    transforms=[Spectrogram(fft_size=dataset_metadata[\"fft_size\"])],\n",
    ")\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(dataset().data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting Dataset has several SignalGenerators attached to it by default, each responsible for creating data for different signal types.\n",
    "Right now these generators all share the same metadata, but they can also be modified individually as needed.\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for generator in dataset.signal_generators:\n",
    "    if \"ask\" in generator[\"class_name\"]:\n",
    "        generator[\"signal_duration_max\"] = 240000  # lower than default max duration\n",
    "        generator[\"anomalous\"] = True\n",
    "    else:\n",
    "        generator[\"anomalous\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[signal.anomalous for signal in dataset().component_signals]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we've shortened the maximum duration for the ASK signals in out dataset, so that they will on average be shorter than other signals.\n",
    "We've also set a new metadata variable 'anomalous', which is true for our ASK signals and False otherwise.\n",
    "This naturally sets us up for classification or anomaly detection models.\n",
    "If we wanted, we could add other, non-anomalous ASK signal generators with different parameters to make detecting them harder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsig.datasets.datasets import TorchSigIterableDataset\n",
    "\n",
    "# Without target_labels, returns Signal objects with rich metadata\n",
    "dataset = TorchSigIterableDataset(\n",
    "    metadata=dataset_metadata,\n",
    ")\n",
    "\n",
    "for i in range(5):\n",
    "    signal = next(dataset)\n",
    "\n",
    "    print(f\"IQ Data shape: {signal.data.shape}\")\n",
    "    print(f\"Component Signals: {len(signal.component_signals)}\")\n",
    "\n",
    "    # Access metadata from component signals\n",
    "    for j, comp_signal in enumerate(signal.component_signals):\n",
    "        print(f\"  Signal {j}: {comp_signal.class_name}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Domain Plot\n",
    "The default data returned from datasets are IQ samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# With target_labels, returns (data, metadata) tuples\n",
    "dataset_time_series = TorchSigIterableDataset(\n",
    "    metadata=dataset_metadata, target_labels=[\"class_index\"]\n",
    ")\n",
    "\n",
    "data, metadata = next(dataset_time_series)\n",
    "t = np.arange(0, len(data)) / dataset_time_series.sample_rate\n",
    "\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.plot(t, np.real(data), alpha=0.5, label=\"Real\")\n",
    "ax.plot(t, np.imag(data), alpha=0.5, label=\"Imag\")\n",
    "ax.set_xlim([t[0], t[-1]])\n",
    "ax.set_xlabel(\"Time (sec)\")\n",
    "ax.set_ylabel(\"Amplitude\")\n",
    "ax.set_title(\"Time Domain\")\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectrogram Plot\n",
    "Spectrograms can be generated by passing in the `Spectrogram()` transform into the metadata. For more detailed code and information on spectrogram plots, please see following section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsig.transforms.transforms import Spectrogram\n",
    "\n",
    "dataset_spectrogram = TorchSigIterableDataset(\n",
    "    metadata=dataset_metadata,\n",
    "    target_labels=[\"class_index\"],\n",
    "    transforms=[Spectrogram(fft_size=dataset_metadata[\"fft_size\"])],\n",
    ")\n",
    "\n",
    "data, metadata = next(dataset_spectrogram)\n",
    "\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.imshow(data, aspect=\"auto\", cmap=\"Wistia\", vmin=0)\n",
    "ax.set_xlabel(\"Time Axis\")\n",
    "ax.set_ylabel(\"Frequency Axis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Dataset to Disk\n",
    "In order to access previously generated examples, or save the finite dataset for later, use the `DatasetCreator`. Pass in the Dataset to be saved, where to write the dataset (root), and whether to overwrite any existing datasets. `num_samples` must be defined, otherwise the `DatasetCreator` will attempt to create an infinite dataset.\n",
    "\n",
    "**Note:** The new DatasetCreator API is simpler and uses HDF5 storage only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsig.utils.writer import DatasetCreator\n",
    "from torchsig.datasets.datasets import TorchSigIterableDataset\n",
    "from torchsig.utils.data_loading import WorkerSeedingDataLoader\n",
    "\n",
    "root = \"./datasets/create_dataset_example\"\n",
    "seed = 123456789"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't use target_labels to get Signal objects with rich metadata\n",
    "dataset = TorchSigIterableDataset(\n",
    "    metadata=dataset_metadata,\n",
    "    transforms=[Spectrogram(fft_size=dataset_metadata[\"fft_size\"])],\n",
    ")\n",
    "\n",
    "dataset_length = len(dataset.signal_generators) * 10\n",
    "\n",
    "dataloader = WorkerSeedingDataLoader(dataset, batch_size=11)\n",
    "dataloader.seed(seed)\n",
    "\n",
    "# New simplified DatasetCreator API\n",
    "dataset_creator = DatasetCreator(\n",
    "    dataset_length=dataset_length,\n",
    "    dataloader=dataloader,\n",
    "    root=root,\n",
    "    overwrite=True,\n",
    "    multithreading=False,\n",
    ")\n",
    "\n",
    "dataset_creator.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Dataset from Disk\n",
    "Assuming you wrote a dataset to disk, you can load it back in my instantiating a `StaticTorchSigDataset`.\n",
    "\n",
    "Warning: The following code assumes you have the code in the section **Writing Dataset to Disk**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsig.datasets.datasets import StaticTorchSigDataset\n",
    "\n",
    "static_dataset = StaticTorchSigDataset(\n",
    "    root=root, target_labels=[\"class_name\", \"start\", \"stop\", \"lower_freq\", \"upper_freq\"]\n",
    ")\n",
    "\n",
    "# can access any sample\n",
    "print(static_dataset[100][1])\n",
    "print(static_dataset[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the dataset written to disk is raw (aka no Transforms or Target Transforms were applied to it before writing to disk), then you can define whatever transforms and target transforms for use by the static dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_spectrogram(ax, start_time, stop_time, lower, upper):\n",
    "    start_time = float(start_time)\n",
    "    stop_time = float(stop_time)\n",
    "    lower = float(lower)\n",
    "    upper = float(upper)\n",
    "    ax.plot([start_time, start_time], [lower, upper], \"b\", alpha=0.5)\n",
    "    ax.plot([stop_time, stop_time], [lower, upper], \"b\", alpha=0.5)\n",
    "    ax.plot([start_time, stop_time], [lower, lower], \"b\", alpha=0.5)\n",
    "    ax.plot([start_time, stop_time], [upper, upper], \"b\", alpha=0.5)\n",
    "    textDisplay = str(classname)\n",
    "    ax.text(\n",
    "        start_time, lower, textDisplay, bbox=dict(facecolor=\"w\", alpha=0.5, linewidth=0)\n",
    "    )\n",
    "    ax.set_xlim([xmin, xmax])\n",
    "    ax.set_ylim([ymin, ymax])\n",
    "    ax.set_ylabel(\"Frequency (Hz)\")\n",
    "    ax.set_xlabel(f\"Time ({xunits})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsig.datasets.datasets import StaticTorchSigDataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sample_rate = dataset.sample_rate\n",
    "noise_power_db = dataset.noise_power_db\n",
    "num_iq_samples_dataset = dataset.num_iq_samples_dataset\n",
    "\n",
    "num_show = 4\n",
    "num_cols = 2\n",
    "num_rows = num_show // num_cols\n",
    "\n",
    "fig = plt.figure(figsize=(18, 12))\n",
    "fig.tight_layout()\n",
    "\n",
    "max_time = num_iq_samples_dataset / sample_rate\n",
    "\n",
    "ns_time = 1e-9\n",
    "us_time = 1e-6\n",
    "ms_time = 1e-3\n",
    "s_time = 1\n",
    "\n",
    "if max_time < ns_time:\n",
    "    max_time /= ns_time\n",
    "    xunits = \"ns\"\n",
    "elif max_time < us_time:\n",
    "    max_time /= us_time\n",
    "    xunits = \"us\"\n",
    "elif max_time < ms_time:\n",
    "    max_time /= ms_time\n",
    "    xunits = \"ms\"\n",
    "else:\n",
    "    max_time /= s_time\n",
    "    xunits = \"s\"\n",
    "\n",
    "xmin = 0 * max_time\n",
    "xmax = 1 * max_time\n",
    "\n",
    "ymin = -sample_rate / 2\n",
    "ymax = sample_rate / 2\n",
    "\n",
    "for i in range(num_show):\n",
    "\n",
    "    data, targets = static_dataset[i]\n",
    "    ax = fig.add_subplot(num_rows, num_cols, i + 1)\n",
    "    pos = ax.imshow(\n",
    "        data,\n",
    "        extent=[xmin, xmax, ymin, ymax],\n",
    "        aspect=\"auto\",\n",
    "        cmap=\"Wistia\",\n",
    "        vmin=noise_power_db,\n",
    "    )\n",
    "    fig.colorbar(pos, ax=ax, label=\"SNR\")\n",
    "    for i in range(len(targets[0])):\n",
    "        classname = targets[0][i]\n",
    "        start = targets[1][i]\n",
    "        stop = targets[2][i]\n",
    "        lower = targets[3][1 + i]\n",
    "        upper = targets[4][1 + i]\n",
    "\n",
    "        # convert normalized time into real-world time\n",
    "        start_time = float(start) * max_time\n",
    "        stop_time = float(stop) * max_time\n",
    "\n",
    "        update_spectrogram(ax, start_time, stop_time, lower, upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Statistics\n",
    "\n",
    "Below are some plots and statistics about the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default, `TorchSigIterableDataset` uses all the signals available.\n",
    "from torchsig.signals.signal_lists import TORCHSIG_NUM_SIGNALS, TORCHSIG_NUM_FAMILIES\n",
    "\n",
    "print(f\"Number of signal classes in torchsig: {TORCHSIG_NUM_SIGNALS}\")\n",
    "print(f\"Number of signal families in torchsig: {TORCHSIG_NUM_FAMILIES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "class_list = dataset.class_names\n",
    "class_counter = {class_name: 0 for class_name in class_list}\n",
    "num_signals_per_sample = []\n",
    "\n",
    "for sample in tqdm(static_dataset, desc=\"Calculating Dataset Stats\"):\n",
    "    data, targets = sample\n",
    "    for i in range(len(targets[0])):\n",
    "        classname = targets[0][i]\n",
    "        num_signals_per_sample.append(len(targets[0]))\n",
    "        class_counter[classname] += 1\n",
    "\n",
    "class_counts = list(class_counter.values())\n",
    "class_names = list(class_counter.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Distribution Pie Chart\n",
    "# by default, the class distribution is None aka uniform\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.pie(class_counts, labels=class_names)\n",
    "plt.title(\"Class Distribution Pie Chart\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Distribution Bar Chart\n",
    "plt.figure(figsize=(18, 4))\n",
    "plt.bar(class_names, class_counts)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Class Distribution Bar Chart\")\n",
    "plt.xlabel(\"Modulation Class Name\")\n",
    "plt.ylabel(\"Counts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of signals per sample Distribution\n",
    "import numpy as np\n",
    "\n",
    "# Default number of signals per sample is 3\n",
    "print(f\"Min num signals Setting: {dataset.num_signals_min}\")\n",
    "print(f\"Max num signals Setting: {dataset.num_signals_max}\")\n",
    "\n",
    "total = sum(num_signals_per_sample)\n",
    "avg = np.mean(np.asarray(num_signals_per_sample))\n",
    "\n",
    "plt.figure(figsize=(11, 8))\n",
    "plt.hist(\n",
    "    x=num_signals_per_sample, bins=np.arange(max(num_signals_per_sample) + 1) + 0.5\n",
    ")\n",
    "plt.xticks(np.arange(0, max(num_signals_per_sample) + 1, 1).tolist())\n",
    "plt.title(\n",
    "    f\"Distribution of Number of Signals Per Sample\\nTotal Number: {total}, Average: {avg}\"\n",
    ")\n",
    "plt.xlabel(\"Number of Signal Bins\")\n",
    "plt.ylabel(\"Counts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Impairments to datasets\n",
    "To add realism to synthetic datasets, we've created some sets of transforms that simulate real world signal impairments on the data. These can be found in `transforms/impairments.py`, and come in multiple impairment 'levels' which determine how much the signal is being impaired. More on impairments can be found in the `examples/transforms/impairments notebook`.\n",
    "\n",
    "In the example below, we are applying level 1 impairments to a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsig.transforms.impairments import Impairments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impairments = Impairments(level=1)\n",
    "burst_impairments = impairments.signal_transforms\n",
    "whole_signal_impairments = impairments.dataset_transforms\n",
    "\n",
    "burst_impairments, whole_signal_impairments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_impaired = TorchSigIterableDataset(\n",
    "    metadata=dataset_metadata,\n",
    "    transforms=[\n",
    "        whole_signal_impairments,\n",
    "        Spectrogram(fft_size=dataset_metadata[\"fft_size\"]),\n",
    "    ],\n",
    "    component_transforms=[burst_impairments],\n",
    "    target_labels=[],\n",
    ")\n",
    "\n",
    "dataset_unimpaired = TorchSigIterableDataset(\n",
    "    metadata=dataset_metadata,\n",
    "    transforms=[Spectrogram(fft_size=dataset_metadata[\"fft_size\"])],\n",
    "    component_transforms=[],\n",
    "    target_labels=[],\n",
    ")\n",
    "\n",
    "dataset_impaired.seed(seed)\n",
    "dataset_unimpaired.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unimpaired_data = next(dataset_unimpaired)\n",
    "impaired_data = next(dataset_impaired)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.imshow(unimpaired_data, cmap=\"Wistia\", vmin=0)\n",
    "ax.set_xlabel(\"Time Axis\")\n",
    "ax.set_ylabel(\"Frequency Axis\")\n",
    "ax.set_title(\"Un-Impaired Data\")\n",
    "\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "ax2.imshow(impaired_data, cmap=\"Wistia\", vmin=0)\n",
    "ax2.set_xlabel(\"Time Axis\")\n",
    "ax2.set_ylabel(\"Frequency Axis\")\n",
    "ax2.set_title(\"Impaired Data\")"
   ]
  }
 ],
 "kernelspec": {
  "display_name": "Python 3",
  "language": "python",
  "name": "python3"
 },
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}