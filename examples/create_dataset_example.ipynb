{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TorchSig Iterable Dataset Example\n",
    "This notebook showcases the TorchSigIterableDataset dataset.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Variables\n",
    "\n",
    "num_iq_samples_dataset = 4096 # 64^2\n",
    "fft_size = 64\n",
    "num_signals_max = 5\n",
    "num_signals_min = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Metadata\n",
    "In order to create a TorchSigIterableDataset, you must define parameters in DatasetMetadata. This can be done either in code or inside a YAML file. Below we show how to do both. Look at `create_dataset_example.yaml` for a sample YAML file.\n",
    "\n",
    "There are three required parameters: \n",
    "1. `num_iq_samples_dataset` -> how much IQ data per sample\n",
    "2. `fft_size` -> Size of FFT (number of bins) to be used in spectrogram.\n",
    "3. `num_signals_max` -> maximum number of signals per sample.\n",
    "\n",
    "Additionally, there are several optional parameters that can be overridden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Instantiate DatasetMetadata object\n",
    "from torchsig.datasets.dataset_metadata import DatasetMetadata\n",
    "\n",
    "dataset_metadata_1 = DatasetMetadata(\n",
    "    num_iq_samples_dataset = num_iq_samples_dataset,\n",
    "    fft_size = fft_size,\n",
    "    num_signals_max = num_signals_max,\n",
    "    num_signals_min = num_signals_min,\n",
    ")\n",
    "print(dataset_metadata_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Instantiate as a dictionary object\n",
    "\n",
    "dataset_metadata_2 = dict(\n",
    "    num_iq_samples_dataset = num_iq_samples_dataset,\n",
    "    fft_size = fft_size,\n",
    "    num_signals_max = num_signals_max,\n",
    "    num_signals_min = num_signals_min,\n",
    "    impairment_level = 0  # Added required parameter\n",
    ")\n",
    "print(dataset_metadata_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic Dataset\n",
    "To create a new dataset, simply instantiate a TorchSigIterableDataset object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsig.datasets.dataset_metadata import DatasetMetadata\n",
    "from torchsig.datasets.datasets import TorchSigIterableDataset\n",
    "\n",
    "dataset_infinite_metadata = DatasetMetadata(\n",
    "    num_iq_samples_dataset = num_iq_samples_dataset,\n",
    "    fft_size = fft_size,\n",
    "    num_signals_max = num_signals_max,\n",
    "    num_signals_min = num_signals_min\n",
    ")\n",
    "\n",
    "# Without target_labels, returns Signal objects with rich metadata\n",
    "dataset_infinite = TorchSigIterableDataset(\n",
    "    dataset_metadata = dataset_infinite_metadata\n",
    ")\n",
    "\n",
    "for i in range(5):\n",
    "    signal = next(dataset_infinite)\n",
    "    \n",
    "    print(f\"IQ Data shape: {signal.data.shape}\")\n",
    "    print(f\"Component Signals: {len(signal.component_signals)}\")\n",
    "    \n",
    "    # Access metadata from component signals\n",
    "    for j, comp_signal in enumerate(signal.component_signals):\n",
    "        print(f\"  Signal {j}: {comp_signal.metadata.class_name}, SNR: {comp_signal.metadata.snr_db:.1f}dB\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Domain Plot\n",
    "The default data returned from datasets are IQ samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "dataset_finite_time_series_metadata = DatasetMetadata(\n",
    "    num_iq_samples_dataset = num_iq_samples_dataset,\n",
    "    fft_size = fft_size,\n",
    "    num_signals_max = num_signals_max,\n",
    "    num_signals_min = num_signals_min\n",
    ")\n",
    "\n",
    "# With target_labels, returns (data, metadata) tuples\n",
    "dataset_finite_time_series = TorchSigIterableDataset(\n",
    "    dataset_metadata = dataset_finite_time_series_metadata,\n",
    "    target_labels=[\"class_index\"]\n",
    ")\n",
    "\n",
    "data, metadata = next(dataset_finite_time_series)\n",
    "t = np.arange(0,len(data))/dataset_finite_time_series_metadata.sample_rate\n",
    "\n",
    "fig = plt.figure(figsize=(12,4))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.plot(t,np.real(data),alpha=0.5,label='Real')\n",
    "ax.plot(t,np.imag(data),alpha=0.5,label='Imag')\n",
    "ax.set_xlim([t[0], t[-1]])\n",
    "ax.set_xlabel('Time (sec)')\n",
    "ax.set_ylabel('Amplitude')\n",
    "ax.set_title('Time Domain')\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectrogram Plot\n",
    "Spectrograms can be generated by passing in the `Spectrogram()` transform into the metadata. For more detailed code and information on spectrogram plots, please see following section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsig.transforms.transforms import Spectrogram\n",
    "\n",
    "dataset_finite_spectrogram_metadata = DatasetMetadata(\n",
    "    num_iq_samples_dataset = num_iq_samples_dataset,\n",
    "    fft_size = fft_size,\n",
    "    num_signals_max = num_signals_max,\n",
    "    num_signals_min = num_signals_min\n",
    ")\n",
    "\n",
    "dataset_finite_spectrogram = TorchSigIterableDataset(\n",
    "    dataset_metadata = dataset_finite_spectrogram_metadata,\n",
    "    target_labels=[\"class_index\"],\n",
    "    transforms = [Spectrogram(fft_size=fft_size)]\n",
    ")\n",
    "\n",
    "data, metadata = next(dataset_finite_spectrogram)\n",
    "\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.imshow(data,aspect='auto',cmap='Wistia',vmin=0)\n",
    "ax.set_xlabel('Time Axis')\n",
    "ax.set_ylabel('Frequency Axis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Dataset to Disk\n",
    "In order to access previously generated examples, or save the finite dataset for later, use the `DatasetCreator`. Pass in the Dataset to be saved, where to write the dataset (root), and whether to overwrite any existing datasets. `num_samples` must be defined, otherwise the `DatasetCreator` will attempt to create an infinite dataset.\n",
    "\n",
    "**Note:** The new DatasetCreator API is simpler and uses HDF5 storage only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsig.datasets.dataset_metadata import DatasetMetadata\n",
    "from torchsig.utils.writer import DatasetCreator, default_collate_fn\n",
    "from torchsig.signals.signal_lists import TorchSigSignalLists\n",
    "from torchsig.datasets.datasets import TorchSigIterableDataset\n",
    "from torchsig.utils.data_loading import WorkerSeedingDataLoader\n",
    "from torchsig.transforms.transforms import Spectrogram\n",
    "\n",
    "root = \"./datasets/create_dataset_example\"\n",
    "class_list = TorchSigSignalLists.all_signals\n",
    "dataset_length = len(class_list) * 10\n",
    "seed = 123456789\n",
    "\n",
    "dataset_finite_metadata = DatasetMetadata(\n",
    "    num_iq_samples_dataset = num_iq_samples_dataset,\n",
    "    fft_size = fft_size,\n",
    "    num_signals_max = num_signals_max,\n",
    "    num_signals_min = num_signals_min,\n",
    ")\n",
    "\n",
    "# Don't use target_labels to get Signal objects with rich metadata\n",
    "dataset = TorchSigIterableDataset(\n",
    "    dataset_metadata = dataset_finite_metadata,\n",
    "    transforms = [Spectrogram(fft_size = fft_size)],\n",
    "    target_labels = [\"class_name\", \"start\", \"stop\", \"lower_freq\", \"upper_freq\", \"snr_db\"],\n",
    ")\n",
    "\n",
    "dataloader = WorkerSeedingDataLoader(dataset, batch_size=11, num_workers=4, collate_fn=default_collate_fn)\n",
    "dataloader.seed(seed)\n",
    "\n",
    "# New simplified DatasetCreator API\n",
    "dataset_creator = DatasetCreator(\n",
    "    dataset_length=dataset_length,\n",
    "    dataloader = dataloader,\n",
    "    root = root,\n",
    "    overwrite = True,\n",
    "    multithreading=False\n",
    ")\n",
    "\n",
    "dataset_creator.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Dataset from Disk\n",
    "Assuming you wrote a dataset to disk, you can load it back in my instantiating a `StaticTorchSigDataset`.\n",
    "\n",
    "Warning: The following code assumes you have the code in the section **Writing Dataset to Disk**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsig.datasets.datasets import StaticTorchSigDataset\n",
    "\n",
    "static_dataset = StaticTorchSigDataset(\n",
    "    root = root,\n",
    "    target_labels=dataset.target_labels\n",
    ")\n",
    "\n",
    "# can access any sample\n",
    "print(static_dataset[0][1])\n",
    "print(static_dataset[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the dataset written to disk is raw (aka no Transforms or Target Transforms were applied to it before writing to disk), then you can define whatever transforms and target transforms for use by the static dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_dataset[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_spectrogram ( ax, start_time, stop_time, lower, upper):\n",
    "    start_time = float(start_time)\n",
    "    stop_time = float(stop_time)\n",
    "    lower = float(lower)\n",
    "    upper = float(upper)\n",
    "    ax.plot([start_time,start_time],[lower,upper],'b',alpha=0.5)\n",
    "    ax.plot([stop_time, stop_time],[lower,upper],'b',alpha=0.5)\n",
    "    ax.plot([start_time,stop_time],[lower,lower],'b',alpha=0.5)\n",
    "    ax.plot([start_time,stop_time],[upper,upper],'b',alpha=0.5)\n",
    "    textDisplay = str(classname) + ', SNR = ' + str(snr) + ' dB'\n",
    "    ax.text(start_time,lower,textDisplay, bbox=dict(facecolor='w', alpha=0.5, linewidth=0))\n",
    "    ax.set_xlim([xmin,xmax])\n",
    "    ax.set_ylim([ymin,ymax])\n",
    "    ax.set_ylabel(\"Frequency (Hz)\")\n",
    "    ax.set_xlabel(f\"Time ({xunits})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from torchsig.datasets.datasets import StaticTorchSigDataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "static_dataset = StaticTorchSigDataset(\n",
    "    root = root,\n",
    "    target_labels=dataset.target_labels\n",
    ")\n",
    "sample_rate = dataset.dataset_metadata.sample_rate\n",
    "noise_power_db = dataset.dataset_metadata.noise_power_db\n",
    "\n",
    "num_show = 4\n",
    "num_cols = 2\n",
    "num_rows = num_show // num_cols\n",
    "\n",
    "fig = plt.figure(figsize=(18,12))\n",
    "fig.tight_layout()\n",
    "\n",
    "max_time = num_iq_samples_dataset / sample_rate\n",
    "\n",
    "ns_time = 1e-9\n",
    "us_time = 1e-6\n",
    "ms_time = 1e-3\n",
    "s_time = 1\n",
    "\n",
    "if (max_time < ns_time):\n",
    "    max_time /= ns_time\n",
    "    xunits = 'ns'\n",
    "elif (max_time < us_time):\n",
    "    max_time /= us_time\n",
    "    xunits = 'us'\n",
    "elif (max_time < ms_time):\n",
    "    max_time /= ms_time\n",
    "    xunits = 'ms'\n",
    "else:\n",
    "    max_time /= s_time\n",
    "    xunits = 's'\n",
    "\n",
    "xmin = 0 * max_time\n",
    "xmax = 1 * max_time\n",
    "\n",
    "ymin = -sample_rate / 2\n",
    "ymax = sample_rate / 2\n",
    "\n",
    "for i in range(num_show):\n",
    "\n",
    "    data, targets = static_dataset[i]\n",
    "    print(targets)\n",
    "    ax = fig.add_subplot(num_rows,num_cols,i + 1)\n",
    "    pos = ax.imshow(data,extent=[xmin,xmax,ymin,ymax],aspect='auto',cmap='Wistia',vmin=noise_power_db)\n",
    "    fig.colorbar(pos, ax=ax, label='SNR')\n",
    "\n",
    "    for t in targets:\n",
    "        classname, start, stop, lower, upper, snr = t\n",
    "\n",
    "        # convert normalized time into real-world time\n",
    "        start_time = float(start) * max_time\n",
    "        stop_time = float(stop) * max_time\n",
    "\n",
    "        update_spectrogram( ax, start_time, stop_time, lower, upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Statistics\n",
    "\n",
    "Below are some plots and statistics about the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "class_list = dataset.dataset_metadata.class_list\n",
    "class_counter = {class_name: 0 for class_name in class_list}\n",
    "snr_list = []\n",
    "num_signals_per_sample = []\n",
    "\n",
    "for sample in tqdm(static_dataset, desc = \"Calculating Dataset Stats\"):\n",
    "    data, targets = sample\n",
    "\n",
    "    if (isinstance(targets,tuple)):\n",
    "        num_signals_per_sample.append(1)\n",
    "        t = targets\n",
    "        classname, start, stop, lower, upper, snr = t\n",
    "        class_counter[classname] += 1\n",
    "        snr_list.append(snr)\n",
    "    elif (isinstance(targets,list)):\n",
    "        num_signals_per_sample.append(len(targets))\n",
    "        for t in targets:\n",
    "            classname, start, stop, lower, upper, snr = t\n",
    "            class_counter[classname] += 1\n",
    "            snr_list.append(snr)\n",
    "\n",
    "    \n",
    "\n",
    "class_counts = list(class_counter.values())\n",
    "class_names = list(class_counter.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Distribution Pie Chart\n",
    "# by default, the class distribution is None aka uniform\n",
    "print(f\"Class Distribution Setting: {dataset.dataset_metadata.class_distribution}\")\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.pie(class_counts, labels = class_names)\n",
    "plt.title(\"Class Distribution Pie Chart\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Distribution Bar Chart\n",
    "plt.figure(figsize=(18, 4))\n",
    "plt.bar(class_names, class_counts)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Class Distribution Bar Chart\")\n",
    "plt.xlabel(\"Modulation Class Name\")\n",
    "plt.ylabel(\"Counts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of signals per sample Distribution\n",
    "import numpy as np\n",
    "# Default number of signals per sample is 3\n",
    "print(f\"Min num signals Setting: {dataset.dataset_metadata.num_signals_min}\")\n",
    "print(f\"Max num signals Setting: {dataset.dataset_metadata.num_signals_max}\")\n",
    "\n",
    "total = sum(num_signals_per_sample)\n",
    "avg = np.mean(np.asarray(num_signals_per_sample))\n",
    "\n",
    "plt.figure(figsize=(11,8))\n",
    "plt.hist(x=num_signals_per_sample, bins=np.arange(max(num_signals_per_sample) + 1) + 0.5)\n",
    "plt.xticks(np.arange(0, max(num_signals_per_sample) + 1, 1).tolist())\n",
    "plt.title(f\"Distribution of Number of Signals Per Sample\\nTotal Number: {total}, Average: {avg}\")\n",
    "plt.xlabel(\"Number of Signal Bins\")\n",
    "plt.ylabel(\"Counts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SNR Distributions\n",
    "# Default min = 0 db and max = 50 db\n",
    "print(f\"Min SNR Setting: {dataset.dataset_metadata.snr_db_min}\")\n",
    "print(f\"Max SNR Setting: {dataset.dataset_metadata.snr_db_max}\")\n",
    "plt.figure(figsize=(11, 4))\n",
    "plt.hist(x=snr_list, bins=100)\n",
    "plt.title(\"SNR Distribution\")\n",
    "plt.xlabel(\"SNR Bins (dB)\")\n",
    "plt.ylabel(\"Counts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Impairments to datasets\n",
    "To add realism to synthetic datasets, we've created some sets of transforms that simulate real world signal impairments on the data. These can be found in `transforms/impairments.py`, and come in multiple impairment 'levels' which determine how much the signal is being impaired. More on impairments can be found in the `examples/transforms/impairments notebook`.\n",
    "\n",
    "In the example below, we are applying level 1 impairments to a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsig.transforms.impairments import Impairments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impairments = Impairments(level=1)\n",
    "burst_impairments = impairments.signal_transforms\n",
    "whole_signal_impairments = impairments.dataset_transforms\n",
    "\n",
    "burst_impairments, whole_signal_impairments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_impaired = TorchSigIterableDataset(\n",
    "    dataset_metadata=dataset_finite_metadata, \n",
    "    transforms=[whole_signal_impairments, Spectrogram(fft_size=fft_size)], \n",
    "    component_transforms=[burst_impairments], \n",
    "    target_labels=[])\n",
    "\n",
    "dataset_unimpaired = TorchSigIterableDataset(\n",
    "    dataset_metadata=dataset_finite_metadata, \n",
    "    transforms=[Spectrogram(fft_size=fft_size)], \n",
    "    component_transforms=[], \n",
    "    target_labels=[])\n",
    "\n",
    "dataset_impaired.seed(seed)\n",
    "dataset_unimpaired.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=(12,12))\n",
    "ax = fig.add_subplot(1,2,1)\n",
    "ax.imshow(next(dataset_unimpaired),cmap='Wistia',vmin=0)\n",
    "ax.set_xlabel('Time Axis')\n",
    "ax.set_ylabel('Frequency Axis')\n",
    "ax.set_title('Un-Impaired Data')\n",
    "\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "ax2.imshow(next(dataset_impaired),cmap='Wistia',vmin=0)\n",
    "ax2.set_xlabel('Time Axis')\n",
    "ax2.set_ylabel('Frequency Axis')\n",
    "ax2.set_title('Impaired Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
