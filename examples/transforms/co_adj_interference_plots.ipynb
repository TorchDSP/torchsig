{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71d06404-6c20-40be-a8b7-9788df6ec9d5",
   "metadata": {},
   "source": [
    "# Co-Channel and Adjacent Channel Interference Transforms\n",
    "This notebook illustrates the two functional transforms that model co-channel interference and adjacent channel interference. The co-channel interference transform models interference as a configurable noise-like signal. The adjacent channel interference transform adds a similarly structured adjacent channel signal by modifying a copy of the original signal. Using an input high SNR tone signal, this notebook plots the frequency response within the entire sampled bandwidth for both transforms, highlighting the in-band and out-of-band responses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412f7598-c06e-42aa-bc26-1f26abfb4043",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsig.signals.signal_types import Signal\n",
    "from torchsig.datasets.dataset_metadata import DatasetMetadata\n",
    "from torchsig.signals.builders.tone import ToneSignalBuilder\n",
    "import torchsig.transforms.functional as F\n",
    "from torchsig.utils.dsp import (\n",
    "    TorchSigComplexDataType,\n",
    "    low_pass\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "import scipy.signal as sp\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a10a02b-2027-4d4b-8da6-218fb24eedfe",
   "metadata": {},
   "source": [
    "Function for generating input tone signals in the test interference scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3c840a-db6f-40ca-934b-434f2c3477d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tone_signal(num_iq_samples: int = 10, scale: float = 1.0) -> Signal:\n",
    "    \"\"\"Generate a scaled, high SNR baseband tone Signal.\n",
    "\n",
    "        Args:\n",
    "        num_iq_samples (int, optional): Length of sample. Defaults to 10.\n",
    "        scale (int, optional): scale normalized signal data. Defaults to 1.0.\n",
    "\n",
    "        Returns:\n",
    "            signal: generated Signal.\n",
    "\n",
    "    \"\"\"\n",
    "    sample_rate = 10e6\n",
    "    md = DatasetMetadata(\n",
    "        num_iq_samples_dataset = num_iq_samples,\n",
    "        fft_size = 4,\n",
    "        impairment_level = 0,\n",
    "        sample_rate = sample_rate,\n",
    "        num_signals_max = 1,\n",
    "        num_signals_min = 1,\n",
    "        num_signals_distribution = [1.0],\n",
    "        snr_db_min = 100.0,\n",
    "        snr_db_max = 100.0,\n",
    "        signal_duration_min = 1.00*num_iq_samples/sample_rate,\n",
    "        signal_duration_max = 1.00*num_iq_samples/sample_rate,\n",
    "        signal_bandwidth_min = sample_rate/4,\n",
    "        signal_bandwidth_max = sample_rate/4,\n",
    "        signal_center_freq_min = 0.0,\n",
    "        signal_center_freq_max = 0.0,         \n",
    "        class_list = ['tone'],\n",
    "        class_distribution = [1.0],\n",
    "        seed = 42\n",
    "    )\n",
    "\n",
    "    builder = ToneSignalBuilder(\n",
    "        dataset_metadata = md, \n",
    "        class_name = 'tone',\n",
    "        seed = 42\n",
    "    )\n",
    "    signal = builder.build()\n",
    "\n",
    "    # normalize, then scale data   \n",
    "    signal.data = F.normalize(\n",
    "        data = signal.data,\n",
    "        norm_order = 2,\n",
    "        flatten = False\n",
    "    )\n",
    "    signal.data = np.multiply(signal.data, scale).astype(TorchSigComplexDataType)\n",
    "\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f233e0a-c3eb-42b3-a204-8a17d093fb72",
   "metadata": {},
   "source": [
    "Visualize the default filter design for the in-band and out-of-band channel frequency response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d0c8e1-9ffa-4482-b5f1-10cf2b047ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 0.125\n",
    "transition_bandwidth = 0.125\n",
    "sample_rate = 1.0\n",
    "lpf_weights = low_pass(cutoff=cutoff,transition_bandwidth=transition_bandwidth,sample_rate=sample_rate) # design lowpass filter\n",
    "\n",
    "# plots\n",
    "plt.style.use('dark_background')\n",
    "fig, ax = plt.subplots()\n",
    "spectrum, freqs, _ = ax.magnitude_spectrum(lpf_weights, Fs=sample_rate, scale='linear', sides='twosided', color='white');\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('Frequency');\n",
    "ax.set_ylabel('Magnitude [log]');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb61579-4f9f-4f17-ab11-17a836a2d623",
   "metadata": {},
   "source": [
    "Generate and frequency shift a new constant tone signal with calibrated power. Apply the co-channel interference transform to produce an output signal, then estimate the power and frequency of the original input component within the total aggregate signal. Verify the tone frequency is undisturbed by the transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335f5658-388f-410a-9213-7f15bc87ece5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=42)\n",
    "\n",
    "N = 16384\n",
    "sample_rate = 2.0\n",
    "power = 0.01\n",
    "tone_freq = -0.04\n",
    "filter_weights = low_pass(0.1, 0.15, 2.0)\n",
    "tone_bb_data = generate_tone_signal(num_iq_samples = N, scale = 1.0).data \n",
    "tone_data = tone_bb_data * np.exp(2j * np.pi * tone_freq * np.arange(N) / sample_rate) * np.sqrt(N) # f0 = 0.2, total power = 1.0 W\n",
    "est_power = np.sum(np.abs(tone_data)**2)/len(tone_data)\n",
    "print(\"tone_data power: \", est_power) # verify 1.0 W\n",
    "\n",
    "data_co = F.cochannel_interference(\n",
    "    data = tone_data,\n",
    "    power = power,\n",
    "    filter_weights = filter_weights,\n",
    "    color = 'white',\n",
    "    continuous = True,\n",
    ")\n",
    "est_power = np.sum(np.abs(data_co)**2)/len(data_co)\n",
    "print(\"data_co power: \", est_power) # verify 1.0 W + 1.0 W = 2.0 W (uncorrelated)\n",
    "\n",
    "# verify peaks\n",
    "D = np.abs(np.fft.fft(data_co, norm='ortho'))\n",
    "freqs = np.fft.fftfreq(N) * sample_rate\n",
    "peaks, _ = sp.find_peaks(D, height=1.0, distance=N/2)\n",
    "max_peak_ind = np.argmax(D[peaks])\n",
    "print(\"peak freqs: \", freqs[peaks])\n",
    "\n",
    "# plots\n",
    "plt.style.use('dark_background')\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "spectrum, freqs, _ = ax.magnitude_spectrum(tone_data, Fs=sample_rate, scale='linear', sides='twosided', color='white');\n",
    "spectrum, freqs, _ = ax.magnitude_spectrum(data_co, Fs=sample_rate, scale='linear', sides='twosided', color='red');\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('Frequency');\n",
    "ax.set_ylabel('Magnitude');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b52b827-f5af-4b0b-8bd1-7ad961ae5352",
   "metadata": {},
   "source": [
    "Generate and frequency shift a new constant tone signal with calibrated power. Apply the adjacent channel interference transform to produce an output signal, then estimate the power and frequency of the original input component within the total aggregate signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e566ac-ed5d-47a0-b90e-0260d12ba9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=42)\n",
    "\n",
    "tone_data = tone_bb_data * np.exp(2j * np.pi * -0.11 * np.arange(N) / sample_rate) * np.sqrt(N) # f0 = -0.11, total power = 1.0 W\n",
    "sample_rate = 2.4\n",
    "\n",
    "data_adj1 = F.adjacent_channel_interference(\n",
    "    data = tone_data,\n",
    "    power = 2.0,\n",
    "    sample_rate = sample_rate,\n",
    "    center_frequency = -0.05,\n",
    "    filter_weights = low_pass(0.25, 0.25, 2.4),\n",
    "    phase_sigma = 0.1,\n",
    "    time_sigma = 10.0,\n",
    "    rng = rng\n",
    ")\n",
    "est_power = np.sum(np.abs(data_adj1)**2)/len(data_adj1)\n",
    "print(\"output power: \", 10**(est_power/10)) # verify 1.0 W + 1.0 W = 2.0 W (uncorrelated)\n",
    "\n",
    "# plots\n",
    "plt.style.use('dark_background')\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "spectrum, freqs, _ = ax.magnitude_spectrum(tone_data, Fs=sample_rate, scale='linear', sides='twosided', color='white');\n",
    "spectrum, freqs, _ = ax.magnitude_spectrum(data_adj1, Fs=sample_rate, scale='linear', sides='twosided', color='red');\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('Frequency');\n",
    "ax.set_ylabel('Magnitude');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a9870a-9e39-4601-8052-c0f9537a7aca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
