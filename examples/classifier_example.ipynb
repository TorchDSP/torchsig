{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f906ef93",
   "metadata": {},
   "source": [
    "# Training a Model on IQ Samples for Classification\n",
    "\n",
    "This notebook demonstrates how to train a PyTorch model on IQ Samples for modulation recognition.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20666ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "from torchsig.signals.signal_lists import TorchSigSignalLists\n",
    "from torchsig.transforms.transforms import ComplexTo2D\n",
    "import os\n",
    "\n",
    "from torch import Tensor\n",
    "\n",
    "root = \"./datasets/classifier_example\"\n",
    "os.makedirs(root, exist_ok=True)\n",
    "os.makedirs(root + \"/train\", exist_ok=True)\n",
    "os.makedirs(root + \"/val\", exist_ok=True)\n",
    "os.makedirs(root + \"/test\", exist_ok=True)\n",
    "fft_size = 256\n",
    "num_iq_samples_dataset = fft_size ** 2\n",
    "class_list = TorchSigSignalLists.all_signals\n",
    "family_list = TorchSigSignalLists.family_list\n",
    "num_classes = len(class_list)\n",
    "num_samples_train = len(class_list) * 10 # roughly 10 samples per class\n",
    "num_samples_val = len(class_list) * 2\n",
    "impairment_level = 0\n",
    "seed = 123456789\n",
    " # IQ-based mod-rec only operates on 1 signal\n",
    "num_signals_max = 1\n",
    "num_signals_min = 1\n",
    "\n",
    "# ComplexTo2D turns a IQ array of complex values into a 2D array, with one channel for the real component, while the other is for the imaginary component\n",
    "transforms = [ComplexTo2D()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1c3e43",
   "metadata": {},
   "source": [
    "## Create the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442b71b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsig.datasets.dataset_metadata import DatasetMetadata\n",
    "from torchsig.datasets.datasets import TorchSigIterableDataset, StaticTorchSigDataset\n",
    "from torchsig.utils.data_loading import WorkerSeedingDataLoader\n",
    "from torchsig.utils.writer import DatasetCreator\n",
    "\n",
    "dataset_metadata = DatasetMetadata(\n",
    "    num_iq_samples_dataset = num_iq_samples_dataset,\n",
    "    fft_size = fft_size,\n",
    "    class_list = class_list,\n",
    "    num_signals_max = num_signals_max,\n",
    "    num_signals_min = num_signals_min,\n",
    ")\n",
    "\n",
    "train_dataset = TorchSigIterableDataset(dataset_metadata, transforms=transforms, target_labels=None)\n",
    "val_dataset = TorchSigIterableDataset(dataset_metadata, transforms=transforms, target_labels=None)\n",
    "\n",
    "train_dataloader = WorkerSeedingDataLoader(train_dataset, batch_size=4, collate_fn = lambda x: x)\n",
    "val_dataloader = WorkerSeedingDataLoader(val_dataset, collate_fn = lambda x: x)\n",
    "\n",
    "#print(f\"Data shape: {data.shape}\")\n",
    "#print(f\"Targets: {targets}\")\n",
    "# next(train_dataset)\n",
    "\n",
    "dc = DatasetCreator(\n",
    "    dataloader=train_dataloader,\n",
    "    root = f\"{root}/train\",\n",
    "    overwrite=True,\n",
    "    dataset_length=num_samples_train\n",
    ")\n",
    "dc.create()\n",
    "\n",
    "\n",
    "dc = DatasetCreator(\n",
    "    dataloader=val_dataloader,\n",
    "    root = f\"{root}/val\",\n",
    "    overwrite=True,\n",
    "    dataset_length=num_samples_val\n",
    ")\n",
    "dc.create()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbefb65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = StaticTorchSigDataset(\n",
    "    root = f\"{root}/train\",\n",
    "    target_labels=[\"class_index\"]\n",
    ")\n",
    "val_dataset = StaticTorchSigDataset(\n",
    "    root = f\"{root}/val\",\n",
    "    target_labels=[\"class_index\"]\n",
    ")\n",
    "\n",
    "train_dataloader = WorkerSeedingDataLoader(train_dataset, batch_size=4)\n",
    "val_dataloader = WorkerSeedingDataLoader(val_dataset)\n",
    "\n",
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc103624-047a-4628-a439-d9c259fdcf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c54d248",
   "metadata": {},
   "source": [
    "## Create the Model\n",
    "\n",
    "We use our own XCIT model code and utils, but this can be replaced with your own model arhcitecture in PyTorch, Ultralytics, timm, ect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61268f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install timm pytorch_lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a5b0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "\n",
    "class ConvDownSampler(nn.Module):\n",
    "    def __init__(self, in_chans: int, embed_dim: int, ds_rate: int = 16):\n",
    "        super().__init__()\n",
    "        # Use a single convolutional layer with appropriate stride\n",
    "        self.conv = nn.Conv1d(\n",
    "            in_channels=in_chans,\n",
    "            out_channels=embed_dim,\n",
    "            kernel_size=ds_rate * 2,\n",
    "            stride=ds_rate,\n",
    "            padding=ds_rate // 2,\n",
    "        )\n",
    "        self.bn = nn.BatchNorm1d(embed_dim)\n",
    "        self.act = nn.GELU()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.act(x)\n",
    "        return x\n",
    "\n",
    "class Chunker(nn.Module):\n",
    "    def __init__(self, in_chans: int, embed_dim: int, ds_rate: int = 16):\n",
    "        super().__init__()\n",
    "        self.ds_rate = ds_rate\n",
    "        self.embed = nn.Conv1d(in_chans, embed_dim, kernel_size=7, padding=3)\n",
    "        self.pool = nn.AvgPool1d(kernel_size=ds_rate, stride=ds_rate)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.embed(x)  # Shape: [B, embed_dim, L]\n",
    "        x = self.pool(x)   # Downsample by averaging\n",
    "        return x\n",
    "\n",
    "class XCiT1d(nn.Module):\n",
    "    \"\"\"A 1D implementation of the XCiT architecture.\n",
    "\n",
    "    Args:\n",
    "        input_channels (int): Number of 1D input channels.\n",
    "        n_features (int): Number of output features/classes.\n",
    "        xcit_version (str): Version of XCiT model to use (e.g., 'nano_12_p16_224').\n",
    "        drop_path_rate (float): Drop path rate for training.\n",
    "        drop_rate (float): Dropout rate for training.\n",
    "        ds_method (str): Downsampling method ('downsample' or 'chunk').\n",
    "        ds_rate (int): Downsampling rate (e.g., 2 for downsampling by a factor of 2).\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_channels: int,\n",
    "        n_features: int,\n",
    "        xcit_version: str = \"nano_12_p16_224\",\n",
    "        drop_path_rate: float = 0.0,\n",
    "        drop_rate: float = 0.3,\n",
    "        ds_method: str = \"downsample\",\n",
    "        ds_rate: int = 2\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # Ensure the model name is correct\n",
    "        model_name = f\"xcit_{xcit_version}\" if not xcit_version.startswith(\"xcit_\") else xcit_version\n",
    "\n",
    "        # Create the backbone model\n",
    "        self.backbone = timm.create_model(\n",
    "            model_name,\n",
    "            pretrained=False,\n",
    "            num_classes=n_features,\n",
    "            in_chans=input_channels,\n",
    "            drop_path_rate=drop_path_rate,\n",
    "            drop_rate=drop_rate,\n",
    "        )\n",
    "\n",
    "        # Number of features from the backbone\n",
    "        W = self.backbone.num_features\n",
    "\n",
    "        # Include the grouper Conv1d layer\n",
    "        self.grouper = nn.Conv1d(W, n_features, kernel_size=1)\n",
    "\n",
    "        # Replace the patch embedding with a 1D version\n",
    "        if ds_method == \"downsample\":\n",
    "            self.backbone.patch_embed = ConvDownSampler(input_channels, W, ds_rate)\n",
    "        elif ds_method == \"chunk\":\n",
    "            self.backbone.patch_embed = Chunker(input_channels, W, ds_rate)\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"{ds_method} is not a supported downsampling method; currently 'downsample' and 'chunk' are supported\"\n",
    "            )\n",
    "\n",
    "        # Replace the classifier head with an identity layer (since we use self.grouper)\n",
    "        self.backbone.head = nn.Identity()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        mdl = self.backbone\n",
    "        B = x.shape[0]\n",
    "\n",
    "        # Patch embedding\n",
    "        x = self.backbone.patch_embed(x)  # Shape: [B, C, L]\n",
    "\n",
    "        # Define H and W for 1D data\n",
    "        Hp, Wp = x.shape[-1], 1  # Height is sequence length, Width is 1\n",
    "\n",
    "        # Obtain positional encoding\n",
    "        pos_encoding = mdl.pos_embed(B, Hp, Wp).reshape(B, -1, Hp).permute(0, 2, 1)\n",
    "\n",
    "        # Add positional encoding\n",
    "        x = x.transpose(1, 2) + pos_encoding  # Shape: [B, Hp, C]\n",
    "\n",
    "        # Apply transformer blocks\n",
    "        for blk in mdl.blocks:\n",
    "            x = blk(x, Hp, Wp)\n",
    "\n",
    "        # Classification token\n",
    "        cls_tokens = mdl.cls_token.expand(B, -1, -1)  # Shape: [B, 1, C]\n",
    "        x = torch.cat((cls_tokens, x), dim=1)  # Shape: [B, Hp+1, C]\n",
    "\n",
    "        # Apply class attention blocks\n",
    "        for blk in mdl.cls_attn_blocks:\n",
    "            x = blk(x)\n",
    "\n",
    "        # Layer normalization\n",
    "        x = mdl.norm(x)  # Shape: [B, Hp+1, C]\n",
    "\n",
    "        # Apply the grouper Conv1d to the classification token\n",
    "        # Extract the classification token (first token)\n",
    "        cls_token = x[:, 0, :]  # Shape: [B, C]\n",
    "\n",
    "        # Reshape for Conv1d: [B, C, 1]\n",
    "        cls_token = cls_token.unsqueeze(-1)  # Shape: [B, C, 1]\n",
    "\n",
    "        # Apply the grouper Conv1d\n",
    "        x = self.grouper(cls_token).squeeze(-1)  # Shape: [B, n_features]\n",
    "\n",
    "        # If x is 1D (batch size 1), ensure it has the correct shape\n",
    "        if x.dim() == 1:\n",
    "            x = x.unsqueeze(0)\n",
    "\n",
    "        return x\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2.0, alpha=None, reduction='mean', ignore_index=-100):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha  # Can be a scalar or a tensor of shape [num_classes]\n",
    "        self.reduction = reduction\n",
    "        self.ignore_index = ignore_index\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        log_probs = F.log_softmax(inputs, dim=1)\n",
    "        ce_loss = F.nll_loss(log_probs, targets, weight=self.alpha, reduction='none', ignore_index=self.ignore_index)\n",
    "        probs = torch.exp(-ce_loss)\n",
    "        focal_loss = ((1 - probs) ** self.gamma) * ce_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n",
    "    \n",
    "class XCiTClassifier(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_channels: int,\n",
    "        num_classes: int,\n",
    "        xcit_version: str = 'tiny_12_p16_224',\n",
    "        ds_method: str = 'downsample',\n",
    "        ds_rate: int = 16,\n",
    "        learning_rate: float = 1e-3,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.model = XCiT1d(\n",
    "            input_channels=input_channels,\n",
    "            n_features=num_classes,\n",
    "            xcit_version=xcit_version,\n",
    "            ds_method=ds_method,\n",
    "            ds_rate=ds_rate,\n",
    "        )\n",
    "        self.learning_rate = learning_rate\n",
    "        # self.criterion = nn.CrossEntropyLoss()\n",
    "        self.criterion = FocalLoss(gamma=2.0, alpha=None, reduction='mean')\n",
    "\n",
    "        # For logging\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.val_accuracies = []\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx) -> torch.Tensor:\n",
    "        x, y = batch\n",
    "        x = x.float() \n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = (preds == y).float().mean()\n",
    "        self.log('train_loss', loss, on_step=False, on_epoch=True)\n",
    "        self.log('train_acc', acc, on_step=False, on_epoch=True)\n",
    "\n",
    "        self.train_losses.append(loss.item())\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx) -> None:\n",
    "        x, y = batch\n",
    "        x = x.float() \n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = (preds == y).float().mean()\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "        self.val_losses.append(loss.item())\n",
    "        self.val_accuracies.append(acc.item())\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=self.trainer.max_epochs)\n",
    "        return [optimizer], [lr_scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f597b09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9a89ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "model = XCiTClassifier(\n",
    "    input_channels=2,\n",
    "    num_classes=num_classes,\n",
    ")\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1826b1b8",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "\n",
    "Using the [Pytorch Lightning Trainer](https://lightning.ai/docs/pytorch/stable/common/trainer.html), we can train our model for modulation recognition on IQ dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe3c33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    limit_train_batches=10,\n",
    "    limit_val_batches=5,\n",
    "    max_epochs = num_epochs,\n",
    "    accelerator =  'gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    devices = 1\n",
    ")\n",
    "\n",
    "trainer.fit(model, train_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec35214",
   "metadata": {},
   "source": [
    "## Test the Model\n",
    "\n",
    "Now that we've trained the model, we can test its predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89805f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsig.datasets.datasets import TorchSigIterableDataset, StaticTorchSigDataset\n",
    "from torchsig.utils.writer import DatasetCreator, default_collate_fn\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "model.eval()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "test_dataset_size = 10\n",
    "\n",
    "\n",
    "dataset_metadata_test = DatasetMetadata(\n",
    "    num_iq_samples_dataset = num_iq_samples_dataset,\n",
    "    fft_size = fft_size,\n",
    "    class_list = class_list,\n",
    "    num_samples=test_dataset_size,\n",
    "    seed = 123456788, # different than train\n",
    "    num_signals_max = num_signals_max,\n",
    "    num_signals_min = num_signals_min\n",
    ")\n",
    "# print(dataset_metadata_test)\n",
    "dataset = TorchSigIterableDataset(dataset_metadata_test, transforms=transforms, target_labels=None,)#[\"class_index\"])\n",
    "\n",
    "dataloader = WorkerSeedingDataLoader(dataset, num_workers=1, batch_size=1, collate_fn = lambda x: x)#default_collate_fn)\n",
    "\n",
    "dc = DatasetCreator(\n",
    "    dataloader=dataloader,\n",
    "    root = f\"{root}/test\",\n",
    "    overwrite=True,\n",
    "    dataset_length=100\n",
    ")\n",
    "dc.create()\n",
    "\n",
    "test_dataset = StaticTorchSigDataset(\n",
    "    root = f\"{root}/test\",\n",
    "    target_labels=[\"class_index\"]\n",
    ")\n",
    "\n",
    "data, class_index = test_dataset[0]\n",
    "print(f\"Data shape: {data.shape}\")\n",
    "print(f\"Targets: {class_index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ca179d-9000-4daa-af1f-2f6edadd4fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "data, class_index = test_dataset[0]\n",
    "# move to model to the same device as the data\n",
    "model.to(device)\n",
    "# turn the model into evaluation mode\n",
    "model.eval()\n",
    "with torch.no_grad(): # do not update model weights\n",
    "    # convert to tensor and add a batch dimension\n",
    "    data = torch.from_numpy(data).to(device).unsqueeze(dim=0)\n",
    "    # have model predict data\n",
    "    # returns a probability the data is each signal class\n",
    "    pred = model(data)\n",
    "    # print(pred) # if you want to see the list of probabilities\n",
    "\n",
    "    # choose the class with highest confidence\n",
    "    predicted_class = torch.argmax(pred).cpu().numpy()\n",
    "    print(f\"Predicted = {predicted_class} ({class_list[predicted_class]})\")\n",
    "    print(f\"Actual = {class_index} ({class_list[class_index]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e5593d-a1cb-44bc-b96d-234f189f6c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can do this over the whole test dataset to check to accurarcy of our model\n",
    "predictions = []\n",
    "true_classes = []\n",
    "num_correct = 0\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "for sample in test_dataset:\n",
    "    data, actual_class = sample\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        data = torch.from_numpy(data).to(device).unsqueeze(dim=0)\n",
    "        pred = model(data)\n",
    "        predicted_class = torch.argmax(pred).cpu().numpy()\n",
    "        predictions.append(predicted_class)\n",
    "        true_classes.append(actual_class)\n",
    "        if predicted_class == actual_class:\n",
    "            num_correct += 1\n",
    "\n",
    "# try increasing num_epochs or train dataset size to increase accuracy\n",
    "print(f\"Correct Predictions = {num_correct}\")\n",
    "print(f\"Percent Correct = {num_correct / len(test_dataset)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e006863",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4385a0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also plot a confusion matrix using Sklearn's confusion matrix tool\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "matrix = confusion_matrix(true_classes, predictions, labels=list(range(len(family_list))))\n",
    "disp = ConfusionMatrixDisplay(matrix, display_labels=family_list)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaef25d-e62d-4deb-a197-c3724e0ff47e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "py:percent,ipynb"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
