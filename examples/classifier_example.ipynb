{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f906ef93",
   "metadata": {},
   "source": [
    "# Training a Model on IQ Samples for Classification\n",
    "\n",
    "This notebook demonstrates how to train a PyTorch model on IQ Samples for modulation recognition.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20666ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "from torchsig.signals.signal_lists import TorchSigSignalLists\n",
    "from torchsig.transforms.transforms import ComplexTo2D\n",
    "import os\n",
    "\n",
    "from torch import Tensor\n",
    "\n",
    "root = \"./datasets/classifier_example\"\n",
    "os.makedirs(root, exist_ok=True)\n",
    "os.makedirs(root + \"/train\", exist_ok=True)\n",
    "os.makedirs(root + \"/val\", exist_ok=True)\n",
    "os.makedirs(root + \"/test\", exist_ok=True)\n",
    "fft_size = 256\n",
    "num_iq_samples_dataset = fft_size ** 2\n",
    "class_list = TorchSigSignalLists.all_signals\n",
    "family_list = TorchSigSignalLists.family_list\n",
    "num_classes = len(class_list)\n",
    "num_samples_train = len(class_list) * 10 # roughly 10 samples per class\n",
    "num_samples_val = len(class_list) * 2\n",
    "impairment_level = 0\n",
    "seed = 123456789\n",
    " # IQ-based mod-rec only operates on 1 signal\n",
    "num_signals_max = 1\n",
    "num_signals_min = 1\n",
    "\n",
    "# ComplexTo2D turns a IQ array of complex values into a 2D array, with one channel for the real component, while the other is for the imaginary component\n",
    "transforms = [ComplexTo2D()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1c3e43",
   "metadata": {},
   "source": [
    "## Create the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442b71b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsig.datasets.dataset_metadata import DatasetMetadata\n",
    "from torchsig.datasets.datasets import TorchSigIterableDataset, StaticTorchSigDataset\n",
    "from torchsig.utils.data_loading import WorkerSeedingDataLoader\n",
    "from torchsig.utils.writer import DatasetCreator\n",
    "\n",
    "dataset_metadata = DatasetMetadata(\n",
    "    num_iq_samples_dataset = num_iq_samples_dataset,\n",
    "    fft_size = fft_size,\n",
    "    class_list = class_list,\n",
    "    num_signals_max = num_signals_max,\n",
    "    num_signals_min = num_signals_min,\n",
    ")\n",
    "\n",
    "train_dataset = TorchSigIterableDataset(dataset_metadata, transforms=transforms, target_labels=None)\n",
    "val_dataset = TorchSigIterableDataset(dataset_metadata, transforms=transforms, target_labels=None)\n",
    "\n",
    "train_dataloader = WorkerSeedingDataLoader(train_dataset, batch_size=4, collate_fn = lambda x: x)\n",
    "val_dataloader = WorkerSeedingDataLoader(val_dataset, collate_fn = lambda x: x)\n",
    "\n",
    "#print(f\"Data shape: {data.shape}\")\n",
    "#print(f\"Targets: {targets}\")\n",
    "# next(train_dataset)\n",
    "\n",
    "dc = DatasetCreator(\n",
    "    dataloader=train_dataloader,\n",
    "    root = f\"{root}/train\",\n",
    "    overwrite=True,\n",
    "    dataset_length=num_samples_train\n",
    ")\n",
    "dc.create()\n",
    "\n",
    "\n",
    "dc = DatasetCreator(\n",
    "    dataloader=val_dataloader,\n",
    "    root = f\"{root}/val\",\n",
    "    overwrite=True,\n",
    "    dataset_length=num_samples_val\n",
    ")\n",
    "dc.create()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbefb65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = StaticTorchSigDataset(\n",
    "    root = f\"{root}/train\",\n",
    "    target_labels=[\"class_index\"]\n",
    ")\n",
    "val_dataset = StaticTorchSigDataset(\n",
    "    root = f\"{root}/val\",\n",
    "    target_labels=[\"class_index\"]\n",
    ")\n",
    "\n",
    "train_dataloader = WorkerSeedingDataLoader(train_dataset, batch_size=4)\n",
    "val_dataloader = WorkerSeedingDataLoader(val_dataset)\n",
    "\n",
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc103624-047a-4628-a439-d9c259fdcf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c54d248",
   "metadata": {},
   "source": [
    "## Create the Model\n",
    "\n",
    "We use our own XCIT model code and utils, but this can be replaced with your own model arhcitecture in PyTorch, Ultralytics, timm, ect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9a89ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsig.models import XCiTClassifier\n",
    "from torchinfo import summary\n",
    "\n",
    "model = XCiTClassifier(\n",
    "    input_channels=2,\n",
    "    num_classes=num_classes,\n",
    ")\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1826b1b8",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "\n",
    "Using the [Pytorch Lightning Trainer](https://lightning.ai/docs/pytorch/stable/common/trainer.html), we can train our model for modulation recognition on IQ dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe3c33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    limit_train_batches=10,\n",
    "    limit_val_batches=5,\n",
    "    max_epochs = num_epochs,\n",
    "    accelerator =  'gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    devices = 1\n",
    ")\n",
    "\n",
    "trainer.fit(model, train_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec35214",
   "metadata": {},
   "source": [
    "## Test the Model\n",
    "\n",
    "Now that we've trained the model, we can test its predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89805f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsig.datasets.datasets import TorchSigIterableDataset, StaticTorchSigDataset\n",
    "from torchsig.utils.writer import DatasetCreator, default_collate_fn\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "model.eval()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "test_dataset_size = 10\n",
    "\n",
    "\n",
    "dataset_metadata_test = DatasetMetadata(\n",
    "    num_iq_samples_dataset = num_iq_samples_dataset,\n",
    "    fft_size = fft_size,\n",
    "    class_list = class_list,\n",
    "    num_samples=test_dataset_size,\n",
    "    seed = 123456788, # different than train\n",
    "    num_signals_max = num_signals_max,\n",
    "    num_signals_min = num_signals_min\n",
    ")\n",
    "# print(dataset_metadata_test)\n",
    "dataset = TorchSigIterableDataset(dataset_metadata_test, transforms=transforms, target_labels=None,)#[\"class_index\"])\n",
    "\n",
    "dataloader = WorkerSeedingDataLoader(dataset, num_workers=1, batch_size=1, collate_fn = lambda x: x)#default_collate_fn)\n",
    "\n",
    "dc = DatasetCreator(\n",
    "    dataloader=dataloader,\n",
    "    root = f\"{root}/test\",\n",
    "    overwrite=True,\n",
    "    dataset_length=100\n",
    ")\n",
    "dc.create()\n",
    "\n",
    "test_dataset = StaticTorchSigDataset(\n",
    "    root = f\"{root}/test\",\n",
    "    target_labels=[\"class_index\"]\n",
    ")\n",
    "\n",
    "data, class_index = test_dataset[0]\n",
    "print(f\"Data shape: {data.shape}\")\n",
    "print(f\"Targets: {class_index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ca179d-9000-4daa-af1f-2f6edadd4fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "data, class_index = test_dataset[0]\n",
    "# move to model to the same device as the data\n",
    "model.to(device)\n",
    "# turn the model into evaluation mode\n",
    "model.eval()\n",
    "with torch.no_grad(): # do not update model weights\n",
    "    # convert to tensor and add a batch dimension\n",
    "    data = torch.from_numpy(data).to(device).unsqueeze(dim=0)\n",
    "    # have model predict data\n",
    "    # returns a probability the data is each signal class\n",
    "    pred = model(data)\n",
    "    # print(pred) # if you want to see the list of probabilities\n",
    "\n",
    "    # choose the class with highest confidence\n",
    "    predicted_class = torch.argmax(pred).cpu().numpy()\n",
    "    print(f\"Predicted = {predicted_class} ({class_list[predicted_class]})\")\n",
    "    print(f\"Actual = {class_index} ({class_list[class_index]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e5593d-a1cb-44bc-b96d-234f189f6c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can do this over the whole test dataset to check to accurarcy of our model\n",
    "predictions = []\n",
    "true_classes = []\n",
    "num_correct = 0\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "for sample in test_dataset:\n",
    "    data, actual_class = sample\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        data = torch.from_numpy(data).to(device).unsqueeze(dim=0)\n",
    "        pred = model(data)\n",
    "        predicted_class = torch.argmax(pred).cpu().numpy()\n",
    "        predictions.append(predicted_class)\n",
    "        true_classes.append(actual_class)\n",
    "        if predicted_class == actual_class:\n",
    "            num_correct += 1\n",
    "\n",
    "# try increasing num_epochs or train dataset size to increase accuracy\n",
    "print(f\"Correct Predictions = {num_correct}\")\n",
    "print(f\"Percent Correct = {num_correct / len(test_dataset)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4385a0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also plot a confusion matrix using Sklearn's confusion matrix tool\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "matrix = confusion_matrix(true_classes, predictions, labels=list(range(len(family_list))))\n",
    "disp = ConfusionMatrixDisplay(matrix, display_labels=family_list)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaef25d-e62d-4deb-a197-c3724e0ff47e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "py:percent,ipynb"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
