{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04b0d326",
   "metadata": {},
   "source": [
    "# Importing External Data into TorchSig: Bring Your Own Data (BYOD) SigMF\n",
    "This notebook shows how to import externally created data into TorchSig using a basic SigMF example file format.\n",
    "\n",
    "---\n",
    "\n",
    "The main code that the user must write is a subclass of `ExternalFileHandler`, which will be passed into a `ExternalTorchSigDataset`. The `ExternalFileHandler` class must implement 3 methods:\n",
    "| Method | Arguments | Return | Description |\n",
    "| ------ | --------- | ------ | ----------- |\n",
    "| `size` | N/A | int | Number of data samples, dataset size |\n",
    "| `load_dataset_metadata` | N/A | `ExternalDatasetMetadata` | Dataset information, see `datasets/dataset_metadata.py` for more information. |\n",
    "| `load` | idx: int | (np.ndarray, List[Any]) | Load sample `idx`, which includes data as np.ndarray and taregts as a list. |\n",
    "\n",
    "If you want to apply TorchSig's transforms and impairments to your data, note that `load` must return targets that are in `List[Dict]` format, where each dict describes a signal. Additionally, the dict must have the fields required by each transform, e.g., `FamilyName` target transform requires the signal to have `class_name` in its metadata. It is up to the user to figure out what metadata is needed for what transforms/target transforms they wish to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06acb66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime as dt\n",
    "import os\n",
    "from sigmf import SigMFFile, sigmffile\n",
    "from typing import Tuple, Dict, List, Any\n",
    "\n",
    "# TorchSig\n",
    "from torchsig.datasets.datasets import ExternalTorchSigDataset\n",
    "from torchsig.datasets.dataset_metadata import ExternalDatasetMetadata\n",
    "from torchsig.utils.file_handlers import ExternalFileHandler\n",
    "from torchsig.transforms.transforms import ComplexTo2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db11e075-256b-4847-add2-f1fbb512f2f0",
   "metadata": {},
   "source": [
    "## Step 1: External Data Generation Process: create synthetic data outside TorchSig workflow\n",
    "\n",
    "If your data already exists somewhere, you can skip to Step 2.\n",
    "\n",
    "We will write a sample dataset using Numpy's npy for signal data and and csv for metadata. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e6981f-7ac9-4635-8849-d5df6d7281f5",
   "metadata": {},
   "source": [
    "### External Synthetic Data and Metadata Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5a6f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration parameters\n",
    "root = 'datasets/byod_sigmf_example'      # data file top-level folder \n",
    "seed = 1234567890                         # rng seed\n",
    "\n",
    "os.makedirs(root, exist_ok=True)          # directory for files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fabf89",
   "metadata": {},
   "source": [
    "Below, we generate some signals (outside of TorchSig)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be33642-0514-4eae-8552-b7ddc8eb4183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "fs = 1_000_000                              # 1 MHz sample-rate (fixed rate)\n",
    "num_samples = 1024                          # samples per data (fixed size)\n",
    "dataset_size = 8                            # dataset size\n",
    "labels = ['BPSK', 'QPSK', 'Noise']          # three arbitrary metadata class labels (strings)\n",
    "modcod = [0, 1, 2]                          # three arbitrary metadata integers\n",
    "rng = np.random.default_rng(seed)           # random number generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4801f20-ff14-4265-94b6-78cef460d9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create user's external data: non-TorchSig synthetic data along with metadata\n",
    "\n",
    "signals_array = np.empty((dataset_size, num_samples), dtype=np.complex64)  # data\n",
    "meta_rows = [] # metadata                                           \n",
    "\n",
    "t = np.arange(num_samples) / fs  # timesteps\n",
    "\n",
    "# create synthetic dataset elements\n",
    "for idx in range(dataset_size):\n",
    "    label = rng.choice(labels)\n",
    "    mc = rng.choice(modcod)\n",
    "    \n",
    "    if label == \"BPSK\":\n",
    "        bits   = rng.integers(0, 2, num_samples)\n",
    "        sig    = (2*bits-1) + 0j\n",
    "    elif label == \"QPSK\":\n",
    "        bits   = rng.integers(0, 4, num_samples)\n",
    "        table  = {0:1+1j, 1:1-1j, 2:-1+1j, 3:-1-1j}\n",
    "        sig    = np.vectorize(table.get)(bits)\n",
    "    else:  # white noise\n",
    "        sig = (rng.normal(size=num_samples) + 1j*rng.normal(size=num_samples)) * 0.1\n",
    "\n",
    "    sig /= np.sqrt((np.abs(sig)**2).mean()) # normalize power for consistency\n",
    "    signals_array[idx] = sig.astype(np.complex64)\n",
    "    \n",
    "    # add to metadata\n",
    "    meta_rows.append(\n",
    "        dict(\n",
    "            index=idx, \n",
    "            label=label, \n",
    "            modcod=mc, \n",
    "            sample_rate=fs\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcaa12b-ecf4-4827-a247-cde946383324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write and verify basic example SigMF data and metadata files\n",
    "\n",
    "# SigMF stores samples sequentially, so we flatten the 2D\n",
    "# data row-wise to simulate a wideband datastream\n",
    "data_flattened = signals_array.flatten()\n",
    "\n",
    "# write the aggregate binary data file (.sigmf-data)\n",
    "data_filename = f'{root}/byod.sigmf-data'\n",
    "meta_filename = f'{root}/byod.sigmf-meta'\n",
    "data_flattened.tofile(data_filename)\n",
    "\n",
    "# create the metadata file (.sigmf-meta)\n",
    "meta = SigMFFile(\n",
    "    data_file=data_filename,                # Link to the data file\n",
    "    global_info={\n",
    "        SigMFFile.DATATYPE_KEY: 'cf32_le',  # Complex float32, little-endian\n",
    "        SigMFFile.SAMPLE_RATE_KEY: fs,      # Sample rate in Hz\n",
    "        SigMFFile.VERSION_KEY: '1.2.0',     # SigMF version\n",
    "        SigMFFile.AUTHOR_KEY: 'https://github.com/torchdsp/torchsig',\n",
    "        SigMFFile.DESCRIPTION_KEY: 'BYOD SigMF Example',\n",
    "        'core:num_channels': 1,             # Specify number of channels\n",
    "        'core:signal_length': num_samples,  # Number of I/Q samples in each signal\n",
    "        'core:signal_count': dataset_size   # Number of signals in data\n",
    "    }\n",
    ")\n",
    "\n",
    "# add capture information (required)\n",
    "meta.add_capture(0, metadata={\n",
    "    SigMFFile.FREQUENCY_KEY: 2_450_000_000,  # specify some arbitrary center frequency in Hz\n",
    "    SigMFFile.DATETIME_KEY: dt.datetime.utcnow().isoformat() + 'Z',\n",
    "})\n",
    "\n",
    "# save signal-specific metadata as annotations\n",
    "for i, m in enumerate(meta_rows):\n",
    "    generated_metadata = meta_rows[i]   # metadata for signal i\n",
    "    sample_start_idx = i * num_samples  # signal's I/Q start index in data file\n",
    "    meta.add_annotation(\n",
    "        sample_start_idx,\n",
    "        num_samples,\n",
    "        metadata = {\n",
    "            SigMFFile.LABEL_KEY: generated_metadata['label'],\n",
    "            SigMFFile.COMMENT_KEY: str(generated_metadata['modcod'])\n",
    "        }\n",
    "    )\n",
    "            \n",
    "# Validate and write the metadata file (.sigmf-meta)\n",
    "assert not meta.validate()               # sigmf check\n",
    "meta.tofile(f'{root}/byod.sigmf-meta') \n",
    "\n",
    "print(f\"SigMF files created:\")\n",
    "print(f\"  Data: {data_filename}\")\n",
    "print(f\"  Metadata: {meta_filename}\")\n",
    "\n",
    "# check files\n",
    "loaded_sigmf = sigmffile.fromfile(meta_filename)\n",
    "M = loaded_sigmf.get_global_field('core:signal_count')\n",
    "N = loaded_sigmf.get_global_field('core:signal_length')\n",
    "loaded_data = loaded_sigmf.read_samples()   # read all samples\n",
    "print(f\"Meta data size verified: {loaded_data.shape[0] == (M*N)}\")\n",
    "print(f\"Data verified: {np.allclose(data_flattened, loaded_data)}\")\n",
    "print(f\"Synthetic signals + metadata staged in {root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8869659d-2933-4d72-8de8-318aeae9db3b",
   "metadata": {},
   "source": [
    "## Step 2. ExternalFileHandler\n",
    "\n",
    "To have your data on disk interface with TorchSig, you must write your own `ExternalFileHandler` so TorchSig knows how to handle your data. Make sure to call `super()`.\n",
    "\n",
    "Note that the metadata must at least have:\n",
    "- `class_name`\n",
    "- `class_index`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77031156",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BYODExampleFileHandler(ExternalFileHandler):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str\n",
    "    ):\n",
    "        super().__init__(root=root)\n",
    "        \n",
    "        self.data_filename = f'{root}/byod.sigmf-data'\n",
    "        self.meta_filename = f'{root}/byod.sigmf-meta'\n",
    "        self.data_size = None\n",
    "        self.class_list = ['BPSK', 'QPSK', 'Noise'] \n",
    "\n",
    "\n",
    "    def size(self) -> int:\n",
    "        if self.data_size is None:\n",
    "            try:\n",
    "                loaded_sigmf = sigmffile.fromfile(self.meta_filename)\n",
    "                self.data_size = loaded_sigmf.get_global_field('core:signal_count')\n",
    "            except:\n",
    "                raise ValueError(f\"Error loading {self.meta_filename}\")\n",
    "                \n",
    "        return self.data_size\n",
    "\n",
    "    \n",
    "    def load_dataset_metadata(self) -> ExternalDatasetMetadata:\n",
    "        try:\n",
    "            loaded_sigmf = sigmffile.fromfile(self.meta_filename)\n",
    "            num_iq_samples_dataset = loaded_sigmf.get_global_field('core:signal_length')\n",
    "            sample_rate = loaded_sigmf.get_global_field(SigMFFile.SAMPLE_RATE_KEY)\n",
    "            class_list = self.class_list\n",
    "            num_samples = loaded_sigmf.get_global_field('core:signal_count')\n",
    "\n",
    "            \n",
    "            return ExternalDatasetMetadata(\n",
    "                # minimum fields required for ExternalDatasetMetadata\n",
    "                num_iq_samples_dataset = num_iq_samples_dataset,\n",
    "                sample_rate = sample_rate,\n",
    "                class_list = class_list,\n",
    "                num_samples = num_samples\n",
    "            )           \n",
    "        except:\n",
    "            raise ValueError(f\"Error loading {self.meta_filename}\")\n",
    "\n",
    "\n",
    "    def load(self, idx: int) -> Tuple[np.ndarray, List[Dict]]:\n",
    "        try:\n",
    "            sigmf_file = sigmffile.fromfile(self.meta_filename)   # creates data memory map access\n",
    "            sample_rate = sigmf_file.get_global_field(SigMFFile.SAMPLE_RATE_KEY)\n",
    "            annotations = sigmf_file.get_annotations()            # load metadata annotations\n",
    "            \n",
    "            sigmf_signal_meta = annotations[idx]\n",
    "            meta = {}\n",
    "            meta[\"index\"] = idx\n",
    "            meta[\"sample_rate\"] = sample_rate\n",
    "            meta[\"class_name\"] = sigmf_signal_meta[\"core:label\"]\n",
    "            meta[\"class_index\"] = self.class_list.index(meta[\"class_name\"])\n",
    "            meta[\"modcod\"] = sigmf_signal_meta[\"core:comment\"]\n",
    "            \n",
    "            start_idx = sigmf_signal_meta['core:sample_start']\n",
    "            stop_idx = start_idx + sigmf_signal_meta['core:sample_count'] - 1\n",
    "            data = sigmf_file[start_idx:stop_idx]\n",
    "\n",
    "            return data, [meta]\n",
    "        \n",
    "        except:\n",
    "            raise ValueError(f\"Error loading {self.meta_filename}\")            \n",
    "\n",
    "\n",
    "test = BYODExampleFileHandler(root)\n",
    "print(f'Size: {test.size()}')\n",
    "print(f'Metadata: {test.load_dataset_metadata()}')\n",
    "print(f'Load element 2: {test.load(2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd0e530-9864-475b-8ef1-eee3df5751e6",
   "metadata": {},
   "source": [
    "## Step 3: ExternalTorchSigDataset\n",
    "\n",
    "Use `ExternalTorchSigDataset` and custom file handler (above) to load in data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b885c0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'datasets/byod_sigmf_example'    \n",
    "\n",
    "custom_dataset = ExternalTorchSigDataset(\n",
    "    file_handler = BYODExampleFileHandler(root),\n",
    "    target_labels = None\n",
    ")\n",
    "print(f\"Dataset size: {len(custom_dataset)}\")\n",
    "\n",
    "sample = custom_dataset[4]\n",
    "print(f\"data: {sample.data}\")\n",
    "print(f\"metadata: {[meta.to_dict() for meta in sample.get_full_metadata()]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe6d733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can apply transforms and metadata transforms\n",
    "root = 'datasets/byod_sigmf_example'    \n",
    "\n",
    "custom_dataset_2 = ExternalTorchSigDataset(\n",
    "    file_handler = BYODExampleFileHandler(root),\n",
    "    transforms = [ComplexTo2D()],\n",
    "    target_labels = [\"modcod\"]\n",
    ")\n",
    "print(f\"Dataset size: {len(custom_dataset_2)}\")\n",
    "\n",
    "data, metadata = custom_dataset_2[4]\n",
    "print(f\"data: {data.shape}\")\n",
    "print(f\"metadata: {metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7f853c-d45a-4a6f-b488-c6e9eb2e36b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec2a7a2-b13c-4dbd-88a1-4b6c9796f998",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
