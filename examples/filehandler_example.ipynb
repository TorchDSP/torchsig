{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom File Handler Example\n",
    "\n",
    "This notebook shows how to create a custom file handler to write the datasets in a different format. For this example, we will show how to write data as a PNG image.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `DatasetCreator` and any `StaticDatasets` use a `TorchSigFileHandler` to write and read data, respectively. By default, they both use the `ZarrFileHandler` class. But if you want the dataset to be written and read differently, you can create a subclass of `TorchSigFileHandler`. \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "There are 3 functions you are required to implement:\n",
    "```\n",
    "# writes a batch of data to disk\n",
    "def write(self, batch_idx: int, batch: Any) -> None:\n",
    "\n",
    "# determines size of dataset on disk\n",
    "@staticmethod\n",
    "def size(dataset_path: str) -> int:\n",
    "\n",
    "# loads idx into memory\n",
    "@staticmethod\n",
    "def static_load(filename:str, idx: int) -> Tuple[np.ndarray, List[Dict[str, Any]]]:\n",
    "\n",
    "```\n",
    "\n",
    "You can override these functions as needed:\n",
    "```\n",
    "# any pre-requisite set up before the file handler writers\n",
    "def _setup(self) -> None:\n",
    "\n",
    "# any post processes to run after all the data is writtern to disk\n",
    "def teardown(self) -> None:\n",
    "\n",
    "# determine if a dataset exists on disk\n",
    "def exists(self) -> bool:\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsig.utils.file_handlers.base_handler import TorchSigFileHandler\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from typing import List, Any, Tuple, Dict\n",
    "import pickle\n",
    "\n",
    "\n",
    "class ImageFileHandler(TorchSigFileHandler):\n",
    "\n",
    "    file_ext = \".png\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str,\n",
    "        train: bool = None,\n",
    "        batch_size: int = 1\n",
    "    ):\n",
    "        super().__init__(\n",
    "            root = root,\n",
    "            batch_size = batch_size\n",
    "        )\n",
    "\n",
    "        # define a colormap for the image\n",
    "        self.colormap = cv2.COLORMAP_HOT\n",
    "\n",
    "    def _setup(self) -> None:\n",
    "        # create images and targets folder\n",
    "        os.makedirs(f\"{self.root}/images\", exist_ok=True)\n",
    "        os.makedirs(f\"{self.root}/targets\", exist_ok=True)\n",
    "\n",
    "    def exists(self) -> bool:\n",
    "        # checks images/ and targets/ folders are created\n",
    "        # and not empty\n",
    "        images_path =f\"{self.root}/images\"\n",
    "        targets_path = f\"{self.root}/targets\"\n",
    "\n",
    "        images_exist = os.path.exists(images_path) and len(os.listdir(images_path)) > 0\n",
    "        targets_exist = os.path.exists(targets_path) and len(os.listdir(targets_path)) > 0\n",
    "\n",
    "        return images_exist and targets_exist\n",
    "\n",
    "    @staticmethod\n",
    "    def size(dataset_path: str) -> int:\n",
    "        # given path to dataset on disk\n",
    "        # return dataset size\n",
    "        # return how many files in images/ or targets (min)\n",
    "        images_path =f\"{dataset_path}/images\"\n",
    "        targets_path = f\"{dataset_path}/targets\"\n",
    "\n",
    "        num_images = len(os.listdir(images_path))\n",
    "        num_targets = len(os.listdir(targets_path))\n",
    "\n",
    "        return min(num_images, num_targets)\n",
    "\n",
    "    def write(self, batch_idx: int, batch: Any) -> None:\n",
    "        # writes a batch from dataset's __getitem__\n",
    "        start_idx = batch_idx * len(batch[0])\n",
    "        stop_idx = start_idx + len(batch[0])\n",
    "\n",
    "        data, targets = batch\n",
    "        \n",
    "        for i,(d,t) in enumerate(zip(data, targets)):\n",
    "            # convert data (H,W) `-> (H,W,3) with 3 channels RGB\n",
    "            # first normalize data from (0-255)\n",
    "            mi = d.min()\n",
    "            ma = d.max()\n",
    "\n",
    "            d = ((d - mi) / (ma - mi)) * 255\n",
    "            # convert to ints\n",
    "            d = d.astype(np.uint8)\n",
    "\n",
    "            # apply colormap\n",
    "            if self.colormap:\n",
    "                d = cv2.applyColorMap(d, self.colormap)\n",
    "            \n",
    "            self._write_image(d, start_idx+i)\n",
    "            self._write_targets(t, start_idx+i)\n",
    "\n",
    "    @staticmethod\n",
    "    def static_load(filename:str, idx: int) -> Tuple[np.ndarray, List[Dict[str, Any]]]:\n",
    "        # loads sample `idx` from `filename` into memory\n",
    "        # method can be used without instantiating class\n",
    "        # used for just reading\n",
    "        image = cv2.imread(f\"{filename}/images/{idx}{ImageFileHandler.file_ext}\")\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        with open(f\"{filename}/targets/{idx}.pkl\", 'rb') as f:\n",
    "            targets = pickle.load(f)\n",
    "        \n",
    "        return image, targets\n",
    "\n",
    "    # Helper Functions\n",
    "\n",
    "    def _write_image(self, data: np.ndarray, idx: int) -> None:\n",
    "        # convert from RGB to BGR\n",
    "        # data = cv2.cvtColor(data, cv2.COLOR_RGB2BGR)\n",
    "        filename = f\"{self.root}/images/{idx}{self.file_ext}\"\n",
    "        cv2.imwrite(filename, data)\n",
    "\n",
    "    def _write_targets(self, targets: Any, idx: int) -> None:\n",
    "        # pickle targets\n",
    "        filename = f\"{self.root}/targets/{idx}.pkl\"\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(targets, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this file handler\n",
    "from torchsig.datasets.dataset_metadata import DatasetMetadata\n",
    "from torchsig.datasets.wideband import NewWideband, StaticWideband\n",
    "from torchsig.utils.writer import DatasetCreator\n",
    "from torchsig.transforms.transforms import Spectrogram\n",
    "from torchsig.transforms.target_transforms import ClassName\n",
    "\n",
    "root = \"./datasets/filehandler_example\"\n",
    "fft_size = 512\n",
    "num_iq_samples_dataset = fft_size ** 2\n",
    "impairment_level = 0\n",
    "num_samples = 10\n",
    "num_signals_max = 1\n",
    "\n",
    "transforms = [Spectrogram(fft_size=fft_size)]\n",
    "target_transforms = [ClassName()]\n",
    "\n",
    "md = DatasetMetadata(\n",
    "    num_iq_samples_dataset=num_iq_samples_dataset,\n",
    "    fft_size=fft_size,\n",
    "    impairment_level=impairment_level,\n",
    "    num_samples=num_samples,\n",
    "    transforms=transforms,\n",
    "    target_transforms=target_transforms,\n",
    "    num_signals_max = num_signals_max\n",
    ")\n",
    "dc = DatasetCreator(\n",
    "    dataset=NewWideband(dataset_metadata=md),\n",
    "    root=root,\n",
    "    overwrite=True,\n",
    "    # use our custom file handler class\n",
    "    file_handler=ImageFileHandler\n",
    ") \n",
    "dc.create()\n",
    "\n",
    "s = StaticWideband(\n",
    "    root=root,\n",
    "    impairment_level=impairment_level,\n",
    "    # be sure to use the same class that was written to disk\n",
    "    file_handler_class=ImageFileHandler\n",
    ")\n",
    "\n",
    "data, targets = s[0]\n",
    "print(f\"\\nData: {data.shape} ({type(data)})\")\n",
    "print(f\"Targets: {targets}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can plot the data as an RGB image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
