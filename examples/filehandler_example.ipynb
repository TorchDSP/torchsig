{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom File Handler Example\n",
    "\n",
    "This notebook shows how to create a custom file handler to write the datasets in a different format. For this example, we will show how to write data as a PNG image and target labels as a yaml file.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `DatasetCreator` and any `StaticDatasets` use a `BaseFileHandler` to write and read data, respectively. By default, they both use the `HDF5FileHandler` class. But if you want the dataset to be written and read differently, you can create a subclass of `BaseFileHandler`. \n",
    "\n",
    "**Note**: As of TorchSig 2.0, the default file handler is HDF5-based for improved performance and metadata storage."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# TorchSig\n",
    "from torchsig.utils.file_handlers.base_handler import FileWriter, FileReader\n",
    "from torchsig.utils.writer import DatasetCreator\n",
    "from torchsig.utils.data_loading import WorkerSeedingDataLoader\n",
    "from torchsig.utils.defaults import TorchSigDefaults\n",
    "from torchsig.signals.signal_types import Signal\n",
    "from torchsig.datasets.datasets import TorchSigIterableDataset, StaticTorchSigDataset\n",
    "from torchsig.transforms.transforms import Spectrogram\n",
    "\n",
    "# Third Party\n",
    "import cv2\n",
    "import yaml\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Conversion functions for YAML file handling.\n",
    "def _to_builtin(val):\n",
    "    \"\"\"Convert NumPy types to built-in Python types.\"\"\"\n",
    "    if isinstance(val, np.generic):\n",
    "        return val.item()\n",
    "    else:\n",
    "        return val\n",
    "\n",
    "\n",
    "def signal_to_dict(signal: Signal) -> tuple:\n",
    "    \"\"\"Recursively convert a Signal object into a dictionary for YAML serialization.\"\"\"\n",
    "    return {\n",
    "        \"metadata\": {key: _to_builtin(val) for key, val in signal.metadata.items()},\n",
    "        \"component_signals\": [\n",
    "            signal_to_dict(child) for child in signal.component_signals\n",
    "        ],\n",
    "    }\n",
    "\n",
    "\n",
    "def dict_to_signal(data: dict) -> Signal:\n",
    "    \"\"\"Recursively construct a Signal object from a nested dictionary (YAML deserialization).\"\"\"\n",
    "    # Create Signal from metadata\n",
    "    sig = Signal(metadata=data.get(\"metadata\"))\n",
    "    # Recurse for each component signal (if any)\n",
    "    for child_data in data.get(\"component_signals\", []):\n",
    "        sig.component_signals.append(dict_to_signal(child_data))\n",
    "    return sig"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class SpectrogramWriter(FileWriter):\n",
    "    \"\"\"TorchSig FileWriter for handling our custom storage format. Data\n",
    "    is written as a png image file. Metadata is written using human-\n",
    "    readable yaml files, one per element.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def _setup(self) -> None:\n",
    "        \"\"\"Setup directory for storing spectrogram images and targets.\"\"\"\n",
    "        self.spectrogram_dir = self.root.joinpath(\"spectrograms\")\n",
    "        self.target_dir = self.root.joinpath(\"targets\")\n",
    "        self.spectrogram_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.target_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    def write(self, batch_idx: int, batch: list) -> None:\n",
    "        \"\"\"Write a single batch of Signals as spectrograms and targets to disk.\n",
    "\n",
    "        Args:\n",
    "            batch_idx (int): Index of the batch being written.\n",
    "            batch (list): List of Signal objects in batch.\n",
    "\n",
    "        \"\"\"\n",
    "        for idx, sig in enumerate(batch):\n",
    "            spectrogram = sig.data  # numpy spectrogram data\n",
    "            metadata = signal_to_dict(sig)  # convert Signal to dictionary structure\n",
    "\n",
    "            # First normalize data from (0-255)\n",
    "            mi = spectrogram.min()\n",
    "            ma = spectrogram.max()\n",
    "            spectrogram = ((spectrogram - mi) / (ma - mi)) * 255\n",
    "            # convert to 8-bit\n",
    "            spectrogram = spectrogram.astype(np.uint8)\n",
    "\n",
    "            # apply colormap\n",
    "            spectrogram = cv2.applyColorMap(spectrogram, cv2.COLORMAP_HOT)\n",
    "\n",
    "            # Save spectrogram as PNG\n",
    "            spectrogram_path = self.spectrogram_dir.joinpath(\n",
    "                f\"spectrogram_{batch_idx * len(batch) + idx}.png\"\n",
    "            )\n",
    "            cv2.imwrite(str(spectrogram_path), spectrogram)\n",
    "\n",
    "            # Save target as YAML: one yaml file per element\n",
    "            target_path = self.target_dir.joinpath(\n",
    "                f\"target_{batch_idx * len(batch) + idx}.yaml\"\n",
    "            )\n",
    "            with open(target_path, \"w\") as f:\n",
    "                # Dump YAML with block style for readability\n",
    "                yaml.dump(metadata, f, default_flow_style=False, sort_keys=False)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Return the number of saved spectrograms.\"\"\"\n",
    "        return len(list(self.spectrogram_dir.glob(\"spectrogram_*.png\")))\n",
    "\n",
    "\n",
    "class SpectrogramReader(FileReader):\n",
    "    \"\"\"TorchSig FileReader for handling our custom storage format.\"\"\"\n",
    "\n",
    "    def __init__(self, root):\n",
    "        super().__init__(root=root)\n",
    "        self.spectrogram_dir = self.root.joinpath(\"spectrograms\")\n",
    "        self.target_dir = self.root.joinpath(\"targets\")\n",
    "\n",
    "    def read(self, idx: int) -> tuple:\n",
    "        \"\"\"Read a spectrogram and target by index.\n",
    "\n",
    "        Args:\n",
    "            idx (int): Index of the data to read.\n",
    "\n",
    "        Returns:\n",
    "            tuple: (spectrogram, target)\n",
    "        \"\"\"\n",
    "        # Read the spectrogram data as a NumPy array\n",
    "        spectrogram_path = self.root.joinpath(\"spectrograms\", f\"spectrogram_{idx}.png\")\n",
    "        spectrogram = cv2.imread(str(spectrogram_path), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # Read the metadata from yaml file\n",
    "        target_path = self.root.joinpath(\"targets\", f\"target_{idx}.yaml\")\n",
    "        with open(target_path, \"r\") as f:\n",
    "            raw_metadata = yaml.load(f, Loader=yaml.FullLoader)  # parse YAML into dict\n",
    "            targets = dict_to_signal(raw_metadata)\n",
    "\n",
    "        return spectrogram, targets\n",
    "\n",
    "    def size(self) -> int:\n",
    "        \"\"\"Return the total number of spectrograms in the dataset.\"\"\"\n",
    "        spectrograms_path = self.root.joinpath(\"spectrograms\")\n",
    "        return len(list(spectrograms_path.glob(\"spectrogram_*.png\")))\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Return the total number of spectrograms in the dataset.\"\"\"\n",
    "        return self.size()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Define dataset metadata\n",
    "dm = TorchSigDefaults().default_dataset_metadata\n",
    "dm[\"num_signals_max\"] = 4"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Exercise custom file writing and reading with TorchSig datasets\n",
    "\n",
    "# Parameters\n",
    "root = \"./datasets/filehandler_example\"\n",
    "fft_size = 512\n",
    "dataset_length = 10\n",
    "transforms = [Spectrogram(fft_size=fft_size)]\n",
    "target_labels = [\"class_name\", \"class_index\"]\n",
    "\n",
    "# Define original dataset and dataloader\n",
    "dataset = TorchSigIterableDataset(\n",
    "    metadata=dm, transforms=transforms, target_labels=target_labels\n",
    ")\n",
    "dataloader = WorkerSeedingDataLoader(dataset, collate_fn=lambda x: x)\n",
    "dataloader.seed(42)  # seed for reproducibility\n",
    "\n",
    "# Create data on disk\n",
    "dc = DatasetCreator(\n",
    "    dataloader=dataloader,\n",
    "    root=root,\n",
    "    dataset_length=dataset_length,\n",
    "    overwrite=True,\n",
    "    # use our custom file handler class\n",
    "    file_handler=SpectrogramWriter,\n",
    ")\n",
    "dc.create()\n",
    "\n",
    "# Read data as a static dataset\n",
    "s = StaticTorchSigDataset(\n",
    "    root=root,\n",
    "    # be sure to use the same class that was written to disk\n",
    "    file_handler_class=SpectrogramReader,\n",
    ")\n",
    "\n",
    "# Read a particular element\n",
    "data, targets = s[6]\n",
    "print(f\"\\nData: {data.shape}\")\n",
    "print(f\"Targets: {targets}\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Plot the data as an RGB image\n",
    "plt.imshow(data)"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 4,
 "metadata": {
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "kernelspec": {
  "display_name": "Python 3",
  "language": "python",
  "name": "python3"
 }
}