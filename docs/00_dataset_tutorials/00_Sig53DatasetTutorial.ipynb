{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff639336-c092-4882-b08e-78f8b82f741e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# The Official Sig53 Dataset\n",
    "\n",
    "**Number of Classes:** 53   \n",
    "**Size on Disk:** 71 GB (uncompressed)   \n",
    "**Time to Generate:** ~1 hour   \n",
    "\n",
    "**Description:**\n",
    "The Sig53 dataset is a synthetic dataset of modulated RF bursts of various families of modulations that are augmented with highly parameterizable transformations and can be generated on-the-fly or stored on disk. Such a dataset can be used for comparing and benchmarking the performance of machine-learning techniques.\n",
    "\n",
    "For more much more detailed information about the nature of the data, please see [the associated paper on ArXiv](https://arxiv.org/pdf/2207.09918.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337d80fe",
   "metadata": {},
   "source": [
    "### On-the-Fly Dataset\n",
    "#### Generating\n",
    "A Sig53-like dataset can be generated from scratch, on-the-fly, yielding a dataset with essentially inifinite number of unique exemplars (called samples in machine-learning circles) per class. The downside to generating things on-the-fly is that **training is slower.** \n",
    "\n",
    "Before we jump into generating the whole dataset, let's start with a basic example which uses the ```ModulationsDataset```, which is the underlying class used to generate ```Sig53Dataset```. The class has a number of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248bd926",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from torchsig.datasets.modulations import ModulationsDataset\n",
    "\n",
    "# Instantiate the dataset, no data is generated at this point.\n",
    "ds = ModulationsDataset(\n",
    "    level=0, # only AWGN\n",
    "    num_samples=53*10, # 10 exemplars per class\n",
    "    num_iq_samples=4096, # 4096 IQ samples\n",
    ")\n",
    "\n",
    "# Index into the dataset. This actually generates the data\n",
    "# and the associated label\n",
    "data, label = ds[0]\n",
    "\n",
    "# Plot it.\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.title(\"Modulation Type = {}\".format(label))\n",
    "plt.ylabel(\"Time Domain\")\n",
    "plt.plot(data[:100].real, marker=\".\")\n",
    "plt.plot(data[:100].imag, marker=\".\")\n",
    "plt.legend([\"Real\", \"Imag\"])\n",
    "ax = plt.gca()\n",
    "ax.grid(False)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "_ = plt.psd(data)\n",
    "plt.ylabel(\"PSD\")\n",
    "plt.xlabel(\"\")\n",
    "ax = plt.gca()\n",
    "ax.grid(False)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "_ = plt.specgram(data)\n",
    "ax = plt.gca()\n",
    "plt.ylabel(\"Spectrogram\")\n",
    "ax.grid(False)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fd3171",
   "metadata": {},
   "source": [
    "Now, if you want to a more interesting dataset, with more substantial impairments, you can use a different level as an argument. Typically you'll want to look at more than just one sample in the dataset as well. You might want to iterate over the entire dataset to analyze the data yourself, store it in some custom format, or train an ML algorithm with the data. The ```Dataset``` class is a Python ```Generator```, so you can iterate over it just like a list, which is nice.\n",
    "\n",
    "We'll use a more advanced way of iterating over the dataset later, but this may be helpful if you're just getting started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01ee9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the dataset, no data is generated at this point.\n",
    "ds = ModulationsDataset(\n",
    "    level=1, # More like a cabled environment\n",
    "    num_samples=53*10, # 10 exemplars per class\n",
    "    num_iq_samples=4096, # 4096 IQ samples\n",
    ")\n",
    "\n",
    "count = 0\n",
    "\n",
    "# iterate over the dataset once.\n",
    "for data, label in ds:\n",
    "    # Store the data, train on it, analyze it.\n",
    "    data = data + 1\n",
    "    count += 1\n",
    "\n",
    "print(\"There are {} samples in this dataset!\".format(count))\n",
    "\n",
    "# Plot it.\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.title(\"Modulation Type = {}\".format(label))\n",
    "plt.ylabel(\"Time Domain\")\n",
    "plt.plot(data[:100].real, marker=\".\")\n",
    "plt.plot(data[:100].imag, marker=\".\")\n",
    "plt.legend([\"Real\", \"Imag\"])\n",
    "ax = plt.gca()\n",
    "ax.grid(False)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "_ = plt.psd(data)\n",
    "plt.ylabel(\"PSD\")\n",
    "plt.xlabel(\"\")\n",
    "ax = plt.gca()\n",
    "ax.grid(False)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "_ = plt.specgram(data)\n",
    "ax = plt.gca()\n",
    "plt.ylabel(\"Spectrogram\")\n",
    "ax.grid(False)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2de8dd",
   "metadata": {},
   "source": [
    "#### Iterating Over the Dataset\n",
    "Now the Sig53 dataset is a specific configuration of the ```ModulationsDataset``` class. To keep the configuration fixed, we implement classes with fixed parameters of type ```Sig53Conf```. We use the ```Sig53CleanTrianQAConfig```. In this configuration, the dataset ```label``` is actually a Python ```tuple``` which includes the estimated SNR of the produced sample. \n",
    "\n",
    "Using this example, you can choose one of the fixed configurations and generate a Sig53-like dataset on-the-fly as you iterate over it, and train an ML model, store it, or perform some analysis on it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1df2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsig.datasets import conf\n",
    "\n",
    "# A VERY small portion of the Sig53 impaired-train dataset, which is level 2\n",
    "config = conf.Sig53ImpairedTrainQAConfig\n",
    "\n",
    "# Instantiate the dataset, no data is generated at this point.\n",
    "ds = ModulationsDataset(\n",
    "    level=config.level,\n",
    "    num_samples=config.num_samples,\n",
    "    num_iq_samples=config.num_iq_samples,\n",
    "    use_class_idx=config.use_class_idx,\n",
    "    include_snr=config.include_snr,\n",
    "    eb_no=config.eb_no\n",
    ")\n",
    "\n",
    "data, (modulation, snr) = ds[0]\n",
    "print(data)\n",
    "print(modulation, snr)\n",
    "\n",
    "# Plot it.\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.title(\"Modulation Type = {}\".format(label))\n",
    "plt.ylabel(\"Time Domain\")\n",
    "plt.plot(data[:100].real, marker=\".\")\n",
    "plt.plot(data[:100].imag, marker=\".\")\n",
    "plt.legend([\"Real\", \"Imag\"])\n",
    "ax = plt.gca()\n",
    "ax.grid(False)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "_ = plt.psd(data)\n",
    "plt.ylabel(\"PSD\")\n",
    "plt.xlabel(\"\")\n",
    "ax = plt.gca()\n",
    "ax.grid(False)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "_ = plt.specgram(data)\n",
    "ax = plt.gca()\n",
    "plt.ylabel(\"Spectrogram\")\n",
    "ax.grid(False)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bb49fd",
   "metadata": {},
   "source": [
    "### Static Dataset\n",
    "#### Generating\n",
    "The official Sig53 dataset is a fixed-size static dataset and not one of the on-the-fly datasets mentioned above. Fixed datasets are useful because training on them is much faster and when comparing/reproducing results is important, this is the way to go. To use a static dataset, we first have to generate it like we did before, but we need to store it on disk. Then, we need a way to actually read it from the disk so we can train on it.\n",
    "\n",
    "So what we'll do is use a PyTorch ```DataLoader```, which parallelizes the generation of data from ```ModulationsDataset```. It's a very useful class for ML training, which is usually done with batches of data. For each batch of data that's produced, we'll write it to a file. \n",
    "\n",
    "We write data as raw binary to disk here, but we don't use that by default in TorchSig, this is just an example of how you could do it. Raw binary is much more portable than other formats, but is not commonly used in the ML community."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5254ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# A VERY small portion of the Sig53 impaired-train dataset, which is level 2\n",
    "config = conf.Sig53ImpairedTrainSmallConfig\n",
    "\n",
    "# Instantiate the dataset, no data is generated at this point.\n",
    "ds = ModulationsDataset(\n",
    "    level=config.level,\n",
    "    num_samples=config.num_samples,\n",
    "    num_iq_samples=config.num_iq_samples,\n",
    "    use_class_idx=config.use_class_idx,\n",
    "    include_snr=config.include_snr,\n",
    "    eb_no=config.eb_no\n",
    ")\n",
    "\n",
    "# You can iterate through this in a similar way.\n",
    "# The DataLoader produces a torch.Tensor\n",
    "loader = DataLoader(ds, batch_size=16, num_workers=16)\n",
    "\n",
    "if os.path.exists(\"data.fc32\"):\n",
    "    os.remove(\"data.fc32\")\n",
    "\n",
    "if os.path.exists(\"label.int8\"):\n",
    "    os.remove(\"label.int8\")\n",
    "\n",
    "for data, (mod, snr) in loader:\n",
    "    # We convert torch.Tensor to a familiar numpy.ndarray\n",
    "    # with tensor.numpy()\n",
    "    with open(\"data.fc32\", \"ab+\") as data_file:\n",
    "        data_file.write(data.numpy().tobytes())\n",
    "\n",
    "    with open(\"label.int8\", \"ab+\") as label_file:\n",
    "        label_file.write(mod.numpy().astype(np.int8).tobytes())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e300782",
   "metadata": {},
   "source": [
    "#### Reading a Static Dataset\n",
    "We've chosen to write our data as raw binary. We can write a Dataset class that allows us to iterate over that stored data. A Dataset class only needs to implement ```__init__``` and ```__getitem__```. We talk more about creating a custom dataset in a different tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192c7ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsig.datasets.synthetic import SignalDataset\n",
    "from typing import Callable, Tuple, Union\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class CustomDataset(SignalDataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        path: str,\n",
    "        transform: Union[Callable, None] = None,\n",
    "        target_transform: Union[Callable, None] = None,\n",
    "        seed: Union[int, None] = None,\n",
    "    ) -> None:\n",
    "        self.data_file = os.path.join(path, \"data.fc32\")\n",
    "        self.label_file = os.path.join(path, \"label.int8\")\n",
    "\n",
    "        super().__init__(transform, target_transform, seed)\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple:\n",
    "        # the sample at index is 8192 double-precision floating-point numbers long.\n",
    "        # It is located 8192*8 bytes into the file\n",
    "        iq_data = np.fromfile(\n",
    "            self.data_file,\n",
    "            dtype=np.float64,\n",
    "            count=4096 * 2,\n",
    "            offset=index * 4096 * 2 * 8,\n",
    "        ).view(np.complex128)\n",
    "        label = np.fromfile(self.label_file, dtype=np.int8, count=1, offset=index)\n",
    "        return iq_data, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bff8186",
   "metadata": {},
   "source": [
    "Now, we instantiate the ```CustomDataset```, pointing it to what we generated and plotting it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d2a474",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_ds = CustomDataset(path=\".\")\n",
    "\n",
    "data, label = custom_ds[0]\n",
    "\n",
    "# Plot it.\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.title(\"Modulation Type = {}\".format(ModulationsDataset.default_classes[int(label)]))\n",
    "plt.ylabel(\"Time Domain\")\n",
    "plt.plot(data[:100].real, marker=\".\")\n",
    "plt.plot(data[:100].imag, marker=\".\")\n",
    "plt.legend([\"Real\", \"Imag\"])\n",
    "ax = plt.gca()\n",
    "ax.grid(False)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "_ = plt.psd(data)\n",
    "plt.ylabel(\"PSD\")\n",
    "plt.xlabel(\"\")\n",
    "ax = plt.gca()\n",
    "ax.grid(False)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "_ = plt.specgram(data)\n",
    "ax = plt.gca()\n",
    "plt.ylabel(\"Spectrogram\")\n",
    "ax.grid(False)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7e7add",
   "metadata": {},
   "source": [
    "### The Official Sig53 Dataset\n",
    "#### Generating\n",
    "The above examples are to explain through a simplified example how TorchSig statically generates Sig53 and also to give you enough information to roll-your-own static generation method, if you'd like. The official supported method for generation is to use the provided scripts in the ```scripts/``` directory.\n",
    "\n",
    "The official method here employs our own ```DatasetLoader``` and ```DatasetCreator``` which are thin wrappers around a ```DataLoader``` that enables seeded generation and the optional overloading of storage format. The default storage format uses lmdb, which one format used in the broader machine-learning community."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f3ada8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsig.utils.writer import DatasetLoader, DatasetCreator\n",
    "\n",
    "path = \"sig53_qa/\"\n",
    "\n",
    "config = conf.Sig53CleanTrainQAConfig\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)\n",
    "\n",
    "ds = ModulationsDataset(\n",
    "    level=config.level,\n",
    "    num_samples=config.num_samples,\n",
    "    num_iq_samples=config.num_iq_samples,\n",
    "    use_class_idx=config.use_class_idx,\n",
    "    include_snr=config.include_snr,\n",
    "    eb_no=config.eb_no,\n",
    ")\n",
    "loader = DatasetLoader(\n",
    "    ds,\n",
    "    seed=12345678,\n",
    "    num_workers=os.cpu_count() // 2,\n",
    "    batch_size=os.cpu_count() // 2,\n",
    ")\n",
    "creator = DatasetCreator(\n",
    "    ds,\n",
    "    seed=12345678,\n",
    "    path=\"{}\".format(os.path.join(path, config.name)),\n",
    "    loader=loader,\n",
    ")\n",
    "creator.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519af0a3",
   "metadata": {},
   "source": [
    "#### Reading\n",
    "The ```Sig53``` class in TorchSig is similar to ```CustomDataset```, it is provided with a path to find the raw data and it simply reads it from disk as it is accessed with ```__getitem__```. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24ae0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsig.datasets.sig53 import Sig53\n",
    "\n",
    "# The path, train, and impaired arguments tell\n",
    "# this dataset class precisely where to look for data\n",
    "official_sig53 = Sig53(\n",
    "    root=\"sig53_qa\",\n",
    "    train=True,\n",
    "    impaired=False\n",
    ")\n",
    "\n",
    "data, (mod, snr) = official_sig53[0]\n",
    "\n",
    "# Plot it.\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.title(\"Modulation Type = {}\".format(ModulationsDataset.default_classes[int(label)]))\n",
    "plt.ylabel(\"Time Domain\")\n",
    "plt.plot(data[:100].real, marker=\".\")\n",
    "plt.plot(data[:100].imag, marker=\".\")\n",
    "plt.legend([\"Real\", \"Imag\"])\n",
    "ax = plt.gca()\n",
    "ax.grid(False)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "_ = plt.psd(data)\n",
    "plt.ylabel(\"PSD\")\n",
    "plt.xlabel(\"\")\n",
    "ax = plt.gca()\n",
    "ax.grid(False)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "_ = plt.specgram(data)\n",
    "ax = plt.gca()\n",
    "plt.ylabel(\"Spectrogram\")\n",
    "ax.grid(False)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fca0286",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
