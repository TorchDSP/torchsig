diff --git a/.github/ISSUE_TEMPLATE/bug_report.yml b/.github/ISSUE_TEMPLATE/bug_report.yml
index 90e3e5a02..435932907 100644
--- a/.github/ISSUE_TEMPLATE/bug_report.yml
+++ b/.github/ISSUE_TEMPLATE/bug_report.yml
@@ -21,13 +21,13 @@ body:
       label: Version
       description: What version of TorchSig? Note that any bugs before 1.0.0 are not prioritized.
       options:
-        - 1.2.0-dev
-        - 1.1.0 (Default)
+        - 2.0.0 (Default)
+        - 1.1.0
         - 1.0.0
         - 0.6.1
         - 0.6.0
         - Other
-      default: 1
+      default: 0
     validations:
       required: true
   - type: textarea
diff --git a/.gitignore b/.gitignore
index d541d5242..d78895073 100644
--- a/.gitignore
+++ b/.gitignore
@@ -4,7 +4,7 @@ __pycache__/
 build/
 checkpoints/
 lightning_logs/
-dist/
+#dist/
 **.ipynb_checkpoints**
 **.pytest_cache
 *.benchmarks/
@@ -28,12 +28,22 @@ dist/
 **.pytest_cache
 **.zarr
 **.yaml
+**.out
+
+# Rust
+rust_functions/target
+rust_functions/Cargo.lock
+**/*.rs.bk
+**.so
+**.bak
+
 
 # TorchSig
 torchsig.egg-info
 !torchsig/datasets/default_consfigs
 !torchsig/datasets/default_configs/*
 !requirements.txt
+torchsig/utils/pfb_weights
 
 # keep license docs
 !**LICENSE.txt
@@ -53,6 +63,7 @@ examples/*
 examples/datasets
 !examples/old_examples
 !examples/*.ipynb
+!examples/transforms
 !examples/transforms/*.ipynb
 !examples/*.py
 !examples/*.yaml
@@ -71,3 +82,37 @@ tools/examples/datasets/yolo_annotation_data/annotated_yolo_sample_images
 **.coverage
 **coverage.xml
 **report.xml
+
+# Assistant Files
+.claude/
+CLAUDE.md
+SESSION_NOTES.md
+datasets/
+
+
+# Additional ignores to ensure these stay out
+rust_fft/target/
+**/node_modules/
+datasets/
+*.h5
+*.conflict
+__pycache__/
+*.pyc
+*.pyo
+*.pyd
+.Python
+build/
+develop-eggs/
+dist/
+downloads/
+eggs/
+.eggs/
+lib/
+lib64/
+parts/
+sdist/
+var/
+wheels/
+*.egg-info/
+.installed.cfg
+*.egg
diff --git a/Dockerfile b/Dockerfile
index 51016d641..2ec502f07 100755
--- a/Dockerfile
+++ b/Dockerfile
@@ -1,26 +1,75 @@
-FROM nvcr.io/nvidia/pytorch:24.06-py3
+# +----------------------------------------------------------------------------+
+# |                       Stage 1: Builder (with CUDA Toolkit)                |
+# +----------------------------------------------------------------------------+
+FROM nvidia/cuda:12.1.0-devel-ubuntu22.04 AS builder
+WORKDIR /workspace
 
-ENV DEBIAN_FRONTEND=noninteractive
+# +----------------------------------------------------------------------------+
+# | Install system build tools, Python headers, pip and Git                   |
+# +----------------------------------------------------------------------------+
+RUN apt-get update && \
+    apt-get install -y --no-install-recommends \
+      build-essential \          
+      curl \                    
+      libffi-dev libssl-dev \      
+      python3.10 python3-pip \      
+      git && \                       
+    rm -rf /var/lib/apt/lists/*     
 
-RUN apt-get update && apt-get install -y \
-    git \ 
-    zsh \ 
-    ssh \
-    rsync \
-    libgl1-mesa-glx
+# +----------------------------------------------------------------------------+
+# | Install rustup and set up latest stable Rust (>=1.81)                     |
+# +----------------------------------------------------------------------------+
+ENV RUSTUP_HOME=/usr/local/rustup \
+    CARGO_HOME=/usr/local/cargo \
+    PATH=/usr/local/cargo/bin:$PATH
 
+RUN curl https://sh.rustup.rs -sSf | sh -s -- -y --default-toolchain stable \
+    && rustc --version           
 
+# +----------------------------------------------------------------------------+
+# | Upgrade pip and install Python packaging tools (setuptools-rust, wheel)    |
+# +----------------------------------------------------------------------------+
+RUN python3 -m pip install --upgrade pip setuptools setuptools-rust wheel
 
-ADD torchsig/ /build/torchsig
+# +----------------------------------------------------------------------------+
+# | Copy the entire project into the builder image                             |
+# +----------------------------------------------------------------------------+
+COPY . .
 
-ADD pyproject.toml /build/pyproject.toml
+# +----------------------------------------------------------------------------+
+# | Install TorchSig (builds the Rust extension in-place)                     |
+# +----------------------------------------------------------------------------+
+RUN pip install . --no-cache-dir
 
-RUN pip3 install -e /build
+# +============================================================================+
+# |                Stage 2: Runtime (CUDA Runtime Only)                       |
+# +============================================================================+
+FROM nvidia/cuda:12.1.0-runtime-ubuntu22.04
+WORKDIR /workspace
 
-RUN pip3 install notebook jupyterlab==4.2.3
-RUN pip3 install jupyterlab_theme_solarized_dark
-RUN pip3 install ipywidgets
+# +----------------------------------------------------------------------------+
+# | Install minimal system libraries required at runtime (e.g., OpenCV deps)   |
+# +----------------------------------------------------------------------------+
+RUN apt-get update && \
+    apt-get install -y --no-install-recommends \
+      libgl1 \   
+      libsm6 \   
+      libxrender1 \
+      libxext6 && \ 
+    rm -rf /var/lib/apt/lists/*
 
-WORKDIR /workspace/code
+# +----------------------------------------------------------------------------+
+# | Copy installed Python packages from builder into runtime image             |
+# +----------------------------------------------------------------------------+
+COPY --from=builder /usr/local/lib/python3.10/dist-packages/ \
+                     /usr/local/lib/python3.10/dist-packages/
 
-ADD examples/ /workspace/code/examples
+# +----------------------------------------------------------------------------+
+# | (Optional) Copy source/tests/scripts if you need them in the runtime       |
+# +----------------------------------------------------------------------------+
+COPY --from=builder /workspace /workspace
+
+# +----------------------------------------------------------------------------+
+# | Default to bash for interactive GPU testing                                |
+# +----------------------------------------------------------------------------+
+CMD ["bash"]
diff --git a/LICENSE.md b/LICENSE.md
new file mode 100644
index 000000000..550f95ce4
--- /dev/null
+++ b/LICENSE.md
@@ -0,0 +1,21 @@
+MIT License
+
+Copyright (c) 2022-2025 TorchSig
+
+Permission is hereby granted, free of charge, to any person obtaining a copy
+of this software and associated documentation files (the "Software"), to deal
+in the Software without restriction, including without limitation the rights
+to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+copies of the Software, and to permit persons to whom the Software is
+furnished to do so, subject to the following conditions:
+
+The above copyright notice and this permission notice shall be included in all
+copies or substantial portions of the Software.
+
+THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+SOFTWARE.
diff --git a/README.md b/README.md
index dc644ba19..8729d3ee3 100755
--- a/README.md
+++ b/README.md
@@ -7,7 +7,7 @@
 
 -----
 
-[TorchSig](https://torchsig.com) is an open-source signal processing machine learning toolkit based on the PyTorch data handling pipeline. The user-friendly toolkit simplifies common digital signal processing operations, augmentations, and transformations when dealing with both real and complex-valued signals. TorchSig streamlines the integration process of these signals processing tools building on PyTorch, enabling faster and easier development and research for machine learning techniques applied to signals data, particularly within (but not limited to) the radio frequency domain. An example dataset, Narrowband, based on many unique communication signal modulations is included to accelerate the field of modulation classification. Additionally, an example wideband dataset, Wideband, is also included that extends TorchSigNarrowband with larger data example sizes containing multiple signals enabling accelerated research in the fields of wideband signal detection and recognition.
+[TorchSig](https://torchsig.com) is an open-source signal processing machine learning toolkit based on the PyTorch data handling pipeline. The user-friendly toolkit simplifies common digital signal processing operations, augmentations, and transformations when dealing with both real and complex-valued signals. TorchSig streamlines the integration process of these signals processing tools building on PyTorch, enabling faster and easier development and research for machine learning techniques applied to signals data, particularly within (but not limited to) the radio frequency domain.
 
 # Getting Started
 
@@ -32,6 +32,29 @@ pip install -e .
 
 TorchSig has a series of Jupyter notebooks in the `examples/` directory. View the README inside `examples/` to learn more.
 
+# Usage
+
+## Generating Datasets with Python API
+TorchSig 2.0 uses a unified dataset architecture. Create datasets using the Python API:
+```python
+from torchsig.datasets.datasets import TorchSigIterableDataset
+from torchsig.utils.writer import DatasetCreator
+from torchsig.datasets.dataset_metadata import DatasetMetadata
+
+# Create dataset metadata
+metadata = DatasetMetadata(
+    num_iq_samples_dataset=4096,
+    num_samples=100,
+    impairment_level=1,  # 0=perfect, 1=cabled, 2=wireless
+    num_signals_max=1,   # 1 for classification, >1 for detection
+)
+
+# Create and write dataset
+dataset = TorchSigIterableDataset(metadata)
+creator = DatasetCreator(dataset, root="<path to root>")
+creator.create()
+```
+
 # Docker
 One option for running TorchSig is within Docker. Start by building the Docker container:
 
@@ -39,6 +62,42 @@ One option for running TorchSig is within Docker. Start by building the Docker c
 docker build -t torchsig -f Dockerfile .
 ```
 
+## Generating Datasets with Docker
+To create datasets with the Docker container, create a Python script and run it:
+```python
+# create_dataset.py
+from torchsig.datasets.datasets import TorchSigIterableDataset
+from torchsig.utils.writer import DatasetCreator
+from torchsig.datasets.dataset_metadata import DatasetMetadata
+
+# Classification dataset (single signal)
+metadata = DatasetMetadata(
+    num_iq_samples_dataset=100,
+    num_samples=10,
+    impairment_level=2,  # wireless
+    num_signals_max=1,
+)
+dataset = TorchSigIterableDataset(metadata)
+creator = DatasetCreator(dataset, root="/path/to/classification_dataset")
+creator.create()
+
+# Detection dataset (multiple signals)
+metadata = DatasetMetadata(
+    num_iq_samples_dataset=100,
+    num_samples=10,
+    impairment_level=2,  # wireless
+    num_signals_max=3,
+)
+dataset = TorchSigIterableDataset(metadata)
+creator = DatasetCreator(dataset, root="/path/to/detection_dataset")
+creator.create()
+```
+
+```bash
+docker run -u $(id -u ${USER}):$(id -g ${USER}) -v `pwd`:/workspace/code/torchsig torchsig python3 create_dataset.py
+```
+
+## Running Jupyter Notebooks with Docker
 To run with GPU support use `--gpus all`:
 ```
 docker run -d --rm --network=host --shm-size=32g --gpus all --name torchsig_workspace torchsig tail -f /dev/null
@@ -64,21 +123,22 @@ Then use the URL in the output in your browser to run the examples and notebooks
 
 # Key Features
 TorchSig provides many useful tools to facilitate and accelerate research on signals processing machine learning technologies:
-- The Narrowband datasets is a state-of-the-art static modulations-based RF dataset meant to serve as the next baseline for RFML classification development & evaluation.
-- The Wideband datasets is a state-of-the-art static wideband RF signals dataset meant to serve as the baseline for RFML signal detection and recognition development & evaluation.
-- Numerous signals processing transforms enable existing ML techniques to be employed on the signals data, streamline domain-specific signals augmentations in signals processing machine learning experiments, and signals-specific data transformations to speed up the field of expert feature signals processing machine learning integration.
-- TorchSig also includes a model API similar to open source code in other ML domains, where several state-of-the-art convolutional and transformer-based neural architectures have been adapted to the signals domain and pretrained on the Narrowband and Wideband datasets. These models can be easily used for follow-on research in the form of additional hyperparameter tuning, out-of-the-box comparative analysis/evaluations, and/or fine-tuning to custom datasets.
-
-## Classes
-- The `Signal` class and its `SignalMetadata` objects enable signals objects and metadata to be seamlessly handled and operated on throughout the TorchSig infrastructure.
-- The `NewDataset` class synthetically creates, augments, and transforms the largest communications signals modulations dataset to date in a generic, flexible fashion.
-  - Can generate samples infinitely, however you cannot access previously generated samples (only temporarily stored in memory).
-  - Use `NewNarrowband` and `NewWideband` for Narrowband and Wideband,respectively.
-- The `DatasetCreator` class allows writing a `NewDataset` object to disk. Use to load the dataset back in later.
-- The `StaticDataset` class allows for loading a datataset from disk back into memory.
-  - Can access previosly generated samples.
-  - `StaticNarrowband` and `StaticWideband` are subclasses to be used.
+- **Unified Dataset Architecture**: TorchSig 2.0 features a single, flexible dataset system that supports both signal classification (single signal) and signal detection (multiple signals) tasks through configuration.
+- **Comprehensive Signal Library**: Support for 70+ signal types across all major modulation families (FSK, QAM, PSK, ASK, OFDM, Analog) with realistic impairments and channel effects.
+- **Advanced Transform System**: Numerous signals processing transforms enable existing ML techniques to be employed on signals data, with unified impairment models supporting perfect, cabled, and wireless channel conditions.
+- **Web-based UI**: Complete offline web interface for dataset creation, model training, interactive labeling, and visualization - no internet connection required.
+- TorchSig also includes a model API similar to open source code in other ML domains, where several state-of-the-art convolutional and transformer-based neural architectures have been adapted to the signals domain. These models can be easily used for follow-on research in the form of additional hyperparameter tuning, out-of-the-box comparative analysis/evaluations, and/or fine-tuning to custom datasets.
 
+## Core Classes
+- **`Signal` and `SignalMetadata`**: Enable signal objects and metadata to be seamlessly handled and operated on throughout the TorchSig infrastructure.
+- **`TorchSigIterableDataset`**: Unified dataset class that synthetically creates, augments, and transforms signals datasets. Behavior (classification vs detection) is determined by configuration parameters.
+  - Can generate samples infinitely when `num_samples=None`, or finite datasets when `num_samples` is specified.
+  - Dataset type determined by `num_signals_max`: 1 for classification, >1 for detection tasks.
+- **`DatasetCreator`**: Writes `TorchSigIterableDataset` objects to disk with progress tracking and memory optimization.
+- **`StaticTorchSigDataset`**: Loads previously generated datasets from disk back into memory.
+  - Can access previously generated samples efficiently.
+  - Supports both classification and detection datasets through unified interface.
+- **`DatasetMetadata`**: Unified configuration class that replaces separate narrowband/wideband metadata classes.
 
 
 
@@ -98,6 +158,7 @@ TorchSig is released under the MIT License. The MIT license is a popular open-so
 # Publications
 | Title | Year  | Cite (APA) |
 | ----- | ----  | ---------- |
+| [TorchSig 2.0: Dataset Customization, New Transforms and Future Plans](https://events.gnuradio.org/event/26/contributions/752/) | 2025 | Oh, E., Mullins, J., Carrick, M., Vondal, M., Hoffman, J., Leonardo, F., Toliver, P., Miller, R. (2025, September). TorchSig 2.0: Dataset Customization, New Transforms and Future Plans. In Proceedings of the GNU Radio Conference (Vol. 10, No. 1). |
 | [TorchSig: A GNU Radio Block and New Spectrogram Tools for Augmenting ML Training](https://events.gnuradio.org/event/24/contributions/628/) | 2024 | Vallance, P., Oh, E., Mullins, J., Gulati, M., Hoffman, J., & Carrick, M. (2024, September). TorchSig: A GNU Radio Block and New Spectrogram Tools for Augmenting ML Training. In Proceedings of the GNU Radio Conference (Vol. 9, No. 1). |
 | [Large Scale Radio Frequency Wideband Signal Detection & Recognition](https://doi.org/10.48550/arXiv.2211.10335)| 2022 | Boegner, L., Vanhoy, G., Vallance, P., Gulati, M., Feitzinger, D., Comar, B., & Miller, R. D. (2022). Large Scale Radio Frequency Wideband Signal Detection & Recognition. arXiv preprint arXiv:2211.10335. |
 | [Large Scale Radio Frequency Signal Classification](https://doi.org/10.48550/arXiv.2207.09918) | 2022 | Boegner, L., Gulati, M., Vanhoy, G., Vallance, P., Comar, B., Kokalj-Filipovic, S., ... & Miller, R. D. (2022). Large Scale Radio Frequency Signal Classification. arXiv preprint arXiv:2207.09918. |
diff --git a/docker-compose.yml b/docker-compose.yml
deleted file mode 100755
index 0b5ea7289..000000000
--- a/docker-compose.yml
+++ /dev/null
@@ -1,23 +0,0 @@
-name: torch_sig_container_${PROJECT_NAME}
-services:
-    torchsig_service:
-        build: .
-        image: torchsig_github
-        container_name: torchsig_${PROJECT_NAME}
-        stdin_open: true
-        tty: true
-        volumes:
-            - ./:/workspace/code
-        ports:
-            - '${JUP_PORT}:${JUP_PORT}'
-        environment:
-            - NVIDIA_VISIBLE_DEVICES=all
-            - NVIDIA_DRIVER_CAPABILITIES=all
-        command: jupyter lab --allow-root --ip=0.0.0.0 --no-browser --port ${JUP_PORT} --NotebookApp.token=''
-        shm_size: 512GB
-        deploy:
-            resources:
-                reservations:
-                    devices:
-                        - capabilities: [gpu]
-                          driver: nvidia
diff --git a/docs/_autosummary/torchsig.datasets.datamodules.NarrowbandDataModule.rst b/docs/_autosummary/torchsig.datasets.datamodules.NarrowbandDataModule.rst
deleted file mode 100644
index 9a00ceea2..000000000
--- a/docs/_autosummary/torchsig.datasets.datamodules.NarrowbandDataModule.rst
+++ /dev/null
@@ -1,51 +0,0 @@
-torchsig.datasets.datamodules.NarrowbandDataModule
-==================================================
-
-.. currentmodule:: torchsig.datasets.datamodules
-
-.. autoclass:: NarrowbandDataModule
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~NarrowbandDataModule.from_datasets
-      ~NarrowbandDataModule.load_from_checkpoint
-      ~NarrowbandDataModule.load_state_dict
-      ~NarrowbandDataModule.on_after_batch_transfer
-      ~NarrowbandDataModule.on_before_batch_transfer
-      ~NarrowbandDataModule.on_exception
-      ~NarrowbandDataModule.predict_dataloader
-      ~NarrowbandDataModule.prepare_data
-      ~NarrowbandDataModule.save_hyperparameters
-      ~NarrowbandDataModule.setup
-      ~NarrowbandDataModule.state_dict
-      ~NarrowbandDataModule.teardown
-      ~NarrowbandDataModule.test_dataloader
-      ~NarrowbandDataModule.train_dataloader
-      ~NarrowbandDataModule.transfer_batch_to_device
-      ~NarrowbandDataModule.val_dataloader
-   
-   
-
-   
-   
-   .. rubric:: Attributes
-
-   .. autosummary::
-   
-      ~NarrowbandDataModule.CHECKPOINT_HYPER_PARAMS_KEY
-      ~NarrowbandDataModule.CHECKPOINT_HYPER_PARAMS_NAME
-      ~NarrowbandDataModule.CHECKPOINT_HYPER_PARAMS_TYPE
-      ~NarrowbandDataModule.hparams
-      ~NarrowbandDataModule.hparams_initial
-      ~NarrowbandDataModule.name
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.datasets.datamodules.OfficialNarrowbandDataModule.rst b/docs/_autosummary/torchsig.datasets.datamodules.OfficialNarrowbandDataModule.rst
deleted file mode 100644
index 0bdd8ed3b..000000000
--- a/docs/_autosummary/torchsig.datasets.datamodules.OfficialNarrowbandDataModule.rst
+++ /dev/null
@@ -1,51 +0,0 @@
-torchsig.datasets.datamodules.OfficialNarrowbandDataModule
-==========================================================
-
-.. currentmodule:: torchsig.datasets.datamodules
-
-.. autoclass:: OfficialNarrowbandDataModule
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~OfficialNarrowbandDataModule.from_datasets
-      ~OfficialNarrowbandDataModule.load_from_checkpoint
-      ~OfficialNarrowbandDataModule.load_state_dict
-      ~OfficialNarrowbandDataModule.on_after_batch_transfer
-      ~OfficialNarrowbandDataModule.on_before_batch_transfer
-      ~OfficialNarrowbandDataModule.on_exception
-      ~OfficialNarrowbandDataModule.predict_dataloader
-      ~OfficialNarrowbandDataModule.prepare_data
-      ~OfficialNarrowbandDataModule.save_hyperparameters
-      ~OfficialNarrowbandDataModule.setup
-      ~OfficialNarrowbandDataModule.state_dict
-      ~OfficialNarrowbandDataModule.teardown
-      ~OfficialNarrowbandDataModule.test_dataloader
-      ~OfficialNarrowbandDataModule.train_dataloader
-      ~OfficialNarrowbandDataModule.transfer_batch_to_device
-      ~OfficialNarrowbandDataModule.val_dataloader
-   
-   
-
-   
-   
-   .. rubric:: Attributes
-
-   .. autosummary::
-   
-      ~OfficialNarrowbandDataModule.CHECKPOINT_HYPER_PARAMS_KEY
-      ~OfficialNarrowbandDataModule.CHECKPOINT_HYPER_PARAMS_NAME
-      ~OfficialNarrowbandDataModule.CHECKPOINT_HYPER_PARAMS_TYPE
-      ~OfficialNarrowbandDataModule.hparams
-      ~OfficialNarrowbandDataModule.hparams_initial
-      ~OfficialNarrowbandDataModule.name
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.datasets.datamodules.OfficialTorchSigDataModdule.rst b/docs/_autosummary/torchsig.datasets.datamodules.OfficialTorchSigDataModdule.rst
deleted file mode 100644
index 0a934a825..000000000
--- a/docs/_autosummary/torchsig.datasets.datamodules.OfficialTorchSigDataModdule.rst
+++ /dev/null
@@ -1,51 +0,0 @@
-torchsig.datasets.datamodules.OfficialTorchSigDataModdule
-=========================================================
-
-.. currentmodule:: torchsig.datasets.datamodules
-
-.. autoclass:: OfficialTorchSigDataModdule
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~OfficialTorchSigDataModdule.from_datasets
-      ~OfficialTorchSigDataModdule.load_from_checkpoint
-      ~OfficialTorchSigDataModdule.load_state_dict
-      ~OfficialTorchSigDataModdule.on_after_batch_transfer
-      ~OfficialTorchSigDataModdule.on_before_batch_transfer
-      ~OfficialTorchSigDataModdule.on_exception
-      ~OfficialTorchSigDataModdule.predict_dataloader
-      ~OfficialTorchSigDataModdule.prepare_data
-      ~OfficialTorchSigDataModdule.save_hyperparameters
-      ~OfficialTorchSigDataModdule.setup
-      ~OfficialTorchSigDataModdule.state_dict
-      ~OfficialTorchSigDataModdule.teardown
-      ~OfficialTorchSigDataModdule.test_dataloader
-      ~OfficialTorchSigDataModdule.train_dataloader
-      ~OfficialTorchSigDataModdule.transfer_batch_to_device
-      ~OfficialTorchSigDataModdule.val_dataloader
-   
-   
-
-   
-   
-   .. rubric:: Attributes
-
-   .. autosummary::
-   
-      ~OfficialTorchSigDataModdule.CHECKPOINT_HYPER_PARAMS_KEY
-      ~OfficialTorchSigDataModdule.CHECKPOINT_HYPER_PARAMS_NAME
-      ~OfficialTorchSigDataModdule.CHECKPOINT_HYPER_PARAMS_TYPE
-      ~OfficialTorchSigDataModdule.hparams
-      ~OfficialTorchSigDataModdule.hparams_initial
-      ~OfficialTorchSigDataModdule.name
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.datasets.datamodules.OfficialWidebandDataModule.rst b/docs/_autosummary/torchsig.datasets.datamodules.OfficialWidebandDataModule.rst
deleted file mode 100644
index c571518c5..000000000
--- a/docs/_autosummary/torchsig.datasets.datamodules.OfficialWidebandDataModule.rst
+++ /dev/null
@@ -1,51 +0,0 @@
-torchsig.datasets.datamodules.OfficialWidebandDataModule
-========================================================
-
-.. currentmodule:: torchsig.datasets.datamodules
-
-.. autoclass:: OfficialWidebandDataModule
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~OfficialWidebandDataModule.from_datasets
-      ~OfficialWidebandDataModule.load_from_checkpoint
-      ~OfficialWidebandDataModule.load_state_dict
-      ~OfficialWidebandDataModule.on_after_batch_transfer
-      ~OfficialWidebandDataModule.on_before_batch_transfer
-      ~OfficialWidebandDataModule.on_exception
-      ~OfficialWidebandDataModule.predict_dataloader
-      ~OfficialWidebandDataModule.prepare_data
-      ~OfficialWidebandDataModule.save_hyperparameters
-      ~OfficialWidebandDataModule.setup
-      ~OfficialWidebandDataModule.state_dict
-      ~OfficialWidebandDataModule.teardown
-      ~OfficialWidebandDataModule.test_dataloader
-      ~OfficialWidebandDataModule.train_dataloader
-      ~OfficialWidebandDataModule.transfer_batch_to_device
-      ~OfficialWidebandDataModule.val_dataloader
-   
-   
-
-   
-   
-   .. rubric:: Attributes
-
-   .. autosummary::
-   
-      ~OfficialWidebandDataModule.CHECKPOINT_HYPER_PARAMS_KEY
-      ~OfficialWidebandDataModule.CHECKPOINT_HYPER_PARAMS_NAME
-      ~OfficialWidebandDataModule.CHECKPOINT_HYPER_PARAMS_TYPE
-      ~OfficialWidebandDataModule.hparams
-      ~OfficialWidebandDataModule.hparams_initial
-      ~OfficialWidebandDataModule.name
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.datasets.datamodules.TorchSigDataModule.rst b/docs/_autosummary/torchsig.datasets.datamodules.TorchSigDataModule.rst
deleted file mode 100644
index 2641f88b5..000000000
--- a/docs/_autosummary/torchsig.datasets.datamodules.TorchSigDataModule.rst
+++ /dev/null
@@ -1,51 +0,0 @@
-torchsig.datasets.datamodules.TorchSigDataModule
-================================================
-
-.. currentmodule:: torchsig.datasets.datamodules
-
-.. autoclass:: TorchSigDataModule
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~TorchSigDataModule.from_datasets
-      ~TorchSigDataModule.load_from_checkpoint
-      ~TorchSigDataModule.load_state_dict
-      ~TorchSigDataModule.on_after_batch_transfer
-      ~TorchSigDataModule.on_before_batch_transfer
-      ~TorchSigDataModule.on_exception
-      ~TorchSigDataModule.predict_dataloader
-      ~TorchSigDataModule.prepare_data
-      ~TorchSigDataModule.save_hyperparameters
-      ~TorchSigDataModule.setup
-      ~TorchSigDataModule.state_dict
-      ~TorchSigDataModule.teardown
-      ~TorchSigDataModule.test_dataloader
-      ~TorchSigDataModule.train_dataloader
-      ~TorchSigDataModule.transfer_batch_to_device
-      ~TorchSigDataModule.val_dataloader
-   
-   
-
-   
-   
-   .. rubric:: Attributes
-
-   .. autosummary::
-   
-      ~TorchSigDataModule.CHECKPOINT_HYPER_PARAMS_KEY
-      ~TorchSigDataModule.CHECKPOINT_HYPER_PARAMS_NAME
-      ~TorchSigDataModule.CHECKPOINT_HYPER_PARAMS_TYPE
-      ~TorchSigDataModule.hparams
-      ~TorchSigDataModule.hparams_initial
-      ~TorchSigDataModule.name
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.datasets.datamodules.WidebandDataModule.rst b/docs/_autosummary/torchsig.datasets.datamodules.WidebandDataModule.rst
deleted file mode 100644
index c1f5e25fe..000000000
--- a/docs/_autosummary/torchsig.datasets.datamodules.WidebandDataModule.rst
+++ /dev/null
@@ -1,51 +0,0 @@
-torchsig.datasets.datamodules.WidebandDataModule
-================================================
-
-.. currentmodule:: torchsig.datasets.datamodules
-
-.. autoclass:: WidebandDataModule
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~WidebandDataModule.from_datasets
-      ~WidebandDataModule.load_from_checkpoint
-      ~WidebandDataModule.load_state_dict
-      ~WidebandDataModule.on_after_batch_transfer
-      ~WidebandDataModule.on_before_batch_transfer
-      ~WidebandDataModule.on_exception
-      ~WidebandDataModule.predict_dataloader
-      ~WidebandDataModule.prepare_data
-      ~WidebandDataModule.save_hyperparameters
-      ~WidebandDataModule.setup
-      ~WidebandDataModule.state_dict
-      ~WidebandDataModule.teardown
-      ~WidebandDataModule.test_dataloader
-      ~WidebandDataModule.train_dataloader
-      ~WidebandDataModule.transfer_batch_to_device
-      ~WidebandDataModule.val_dataloader
-   
-   
-
-   
-   
-   .. rubric:: Attributes
-
-   .. autosummary::
-   
-      ~WidebandDataModule.CHECKPOINT_HYPER_PARAMS_KEY
-      ~WidebandDataModule.CHECKPOINT_HYPER_PARAMS_NAME
-      ~WidebandDataModule.CHECKPOINT_HYPER_PARAMS_TYPE
-      ~WidebandDataModule.hparams
-      ~WidebandDataModule.hparams_initial
-      ~WidebandDataModule.name
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.datasets.datamodules.rst b/docs/_autosummary/torchsig.datasets.datamodules.rst
deleted file mode 100644
index cf86c5e49..000000000
--- a/docs/_autosummary/torchsig.datasets.datamodules.rst
+++ /dev/null
@@ -1,37 +0,0 @@
-torchsig.datasets.datamodules
-=============================
-
-.. automodule:: torchsig.datasets.datamodules
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Classes
-
-   .. autosummary::
-      :toctree:
-      :template: custom_class_template.rst
-      :nosignatures:
-   
-      NarrowbandDataModule
-      OfficialNarrowbandDataModule
-      OfficialTorchSigDataModdule
-      OfficialWidebandDataModule
-      TorchSigDataModule
-      WidebandDataModule
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.datasets.dataset_metadata.DatasetMetadata.rst b/docs/_autosummary/torchsig.datasets.dataset_metadata.DatasetMetadata.rst
deleted file mode 100644
index 4847eefa4..000000000
--- a/docs/_autosummary/torchsig.datasets.dataset_metadata.DatasetMetadata.rst
+++ /dev/null
@@ -1,77 +0,0 @@
-torchsig.datasets.dataset\_metadata.DatasetMetadata
-===================================================
-
-.. currentmodule:: torchsig.datasets.dataset_metadata
-
-.. autoclass:: DatasetMetadata
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~DatasetMetadata.add_parent
-      ~DatasetMetadata.get_distribution
-      ~DatasetMetadata.get_second_seed
-      ~DatasetMetadata.seed
-      ~DatasetMetadata.setup_rngs
-      ~DatasetMetadata.to_dict
-      ~DatasetMetadata.update_from_parent
-   
-   
-
-   
-   
-   .. rubric:: Attributes
-
-   .. autosummary::
-   
-      ~DatasetMetadata.class_distribution
-      ~DatasetMetadata.class_list
-      ~DatasetMetadata.dataset_bandwidth_max
-      ~DatasetMetadata.dataset_bandwidth_min
-      ~DatasetMetadata.dataset_center_freq_max
-      ~DatasetMetadata.dataset_center_freq_min
-      ~DatasetMetadata.dataset_duration_in_samples_max
-      ~DatasetMetadata.dataset_duration_in_samples_min
-      ~DatasetMetadata.dataset_duration_max
-      ~DatasetMetadata.dataset_duration_min
-      ~DatasetMetadata.dataset_type
-      ~DatasetMetadata.fft_frequency_max
-      ~DatasetMetadata.fft_frequency_min
-      ~DatasetMetadata.fft_frequency_resolution
-      ~DatasetMetadata.fft_size
-      ~DatasetMetadata.fft_stride
-      ~DatasetMetadata.frequency_max
-      ~DatasetMetadata.frequency_min
-      ~DatasetMetadata.impairment_level
-      ~DatasetMetadata.impairments
-      ~DatasetMetadata.minimum_params
-      ~DatasetMetadata.noise_power_db
-      ~DatasetMetadata.num_iq_samples_dataset
-      ~DatasetMetadata.num_samples
-      ~DatasetMetadata.num_signals_distribution
-      ~DatasetMetadata.num_signals_max
-      ~DatasetMetadata.num_signals_min
-      ~DatasetMetadata.num_signals_range
-      ~DatasetMetadata.sample_rate
-      ~DatasetMetadata.signal_bandwidth_max
-      ~DatasetMetadata.signal_bandwidth_min
-      ~DatasetMetadata.signal_center_freq_max
-      ~DatasetMetadata.signal_center_freq_min
-      ~DatasetMetadata.signal_duration_in_samples_max
-      ~DatasetMetadata.signal_duration_in_samples_min
-      ~DatasetMetadata.signal_duration_max
-      ~DatasetMetadata.signal_duration_min
-      ~DatasetMetadata.snr_db_max
-      ~DatasetMetadata.snr_db_min
-      ~DatasetMetadata.target_transforms
-      ~DatasetMetadata.transforms
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.datasets.dataset_metadata.NarrowbandMetadata.rst b/docs/_autosummary/torchsig.datasets.dataset_metadata.NarrowbandMetadata.rst
deleted file mode 100644
index 8e9a437e7..000000000
--- a/docs/_autosummary/torchsig.datasets.dataset_metadata.NarrowbandMetadata.rst
+++ /dev/null
@@ -1,77 +0,0 @@
-torchsig.datasets.dataset\_metadata.NarrowbandMetadata
-======================================================
-
-.. currentmodule:: torchsig.datasets.dataset_metadata
-
-.. autoclass:: NarrowbandMetadata
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~NarrowbandMetadata.add_parent
-      ~NarrowbandMetadata.get_distribution
-      ~NarrowbandMetadata.get_second_seed
-      ~NarrowbandMetadata.seed
-      ~NarrowbandMetadata.setup_rngs
-      ~NarrowbandMetadata.to_dict
-      ~NarrowbandMetadata.update_from_parent
-   
-   
-
-   
-   
-   .. rubric:: Attributes
-
-   .. autosummary::
-   
-      ~NarrowbandMetadata.class_distribution
-      ~NarrowbandMetadata.class_list
-      ~NarrowbandMetadata.dataset_bandwidth_max
-      ~NarrowbandMetadata.dataset_bandwidth_min
-      ~NarrowbandMetadata.dataset_center_freq_max
-      ~NarrowbandMetadata.dataset_center_freq_min
-      ~NarrowbandMetadata.dataset_duration_in_samples_max
-      ~NarrowbandMetadata.dataset_duration_in_samples_min
-      ~NarrowbandMetadata.dataset_duration_max
-      ~NarrowbandMetadata.dataset_duration_min
-      ~NarrowbandMetadata.dataset_type
-      ~NarrowbandMetadata.fft_frequency_max
-      ~NarrowbandMetadata.fft_frequency_min
-      ~NarrowbandMetadata.fft_frequency_resolution
-      ~NarrowbandMetadata.fft_size
-      ~NarrowbandMetadata.fft_stride
-      ~NarrowbandMetadata.frequency_max
-      ~NarrowbandMetadata.frequency_min
-      ~NarrowbandMetadata.impairment_level
-      ~NarrowbandMetadata.impairments
-      ~NarrowbandMetadata.minimum_params
-      ~NarrowbandMetadata.noise_power_db
-      ~NarrowbandMetadata.num_iq_samples_dataset
-      ~NarrowbandMetadata.num_samples
-      ~NarrowbandMetadata.num_signals_distribution
-      ~NarrowbandMetadata.num_signals_max
-      ~NarrowbandMetadata.num_signals_min
-      ~NarrowbandMetadata.num_signals_range
-      ~NarrowbandMetadata.sample_rate
-      ~NarrowbandMetadata.signal_bandwidth_max
-      ~NarrowbandMetadata.signal_bandwidth_min
-      ~NarrowbandMetadata.signal_center_freq_max
-      ~NarrowbandMetadata.signal_center_freq_min
-      ~NarrowbandMetadata.signal_duration_in_samples_max
-      ~NarrowbandMetadata.signal_duration_in_samples_min
-      ~NarrowbandMetadata.signal_duration_max
-      ~NarrowbandMetadata.signal_duration_min
-      ~NarrowbandMetadata.snr_db_max
-      ~NarrowbandMetadata.snr_db_min
-      ~NarrowbandMetadata.target_transforms
-      ~NarrowbandMetadata.transforms
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.datasets.dataset_metadata.WidebandMetadata.rst b/docs/_autosummary/torchsig.datasets.dataset_metadata.WidebandMetadata.rst
deleted file mode 100644
index 1859f71c6..000000000
--- a/docs/_autosummary/torchsig.datasets.dataset_metadata.WidebandMetadata.rst
+++ /dev/null
@@ -1,77 +0,0 @@
-torchsig.datasets.dataset\_metadata.WidebandMetadata
-====================================================
-
-.. currentmodule:: torchsig.datasets.dataset_metadata
-
-.. autoclass:: WidebandMetadata
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~WidebandMetadata.add_parent
-      ~WidebandMetadata.get_distribution
-      ~WidebandMetadata.get_second_seed
-      ~WidebandMetadata.seed
-      ~WidebandMetadata.setup_rngs
-      ~WidebandMetadata.to_dict
-      ~WidebandMetadata.update_from_parent
-   
-   
-
-   
-   
-   .. rubric:: Attributes
-
-   .. autosummary::
-   
-      ~WidebandMetadata.class_distribution
-      ~WidebandMetadata.class_list
-      ~WidebandMetadata.dataset_bandwidth_max
-      ~WidebandMetadata.dataset_bandwidth_min
-      ~WidebandMetadata.dataset_center_freq_max
-      ~WidebandMetadata.dataset_center_freq_min
-      ~WidebandMetadata.dataset_duration_in_samples_max
-      ~WidebandMetadata.dataset_duration_in_samples_min
-      ~WidebandMetadata.dataset_duration_max
-      ~WidebandMetadata.dataset_duration_min
-      ~WidebandMetadata.dataset_type
-      ~WidebandMetadata.fft_frequency_max
-      ~WidebandMetadata.fft_frequency_min
-      ~WidebandMetadata.fft_frequency_resolution
-      ~WidebandMetadata.fft_size
-      ~WidebandMetadata.fft_stride
-      ~WidebandMetadata.frequency_max
-      ~WidebandMetadata.frequency_min
-      ~WidebandMetadata.impairment_level
-      ~WidebandMetadata.impairments
-      ~WidebandMetadata.minimum_params
-      ~WidebandMetadata.noise_power_db
-      ~WidebandMetadata.num_iq_samples_dataset
-      ~WidebandMetadata.num_samples
-      ~WidebandMetadata.num_signals_distribution
-      ~WidebandMetadata.num_signals_max
-      ~WidebandMetadata.num_signals_min
-      ~WidebandMetadata.num_signals_range
-      ~WidebandMetadata.sample_rate
-      ~WidebandMetadata.signal_bandwidth_max
-      ~WidebandMetadata.signal_bandwidth_min
-      ~WidebandMetadata.signal_center_freq_max
-      ~WidebandMetadata.signal_center_freq_min
-      ~WidebandMetadata.signal_duration_in_samples_max
-      ~WidebandMetadata.signal_duration_in_samples_min
-      ~WidebandMetadata.signal_duration_max
-      ~WidebandMetadata.signal_duration_min
-      ~WidebandMetadata.snr_db_max
-      ~WidebandMetadata.snr_db_min
-      ~WidebandMetadata.target_transforms
-      ~WidebandMetadata.transforms
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.datasets.dataset_metadata.rst b/docs/_autosummary/torchsig.datasets.dataset_metadata.rst
deleted file mode 100644
index 5b976dc9f..000000000
--- a/docs/_autosummary/torchsig.datasets.dataset_metadata.rst
+++ /dev/null
@@ -1,34 +0,0 @@
-torchsig.datasets.dataset\_metadata
-===================================
-
-.. automodule:: torchsig.datasets.dataset_metadata
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Classes
-
-   .. autosummary::
-      :toctree:
-      :template: custom_class_template.rst
-      :nosignatures:
-   
-      DatasetMetadata
-      NarrowbandMetadata
-      WidebandMetadata
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.datasets.dataset_utils.collate_fn.rst b/docs/_autosummary/torchsig.datasets.dataset_utils.collate_fn.rst
deleted file mode 100644
index 92caeb0b2..000000000
--- a/docs/_autosummary/torchsig.datasets.dataset_utils.collate_fn.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.datasets.dataset\_utils.collate\_fn
-============================================
-
-.. currentmodule:: torchsig.datasets.dataset_utils
-
-.. autofunction:: collate_fn
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.datasets.dataset_utils.dataset_full_path.rst b/docs/_autosummary/torchsig.datasets.dataset_utils.dataset_full_path.rst
deleted file mode 100644
index 90347873a..000000000
--- a/docs/_autosummary/torchsig.datasets.dataset_utils.dataset_full_path.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.datasets.dataset\_utils.dataset\_full\_path
-====================================================
-
-.. currentmodule:: torchsig.datasets.dataset_utils
-
-.. autofunction:: dataset_full_path
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.datasets.dataset_utils.frequency_shift_signal.rst b/docs/_autosummary/torchsig.datasets.dataset_utils.frequency_shift_signal.rst
deleted file mode 100644
index dcf18e74f..000000000
--- a/docs/_autosummary/torchsig.datasets.dataset_utils.frequency_shift_signal.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.datasets.dataset\_utils.frequency\_shift\_signal
-=========================================================
-
-.. currentmodule:: torchsig.datasets.dataset_utils
-
-.. autofunction:: frequency_shift_signal
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.datasets.dataset_utils.rst b/docs/_autosummary/torchsig.datasets.dataset_utils.rst
deleted file mode 100644
index 86cfe97c6..000000000
--- a/docs/_autosummary/torchsig.datasets.dataset_utils.rst
+++ /dev/null
@@ -1,35 +0,0 @@
-torchsig.datasets.dataset\_utils
-================================
-
-.. automodule:: torchsig.datasets.dataset_utils
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Functions
-
-   .. autosummary::
-      :toctree:
-      :nosignatures:
-   
-      collate_fn
-      dataset_full_path
-      frequency_shift_signal
-      save_type
-      to_dataset_metadata
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.datasets.dataset_utils.save_type.rst b/docs/_autosummary/torchsig.datasets.dataset_utils.save_type.rst
deleted file mode 100644
index bf98ff912..000000000
--- a/docs/_autosummary/torchsig.datasets.dataset_utils.save_type.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.datasets.dataset\_utils.save\_type
-===========================================
-
-.. currentmodule:: torchsig.datasets.dataset_utils
-
-.. autofunction:: save_type
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.datasets.dataset_utils.to_dataset_metadata.rst b/docs/_autosummary/torchsig.datasets.dataset_utils.to_dataset_metadata.rst
deleted file mode 100644
index e04731e5d..000000000
--- a/docs/_autosummary/torchsig.datasets.dataset_utils.to_dataset_metadata.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.datasets.dataset\_utils.to\_dataset\_metadata
-======================================================
-
-.. currentmodule:: torchsig.datasets.dataset_utils
-
-.. autofunction:: to_dataset_metadata
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.datasets.datasets.NewTorchSigDataset.rst b/docs/_autosummary/torchsig.datasets.datasets.NewTorchSigDataset.rst
deleted file mode 100644
index 88bd03c60..000000000
--- a/docs/_autosummary/torchsig.datasets.datasets.NewTorchSigDataset.rst
+++ /dev/null
@@ -1,37 +0,0 @@
-torchsig.datasets.datasets.NewTorchSigDataset
-=============================================
-
-.. currentmodule:: torchsig.datasets.datasets
-
-.. autoclass:: NewTorchSigDataset
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~NewTorchSigDataset.add_parent
-      ~NewTorchSigDataset.get_distribution
-      ~NewTorchSigDataset.get_second_seed
-      ~NewTorchSigDataset.reset
-      ~NewTorchSigDataset.seed
-      ~NewTorchSigDataset.setup_rngs
-      ~NewTorchSigDataset.update_from_parent
-   
-   
-
-   
-   
-   .. rubric:: Attributes
-
-   .. autosummary::
-   
-      ~NewTorchSigDataset.dataset_metadata
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.datasets.datasets.StaticTorchSigDataset.rst b/docs/_autosummary/torchsig.datasets.datasets.StaticTorchSigDataset.rst
deleted file mode 100644
index c3429faa2..000000000
--- a/docs/_autosummary/torchsig.datasets.datasets.StaticTorchSigDataset.rst
+++ /dev/null
@@ -1,24 +0,0 @@
-torchsig.datasets.datasets.StaticTorchSigDataset
-================================================
-
-.. currentmodule:: torchsig.datasets.datasets
-
-.. autoclass:: StaticTorchSigDataset
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.datasets.datasets.TorchsigIterableDataset.rst b/docs/_autosummary/torchsig.datasets.datasets.TorchsigIterableDataset.rst
deleted file mode 100644
index 0b1c8955a..000000000
--- a/docs/_autosummary/torchsig.datasets.datasets.TorchsigIterableDataset.rst
+++ /dev/null
@@ -1,37 +0,0 @@
-torchsig.datasets.datasets.TorchsigIterableDataset
-==================================================
-
-.. currentmodule:: torchsig.datasets.datasets
-
-.. autoclass:: TorchsigIterableDataset
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~TorchsigIterableDataset.add_parent
-      ~TorchsigIterableDataset.get_distribution
-      ~TorchsigIterableDataset.get_second_seed
-      ~TorchsigIterableDataset.reset
-      ~TorchsigIterableDataset.seed
-      ~TorchsigIterableDataset.setup_rngs
-      ~TorchsigIterableDataset.update_from_parent
-   
-   
-
-   
-   
-   .. rubric:: Attributes
-
-   .. autosummary::
-   
-      ~TorchsigIterableDataset.dataset_metadata
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.datasets.datasets.rst b/docs/_autosummary/torchsig.datasets.datasets.rst
deleted file mode 100644
index ee8ea31a9..000000000
--- a/docs/_autosummary/torchsig.datasets.datasets.rst
+++ /dev/null
@@ -1,34 +0,0 @@
-torchsig.datasets.datasets
-==========================
-
-.. automodule:: torchsig.datasets.datasets
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Classes
-
-   .. autosummary::
-      :toctree:
-      :template: custom_class_template.rst
-      :nosignatures:
-   
-      NewTorchSigDataset
-      StaticTorchSigDataset
-      TorchsigIterableDataset
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.datasets.default_configs.loader.get_default_yaml_config.rst b/docs/_autosummary/torchsig.datasets.default_configs.loader.get_default_yaml_config.rst
deleted file mode 100644
index 9fa4f0424..000000000
--- a/docs/_autosummary/torchsig.datasets.default_configs.loader.get_default_yaml_config.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.datasets.default\_configs.loader.get\_default\_yaml\_config
-====================================================================
-
-.. currentmodule:: torchsig.datasets.default_configs.loader
-
-.. autofunction:: get_default_yaml_config
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.datasets.default_configs.loader.rst b/docs/_autosummary/torchsig.datasets.default_configs.loader.rst
deleted file mode 100644
index 90c085da4..000000000
--- a/docs/_autosummary/torchsig.datasets.default_configs.loader.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.datasets.default\_configs.loader
-=========================================
-
-.. automodule:: torchsig.datasets.default_configs.loader
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Functions
-
-   .. autosummary::
-      :toctree:
-      :nosignatures:
-   
-      get_default_yaml_config
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.datasets.default_configs.rst b/docs/_autosummary/torchsig.datasets.default_configs.rst
deleted file mode 100644
index 00ae2b5b5..000000000
--- a/docs/_autosummary/torchsig.datasets.default_configs.rst
+++ /dev/null
@@ -1,30 +0,0 @@
-torchsig.datasets.default\_configs
-==================================
-
-.. automodule:: torchsig.datasets.default_configs
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-
-
-.. autosummary::
-   :toctree:
-   :template: custom_module_template.rst
-   :recursive:
-
-   loader
-
diff --git a/docs/_autosummary/torchsig.datasets.narrowband.NewNarrowband.rst b/docs/_autosummary/torchsig.datasets.narrowband.NewNarrowband.rst
deleted file mode 100644
index 52aa43dd7..000000000
--- a/docs/_autosummary/torchsig.datasets.narrowband.NewNarrowband.rst
+++ /dev/null
@@ -1,37 +0,0 @@
-torchsig.datasets.narrowband.NewNarrowband
-==========================================
-
-.. currentmodule:: torchsig.datasets.narrowband
-
-.. autoclass:: NewNarrowband
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~NewNarrowband.add_parent
-      ~NewNarrowband.get_distribution
-      ~NewNarrowband.get_second_seed
-      ~NewNarrowband.reset
-      ~NewNarrowband.seed
-      ~NewNarrowband.setup_rngs
-      ~NewNarrowband.update_from_parent
-   
-   
-
-   
-   
-   .. rubric:: Attributes
-
-   .. autosummary::
-   
-      ~NewNarrowband.dataset_metadata
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.datasets.narrowband.StaticNarrowband.rst b/docs/_autosummary/torchsig.datasets.narrowband.StaticNarrowband.rst
deleted file mode 100644
index c494dca73..000000000
--- a/docs/_autosummary/torchsig.datasets.narrowband.StaticNarrowband.rst
+++ /dev/null
@@ -1,24 +0,0 @@
-torchsig.datasets.narrowband.StaticNarrowband
-=============================================
-
-.. currentmodule:: torchsig.datasets.narrowband
-
-.. autoclass:: StaticNarrowband
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.datasets.narrowband.rst b/docs/_autosummary/torchsig.datasets.narrowband.rst
deleted file mode 100644
index dd8243fc7..000000000
--- a/docs/_autosummary/torchsig.datasets.narrowband.rst
+++ /dev/null
@@ -1,33 +0,0 @@
-torchsig.datasets.narrowband
-============================
-
-.. automodule:: torchsig.datasets.narrowband
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Classes
-
-   .. autosummary::
-      :toctree:
-      :template: custom_class_template.rst
-      :nosignatures:
-   
-      NewNarrowband
-      StaticNarrowband
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.datasets.rst b/docs/_autosummary/torchsig.datasets.rst
deleted file mode 100644
index bfed2c0ee..000000000
--- a/docs/_autosummary/torchsig.datasets.rst
+++ /dev/null
@@ -1,37 +0,0 @@
-torchsig.datasets
-=================
-
-.. automodule:: torchsig.datasets
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-
-
-.. autosummary::
-   :toctree:
-   :template: custom_module_template.rst
-   :recursive:
-
-   custom_datasets
-   datamodules
-   dataset_metadata
-   dataset_utils
-   datasets
-   default_configs
-   narrowband
-   wideband
-
diff --git a/docs/_autosummary/torchsig.datasets.wideband.NewWideband.rst b/docs/_autosummary/torchsig.datasets.wideband.NewWideband.rst
deleted file mode 100644
index 392af8911..000000000
--- a/docs/_autosummary/torchsig.datasets.wideband.NewWideband.rst
+++ /dev/null
@@ -1,37 +0,0 @@
-torchsig.datasets.wideband.NewWideband
-======================================
-
-.. currentmodule:: torchsig.datasets.wideband
-
-.. autoclass:: NewWideband
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~NewWideband.add_parent
-      ~NewWideband.get_distribution
-      ~NewWideband.get_second_seed
-      ~NewWideband.reset
-      ~NewWideband.seed
-      ~NewWideband.setup_rngs
-      ~NewWideband.update_from_parent
-   
-   
-
-   
-   
-   .. rubric:: Attributes
-
-   .. autosummary::
-   
-      ~NewWideband.dataset_metadata
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.datasets.wideband.StaticWideband.rst b/docs/_autosummary/torchsig.datasets.wideband.StaticWideband.rst
deleted file mode 100644
index e6032c772..000000000
--- a/docs/_autosummary/torchsig.datasets.wideband.StaticWideband.rst
+++ /dev/null
@@ -1,24 +0,0 @@
-torchsig.datasets.wideband.StaticWideband
-=========================================
-
-.. currentmodule:: torchsig.datasets.wideband
-
-.. autoclass:: StaticWideband
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.datasets.wideband.rst b/docs/_autosummary/torchsig.datasets.wideband.rst
deleted file mode 100644
index d93013dc3..000000000
--- a/docs/_autosummary/torchsig.datasets.wideband.rst
+++ /dev/null
@@ -1,33 +0,0 @@
-torchsig.datasets.wideband
-==========================
-
-.. automodule:: torchsig.datasets.wideband
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Classes
-
-   .. autosummary::
-      :toctree:
-      :template: custom_class_template.rst
-      :nosignatures:
-   
-      NewWideband
-      StaticWideband
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.image_datasets.dataset_generation.batched_write_yolo_synthetic_dataset.rst b/docs/_autosummary/torchsig.image_datasets.dataset_generation.batched_write_yolo_synthetic_dataset.rst
deleted file mode 100644
index 62c179a5a..000000000
--- a/docs/_autosummary/torchsig.image_datasets.dataset_generation.batched_write_yolo_synthetic_dataset.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.image\_datasets.dataset\_generation.batched\_write\_yolo\_synthetic\_dataset
-=====================================================================================
-
-.. currentmodule:: torchsig.image_datasets.dataset_generation
-
-.. autofunction:: batched_write_yolo_synthetic_dataset
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.image_datasets.dataset_generation.rst b/docs/_autosummary/torchsig.image_datasets.dataset_generation.rst
deleted file mode 100644
index 650dd5495..000000000
--- a/docs/_autosummary/torchsig.image_datasets.dataset_generation.rst
+++ /dev/null
@@ -1,32 +0,0 @@
-torchsig.image\_datasets.dataset\_generation
-============================================
-
-.. automodule:: torchsig.image_datasets.dataset_generation
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Functions
-
-   .. autosummary::
-      :toctree:
-      :nosignatures:
-   
-      batched_write_yolo_synthetic_dataset
-      save_yolo_data
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.image_datasets.dataset_generation.save_yolo_data.rst b/docs/_autosummary/torchsig.image_datasets.dataset_generation.save_yolo_data.rst
deleted file mode 100644
index 9ec5dd5ae..000000000
--- a/docs/_autosummary/torchsig.image_datasets.dataset_generation.save_yolo_data.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.image\_datasets.dataset\_generation.save\_yolo\_data
-=============================================================
-
-.. currentmodule:: torchsig.image_datasets.dataset_generation
-
-.. autofunction:: save_yolo_data
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.image_datasets.datasets.composites.ConcatDataset.rst b/docs/_autosummary/torchsig.image_datasets.datasets.composites.ConcatDataset.rst
deleted file mode 100644
index 36b9f2bcc..000000000
--- a/docs/_autosummary/torchsig.image_datasets.datasets.composites.ConcatDataset.rst
+++ /dev/null
@@ -1,25 +0,0 @@
-torchsig.image\_datasets.datasets.composites.ConcatDataset
-==========================================================
-
-.. currentmodule:: torchsig.image_datasets.datasets.composites
-
-.. autoclass:: ConcatDataset
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~ConcatDataset.next
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.image_datasets.datasets.composites.rst b/docs/_autosummary/torchsig.image_datasets.datasets.composites.rst
deleted file mode 100644
index d35c664d3..000000000
--- a/docs/_autosummary/torchsig.image_datasets.datasets.composites.rst
+++ /dev/null
@@ -1,32 +0,0 @@
-torchsig.image\_datasets.datasets.composites
-============================================
-
-.. automodule:: torchsig.image_datasets.datasets.composites
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Classes
-
-   .. autosummary::
-      :toctree:
-      :template: custom_class_template.rst
-      :nosignatures:
-   
-      ConcatDataset
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.image_datasets.datasets.file_loading_datasets.ImageDirectoryDataset.rst b/docs/_autosummary/torchsig.image_datasets.datasets.file_loading_datasets.ImageDirectoryDataset.rst
deleted file mode 100644
index 35b587cc4..000000000
--- a/docs/_autosummary/torchsig.image_datasets.datasets.file_loading_datasets.ImageDirectoryDataset.rst
+++ /dev/null
@@ -1,25 +0,0 @@
-torchsig.image\_datasets.datasets.file\_loading\_datasets.ImageDirectoryDataset
-===============================================================================
-
-.. currentmodule:: torchsig.image_datasets.datasets.file_loading_datasets
-
-.. autoclass:: ImageDirectoryDataset
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~ImageDirectoryDataset.next
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.image_datasets.datasets.file_loading_datasets.LazyImageDirectoryDataset.rst b/docs/_autosummary/torchsig.image_datasets.datasets.file_loading_datasets.LazyImageDirectoryDataset.rst
deleted file mode 100644
index da0055ff2..000000000
--- a/docs/_autosummary/torchsig.image_datasets.datasets.file_loading_datasets.LazyImageDirectoryDataset.rst
+++ /dev/null
@@ -1,25 +0,0 @@
-torchsig.image\_datasets.datasets.file\_loading\_datasets.LazyImageDirectoryDataset
-===================================================================================
-
-.. currentmodule:: torchsig.image_datasets.datasets.file_loading_datasets
-
-.. autoclass:: LazyImageDirectoryDataset
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~LazyImageDirectoryDataset.next
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.image_datasets.datasets.file_loading_datasets.SOIExtractorDataset.rst b/docs/_autosummary/torchsig.image_datasets.datasets.file_loading_datasets.SOIExtractorDataset.rst
deleted file mode 100644
index 2befb8beb..000000000
--- a/docs/_autosummary/torchsig.image_datasets.datasets.file_loading_datasets.SOIExtractorDataset.rst
+++ /dev/null
@@ -1,25 +0,0 @@
-torchsig.image\_datasets.datasets.file\_loading\_datasets.SOIExtractorDataset
-=============================================================================
-
-.. currentmodule:: torchsig.image_datasets.datasets.file_loading_datasets
-
-.. autoclass:: SOIExtractorDataset
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~SOIExtractorDataset.next
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.image_datasets.datasets.file_loading_datasets.extract_bounding_boxes.rst b/docs/_autosummary/torchsig.image_datasets.datasets.file_loading_datasets.extract_bounding_boxes.rst
deleted file mode 100644
index f699f3cd2..000000000
--- a/docs/_autosummary/torchsig.image_datasets.datasets.file_loading_datasets.extract_bounding_boxes.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.image\_datasets.datasets.file\_loading\_datasets.extract\_bounding\_boxes
-==================================================================================
-
-.. currentmodule:: torchsig.image_datasets.datasets.file_loading_datasets
-
-.. autofunction:: extract_bounding_boxes
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.image_datasets.datasets.file_loading_datasets.extract_bounding_boxes_from_image.rst b/docs/_autosummary/torchsig.image_datasets.datasets.file_loading_datasets.extract_bounding_boxes_from_image.rst
deleted file mode 100644
index 32edda582..000000000
--- a/docs/_autosummary/torchsig.image_datasets.datasets.file_loading_datasets.extract_bounding_boxes_from_image.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.image\_datasets.datasets.file\_loading\_datasets.extract\_bounding\_boxes\_from\_image
-===============================================================================================
-
-.. currentmodule:: torchsig.image_datasets.datasets.file_loading_datasets
-
-.. autofunction:: extract_bounding_boxes_from_image
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.image_datasets.datasets.file_loading_datasets.extract_sois.rst b/docs/_autosummary/torchsig.image_datasets.datasets.file_loading_datasets.extract_sois.rst
deleted file mode 100644
index b8282b853..000000000
--- a/docs/_autosummary/torchsig.image_datasets.datasets.file_loading_datasets.extract_sois.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.image\_datasets.datasets.file\_loading\_datasets.extract\_sois
-=======================================================================
-
-.. currentmodule:: torchsig.image_datasets.datasets.file_loading_datasets
-
-.. autofunction:: extract_sois
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.image_datasets.datasets.file_loading_datasets.isolate_soi.rst b/docs/_autosummary/torchsig.image_datasets.datasets.file_loading_datasets.isolate_soi.rst
deleted file mode 100644
index 60035b7d8..000000000
--- a/docs/_autosummary/torchsig.image_datasets.datasets.file_loading_datasets.isolate_soi.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.image\_datasets.datasets.file\_loading\_datasets.isolate\_soi
-======================================================================
-
-.. currentmodule:: torchsig.image_datasets.datasets.file_loading_datasets
-
-.. autofunction:: isolate_soi
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.image_datasets.datasets.file_loading_datasets.load_image_grey.rst b/docs/_autosummary/torchsig.image_datasets.datasets.file_loading_datasets.load_image_grey.rst
deleted file mode 100644
index 0236f1b11..000000000
--- a/docs/_autosummary/torchsig.image_datasets.datasets.file_loading_datasets.load_image_grey.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.image\_datasets.datasets.file\_loading\_datasets.load\_image\_grey
-===========================================================================
-
-.. currentmodule:: torchsig.image_datasets.datasets.file_loading_datasets
-
-.. autofunction:: load_image_grey
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.image_datasets.datasets.file_loading_datasets.load_image_rgb.rst b/docs/_autosummary/torchsig.image_datasets.datasets.file_loading_datasets.load_image_rgb.rst
deleted file mode 100644
index 07585da2a..000000000
--- a/docs/_autosummary/torchsig.image_datasets.datasets.file_loading_datasets.load_image_rgb.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.image\_datasets.datasets.file\_loading\_datasets.load\_image\_rgb
-==========================================================================
-
-.. currentmodule:: torchsig.image_datasets.datasets.file_loading_datasets
-
-.. autofunction:: load_image_rgb
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.image_datasets.datasets.file_loading_datasets.rst b/docs/_autosummary/torchsig.image_datasets.datasets.file_loading_datasets.rst
deleted file mode 100644
index 3313d831c..000000000
--- a/docs/_autosummary/torchsig.image_datasets.datasets.file_loading_datasets.rst
+++ /dev/null
@@ -1,47 +0,0 @@
-torchsig.image\_datasets.datasets.file\_loading\_datasets
-=========================================================
-
-.. automodule:: torchsig.image_datasets.datasets.file_loading_datasets
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Functions
-
-   .. autosummary::
-      :toctree:
-      :nosignatures:
-   
-      extract_bounding_boxes
-      extract_bounding_boxes_from_image
-      extract_sois
-      isolate_soi
-      load_image_grey
-      load_image_rgb
-   
-   
-
-   
-   
-   .. rubric:: Classes
-
-   .. autosummary::
-      :toctree:
-      :template: custom_class_template.rst
-      :nosignatures:
-   
-      ImageDirectoryDataset
-      LazyImageDirectoryDataset
-      SOIExtractorDataset
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.image_datasets.datasets.protocols.CFGSignalProtocolDataset.rst b/docs/_autosummary/torchsig.image_datasets.datasets.protocols.CFGSignalProtocolDataset.rst
deleted file mode 100644
index 504393317..000000000
--- a/docs/_autosummary/torchsig.image_datasets.datasets.protocols.CFGSignalProtocolDataset.rst
+++ /dev/null
@@ -1,33 +0,0 @@
-torchsig.image\_datasets.datasets.protocols.CFGSignalProtocolDataset
-====================================================================
-
-.. currentmodule:: torchsig.image_datasets.datasets.protocols
-
-.. autoclass:: CFGSignalProtocolDataset
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~CFGSignalProtocolDataset.add_rule
-      ~CFGSignalProtocolDataset.combine_products
-      ~CFGSignalProtocolDataset.compose_data
-      ~CFGSignalProtocolDataset.format_blank_image
-      ~CFGSignalProtocolDataset.get_random_product
-      ~CFGSignalProtocolDataset.get_subproduct_list
-      ~CFGSignalProtocolDataset.get_token_product
-      ~CFGSignalProtocolDataset.next
-      ~CFGSignalProtocolDataset.set_initial_token
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.image_datasets.datasets.protocols.FrequencyHoppingDataset.rst b/docs/_autosummary/torchsig.image_datasets.datasets.protocols.FrequencyHoppingDataset.rst
deleted file mode 100644
index 96199c6eb..000000000
--- a/docs/_autosummary/torchsig.image_datasets.datasets.protocols.FrequencyHoppingDataset.rst
+++ /dev/null
@@ -1,28 +0,0 @@
-torchsig.image\_datasets.datasets.protocols.FrequencyHoppingDataset
-===================================================================
-
-.. currentmodule:: torchsig.image_datasets.datasets.protocols
-
-.. autoclass:: FrequencyHoppingDataset
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~FrequencyHoppingDataset.compose_data
-      ~FrequencyHoppingDataset.format_blank_image
-      ~FrequencyHoppingDataset.generate_hopping_signal
-      ~FrequencyHoppingDataset.next
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.image_datasets.datasets.protocols.VerticalCFGSignalProtocolDataset.rst b/docs/_autosummary/torchsig.image_datasets.datasets.protocols.VerticalCFGSignalProtocolDataset.rst
deleted file mode 100644
index 5cca3bf6f..000000000
--- a/docs/_autosummary/torchsig.image_datasets.datasets.protocols.VerticalCFGSignalProtocolDataset.rst
+++ /dev/null
@@ -1,33 +0,0 @@
-torchsig.image\_datasets.datasets.protocols.VerticalCFGSignalProtocolDataset
-============================================================================
-
-.. currentmodule:: torchsig.image_datasets.datasets.protocols
-
-.. autoclass:: VerticalCFGSignalProtocolDataset
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~VerticalCFGSignalProtocolDataset.add_rule
-      ~VerticalCFGSignalProtocolDataset.combine_products
-      ~VerticalCFGSignalProtocolDataset.compose_data
-      ~VerticalCFGSignalProtocolDataset.format_blank_image
-      ~VerticalCFGSignalProtocolDataset.get_random_product
-      ~VerticalCFGSignalProtocolDataset.get_subproduct_list
-      ~VerticalCFGSignalProtocolDataset.get_token_product
-      ~VerticalCFGSignalProtocolDataset.next
-      ~VerticalCFGSignalProtocolDataset.set_initial_token
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.image_datasets.datasets.protocols.YOLOCFGSignalProtocolDataset.rst b/docs/_autosummary/torchsig.image_datasets.datasets.protocols.YOLOCFGSignalProtocolDataset.rst
deleted file mode 100644
index 990327617..000000000
--- a/docs/_autosummary/torchsig.image_datasets.datasets.protocols.YOLOCFGSignalProtocolDataset.rst
+++ /dev/null
@@ -1,33 +0,0 @@
-torchsig.image\_datasets.datasets.protocols.YOLOCFGSignalProtocolDataset
-========================================================================
-
-.. currentmodule:: torchsig.image_datasets.datasets.protocols
-
-.. autoclass:: YOLOCFGSignalProtocolDataset
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~YOLOCFGSignalProtocolDataset.add_rule
-      ~YOLOCFGSignalProtocolDataset.combine_products
-      ~YOLOCFGSignalProtocolDataset.compose_data
-      ~YOLOCFGSignalProtocolDataset.format_blank_image
-      ~YOLOCFGSignalProtocolDataset.get_random_product
-      ~YOLOCFGSignalProtocolDataset.get_subproduct_list
-      ~YOLOCFGSignalProtocolDataset.get_token_product
-      ~YOLOCFGSignalProtocolDataset.next
-      ~YOLOCFGSignalProtocolDataset.set_initial_token
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.image_datasets.datasets.protocols.YOLOFrequencyHoppingDataset.rst b/docs/_autosummary/torchsig.image_datasets.datasets.protocols.YOLOFrequencyHoppingDataset.rst
deleted file mode 100644
index 9a1362459..000000000
--- a/docs/_autosummary/torchsig.image_datasets.datasets.protocols.YOLOFrequencyHoppingDataset.rst
+++ /dev/null
@@ -1,28 +0,0 @@
-torchsig.image\_datasets.datasets.protocols.YOLOFrequencyHoppingDataset
-=======================================================================
-
-.. currentmodule:: torchsig.image_datasets.datasets.protocols
-
-.. autoclass:: YOLOFrequencyHoppingDataset
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~YOLOFrequencyHoppingDataset.compose_data
-      ~YOLOFrequencyHoppingDataset.format_blank_image
-      ~YOLOFrequencyHoppingDataset.generate_hopping_signal
-      ~YOLOFrequencyHoppingDataset.next
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.image_datasets.datasets.protocols.YOLOVerticalCFGSignalProtocolDataset.rst b/docs/_autosummary/torchsig.image_datasets.datasets.protocols.YOLOVerticalCFGSignalProtocolDataset.rst
deleted file mode 100644
index 3839b0aaa..000000000
--- a/docs/_autosummary/torchsig.image_datasets.datasets.protocols.YOLOVerticalCFGSignalProtocolDataset.rst
+++ /dev/null
@@ -1,33 +0,0 @@
-torchsig.image\_datasets.datasets.protocols.YOLOVerticalCFGSignalProtocolDataset
-================================================================================
-
-.. currentmodule:: torchsig.image_datasets.datasets.protocols
-
-.. autoclass:: YOLOVerticalCFGSignalProtocolDataset
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~YOLOVerticalCFGSignalProtocolDataset.add_rule
-      ~YOLOVerticalCFGSignalProtocolDataset.combine_products
-      ~YOLOVerticalCFGSignalProtocolDataset.compose_data
-      ~YOLOVerticalCFGSignalProtocolDataset.format_blank_image
-      ~YOLOVerticalCFGSignalProtocolDataset.get_random_product
-      ~YOLOVerticalCFGSignalProtocolDataset.get_subproduct_list
-      ~YOLOVerticalCFGSignalProtocolDataset.get_token_product
-      ~YOLOVerticalCFGSignalProtocolDataset.next
-      ~YOLOVerticalCFGSignalProtocolDataset.set_initial_token
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.image_datasets.datasets.protocols.random_hopping.rst b/docs/_autosummary/torchsig.image_datasets.datasets.protocols.random_hopping.rst
deleted file mode 100644
index 5b8afbc55..000000000
--- a/docs/_autosummary/torchsig.image_datasets.datasets.protocols.random_hopping.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.image\_datasets.datasets.protocols.random\_hopping
-===========================================================
-
-.. currentmodule:: torchsig.image_datasets.datasets.protocols
-
-.. autofunction:: random_hopping
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.image_datasets.datasets.protocols.rst b/docs/_autosummary/torchsig.image_datasets.datasets.protocols.rst
deleted file mode 100644
index 6acf0a318..000000000
--- a/docs/_autosummary/torchsig.image_datasets.datasets.protocols.rst
+++ /dev/null
@@ -1,45 +0,0 @@
-torchsig.image\_datasets.datasets.protocols
-===========================================
-
-.. automodule:: torchsig.image_datasets.datasets.protocols
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Functions
-
-   .. autosummary::
-      :toctree:
-      :nosignatures:
-   
-      random_hopping
-   
-   
-
-   
-   
-   .. rubric:: Classes
-
-   .. autosummary::
-      :toctree:
-      :template: custom_class_template.rst
-      :nosignatures:
-   
-      CFGSignalProtocolDataset
-      FrequencyHoppingDataset
-      VerticalCFGSignalProtocolDataset
-      YOLOCFGSignalProtocolDataset
-      YOLOFrequencyHoppingDataset
-      YOLOVerticalCFGSignalProtocolDataset
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.image_datasets.datasets.rst b/docs/_autosummary/torchsig.image_datasets.datasets.rst
deleted file mode 100644
index 00dd88f1c..000000000
--- a/docs/_autosummary/torchsig.image_datasets.datasets.rst
+++ /dev/null
@@ -1,34 +0,0 @@
-torchsig.image\_datasets.datasets
-=================================
-
-.. automodule:: torchsig.image_datasets.datasets
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-
-
-.. autosummary::
-   :toctree:
-   :template: custom_module_template.rst
-   :recursive:
-
-   composites
-   file_loading_datasets
-   protocols
-   synthetic_signals
-   yolo_datasets
-
diff --git a/docs/_autosummary/torchsig.image_datasets.datasets.synthetic_signals.GeneratorFunctionDataset.rst b/docs/_autosummary/torchsig.image_datasets.datasets.synthetic_signals.GeneratorFunctionDataset.rst
deleted file mode 100644
index d69b6de6f..000000000
--- a/docs/_autosummary/torchsig.image_datasets.datasets.synthetic_signals.GeneratorFunctionDataset.rst
+++ /dev/null
@@ -1,25 +0,0 @@
-torchsig.image\_datasets.datasets.synthetic\_signals.GeneratorFunctionDataset
-=============================================================================
-
-.. currentmodule:: torchsig.image_datasets.datasets.synthetic_signals
-
-.. autoclass:: GeneratorFunctionDataset
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~GeneratorFunctionDataset.next
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.image_datasets.datasets.synthetic_signals.chirp_generator_function.rst b/docs/_autosummary/torchsig.image_datasets.datasets.synthetic_signals.chirp_generator_function.rst
deleted file mode 100644
index f8c63cc51..000000000
--- a/docs/_autosummary/torchsig.image_datasets.datasets.synthetic_signals.chirp_generator_function.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.image\_datasets.datasets.synthetic\_signals.chirp\_generator\_function
-===============================================================================
-
-.. currentmodule:: torchsig.image_datasets.datasets.synthetic_signals
-
-.. autofunction:: chirp_generator_function
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.image_datasets.datasets.synthetic_signals.generate_chirp.rst b/docs/_autosummary/torchsig.image_datasets.datasets.synthetic_signals.generate_chirp.rst
deleted file mode 100644
index f8ecc10a7..000000000
--- a/docs/_autosummary/torchsig.image_datasets.datasets.synthetic_signals.generate_chirp.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.image\_datasets.datasets.synthetic\_signals.generate\_chirp
-====================================================================
-
-.. currentmodule:: torchsig.image_datasets.datasets.synthetic_signals
-
-.. autofunction:: generate_chirp
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.image_datasets.datasets.synthetic_signals.generate_rectangle_signal.rst b/docs/_autosummary/torchsig.image_datasets.datasets.synthetic_signals.generate_rectangle_signal.rst
deleted file mode 100644
index c744cf8b4..000000000
--- a/docs/_autosummary/torchsig.image_datasets.datasets.synthetic_signals.generate_rectangle_signal.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.image\_datasets.datasets.synthetic\_signals.generate\_rectangle\_signal
-================================================================================
-
-.. currentmodule:: torchsig.image_datasets.datasets.synthetic_signals
-
-.. autofunction:: generate_rectangle_signal
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.image_datasets.datasets.synthetic_signals.generate_repeated_signal.rst b/docs/_autosummary/torchsig.image_datasets.datasets.synthetic_signals.generate_repeated_signal.rst
deleted file mode 100644
index 5d5fa8258..000000000
--- a/docs/_autosummary/torchsig.image_datasets.datasets.synthetic_signals.generate_repeated_signal.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.image\_datasets.datasets.synthetic\_signals.generate\_repeated\_signal
-===============================================================================
-
-.. currentmodule:: torchsig.image_datasets.datasets.synthetic_signals
-
-.. autofunction:: generate_repeated_signal
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.image_datasets.datasets.synthetic_signals.generate_tone.rst b/docs/_autosummary/torchsig.image_datasets.datasets.synthetic_signals.generate_tone.rst
deleted file mode 100644
index 1136ff6df..000000000
--- a/docs/_autosummary/torchsig.image_datasets.datasets.synthetic_signals.generate_tone.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.image\_datasets.datasets.synthetic\_signals.generate\_tone
-===================================================================
-
-.. currentmodule:: torchsig.image_datasets.datasets.synthetic_signals
-
-.. autofunction:: generate_tone
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.image_datasets.datasets.synthetic_signals.rectangle_signal_generator_function.rst b/docs/_autosummary/torchsig.image_datasets.datasets.synthetic_signals.rectangle_signal_generator_function.rst
deleted file mode 100644
index 274245f2f..000000000
--- a/docs/_autosummary/torchsig.image_datasets.datasets.synthetic_signals.rectangle_signal_generator_function.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.image\_datasets.datasets.synthetic\_signals.rectangle\_signal\_generator\_function
-===========================================================================================
-
-.. currentmodule:: torchsig.image_datasets.datasets.synthetic_signals
-
-.. autofunction:: rectangle_signal_generator_function
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.image_datasets.datasets.synthetic_signals.repeated_signal_generator_function.rst b/docs/_autosummary/torchsig.image_datasets.datasets.synthetic_signals.repeated_signal_generator_function.rst
deleted file mode 100644
index b903f02d8..000000000
--- a/docs/_autosummary/torchsig.image_datasets.datasets.synthetic_signals.repeated_signal_generator_function.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.image\_datasets.datasets.synthetic\_signals.repeated\_signal\_generator\_function
-==========================================================================================
-
-.. currentmodule:: torchsig.image_datasets.datasets.synthetic_signals
-
-.. autofunction:: repeated_signal_generator_function
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.image_datasets.datasets.synthetic_signals.rst b/docs/_autosummary/torchsig.image_datasets.datasets.synthetic_signals.rst
deleted file mode 100644
index 70a1a23cf..000000000
--- a/docs/_autosummary/torchsig.image_datasets.datasets.synthetic_signals.rst
+++ /dev/null
@@ -1,47 +0,0 @@
-torchsig.image\_datasets.datasets.synthetic\_signals
-====================================================
-
-.. automodule:: torchsig.image_datasets.datasets.synthetic_signals
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Functions
-
-   .. autosummary::
-      :toctree:
-      :nosignatures:
-   
-      chirp_generator_function
-      generate_chirp
-      generate_rectangle_signal
-      generate_repeated_signal
-      generate_tone
-      rectangle_signal_generator_function
-      repeated_signal_generator_function
-      tone_generator_function
-   
-   
-
-   
-   
-   .. rubric:: Classes
-
-   .. autosummary::
-      :toctree:
-      :template: custom_class_template.rst
-      :nosignatures:
-   
-      GeneratorFunctionDataset
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.image_datasets.datasets.synthetic_signals.tone_generator_function.rst b/docs/_autosummary/torchsig.image_datasets.datasets.synthetic_signals.tone_generator_function.rst
deleted file mode 100644
index 620ac6f8b..000000000
--- a/docs/_autosummary/torchsig.image_datasets.datasets.synthetic_signals.tone_generator_function.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.image\_datasets.datasets.synthetic\_signals.tone\_generator\_function
-==============================================================================
-
-.. currentmodule:: torchsig.image_datasets.datasets.synthetic_signals
-
-.. autofunction:: tone_generator_function
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.image_datasets.datasets.yolo_datasets.YOLODatasetAdapter.rst b/docs/_autosummary/torchsig.image_datasets.datasets.yolo_datasets.YOLODatasetAdapter.rst
deleted file mode 100644
index 703dcd4f2..000000000
--- a/docs/_autosummary/torchsig.image_datasets.datasets.yolo_datasets.YOLODatasetAdapter.rst
+++ /dev/null
@@ -1,24 +0,0 @@
-torchsig.image\_datasets.datasets.yolo\_datasets.YOLODatasetAdapter
-===================================================================
-
-.. currentmodule:: torchsig.image_datasets.datasets.yolo_datasets
-
-.. autoclass:: YOLODatasetAdapter
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.image_datasets.datasets.yolo_datasets.YOLODatum.rst b/docs/_autosummary/torchsig.image_datasets.datasets.yolo_datasets.YOLODatum.rst
deleted file mode 100644
index 8b47546be..000000000
--- a/docs/_autosummary/torchsig.image_datasets.datasets.yolo_datasets.YOLODatum.rst
+++ /dev/null
@@ -1,37 +0,0 @@
-torchsig.image\_datasets.datasets.yolo\_datasets.YOLODatum
-==========================================================
-
-.. currentmodule:: torchsig.image_datasets.datasets.yolo_datasets
-
-.. autoclass:: YOLODatum
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~YOLODatum.append_labels
-      ~YOLODatum.append_yolo_labels
-      ~YOLODatum.compose_yolo_data
-      ~YOLODatum.has_labels
-      ~YOLODatum.size
-      ~YOLODatum.transpose_yolo_labels
-   
-   
-
-   
-   
-   .. rubric:: Attributes
-
-   .. autosummary::
-   
-      ~YOLODatum.labels
-      ~YOLODatum.shape
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.image_datasets.datasets.yolo_datasets.YOLOFileDataset.rst b/docs/_autosummary/torchsig.image_datasets.datasets.yolo_datasets.YOLOFileDataset.rst
deleted file mode 100644
index 70992fc83..000000000
--- a/docs/_autosummary/torchsig.image_datasets.datasets.yolo_datasets.YOLOFileDataset.rst
+++ /dev/null
@@ -1,25 +0,0 @@
-torchsig.image\_datasets.datasets.yolo\_datasets.YOLOFileDataset
-================================================================
-
-.. currentmodule:: torchsig.image_datasets.datasets.yolo_datasets
-
-.. autoclass:: YOLOFileDataset
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~YOLOFileDataset.next
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.image_datasets.datasets.yolo_datasets.YOLOImageCompositeDataset.rst b/docs/_autosummary/torchsig.image_datasets.datasets.yolo_datasets.YOLOImageCompositeDataset.rst
deleted file mode 100644
index 768214f1b..000000000
--- a/docs/_autosummary/torchsig.image_datasets.datasets.yolo_datasets.YOLOImageCompositeDataset.rst
+++ /dev/null
@@ -1,27 +0,0 @@
-torchsig.image\_datasets.datasets.yolo\_datasets.YOLOImageCompositeDataset
-==========================================================================
-
-.. currentmodule:: torchsig.image_datasets.datasets.yolo_datasets
-
-.. autoclass:: YOLOImageCompositeDataset
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~YOLOImageCompositeDataset.add_component
-      ~YOLOImageCompositeDataset.add_component_to_image_and_labels
-      ~YOLOImageCompositeDataset.get_components_to_add
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.image_datasets.datasets.yolo_datasets.YOLOImageCompositeDatasetComponent.rst b/docs/_autosummary/torchsig.image_datasets.datasets.yolo_datasets.YOLOImageCompositeDatasetComponent.rst
deleted file mode 100644
index eae436123..000000000
--- a/docs/_autosummary/torchsig.image_datasets.datasets.yolo_datasets.YOLOImageCompositeDatasetComponent.rst
+++ /dev/null
@@ -1,26 +0,0 @@
-torchsig.image\_datasets.datasets.yolo\_datasets.YOLOImageCompositeDatasetComponent
-===================================================================================
-
-.. currentmodule:: torchsig.image_datasets.datasets.yolo_datasets
-
-.. autoclass:: YOLOImageCompositeDatasetComponent
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~YOLOImageCompositeDatasetComponent.get_components_to_add
-      ~YOLOImageCompositeDatasetComponent.next
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.image_datasets.datasets.yolo_datasets.YOLOSOIExtractorDataset.rst b/docs/_autosummary/torchsig.image_datasets.datasets.yolo_datasets.YOLOSOIExtractorDataset.rst
deleted file mode 100644
index af91d813a..000000000
--- a/docs/_autosummary/torchsig.image_datasets.datasets.yolo_datasets.YOLOSOIExtractorDataset.rst
+++ /dev/null
@@ -1,25 +0,0 @@
-torchsig.image\_datasets.datasets.yolo\_datasets.YOLOSOIExtractorDataset
-========================================================================
-
-.. currentmodule:: torchsig.image_datasets.datasets.yolo_datasets
-
-.. autoclass:: YOLOSOIExtractorDataset
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~YOLOSOIExtractorDataset.next
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.image_datasets.datasets.yolo_datasets.extract_yolo_boxes.rst b/docs/_autosummary/torchsig.image_datasets.datasets.yolo_datasets.extract_yolo_boxes.rst
deleted file mode 100644
index f203eb6c1..000000000
--- a/docs/_autosummary/torchsig.image_datasets.datasets.yolo_datasets.extract_yolo_boxes.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.image\_datasets.datasets.yolo\_datasets.extract\_yolo\_boxes
-=====================================================================
-
-.. currentmodule:: torchsig.image_datasets.datasets.yolo_datasets
-
-.. autofunction:: extract_yolo_boxes
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.image_datasets.datasets.yolo_datasets.read_yolo_datum.rst b/docs/_autosummary/torchsig.image_datasets.datasets.yolo_datasets.read_yolo_datum.rst
deleted file mode 100644
index 85f6718e2..000000000
--- a/docs/_autosummary/torchsig.image_datasets.datasets.yolo_datasets.read_yolo_datum.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.image\_datasets.datasets.yolo\_datasets.read\_yolo\_datum
-==================================================================
-
-.. currentmodule:: torchsig.image_datasets.datasets.yolo_datasets
-
-.. autofunction:: read_yolo_datum
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.image_datasets.datasets.yolo_datasets.rst b/docs/_autosummary/torchsig.image_datasets.datasets.yolo_datasets.rst
deleted file mode 100644
index ef6cc55e2..000000000
--- a/docs/_autosummary/torchsig.image_datasets.datasets.yolo_datasets.rst
+++ /dev/null
@@ -1,48 +0,0 @@
-torchsig.image\_datasets.datasets.yolo\_datasets
-================================================
-
-.. automodule:: torchsig.image_datasets.datasets.yolo_datasets
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Functions
-
-   .. autosummary::
-      :toctree:
-      :nosignatures:
-   
-      extract_yolo_boxes
-      read_yolo_datum
-      yolo_box_on_image
-      yolo_to_pixels_on_image
-   
-   
-
-   
-   
-   .. rubric:: Classes
-
-   .. autosummary::
-      :toctree:
-      :template: custom_class_template.rst
-      :nosignatures:
-   
-      YOLODatasetAdapter
-      YOLODatum
-      YOLOFileDataset
-      YOLOImageCompositeDataset
-      YOLOImageCompositeDatasetComponent
-      YOLOSOIExtractorDataset
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.image_datasets.datasets.yolo_datasets.yolo_box_on_image.rst b/docs/_autosummary/torchsig.image_datasets.datasets.yolo_datasets.yolo_box_on_image.rst
deleted file mode 100644
index fd29fae61..000000000
--- a/docs/_autosummary/torchsig.image_datasets.datasets.yolo_datasets.yolo_box_on_image.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.image\_datasets.datasets.yolo\_datasets.yolo\_box\_on\_image
-=====================================================================
-
-.. currentmodule:: torchsig.image_datasets.datasets.yolo_datasets
-
-.. autofunction:: yolo_box_on_image
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.image_datasets.datasets.yolo_datasets.yolo_to_pixels_on_image.rst b/docs/_autosummary/torchsig.image_datasets.datasets.yolo_datasets.yolo_to_pixels_on_image.rst
deleted file mode 100644
index c2e2f8a65..000000000
--- a/docs/_autosummary/torchsig.image_datasets.datasets.yolo_datasets.yolo_to_pixels_on_image.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.image\_datasets.datasets.yolo\_datasets.yolo\_to\_pixels\_on\_image
-============================================================================
-
-.. currentmodule:: torchsig.image_datasets.datasets.yolo_datasets
-
-.. autofunction:: yolo_to_pixels_on_image
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.image_datasets.plotting.plotting.plot_yolo_boxes_on_image.rst b/docs/_autosummary/torchsig.image_datasets.plotting.plotting.plot_yolo_boxes_on_image.rst
deleted file mode 100644
index 473151a05..000000000
--- a/docs/_autosummary/torchsig.image_datasets.plotting.plotting.plot_yolo_boxes_on_image.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.image\_datasets.plotting.plotting.plot\_yolo\_boxes\_on\_image
-=======================================================================
-
-.. currentmodule:: torchsig.image_datasets.plotting.plotting
-
-.. autofunction:: plot_yolo_boxes_on_image
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.image_datasets.plotting.plotting.plot_yolo_datum.rst b/docs/_autosummary/torchsig.image_datasets.plotting.plotting.plot_yolo_datum.rst
deleted file mode 100644
index 53a400b0f..000000000
--- a/docs/_autosummary/torchsig.image_datasets.plotting.plotting.plot_yolo_datum.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.image\_datasets.plotting.plotting.plot\_yolo\_datum
-============================================================
-
-.. currentmodule:: torchsig.image_datasets.plotting.plotting
-
-.. autofunction:: plot_yolo_datum
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.image_datasets.plotting.plotting.rst b/docs/_autosummary/torchsig.image_datasets.plotting.plotting.rst
deleted file mode 100644
index 2d4273211..000000000
--- a/docs/_autosummary/torchsig.image_datasets.plotting.plotting.rst
+++ /dev/null
@@ -1,32 +0,0 @@
-torchsig.image\_datasets.plotting.plotting
-==========================================
-
-.. automodule:: torchsig.image_datasets.plotting.plotting
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Functions
-
-   .. autosummary::
-      :toctree:
-      :nosignatures:
-   
-      plot_yolo_boxes_on_image
-      plot_yolo_datum
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.image_datasets.plotting.rst b/docs/_autosummary/torchsig.image_datasets.plotting.rst
deleted file mode 100644
index 612b0f94d..000000000
--- a/docs/_autosummary/torchsig.image_datasets.plotting.rst
+++ /dev/null
@@ -1,30 +0,0 @@
-torchsig.image\_datasets.plotting
-=================================
-
-.. automodule:: torchsig.image_datasets.plotting
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-
-
-.. autosummary::
-   :toctree:
-   :template: custom_module_template.rst
-   :recursive:
-
-   plotting
-
diff --git a/docs/_autosummary/torchsig.image_datasets.rst b/docs/_autosummary/torchsig.image_datasets.rst
deleted file mode 100644
index 6a2f4ee08..000000000
--- a/docs/_autosummary/torchsig.image_datasets.rst
+++ /dev/null
@@ -1,34 +0,0 @@
-torchsig.image\_datasets
-========================
-
-.. automodule:: torchsig.image_datasets
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-
-
-.. autosummary::
-   :toctree:
-   :template: custom_module_template.rst
-   :recursive:
-
-   dataset_generation
-   datasets
-   generate_dataset
-   plotting
-   transforms
-
diff --git a/docs/_autosummary/torchsig.image_datasets.transforms.denoising.isolate_foreground_signal.rst b/docs/_autosummary/torchsig.image_datasets.transforms.denoising.isolate_foreground_signal.rst
deleted file mode 100644
index 16ba408e4..000000000
--- a/docs/_autosummary/torchsig.image_datasets.transforms.denoising.isolate_foreground_signal.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.image\_datasets.transforms.denoising.isolate\_foreground\_signal
-=========================================================================
-
-.. currentmodule:: torchsig.image_datasets.transforms.denoising
-
-.. autofunction:: isolate_foreground_signal
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.image_datasets.transforms.denoising.normalize_image.rst b/docs/_autosummary/torchsig.image_datasets.transforms.denoising.normalize_image.rst
deleted file mode 100644
index 1d8eea1a7..000000000
--- a/docs/_autosummary/torchsig.image_datasets.transforms.denoising.normalize_image.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.image\_datasets.transforms.denoising.normalize\_image
-==============================================================
-
-.. currentmodule:: torchsig.image_datasets.transforms.denoising
-
-.. autofunction:: normalize_image
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.image_datasets.transforms.denoising.rst b/docs/_autosummary/torchsig.image_datasets.transforms.denoising.rst
deleted file mode 100644
index 1aa552650..000000000
--- a/docs/_autosummary/torchsig.image_datasets.transforms.denoising.rst
+++ /dev/null
@@ -1,32 +0,0 @@
-torchsig.image\_datasets.transforms.denoising
-=============================================
-
-.. automodule:: torchsig.image_datasets.transforms.denoising
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Functions
-
-   .. autosummary::
-      :toctree:
-      :nosignatures:
-   
-      isolate_foreground_signal
-      normalize_image
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.image_datasets.transforms.impairments.BlurTransform.rst b/docs/_autosummary/torchsig.image_datasets.transforms.impairments.BlurTransform.rst
deleted file mode 100644
index d446f89ea..000000000
--- a/docs/_autosummary/torchsig.image_datasets.transforms.impairments.BlurTransform.rst
+++ /dev/null
@@ -1,30 +0,0 @@
-torchsig.image\_datasets.transforms.impairments.BlurTransform
-=============================================================
-
-.. currentmodule:: torchsig.image_datasets.transforms.impairments
-
-.. autoclass:: BlurTransform
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~BlurTransform.add_parent
-      ~BlurTransform.get_distribution
-      ~BlurTransform.get_second_seed
-      ~BlurTransform.seed
-      ~BlurTransform.setup_rngs
-      ~BlurTransform.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.image_datasets.transforms.impairments.GaussianNoiseTransform.rst b/docs/_autosummary/torchsig.image_datasets.transforms.impairments.GaussianNoiseTransform.rst
deleted file mode 100644
index 6accd9615..000000000
--- a/docs/_autosummary/torchsig.image_datasets.transforms.impairments.GaussianNoiseTransform.rst
+++ /dev/null
@@ -1,30 +0,0 @@
-torchsig.image\_datasets.transforms.impairments.GaussianNoiseTransform
-======================================================================
-
-.. currentmodule:: torchsig.image_datasets.transforms.impairments
-
-.. autoclass:: GaussianNoiseTransform
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~GaussianNoiseTransform.add_parent
-      ~GaussianNoiseTransform.get_distribution
-      ~GaussianNoiseTransform.get_second_seed
-      ~GaussianNoiseTransform.seed
-      ~GaussianNoiseTransform.setup_rngs
-      ~GaussianNoiseTransform.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.image_datasets.transforms.impairments.RandomGaussianNoiseTransform.rst b/docs/_autosummary/torchsig.image_datasets.transforms.impairments.RandomGaussianNoiseTransform.rst
deleted file mode 100644
index 0129ee52e..000000000
--- a/docs/_autosummary/torchsig.image_datasets.transforms.impairments.RandomGaussianNoiseTransform.rst
+++ /dev/null
@@ -1,30 +0,0 @@
-torchsig.image\_datasets.transforms.impairments.RandomGaussianNoiseTransform
-============================================================================
-
-.. currentmodule:: torchsig.image_datasets.transforms.impairments
-
-.. autoclass:: RandomGaussianNoiseTransform
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~RandomGaussianNoiseTransform.add_parent
-      ~RandomGaussianNoiseTransform.get_distribution
-      ~RandomGaussianNoiseTransform.get_second_seed
-      ~RandomGaussianNoiseTransform.seed
-      ~RandomGaussianNoiseTransform.setup_rngs
-      ~RandomGaussianNoiseTransform.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.image_datasets.transforms.impairments.RandomImageResizeTransform.rst b/docs/_autosummary/torchsig.image_datasets.transforms.impairments.RandomImageResizeTransform.rst
deleted file mode 100644
index af017223c..000000000
--- a/docs/_autosummary/torchsig.image_datasets.transforms.impairments.RandomImageResizeTransform.rst
+++ /dev/null
@@ -1,30 +0,0 @@
-torchsig.image\_datasets.transforms.impairments.RandomImageResizeTransform
-==========================================================================
-
-.. currentmodule:: torchsig.image_datasets.transforms.impairments
-
-.. autoclass:: RandomImageResizeTransform
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~RandomImageResizeTransform.add_parent
-      ~RandomImageResizeTransform.get_distribution
-      ~RandomImageResizeTransform.get_second_seed
-      ~RandomImageResizeTransform.seed
-      ~RandomImageResizeTransform.setup_rngs
-      ~RandomImageResizeTransform.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.image_datasets.transforms.impairments.RandomRippleNoiseTransform.rst b/docs/_autosummary/torchsig.image_datasets.transforms.impairments.RandomRippleNoiseTransform.rst
deleted file mode 100644
index e5f540062..000000000
--- a/docs/_autosummary/torchsig.image_datasets.transforms.impairments.RandomRippleNoiseTransform.rst
+++ /dev/null
@@ -1,30 +0,0 @@
-torchsig.image\_datasets.transforms.impairments.RandomRippleNoiseTransform
-==========================================================================
-
-.. currentmodule:: torchsig.image_datasets.transforms.impairments
-
-.. autoclass:: RandomRippleNoiseTransform
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~RandomRippleNoiseTransform.add_parent
-      ~RandomRippleNoiseTransform.get_distribution
-      ~RandomRippleNoiseTransform.get_second_seed
-      ~RandomRippleNoiseTransform.seed
-      ~RandomRippleNoiseTransform.setup_rngs
-      ~RandomRippleNoiseTransform.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.image_datasets.transforms.impairments.RippleNoiseTransform.rst b/docs/_autosummary/torchsig.image_datasets.transforms.impairments.RippleNoiseTransform.rst
deleted file mode 100644
index 037550482..000000000
--- a/docs/_autosummary/torchsig.image_datasets.transforms.impairments.RippleNoiseTransform.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.image\_datasets.transforms.impairments.RippleNoiseTransform
-====================================================================
-
-.. currentmodule:: torchsig.image_datasets.transforms.impairments
-
-.. autoclass:: RippleNoiseTransform
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~RippleNoiseTransform.add_parent
-      ~RippleNoiseTransform.get_distribution
-      ~RippleNoiseTransform.get_second_seed
-      ~RippleNoiseTransform.seed
-      ~RippleNoiseTransform.setup_rngs
-      ~RippleNoiseTransform.update_from_parent
-      ~RippleNoiseTransform.update_mesh_spacing
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.image_datasets.transforms.impairments.ScaleTransform.rst b/docs/_autosummary/torchsig.image_datasets.transforms.impairments.ScaleTransform.rst
deleted file mode 100644
index 38178c643..000000000
--- a/docs/_autosummary/torchsig.image_datasets.transforms.impairments.ScaleTransform.rst
+++ /dev/null
@@ -1,30 +0,0 @@
-torchsig.image\_datasets.transforms.impairments.ScaleTransform
-==============================================================
-
-.. currentmodule:: torchsig.image_datasets.transforms.impairments
-
-.. autoclass:: ScaleTransform
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~ScaleTransform.add_parent
-      ~ScaleTransform.get_distribution
-      ~ScaleTransform.get_second_seed
-      ~ScaleTransform.seed
-      ~ScaleTransform.setup_rngs
-      ~ScaleTransform.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.image_datasets.transforms.impairments.pad_border.rst b/docs/_autosummary/torchsig.image_datasets.transforms.impairments.pad_border.rst
deleted file mode 100644
index 47009f5bc..000000000
--- a/docs/_autosummary/torchsig.image_datasets.transforms.impairments.pad_border.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.image\_datasets.transforms.impairments.pad\_border
-===========================================================
-
-.. currentmodule:: torchsig.image_datasets.transforms.impairments
-
-.. autofunction:: pad_border
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.image_datasets.transforms.impairments.rst b/docs/_autosummary/torchsig.image_datasets.transforms.impairments.rst
deleted file mode 100644
index 2be0f58f6..000000000
--- a/docs/_autosummary/torchsig.image_datasets.transforms.impairments.rst
+++ /dev/null
@@ -1,47 +0,0 @@
-torchsig.image\_datasets.transforms.impairments
-===============================================
-
-.. automodule:: torchsig.image_datasets.transforms.impairments
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Functions
-
-   .. autosummary::
-      :toctree:
-      :nosignatures:
-   
-      pad_border
-      scale_dynamic_range
-   
-   
-
-   
-   
-   .. rubric:: Classes
-
-   .. autosummary::
-      :toctree:
-      :template: custom_class_template.rst
-      :nosignatures:
-   
-      BlurTransform
-      GaussianNoiseTransform
-      RandomGaussianNoiseTransform
-      RandomImageResizeTransform
-      RandomRippleNoiseTransform
-      RippleNoiseTransform
-      ScaleTransform
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.image_datasets.transforms.impairments.scale_dynamic_range.rst b/docs/_autosummary/torchsig.image_datasets.transforms.impairments.scale_dynamic_range.rst
deleted file mode 100644
index 80aaf9641..000000000
--- a/docs/_autosummary/torchsig.image_datasets.transforms.impairments.scale_dynamic_range.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.image\_datasets.transforms.impairments.scale\_dynamic\_range
-=====================================================================
-
-.. currentmodule:: torchsig.image_datasets.transforms.impairments
-
-.. autofunction:: scale_dynamic_range
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.image_datasets.transforms.rst b/docs/_autosummary/torchsig.image_datasets.transforms.rst
deleted file mode 100644
index 892cb4b24..000000000
--- a/docs/_autosummary/torchsig.image_datasets.transforms.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.image\_datasets.transforms
-===================================
-
-.. automodule:: torchsig.image_datasets.transforms
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-
-
-.. autosummary::
-   :toctree:
-   :template: custom_module_template.rst
-   :recursive:
-
-   denoising
-   impairments
-
diff --git a/docs/_autosummary/torchsig.models.iq_models.rst b/docs/_autosummary/torchsig.models.iq_models.rst
deleted file mode 100644
index 1106f0cc0..000000000
--- a/docs/_autosummary/torchsig.models.iq_models.rst
+++ /dev/null
@@ -1,30 +0,0 @@
-torchsig.models.iq\_models
-==========================
-
-.. automodule:: torchsig.models.iq_models
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-
-
-.. autosummary::
-   :toctree:
-   :template: custom_module_template.rst
-   :recursive:
-
-   xcit
-
diff --git a/docs/_autosummary/torchsig.models.iq_models.xcit.rst b/docs/_autosummary/torchsig.models.iq_models.xcit.rst
deleted file mode 100644
index d4249c6d2..000000000
--- a/docs/_autosummary/torchsig.models.iq_models.xcit.rst
+++ /dev/null
@@ -1,30 +0,0 @@
-torchsig.models.iq\_models.xcit
-===============================
-
-.. automodule:: torchsig.models.iq_models.xcit
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-
-
-.. autosummary::
-   :toctree:
-   :template: custom_module_template.rst
-   :recursive:
-
-   xcit1d
-
diff --git a/docs/_autosummary/torchsig.models.iq_models.xcit.xcit1d.Chunker.rst b/docs/_autosummary/torchsig.models.iq_models.xcit.xcit1d.Chunker.rst
deleted file mode 100644
index 7584cf1d5..000000000
--- a/docs/_autosummary/torchsig.models.iq_models.xcit.xcit1d.Chunker.rst
+++ /dev/null
@@ -1,83 +0,0 @@
-torchsig.models.iq\_models.xcit.xcit1d.Chunker
-==============================================
-
-.. currentmodule:: torchsig.models.iq_models.xcit.xcit1d
-
-.. autoclass:: Chunker
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~Chunker.add_module
-      ~Chunker.apply
-      ~Chunker.bfloat16
-      ~Chunker.buffers
-      ~Chunker.children
-      ~Chunker.compile
-      ~Chunker.cpu
-      ~Chunker.cuda
-      ~Chunker.double
-      ~Chunker.eval
-      ~Chunker.extra_repr
-      ~Chunker.float
-      ~Chunker.forward
-      ~Chunker.get_buffer
-      ~Chunker.get_extra_state
-      ~Chunker.get_parameter
-      ~Chunker.get_submodule
-      ~Chunker.half
-      ~Chunker.ipu
-      ~Chunker.load_state_dict
-      ~Chunker.modules
-      ~Chunker.mtia
-      ~Chunker.named_buffers
-      ~Chunker.named_children
-      ~Chunker.named_modules
-      ~Chunker.named_parameters
-      ~Chunker.parameters
-      ~Chunker.register_backward_hook
-      ~Chunker.register_buffer
-      ~Chunker.register_forward_hook
-      ~Chunker.register_forward_pre_hook
-      ~Chunker.register_full_backward_hook
-      ~Chunker.register_full_backward_pre_hook
-      ~Chunker.register_load_state_dict_post_hook
-      ~Chunker.register_load_state_dict_pre_hook
-      ~Chunker.register_module
-      ~Chunker.register_parameter
-      ~Chunker.register_state_dict_post_hook
-      ~Chunker.register_state_dict_pre_hook
-      ~Chunker.requires_grad_
-      ~Chunker.set_extra_state
-      ~Chunker.set_submodule
-      ~Chunker.share_memory
-      ~Chunker.state_dict
-      ~Chunker.to
-      ~Chunker.to_empty
-      ~Chunker.train
-      ~Chunker.type
-      ~Chunker.xpu
-      ~Chunker.zero_grad
-   
-   
-
-   
-   
-   .. rubric:: Attributes
-
-   .. autosummary::
-   
-      ~Chunker.T_destination
-      ~Chunker.call_super_init
-      ~Chunker.dump_patches
-      ~Chunker.training
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.iq_models.xcit.xcit1d.ClassifierMetrics.rst b/docs/_autosummary/torchsig.models.iq_models.xcit.xcit1d.ClassifierMetrics.rst
deleted file mode 100644
index 171b5e9a1..000000000
--- a/docs/_autosummary/torchsig.models.iq_models.xcit.xcit1d.ClassifierMetrics.rst
+++ /dev/null
@@ -1,69 +0,0 @@
-torchsig.models.iq\_models.xcit.xcit1d.ClassifierMetrics
-========================================================
-
-.. currentmodule:: torchsig.models.iq_models.xcit.xcit1d
-
-.. autoclass:: ClassifierMetrics
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~ClassifierMetrics.load_state_dict
-      ~ClassifierMetrics.on_after_backward
-      ~ClassifierMetrics.on_before_backward
-      ~ClassifierMetrics.on_before_optimizer_step
-      ~ClassifierMetrics.on_before_zero_grad
-      ~ClassifierMetrics.on_exception
-      ~ClassifierMetrics.on_fit_end
-      ~ClassifierMetrics.on_fit_start
-      ~ClassifierMetrics.on_load_checkpoint
-      ~ClassifierMetrics.on_predict_batch_end
-      ~ClassifierMetrics.on_predict_batch_start
-      ~ClassifierMetrics.on_predict_end
-      ~ClassifierMetrics.on_predict_epoch_end
-      ~ClassifierMetrics.on_predict_epoch_start
-      ~ClassifierMetrics.on_predict_start
-      ~ClassifierMetrics.on_sanity_check_end
-      ~ClassifierMetrics.on_sanity_check_start
-      ~ClassifierMetrics.on_save_checkpoint
-      ~ClassifierMetrics.on_test_batch_end
-      ~ClassifierMetrics.on_test_batch_start
-      ~ClassifierMetrics.on_test_end
-      ~ClassifierMetrics.on_test_epoch_end
-      ~ClassifierMetrics.on_test_epoch_start
-      ~ClassifierMetrics.on_test_start
-      ~ClassifierMetrics.on_train_batch_end
-      ~ClassifierMetrics.on_train_batch_start
-      ~ClassifierMetrics.on_train_end
-      ~ClassifierMetrics.on_train_epoch_end
-      ~ClassifierMetrics.on_train_epoch_start
-      ~ClassifierMetrics.on_train_start
-      ~ClassifierMetrics.on_validation_batch_end
-      ~ClassifierMetrics.on_validation_batch_start
-      ~ClassifierMetrics.on_validation_end
-      ~ClassifierMetrics.on_validation_epoch_end
-      ~ClassifierMetrics.on_validation_epoch_start
-      ~ClassifierMetrics.on_validation_start
-      ~ClassifierMetrics.setup
-      ~ClassifierMetrics.state_dict
-      ~ClassifierMetrics.teardown
-   
-   
-
-   
-   
-   .. rubric:: Attributes
-
-   .. autosummary::
-   
-      ~ClassifierMetrics.state_key
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.iq_models.xcit.xcit1d.ConvDownSampler.rst b/docs/_autosummary/torchsig.models.iq_models.xcit.xcit1d.ConvDownSampler.rst
deleted file mode 100644
index bd303535f..000000000
--- a/docs/_autosummary/torchsig.models.iq_models.xcit.xcit1d.ConvDownSampler.rst
+++ /dev/null
@@ -1,83 +0,0 @@
-torchsig.models.iq\_models.xcit.xcit1d.ConvDownSampler
-======================================================
-
-.. currentmodule:: torchsig.models.iq_models.xcit.xcit1d
-
-.. autoclass:: ConvDownSampler
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~ConvDownSampler.add_module
-      ~ConvDownSampler.apply
-      ~ConvDownSampler.bfloat16
-      ~ConvDownSampler.buffers
-      ~ConvDownSampler.children
-      ~ConvDownSampler.compile
-      ~ConvDownSampler.cpu
-      ~ConvDownSampler.cuda
-      ~ConvDownSampler.double
-      ~ConvDownSampler.eval
-      ~ConvDownSampler.extra_repr
-      ~ConvDownSampler.float
-      ~ConvDownSampler.forward
-      ~ConvDownSampler.get_buffer
-      ~ConvDownSampler.get_extra_state
-      ~ConvDownSampler.get_parameter
-      ~ConvDownSampler.get_submodule
-      ~ConvDownSampler.half
-      ~ConvDownSampler.ipu
-      ~ConvDownSampler.load_state_dict
-      ~ConvDownSampler.modules
-      ~ConvDownSampler.mtia
-      ~ConvDownSampler.named_buffers
-      ~ConvDownSampler.named_children
-      ~ConvDownSampler.named_modules
-      ~ConvDownSampler.named_parameters
-      ~ConvDownSampler.parameters
-      ~ConvDownSampler.register_backward_hook
-      ~ConvDownSampler.register_buffer
-      ~ConvDownSampler.register_forward_hook
-      ~ConvDownSampler.register_forward_pre_hook
-      ~ConvDownSampler.register_full_backward_hook
-      ~ConvDownSampler.register_full_backward_pre_hook
-      ~ConvDownSampler.register_load_state_dict_post_hook
-      ~ConvDownSampler.register_load_state_dict_pre_hook
-      ~ConvDownSampler.register_module
-      ~ConvDownSampler.register_parameter
-      ~ConvDownSampler.register_state_dict_post_hook
-      ~ConvDownSampler.register_state_dict_pre_hook
-      ~ConvDownSampler.requires_grad_
-      ~ConvDownSampler.set_extra_state
-      ~ConvDownSampler.set_submodule
-      ~ConvDownSampler.share_memory
-      ~ConvDownSampler.state_dict
-      ~ConvDownSampler.to
-      ~ConvDownSampler.to_empty
-      ~ConvDownSampler.train
-      ~ConvDownSampler.type
-      ~ConvDownSampler.xpu
-      ~ConvDownSampler.zero_grad
-   
-   
-
-   
-   
-   .. rubric:: Attributes
-
-   .. autosummary::
-   
-      ~ConvDownSampler.T_destination
-      ~ConvDownSampler.call_super_init
-      ~ConvDownSampler.dump_patches
-      ~ConvDownSampler.training
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.iq_models.xcit.xcit1d.FocalLoss.rst b/docs/_autosummary/torchsig.models.iq_models.xcit.xcit1d.FocalLoss.rst
deleted file mode 100644
index 7ef4b405b..000000000
--- a/docs/_autosummary/torchsig.models.iq_models.xcit.xcit1d.FocalLoss.rst
+++ /dev/null
@@ -1,83 +0,0 @@
-torchsig.models.iq\_models.xcit.xcit1d.FocalLoss
-================================================
-
-.. currentmodule:: torchsig.models.iq_models.xcit.xcit1d
-
-.. autoclass:: FocalLoss
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~FocalLoss.add_module
-      ~FocalLoss.apply
-      ~FocalLoss.bfloat16
-      ~FocalLoss.buffers
-      ~FocalLoss.children
-      ~FocalLoss.compile
-      ~FocalLoss.cpu
-      ~FocalLoss.cuda
-      ~FocalLoss.double
-      ~FocalLoss.eval
-      ~FocalLoss.extra_repr
-      ~FocalLoss.float
-      ~FocalLoss.forward
-      ~FocalLoss.get_buffer
-      ~FocalLoss.get_extra_state
-      ~FocalLoss.get_parameter
-      ~FocalLoss.get_submodule
-      ~FocalLoss.half
-      ~FocalLoss.ipu
-      ~FocalLoss.load_state_dict
-      ~FocalLoss.modules
-      ~FocalLoss.mtia
-      ~FocalLoss.named_buffers
-      ~FocalLoss.named_children
-      ~FocalLoss.named_modules
-      ~FocalLoss.named_parameters
-      ~FocalLoss.parameters
-      ~FocalLoss.register_backward_hook
-      ~FocalLoss.register_buffer
-      ~FocalLoss.register_forward_hook
-      ~FocalLoss.register_forward_pre_hook
-      ~FocalLoss.register_full_backward_hook
-      ~FocalLoss.register_full_backward_pre_hook
-      ~FocalLoss.register_load_state_dict_post_hook
-      ~FocalLoss.register_load_state_dict_pre_hook
-      ~FocalLoss.register_module
-      ~FocalLoss.register_parameter
-      ~FocalLoss.register_state_dict_post_hook
-      ~FocalLoss.register_state_dict_pre_hook
-      ~FocalLoss.requires_grad_
-      ~FocalLoss.set_extra_state
-      ~FocalLoss.set_submodule
-      ~FocalLoss.share_memory
-      ~FocalLoss.state_dict
-      ~FocalLoss.to
-      ~FocalLoss.to_empty
-      ~FocalLoss.train
-      ~FocalLoss.type
-      ~FocalLoss.xpu
-      ~FocalLoss.zero_grad
-   
-   
-
-   
-   
-   .. rubric:: Attributes
-
-   .. autosummary::
-   
-      ~FocalLoss.T_destination
-      ~FocalLoss.call_super_init
-      ~FocalLoss.dump_patches
-      ~FocalLoss.training
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.iq_models.xcit.xcit1d.PositionalEncoding1D.rst b/docs/_autosummary/torchsig.models.iq_models.xcit.xcit1d.PositionalEncoding1D.rst
deleted file mode 100644
index c9f00f6f7..000000000
--- a/docs/_autosummary/torchsig.models.iq_models.xcit.xcit1d.PositionalEncoding1D.rst
+++ /dev/null
@@ -1,83 +0,0 @@
-torchsig.models.iq\_models.xcit.xcit1d.PositionalEncoding1D
-===========================================================
-
-.. currentmodule:: torchsig.models.iq_models.xcit.xcit1d
-
-.. autoclass:: PositionalEncoding1D
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~PositionalEncoding1D.add_module
-      ~PositionalEncoding1D.apply
-      ~PositionalEncoding1D.bfloat16
-      ~PositionalEncoding1D.buffers
-      ~PositionalEncoding1D.children
-      ~PositionalEncoding1D.compile
-      ~PositionalEncoding1D.cpu
-      ~PositionalEncoding1D.cuda
-      ~PositionalEncoding1D.double
-      ~PositionalEncoding1D.eval
-      ~PositionalEncoding1D.extra_repr
-      ~PositionalEncoding1D.float
-      ~PositionalEncoding1D.forward
-      ~PositionalEncoding1D.get_buffer
-      ~PositionalEncoding1D.get_extra_state
-      ~PositionalEncoding1D.get_parameter
-      ~PositionalEncoding1D.get_submodule
-      ~PositionalEncoding1D.half
-      ~PositionalEncoding1D.ipu
-      ~PositionalEncoding1D.load_state_dict
-      ~PositionalEncoding1D.modules
-      ~PositionalEncoding1D.mtia
-      ~PositionalEncoding1D.named_buffers
-      ~PositionalEncoding1D.named_children
-      ~PositionalEncoding1D.named_modules
-      ~PositionalEncoding1D.named_parameters
-      ~PositionalEncoding1D.parameters
-      ~PositionalEncoding1D.register_backward_hook
-      ~PositionalEncoding1D.register_buffer
-      ~PositionalEncoding1D.register_forward_hook
-      ~PositionalEncoding1D.register_forward_pre_hook
-      ~PositionalEncoding1D.register_full_backward_hook
-      ~PositionalEncoding1D.register_full_backward_pre_hook
-      ~PositionalEncoding1D.register_load_state_dict_post_hook
-      ~PositionalEncoding1D.register_load_state_dict_pre_hook
-      ~PositionalEncoding1D.register_module
-      ~PositionalEncoding1D.register_parameter
-      ~PositionalEncoding1D.register_state_dict_post_hook
-      ~PositionalEncoding1D.register_state_dict_pre_hook
-      ~PositionalEncoding1D.requires_grad_
-      ~PositionalEncoding1D.set_extra_state
-      ~PositionalEncoding1D.set_submodule
-      ~PositionalEncoding1D.share_memory
-      ~PositionalEncoding1D.state_dict
-      ~PositionalEncoding1D.to
-      ~PositionalEncoding1D.to_empty
-      ~PositionalEncoding1D.train
-      ~PositionalEncoding1D.type
-      ~PositionalEncoding1D.xpu
-      ~PositionalEncoding1D.zero_grad
-   
-   
-
-   
-   
-   .. rubric:: Attributes
-
-   .. autosummary::
-   
-      ~PositionalEncoding1D.T_destination
-      ~PositionalEncoding1D.call_super_init
-      ~PositionalEncoding1D.dump_patches
-      ~PositionalEncoding1D.training
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.iq_models.xcit.xcit1d.XCiT1d.rst b/docs/_autosummary/torchsig.models.iq_models.xcit.xcit1d.XCiT1d.rst
deleted file mode 100644
index a372f73ab..000000000
--- a/docs/_autosummary/torchsig.models.iq_models.xcit.xcit1d.XCiT1d.rst
+++ /dev/null
@@ -1,83 +0,0 @@
-torchsig.models.iq\_models.xcit.xcit1d.XCiT1d
-=============================================
-
-.. currentmodule:: torchsig.models.iq_models.xcit.xcit1d
-
-.. autoclass:: XCiT1d
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~XCiT1d.add_module
-      ~XCiT1d.apply
-      ~XCiT1d.bfloat16
-      ~XCiT1d.buffers
-      ~XCiT1d.children
-      ~XCiT1d.compile
-      ~XCiT1d.cpu
-      ~XCiT1d.cuda
-      ~XCiT1d.double
-      ~XCiT1d.eval
-      ~XCiT1d.extra_repr
-      ~XCiT1d.float
-      ~XCiT1d.forward
-      ~XCiT1d.get_buffer
-      ~XCiT1d.get_extra_state
-      ~XCiT1d.get_parameter
-      ~XCiT1d.get_submodule
-      ~XCiT1d.half
-      ~XCiT1d.ipu
-      ~XCiT1d.load_state_dict
-      ~XCiT1d.modules
-      ~XCiT1d.mtia
-      ~XCiT1d.named_buffers
-      ~XCiT1d.named_children
-      ~XCiT1d.named_modules
-      ~XCiT1d.named_parameters
-      ~XCiT1d.parameters
-      ~XCiT1d.register_backward_hook
-      ~XCiT1d.register_buffer
-      ~XCiT1d.register_forward_hook
-      ~XCiT1d.register_forward_pre_hook
-      ~XCiT1d.register_full_backward_hook
-      ~XCiT1d.register_full_backward_pre_hook
-      ~XCiT1d.register_load_state_dict_post_hook
-      ~XCiT1d.register_load_state_dict_pre_hook
-      ~XCiT1d.register_module
-      ~XCiT1d.register_parameter
-      ~XCiT1d.register_state_dict_post_hook
-      ~XCiT1d.register_state_dict_pre_hook
-      ~XCiT1d.requires_grad_
-      ~XCiT1d.set_extra_state
-      ~XCiT1d.set_submodule
-      ~XCiT1d.share_memory
-      ~XCiT1d.state_dict
-      ~XCiT1d.to
-      ~XCiT1d.to_empty
-      ~XCiT1d.train
-      ~XCiT1d.type
-      ~XCiT1d.xpu
-      ~XCiT1d.zero_grad
-   
-   
-
-   
-   
-   .. rubric:: Attributes
-
-   .. autosummary::
-   
-      ~XCiT1d.T_destination
-      ~XCiT1d.call_super_init
-      ~XCiT1d.dump_patches
-      ~XCiT1d.training
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.iq_models.xcit.xcit1d.XCiTClassifier.rst b/docs/_autosummary/torchsig.models.iq_models.xcit.xcit1d.XCiTClassifier.rst
deleted file mode 100644
index f511d755f..000000000
--- a/docs/_autosummary/torchsig.models.iq_models.xcit.xcit1d.XCiTClassifier.rst
+++ /dev/null
@@ -1,180 +0,0 @@
-torchsig.models.iq\_models.xcit.xcit1d.XCiTClassifier
-=====================================================
-
-.. currentmodule:: torchsig.models.iq_models.xcit.xcit1d
-
-.. autoclass:: XCiTClassifier
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~XCiTClassifier.add_module
-      ~XCiTClassifier.all_gather
-      ~XCiTClassifier.apply
-      ~XCiTClassifier.backward
-      ~XCiTClassifier.bfloat16
-      ~XCiTClassifier.buffers
-      ~XCiTClassifier.children
-      ~XCiTClassifier.clip_gradients
-      ~XCiTClassifier.compile
-      ~XCiTClassifier.configure_callbacks
-      ~XCiTClassifier.configure_gradient_clipping
-      ~XCiTClassifier.configure_model
-      ~XCiTClassifier.configure_optimizers
-      ~XCiTClassifier.configure_sharded_model
-      ~XCiTClassifier.cpu
-      ~XCiTClassifier.cuda
-      ~XCiTClassifier.double
-      ~XCiTClassifier.eval
-      ~XCiTClassifier.extra_repr
-      ~XCiTClassifier.float
-      ~XCiTClassifier.forward
-      ~XCiTClassifier.freeze
-      ~XCiTClassifier.get_buffer
-      ~XCiTClassifier.get_extra_state
-      ~XCiTClassifier.get_parameter
-      ~XCiTClassifier.get_submodule
-      ~XCiTClassifier.half
-      ~XCiTClassifier.ipu
-      ~XCiTClassifier.load_from_checkpoint
-      ~XCiTClassifier.load_state_dict
-      ~XCiTClassifier.log
-      ~XCiTClassifier.log_dict
-      ~XCiTClassifier.lr_scheduler_step
-      ~XCiTClassifier.lr_schedulers
-      ~XCiTClassifier.manual_backward
-      ~XCiTClassifier.modules
-      ~XCiTClassifier.mtia
-      ~XCiTClassifier.named_buffers
-      ~XCiTClassifier.named_children
-      ~XCiTClassifier.named_modules
-      ~XCiTClassifier.named_parameters
-      ~XCiTClassifier.on_after_backward
-      ~XCiTClassifier.on_after_batch_transfer
-      ~XCiTClassifier.on_before_backward
-      ~XCiTClassifier.on_before_batch_transfer
-      ~XCiTClassifier.on_before_optimizer_step
-      ~XCiTClassifier.on_before_zero_grad
-      ~XCiTClassifier.on_fit_end
-      ~XCiTClassifier.on_fit_start
-      ~XCiTClassifier.on_load_checkpoint
-      ~XCiTClassifier.on_predict_batch_end
-      ~XCiTClassifier.on_predict_batch_start
-      ~XCiTClassifier.on_predict_end
-      ~XCiTClassifier.on_predict_epoch_end
-      ~XCiTClassifier.on_predict_epoch_start
-      ~XCiTClassifier.on_predict_model_eval
-      ~XCiTClassifier.on_predict_start
-      ~XCiTClassifier.on_save_checkpoint
-      ~XCiTClassifier.on_test_batch_end
-      ~XCiTClassifier.on_test_batch_start
-      ~XCiTClassifier.on_test_end
-      ~XCiTClassifier.on_test_epoch_end
-      ~XCiTClassifier.on_test_epoch_start
-      ~XCiTClassifier.on_test_model_eval
-      ~XCiTClassifier.on_test_model_train
-      ~XCiTClassifier.on_test_start
-      ~XCiTClassifier.on_train_batch_end
-      ~XCiTClassifier.on_train_batch_start
-      ~XCiTClassifier.on_train_end
-      ~XCiTClassifier.on_train_epoch_end
-      ~XCiTClassifier.on_train_epoch_start
-      ~XCiTClassifier.on_train_start
-      ~XCiTClassifier.on_validation_batch_end
-      ~XCiTClassifier.on_validation_batch_start
-      ~XCiTClassifier.on_validation_end
-      ~XCiTClassifier.on_validation_epoch_end
-      ~XCiTClassifier.on_validation_epoch_start
-      ~XCiTClassifier.on_validation_model_eval
-      ~XCiTClassifier.on_validation_model_train
-      ~XCiTClassifier.on_validation_model_zero_grad
-      ~XCiTClassifier.on_validation_start
-      ~XCiTClassifier.optimizer_step
-      ~XCiTClassifier.optimizer_zero_grad
-      ~XCiTClassifier.optimizers
-      ~XCiTClassifier.parameters
-      ~XCiTClassifier.predict_dataloader
-      ~XCiTClassifier.predict_step
-      ~XCiTClassifier.prepare_data
-      ~XCiTClassifier.print
-      ~XCiTClassifier.register_backward_hook
-      ~XCiTClassifier.register_buffer
-      ~XCiTClassifier.register_forward_hook
-      ~XCiTClassifier.register_forward_pre_hook
-      ~XCiTClassifier.register_full_backward_hook
-      ~XCiTClassifier.register_full_backward_pre_hook
-      ~XCiTClassifier.register_load_state_dict_post_hook
-      ~XCiTClassifier.register_load_state_dict_pre_hook
-      ~XCiTClassifier.register_module
-      ~XCiTClassifier.register_parameter
-      ~XCiTClassifier.register_state_dict_post_hook
-      ~XCiTClassifier.register_state_dict_pre_hook
-      ~XCiTClassifier.requires_grad_
-      ~XCiTClassifier.save_hyperparameters
-      ~XCiTClassifier.set_extra_state
-      ~XCiTClassifier.set_submodule
-      ~XCiTClassifier.setup
-      ~XCiTClassifier.share_memory
-      ~XCiTClassifier.state_dict
-      ~XCiTClassifier.teardown
-      ~XCiTClassifier.test_dataloader
-      ~XCiTClassifier.test_step
-      ~XCiTClassifier.to
-      ~XCiTClassifier.to_empty
-      ~XCiTClassifier.to_onnx
-      ~XCiTClassifier.to_torchscript
-      ~XCiTClassifier.toggle_optimizer
-      ~XCiTClassifier.train
-      ~XCiTClassifier.train_dataloader
-      ~XCiTClassifier.training_step
-      ~XCiTClassifier.transfer_batch_to_device
-      ~XCiTClassifier.type
-      ~XCiTClassifier.unfreeze
-      ~XCiTClassifier.untoggle_optimizer
-      ~XCiTClassifier.val_dataloader
-      ~XCiTClassifier.validation_step
-      ~XCiTClassifier.xpu
-      ~XCiTClassifier.zero_grad
-   
-   
-
-   
-   
-   .. rubric:: Attributes
-
-   .. autosummary::
-   
-      ~XCiTClassifier.CHECKPOINT_HYPER_PARAMS_KEY
-      ~XCiTClassifier.CHECKPOINT_HYPER_PARAMS_NAME
-      ~XCiTClassifier.CHECKPOINT_HYPER_PARAMS_TYPE
-      ~XCiTClassifier.T_destination
-      ~XCiTClassifier.automatic_optimization
-      ~XCiTClassifier.call_super_init
-      ~XCiTClassifier.current_epoch
-      ~XCiTClassifier.device
-      ~XCiTClassifier.device_mesh
-      ~XCiTClassifier.dtype
-      ~XCiTClassifier.dump_patches
-      ~XCiTClassifier.example_input_array
-      ~XCiTClassifier.fabric
-      ~XCiTClassifier.global_rank
-      ~XCiTClassifier.global_step
-      ~XCiTClassifier.hparams
-      ~XCiTClassifier.hparams_initial
-      ~XCiTClassifier.local_rank
-      ~XCiTClassifier.logger
-      ~XCiTClassifier.loggers
-      ~XCiTClassifier.on_gpu
-      ~XCiTClassifier.strict_loading
-      ~XCiTClassifier.trainer
-      ~XCiTClassifier.training
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.iq_models.xcit.xcit1d.rst b/docs/_autosummary/torchsig.models.iq_models.xcit.xcit1d.rst
deleted file mode 100644
index 7e6c5935a..000000000
--- a/docs/_autosummary/torchsig.models.iq_models.xcit.xcit1d.rst
+++ /dev/null
@@ -1,38 +0,0 @@
-torchsig.models.iq\_models.xcit.xcit1d
-======================================
-
-.. automodule:: torchsig.models.iq_models.xcit.xcit1d
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Classes
-
-   .. autosummary::
-      :toctree:
-      :template: custom_class_template.rst
-      :nosignatures:
-   
-      Chunker
-      ClassifierMetrics
-      ConvDownSampler
-      FocalLoss
-      PositionalEncoding1D
-      XCiT1d
-      XCiTClassifier
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.models.model_utils.general_layers.DebugPrintLayer.rst b/docs/_autosummary/torchsig.models.model_utils.general_layers.DebugPrintLayer.rst
deleted file mode 100644
index a39123eb3..000000000
--- a/docs/_autosummary/torchsig.models.model_utils.general_layers.DebugPrintLayer.rst
+++ /dev/null
@@ -1,83 +0,0 @@
-torchsig.models.model\_utils.general\_layers.DebugPrintLayer
-============================================================
-
-.. currentmodule:: torchsig.models.model_utils.general_layers
-
-.. autoclass:: DebugPrintLayer
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~DebugPrintLayer.add_module
-      ~DebugPrintLayer.apply
-      ~DebugPrintLayer.bfloat16
-      ~DebugPrintLayer.buffers
-      ~DebugPrintLayer.children
-      ~DebugPrintLayer.compile
-      ~DebugPrintLayer.cpu
-      ~DebugPrintLayer.cuda
-      ~DebugPrintLayer.double
-      ~DebugPrintLayer.eval
-      ~DebugPrintLayer.extra_repr
-      ~DebugPrintLayer.float
-      ~DebugPrintLayer.forward
-      ~DebugPrintLayer.get_buffer
-      ~DebugPrintLayer.get_extra_state
-      ~DebugPrintLayer.get_parameter
-      ~DebugPrintLayer.get_submodule
-      ~DebugPrintLayer.half
-      ~DebugPrintLayer.ipu
-      ~DebugPrintLayer.load_state_dict
-      ~DebugPrintLayer.modules
-      ~DebugPrintLayer.mtia
-      ~DebugPrintLayer.named_buffers
-      ~DebugPrintLayer.named_children
-      ~DebugPrintLayer.named_modules
-      ~DebugPrintLayer.named_parameters
-      ~DebugPrintLayer.parameters
-      ~DebugPrintLayer.register_backward_hook
-      ~DebugPrintLayer.register_buffer
-      ~DebugPrintLayer.register_forward_hook
-      ~DebugPrintLayer.register_forward_pre_hook
-      ~DebugPrintLayer.register_full_backward_hook
-      ~DebugPrintLayer.register_full_backward_pre_hook
-      ~DebugPrintLayer.register_load_state_dict_post_hook
-      ~DebugPrintLayer.register_load_state_dict_pre_hook
-      ~DebugPrintLayer.register_module
-      ~DebugPrintLayer.register_parameter
-      ~DebugPrintLayer.register_state_dict_post_hook
-      ~DebugPrintLayer.register_state_dict_pre_hook
-      ~DebugPrintLayer.requires_grad_
-      ~DebugPrintLayer.set_extra_state
-      ~DebugPrintLayer.set_submodule
-      ~DebugPrintLayer.share_memory
-      ~DebugPrintLayer.state_dict
-      ~DebugPrintLayer.to
-      ~DebugPrintLayer.to_empty
-      ~DebugPrintLayer.train
-      ~DebugPrintLayer.type
-      ~DebugPrintLayer.xpu
-      ~DebugPrintLayer.zero_grad
-   
-   
-
-   
-   
-   .. rubric:: Attributes
-
-   .. autosummary::
-   
-      ~DebugPrintLayer.T_destination
-      ~DebugPrintLayer.call_super_init
-      ~DebugPrintLayer.dump_patches
-      ~DebugPrintLayer.training
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.model_utils.general_layers.DropChannel.rst b/docs/_autosummary/torchsig.models.model_utils.general_layers.DropChannel.rst
deleted file mode 100644
index 289b55166..000000000
--- a/docs/_autosummary/torchsig.models.model_utils.general_layers.DropChannel.rst
+++ /dev/null
@@ -1,83 +0,0 @@
-torchsig.models.model\_utils.general\_layers.DropChannel
-========================================================
-
-.. currentmodule:: torchsig.models.model_utils.general_layers
-
-.. autoclass:: DropChannel
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~DropChannel.add_module
-      ~DropChannel.apply
-      ~DropChannel.bfloat16
-      ~DropChannel.buffers
-      ~DropChannel.children
-      ~DropChannel.compile
-      ~DropChannel.cpu
-      ~DropChannel.cuda
-      ~DropChannel.double
-      ~DropChannel.eval
-      ~DropChannel.extra_repr
-      ~DropChannel.float
-      ~DropChannel.forward
-      ~DropChannel.get_buffer
-      ~DropChannel.get_extra_state
-      ~DropChannel.get_parameter
-      ~DropChannel.get_submodule
-      ~DropChannel.half
-      ~DropChannel.ipu
-      ~DropChannel.load_state_dict
-      ~DropChannel.modules
-      ~DropChannel.mtia
-      ~DropChannel.named_buffers
-      ~DropChannel.named_children
-      ~DropChannel.named_modules
-      ~DropChannel.named_parameters
-      ~DropChannel.parameters
-      ~DropChannel.register_backward_hook
-      ~DropChannel.register_buffer
-      ~DropChannel.register_forward_hook
-      ~DropChannel.register_forward_pre_hook
-      ~DropChannel.register_full_backward_hook
-      ~DropChannel.register_full_backward_pre_hook
-      ~DropChannel.register_load_state_dict_post_hook
-      ~DropChannel.register_load_state_dict_pre_hook
-      ~DropChannel.register_module
-      ~DropChannel.register_parameter
-      ~DropChannel.register_state_dict_post_hook
-      ~DropChannel.register_state_dict_pre_hook
-      ~DropChannel.requires_grad_
-      ~DropChannel.set_extra_state
-      ~DropChannel.set_submodule
-      ~DropChannel.share_memory
-      ~DropChannel.state_dict
-      ~DropChannel.to
-      ~DropChannel.to_empty
-      ~DropChannel.train
-      ~DropChannel.type
-      ~DropChannel.xpu
-      ~DropChannel.zero_grad
-   
-   
-
-   
-   
-   .. rubric:: Attributes
-
-   .. autosummary::
-   
-      ~DropChannel.T_destination
-      ~DropChannel.call_super_init
-      ~DropChannel.dump_patches
-      ~DropChannel.training
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.model_utils.general_layers.LSTMImageReader.rst b/docs/_autosummary/torchsig.models.model_utils.general_layers.LSTMImageReader.rst
deleted file mode 100644
index 0444057cb..000000000
--- a/docs/_autosummary/torchsig.models.model_utils.general_layers.LSTMImageReader.rst
+++ /dev/null
@@ -1,83 +0,0 @@
-torchsig.models.model\_utils.general\_layers.LSTMImageReader
-============================================================
-
-.. currentmodule:: torchsig.models.model_utils.general_layers
-
-.. autoclass:: LSTMImageReader
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~LSTMImageReader.add_module
-      ~LSTMImageReader.apply
-      ~LSTMImageReader.bfloat16
-      ~LSTMImageReader.buffers
-      ~LSTMImageReader.children
-      ~LSTMImageReader.compile
-      ~LSTMImageReader.cpu
-      ~LSTMImageReader.cuda
-      ~LSTMImageReader.double
-      ~LSTMImageReader.eval
-      ~LSTMImageReader.extra_repr
-      ~LSTMImageReader.float
-      ~LSTMImageReader.forward
-      ~LSTMImageReader.get_buffer
-      ~LSTMImageReader.get_extra_state
-      ~LSTMImageReader.get_parameter
-      ~LSTMImageReader.get_submodule
-      ~LSTMImageReader.half
-      ~LSTMImageReader.ipu
-      ~LSTMImageReader.load_state_dict
-      ~LSTMImageReader.modules
-      ~LSTMImageReader.mtia
-      ~LSTMImageReader.named_buffers
-      ~LSTMImageReader.named_children
-      ~LSTMImageReader.named_modules
-      ~LSTMImageReader.named_parameters
-      ~LSTMImageReader.parameters
-      ~LSTMImageReader.register_backward_hook
-      ~LSTMImageReader.register_buffer
-      ~LSTMImageReader.register_forward_hook
-      ~LSTMImageReader.register_forward_pre_hook
-      ~LSTMImageReader.register_full_backward_hook
-      ~LSTMImageReader.register_full_backward_pre_hook
-      ~LSTMImageReader.register_load_state_dict_post_hook
-      ~LSTMImageReader.register_load_state_dict_pre_hook
-      ~LSTMImageReader.register_module
-      ~LSTMImageReader.register_parameter
-      ~LSTMImageReader.register_state_dict_post_hook
-      ~LSTMImageReader.register_state_dict_pre_hook
-      ~LSTMImageReader.requires_grad_
-      ~LSTMImageReader.set_extra_state
-      ~LSTMImageReader.set_submodule
-      ~LSTMImageReader.share_memory
-      ~LSTMImageReader.state_dict
-      ~LSTMImageReader.to
-      ~LSTMImageReader.to_empty
-      ~LSTMImageReader.train
-      ~LSTMImageReader.type
-      ~LSTMImageReader.xpu
-      ~LSTMImageReader.zero_grad
-   
-   
-
-   
-   
-   .. rubric:: Attributes
-
-   .. autosummary::
-   
-      ~LSTMImageReader.T_destination
-      ~LSTMImageReader.call_super_init
-      ~LSTMImageReader.dump_patches
-      ~LSTMImageReader.training
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.model_utils.general_layers.Mean.rst b/docs/_autosummary/torchsig.models.model_utils.general_layers.Mean.rst
deleted file mode 100644
index 4aac4482d..000000000
--- a/docs/_autosummary/torchsig.models.model_utils.general_layers.Mean.rst
+++ /dev/null
@@ -1,83 +0,0 @@
-torchsig.models.model\_utils.general\_layers.Mean
-=================================================
-
-.. currentmodule:: torchsig.models.model_utils.general_layers
-
-.. autoclass:: Mean
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~Mean.add_module
-      ~Mean.apply
-      ~Mean.bfloat16
-      ~Mean.buffers
-      ~Mean.children
-      ~Mean.compile
-      ~Mean.cpu
-      ~Mean.cuda
-      ~Mean.double
-      ~Mean.eval
-      ~Mean.extra_repr
-      ~Mean.float
-      ~Mean.forward
-      ~Mean.get_buffer
-      ~Mean.get_extra_state
-      ~Mean.get_parameter
-      ~Mean.get_submodule
-      ~Mean.half
-      ~Mean.ipu
-      ~Mean.load_state_dict
-      ~Mean.modules
-      ~Mean.mtia
-      ~Mean.named_buffers
-      ~Mean.named_children
-      ~Mean.named_modules
-      ~Mean.named_parameters
-      ~Mean.parameters
-      ~Mean.register_backward_hook
-      ~Mean.register_buffer
-      ~Mean.register_forward_hook
-      ~Mean.register_forward_pre_hook
-      ~Mean.register_full_backward_hook
-      ~Mean.register_full_backward_pre_hook
-      ~Mean.register_load_state_dict_post_hook
-      ~Mean.register_load_state_dict_pre_hook
-      ~Mean.register_module
-      ~Mean.register_parameter
-      ~Mean.register_state_dict_post_hook
-      ~Mean.register_state_dict_pre_hook
-      ~Mean.requires_grad_
-      ~Mean.set_extra_state
-      ~Mean.set_submodule
-      ~Mean.share_memory
-      ~Mean.state_dict
-      ~Mean.to
-      ~Mean.to_empty
-      ~Mean.train
-      ~Mean.type
-      ~Mean.xpu
-      ~Mean.zero_grad
-   
-   
-
-   
-   
-   .. rubric:: Attributes
-
-   .. autosummary::
-   
-      ~Mean.T_destination
-      ~Mean.call_super_init
-      ~Mean.dump_patches
-      ~Mean.training
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.model_utils.general_layers.Reshape.rst b/docs/_autosummary/torchsig.models.model_utils.general_layers.Reshape.rst
deleted file mode 100644
index 5cec85155..000000000
--- a/docs/_autosummary/torchsig.models.model_utils.general_layers.Reshape.rst
+++ /dev/null
@@ -1,83 +0,0 @@
-torchsig.models.model\_utils.general\_layers.Reshape
-====================================================
-
-.. currentmodule:: torchsig.models.model_utils.general_layers
-
-.. autoclass:: Reshape
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~Reshape.add_module
-      ~Reshape.apply
-      ~Reshape.bfloat16
-      ~Reshape.buffers
-      ~Reshape.children
-      ~Reshape.compile
-      ~Reshape.cpu
-      ~Reshape.cuda
-      ~Reshape.double
-      ~Reshape.eval
-      ~Reshape.extra_repr
-      ~Reshape.float
-      ~Reshape.forward
-      ~Reshape.get_buffer
-      ~Reshape.get_extra_state
-      ~Reshape.get_parameter
-      ~Reshape.get_submodule
-      ~Reshape.half
-      ~Reshape.ipu
-      ~Reshape.load_state_dict
-      ~Reshape.modules
-      ~Reshape.mtia
-      ~Reshape.named_buffers
-      ~Reshape.named_children
-      ~Reshape.named_modules
-      ~Reshape.named_parameters
-      ~Reshape.parameters
-      ~Reshape.register_backward_hook
-      ~Reshape.register_buffer
-      ~Reshape.register_forward_hook
-      ~Reshape.register_forward_pre_hook
-      ~Reshape.register_full_backward_hook
-      ~Reshape.register_full_backward_pre_hook
-      ~Reshape.register_load_state_dict_post_hook
-      ~Reshape.register_load_state_dict_pre_hook
-      ~Reshape.register_module
-      ~Reshape.register_parameter
-      ~Reshape.register_state_dict_post_hook
-      ~Reshape.register_state_dict_pre_hook
-      ~Reshape.requires_grad_
-      ~Reshape.set_extra_state
-      ~Reshape.set_submodule
-      ~Reshape.share_memory
-      ~Reshape.state_dict
-      ~Reshape.to
-      ~Reshape.to_empty
-      ~Reshape.train
-      ~Reshape.type
-      ~Reshape.xpu
-      ~Reshape.zero_grad
-   
-   
-
-   
-   
-   .. rubric:: Attributes
-
-   .. autosummary::
-   
-      ~Reshape.T_destination
-      ~Reshape.call_super_init
-      ~Reshape.dump_patches
-      ~Reshape.training
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.model_utils.general_layers.ScalingLayer.rst b/docs/_autosummary/torchsig.models.model_utils.general_layers.ScalingLayer.rst
deleted file mode 100644
index 3c3e5e51c..000000000
--- a/docs/_autosummary/torchsig.models.model_utils.general_layers.ScalingLayer.rst
+++ /dev/null
@@ -1,83 +0,0 @@
-torchsig.models.model\_utils.general\_layers.ScalingLayer
-=========================================================
-
-.. currentmodule:: torchsig.models.model_utils.general_layers
-
-.. autoclass:: ScalingLayer
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~ScalingLayer.add_module
-      ~ScalingLayer.apply
-      ~ScalingLayer.bfloat16
-      ~ScalingLayer.buffers
-      ~ScalingLayer.children
-      ~ScalingLayer.compile
-      ~ScalingLayer.cpu
-      ~ScalingLayer.cuda
-      ~ScalingLayer.double
-      ~ScalingLayer.eval
-      ~ScalingLayer.extra_repr
-      ~ScalingLayer.float
-      ~ScalingLayer.forward
-      ~ScalingLayer.get_buffer
-      ~ScalingLayer.get_extra_state
-      ~ScalingLayer.get_parameter
-      ~ScalingLayer.get_submodule
-      ~ScalingLayer.half
-      ~ScalingLayer.ipu
-      ~ScalingLayer.load_state_dict
-      ~ScalingLayer.modules
-      ~ScalingLayer.mtia
-      ~ScalingLayer.named_buffers
-      ~ScalingLayer.named_children
-      ~ScalingLayer.named_modules
-      ~ScalingLayer.named_parameters
-      ~ScalingLayer.parameters
-      ~ScalingLayer.register_backward_hook
-      ~ScalingLayer.register_buffer
-      ~ScalingLayer.register_forward_hook
-      ~ScalingLayer.register_forward_pre_hook
-      ~ScalingLayer.register_full_backward_hook
-      ~ScalingLayer.register_full_backward_pre_hook
-      ~ScalingLayer.register_load_state_dict_post_hook
-      ~ScalingLayer.register_load_state_dict_pre_hook
-      ~ScalingLayer.register_module
-      ~ScalingLayer.register_parameter
-      ~ScalingLayer.register_state_dict_post_hook
-      ~ScalingLayer.register_state_dict_pre_hook
-      ~ScalingLayer.requires_grad_
-      ~ScalingLayer.set_extra_state
-      ~ScalingLayer.set_submodule
-      ~ScalingLayer.share_memory
-      ~ScalingLayer.state_dict
-      ~ScalingLayer.to
-      ~ScalingLayer.to_empty
-      ~ScalingLayer.train
-      ~ScalingLayer.type
-      ~ScalingLayer.xpu
-      ~ScalingLayer.zero_grad
-   
-   
-
-   
-   
-   .. rubric:: Attributes
-
-   .. autosummary::
-   
-      ~ScalingLayer.T_destination
-      ~ScalingLayer.call_super_init
-      ~ScalingLayer.dump_patches
-      ~ScalingLayer.training
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.model_utils.general_layers.rst b/docs/_autosummary/torchsig.models.model_utils.general_layers.rst
deleted file mode 100644
index 701fd71f9..000000000
--- a/docs/_autosummary/torchsig.models.model_utils.general_layers.rst
+++ /dev/null
@@ -1,37 +0,0 @@
-torchsig.models.model\_utils.general\_layers
-============================================
-
-.. automodule:: torchsig.models.model_utils.general_layers
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Classes
-
-   .. autosummary::
-      :toctree:
-      :template: custom_class_template.rst
-      :nosignatures:
-   
-      DebugPrintLayer
-      DropChannel
-      LSTMImageReader
-      Mean
-      Reshape
-      ScalingLayer
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.models.model_utils.layer_tools.get_layer_list.rst b/docs/_autosummary/torchsig.models.model_utils.layer_tools.get_layer_list.rst
deleted file mode 100644
index bf1924be0..000000000
--- a/docs/_autosummary/torchsig.models.model_utils.layer_tools.get_layer_list.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.models.model\_utils.layer\_tools.get\_layer\_list
-==========================================================
-
-.. currentmodule:: torchsig.models.model_utils.layer_tools
-
-.. autofunction:: get_layer_list
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.model_utils.layer_tools.is_same_type.rst b/docs/_autosummary/torchsig.models.model_utils.layer_tools.is_same_type.rst
deleted file mode 100644
index cf404c5a7..000000000
--- a/docs/_autosummary/torchsig.models.model_utils.layer_tools.is_same_type.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.models.model\_utils.layer\_tools.is\_same\_type
-========================================================
-
-.. currentmodule:: torchsig.models.model_utils.layer_tools
-
-.. autofunction:: is_same_type
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.model_utils.layer_tools.replace_layer.rst b/docs/_autosummary/torchsig.models.model_utils.layer_tools.replace_layer.rst
deleted file mode 100644
index a1e2f034b..000000000
--- a/docs/_autosummary/torchsig.models.model_utils.layer_tools.replace_layer.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.models.model\_utils.layer\_tools.replace\_layer
-========================================================
-
-.. currentmodule:: torchsig.models.model_utils.layer_tools
-
-.. autofunction:: replace_layer
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.model_utils.layer_tools.replace_layers_of_type.rst b/docs/_autosummary/torchsig.models.model_utils.layer_tools.replace_layers_of_type.rst
deleted file mode 100644
index d76a6ae0e..000000000
--- a/docs/_autosummary/torchsig.models.model_utils.layer_tools.replace_layers_of_type.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.models.model\_utils.layer\_tools.replace\_layers\_of\_type
-===================================================================
-
-.. currentmodule:: torchsig.models.model_utils.layer_tools
-
-.. autofunction:: replace_layers_of_type
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.model_utils.layer_tools.replace_layers_of_types.rst b/docs/_autosummary/torchsig.models.model_utils.layer_tools.replace_layers_of_types.rst
deleted file mode 100644
index d3c4b907f..000000000
--- a/docs/_autosummary/torchsig.models.model_utils.layer_tools.replace_layers_of_types.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.models.model\_utils.layer\_tools.replace\_layers\_of\_types
-====================================================================
-
-.. currentmodule:: torchsig.models.model_utils.layer_tools
-
-.. autofunction:: replace_layers_of_types
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.model_utils.layer_tools.replace_layers_on_condition.rst b/docs/_autosummary/torchsig.models.model_utils.layer_tools.replace_layers_on_condition.rst
deleted file mode 100644
index 3b50a4caf..000000000
--- a/docs/_autosummary/torchsig.models.model_utils.layer_tools.replace_layers_on_condition.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.models.model\_utils.layer\_tools.replace\_layers\_on\_condition
-========================================================================
-
-.. currentmodule:: torchsig.models.model_utils.layer_tools
-
-.. autofunction:: replace_layers_on_condition
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.model_utils.layer_tools.replace_layers_on_conditions.rst b/docs/_autosummary/torchsig.models.model_utils.layer_tools.replace_layers_on_conditions.rst
deleted file mode 100644
index 0ee317128..000000000
--- a/docs/_autosummary/torchsig.models.model_utils.layer_tools.replace_layers_on_conditions.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.models.model\_utils.layer\_tools.replace\_layers\_on\_conditions
-=========================================================================
-
-.. currentmodule:: torchsig.models.model_utils.layer_tools
-
-.. autofunction:: replace_layers_on_conditions
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.model_utils.layer_tools.rst b/docs/_autosummary/torchsig.models.model_utils.layer_tools.rst
deleted file mode 100644
index fb1177473..000000000
--- a/docs/_autosummary/torchsig.models.model_utils.layer_tools.rst
+++ /dev/null
@@ -1,38 +0,0 @@
-torchsig.models.model\_utils.layer\_tools
-=========================================
-
-.. automodule:: torchsig.models.model_utils.layer_tools
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Functions
-
-   .. autosummary::
-      :toctree:
-      :nosignatures:
-   
-      get_layer_list
-      is_same_type
-      replace_layer
-      replace_layers_of_type
-      replace_layers_of_types
-      replace_layers_on_condition
-      replace_layers_on_conditions
-      same_type_fn
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.models.model_utils.layer_tools.same_type_fn.rst b/docs/_autosummary/torchsig.models.model_utils.layer_tools.same_type_fn.rst
deleted file mode 100644
index ddea08a4b..000000000
--- a/docs/_autosummary/torchsig.models.model_utils.layer_tools.same_type_fn.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.models.model\_utils.layer\_tools.same\_type\_fn
-========================================================
-
-.. currentmodule:: torchsig.models.model_utils.layer_tools
-
-.. autofunction:: same_type_fn
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.conversions_to_1d.avgpool2d_to_avgpool1d.rst b/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.conversions_to_1d.avgpool2d_to_avgpool1d.rst
deleted file mode 100644
index 82f349b23..000000000
--- a/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.conversions_to_1d.avgpool2d_to_avgpool1d.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.models.model\_utils.model\_utils\_1d.conversions\_to\_1d.avgpool2d\_to\_avgpool1d
-==========================================================================================
-
-.. currentmodule:: torchsig.models.model_utils.model_utils_1d.conversions_to_1d
-
-.. autofunction:: avgpool2d_to_avgpool1d
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.conversions_to_1d.batchNorm2d_to_GBN1d.rst b/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.conversions_to_1d.batchNorm2d_to_GBN1d.rst
deleted file mode 100644
index 4c70c6509..000000000
--- a/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.conversions_to_1d.batchNorm2d_to_GBN1d.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.models.model\_utils.model\_utils\_1d.conversions\_to\_1d.batchNorm2d\_to\_GBN1d
-========================================================================================
-
-.. currentmodule:: torchsig.models.model_utils.model_utils_1d.conversions_to_1d
-
-.. autofunction:: batchNorm2d_to_GBN1d
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.conversions_to_1d.batchNorm2d_to_batchNorm1d.rst b/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.conversions_to_1d.batchNorm2d_to_batchNorm1d.rst
deleted file mode 100644
index 2023d65bb..000000000
--- a/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.conversions_to_1d.batchNorm2d_to_batchNorm1d.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.models.model\_utils.model\_utils\_1d.conversions\_to\_1d.batchNorm2d\_to\_batchNorm1d
-==============================================================================================
-
-.. currentmodule:: torchsig.models.model_utils.model_utils_1d.conversions_to_1d
-
-.. autofunction:: batchNorm2d_to_batchNorm1d
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.conversions_to_1d.conv2d_to_conv1d.rst b/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.conversions_to_1d.conv2d_to_conv1d.rst
deleted file mode 100644
index 4412de35e..000000000
--- a/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.conversions_to_1d.conv2d_to_conv1d.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.models.model\_utils.model\_utils\_1d.conversions\_to\_1d.conv2d\_to\_conv1d
-====================================================================================
-
-.. currentmodule:: torchsig.models.model_utils.model_utils_1d.conversions_to_1d
-
-.. autofunction:: conv2d_to_conv1d
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.conversions_to_1d.convert_2d_model_to_1d.rst b/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.conversions_to_1d.convert_2d_model_to_1d.rst
deleted file mode 100644
index 7e48f4c63..000000000
--- a/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.conversions_to_1d.convert_2d_model_to_1d.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.models.model\_utils.model\_utils\_1d.conversions\_to\_1d.convert\_2d\_model\_to\_1d
-============================================================================================
-
-.. currentmodule:: torchsig.models.model_utils.model_utils_1d.conversions_to_1d
-
-.. autofunction:: convert_2d_model_to_1d
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.conversions_to_1d.get_1d_kernel.rst b/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.conversions_to_1d.get_1d_kernel.rst
deleted file mode 100644
index 70fe66536..000000000
--- a/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.conversions_to_1d.get_1d_kernel.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.models.model\_utils.model\_utils\_1d.conversions\_to\_1d.get\_1d\_kernel
-=================================================================================
-
-.. currentmodule:: torchsig.models.model_utils.model_utils_1d.conversions_to_1d
-
-.. autofunction:: get_1d_kernel
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.conversions_to_1d.make_fast_avg_pooling_layer.rst b/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.conversions_to_1d.make_fast_avg_pooling_layer.rst
deleted file mode 100644
index b198a8f93..000000000
--- a/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.conversions_to_1d.make_fast_avg_pooling_layer.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.models.model\_utils.model\_utils\_1d.conversions\_to\_1d.make\_fast\_avg\_pooling\_layer
-=================================================================================================
-
-.. currentmodule:: torchsig.models.model_utils.model_utils_1d.conversions_to_1d
-
-.. autofunction:: make_fast_avg_pooling_layer
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.conversions_to_1d.maxpool2d_to_maxpool1d.rst b/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.conversions_to_1d.maxpool2d_to_maxpool1d.rst
deleted file mode 100644
index 35b202786..000000000
--- a/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.conversions_to_1d.maxpool2d_to_maxpool1d.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.models.model\_utils.model\_utils\_1d.conversions\_to\_1d.maxpool2d\_to\_maxpool1d
-==========================================================================================
-
-.. currentmodule:: torchsig.models.model_utils.model_utils_1d.conversions_to_1d
-
-.. autofunction:: maxpool2d_to_maxpool1d
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.conversions_to_1d.rst b/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.conversions_to_1d.rst
deleted file mode 100644
index fcd1067dc..000000000
--- a/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.conversions_to_1d.rst
+++ /dev/null
@@ -1,40 +0,0 @@
-torchsig.models.model\_utils.model\_utils\_1d.conversions\_to\_1d
-=================================================================
-
-.. automodule:: torchsig.models.model_utils.model_utils_1d.conversions_to_1d
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Functions
-
-   .. autosummary::
-      :toctree:
-      :nosignatures:
-   
-      avgpool2d_to_avgpool1d
-      batchNorm2d_to_GBN1d
-      batchNorm2d_to_batchNorm1d
-      conv2d_to_conv1d
-      convert_2d_model_to_1d
-      get_1d_kernel
-      make_fast_avg_pooling_layer
-      maxpool2d_to_maxpool1d
-      squeezeExcite_to_squeezeExcite1d
-      try_default
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.conversions_to_1d.squeezeExcite_to_squeezeExcite1d.rst b/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.conversions_to_1d.squeezeExcite_to_squeezeExcite1d.rst
deleted file mode 100644
index 79a83b43c..000000000
--- a/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.conversions_to_1d.squeezeExcite_to_squeezeExcite1d.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.models.model\_utils.model\_utils\_1d.conversions\_to\_1d.squeezeExcite\_to\_squeezeExcite1d
-====================================================================================================
-
-.. currentmodule:: torchsig.models.model_utils.model_utils_1d.conversions_to_1d
-
-.. autofunction:: squeezeExcite_to_squeezeExcite1d
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.conversions_to_1d.try_default.rst b/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.conversions_to_1d.try_default.rst
deleted file mode 100644
index 28e1a7bf8..000000000
--- a/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.conversions_to_1d.try_default.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.models.model\_utils.model\_utils\_1d.conversions\_to\_1d.try\_default
-==============================================================================
-
-.. currentmodule:: torchsig.models.model_utils.model_utils_1d.conversions_to_1d
-
-.. autofunction:: try_default
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.iq_sampling.Chunker.rst b/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.iq_sampling.Chunker.rst
deleted file mode 100644
index 7a60a4a8a..000000000
--- a/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.iq_sampling.Chunker.rst
+++ /dev/null
@@ -1,83 +0,0 @@
-torchsig.models.model\_utils.model\_utils\_1d.iq\_sampling.Chunker
-==================================================================
-
-.. currentmodule:: torchsig.models.model_utils.model_utils_1d.iq_sampling
-
-.. autoclass:: Chunker
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~Chunker.add_module
-      ~Chunker.apply
-      ~Chunker.bfloat16
-      ~Chunker.buffers
-      ~Chunker.children
-      ~Chunker.compile
-      ~Chunker.cpu
-      ~Chunker.cuda
-      ~Chunker.double
-      ~Chunker.eval
-      ~Chunker.extra_repr
-      ~Chunker.float
-      ~Chunker.forward
-      ~Chunker.get_buffer
-      ~Chunker.get_extra_state
-      ~Chunker.get_parameter
-      ~Chunker.get_submodule
-      ~Chunker.half
-      ~Chunker.ipu
-      ~Chunker.load_state_dict
-      ~Chunker.modules
-      ~Chunker.mtia
-      ~Chunker.named_buffers
-      ~Chunker.named_children
-      ~Chunker.named_modules
-      ~Chunker.named_parameters
-      ~Chunker.parameters
-      ~Chunker.register_backward_hook
-      ~Chunker.register_buffer
-      ~Chunker.register_forward_hook
-      ~Chunker.register_forward_pre_hook
-      ~Chunker.register_full_backward_hook
-      ~Chunker.register_full_backward_pre_hook
-      ~Chunker.register_load_state_dict_post_hook
-      ~Chunker.register_load_state_dict_pre_hook
-      ~Chunker.register_module
-      ~Chunker.register_parameter
-      ~Chunker.register_state_dict_post_hook
-      ~Chunker.register_state_dict_pre_hook
-      ~Chunker.requires_grad_
-      ~Chunker.set_extra_state
-      ~Chunker.set_submodule
-      ~Chunker.share_memory
-      ~Chunker.state_dict
-      ~Chunker.to
-      ~Chunker.to_empty
-      ~Chunker.train
-      ~Chunker.type
-      ~Chunker.xpu
-      ~Chunker.zero_grad
-   
-   
-
-   
-   
-   .. rubric:: Attributes
-
-   .. autosummary::
-   
-      ~Chunker.T_destination
-      ~Chunker.call_super_init
-      ~Chunker.dump_patches
-      ~Chunker.training
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.iq_sampling.ConvDownSampler.rst b/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.iq_sampling.ConvDownSampler.rst
deleted file mode 100644
index a8119a657..000000000
--- a/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.iq_sampling.ConvDownSampler.rst
+++ /dev/null
@@ -1,83 +0,0 @@
-torchsig.models.model\_utils.model\_utils\_1d.iq\_sampling.ConvDownSampler
-==========================================================================
-
-.. currentmodule:: torchsig.models.model_utils.model_utils_1d.iq_sampling
-
-.. autoclass:: ConvDownSampler
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~ConvDownSampler.add_module
-      ~ConvDownSampler.apply
-      ~ConvDownSampler.bfloat16
-      ~ConvDownSampler.buffers
-      ~ConvDownSampler.children
-      ~ConvDownSampler.compile
-      ~ConvDownSampler.cpu
-      ~ConvDownSampler.cuda
-      ~ConvDownSampler.double
-      ~ConvDownSampler.eval
-      ~ConvDownSampler.extra_repr
-      ~ConvDownSampler.float
-      ~ConvDownSampler.forward
-      ~ConvDownSampler.get_buffer
-      ~ConvDownSampler.get_extra_state
-      ~ConvDownSampler.get_parameter
-      ~ConvDownSampler.get_submodule
-      ~ConvDownSampler.half
-      ~ConvDownSampler.ipu
-      ~ConvDownSampler.load_state_dict
-      ~ConvDownSampler.modules
-      ~ConvDownSampler.mtia
-      ~ConvDownSampler.named_buffers
-      ~ConvDownSampler.named_children
-      ~ConvDownSampler.named_modules
-      ~ConvDownSampler.named_parameters
-      ~ConvDownSampler.parameters
-      ~ConvDownSampler.register_backward_hook
-      ~ConvDownSampler.register_buffer
-      ~ConvDownSampler.register_forward_hook
-      ~ConvDownSampler.register_forward_pre_hook
-      ~ConvDownSampler.register_full_backward_hook
-      ~ConvDownSampler.register_full_backward_pre_hook
-      ~ConvDownSampler.register_load_state_dict_post_hook
-      ~ConvDownSampler.register_load_state_dict_pre_hook
-      ~ConvDownSampler.register_module
-      ~ConvDownSampler.register_parameter
-      ~ConvDownSampler.register_state_dict_post_hook
-      ~ConvDownSampler.register_state_dict_pre_hook
-      ~ConvDownSampler.requires_grad_
-      ~ConvDownSampler.set_extra_state
-      ~ConvDownSampler.set_submodule
-      ~ConvDownSampler.share_memory
-      ~ConvDownSampler.state_dict
-      ~ConvDownSampler.to
-      ~ConvDownSampler.to_empty
-      ~ConvDownSampler.train
-      ~ConvDownSampler.type
-      ~ConvDownSampler.xpu
-      ~ConvDownSampler.zero_grad
-   
-   
-
-   
-   
-   .. rubric:: Attributes
-
-   .. autosummary::
-   
-      ~ConvDownSampler.T_destination
-      ~ConvDownSampler.call_super_init
-      ~ConvDownSampler.dump_patches
-      ~ConvDownSampler.training
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.iq_sampling.rst b/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.iq_sampling.rst
deleted file mode 100644
index 38920f6af..000000000
--- a/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.iq_sampling.rst
+++ /dev/null
@@ -1,33 +0,0 @@
-torchsig.models.model\_utils.model\_utils\_1d.iq\_sampling
-==========================================================
-
-.. automodule:: torchsig.models.model_utils.model_utils_1d.iq_sampling
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Classes
-
-   .. autosummary::
-      :toctree:
-      :template: custom_class_template.rst
-      :nosignatures:
-   
-      Chunker
-      ConvDownSampler
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.layers_1d.FastGlobalAvgPool1d.rst b/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.layers_1d.FastGlobalAvgPool1d.rst
deleted file mode 100644
index 3b76ad586..000000000
--- a/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.layers_1d.FastGlobalAvgPool1d.rst
+++ /dev/null
@@ -1,83 +0,0 @@
-torchsig.models.model\_utils.model\_utils\_1d.layers\_1d.FastGlobalAvgPool1d
-============================================================================
-
-.. currentmodule:: torchsig.models.model_utils.model_utils_1d.layers_1d
-
-.. autoclass:: FastGlobalAvgPool1d
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~FastGlobalAvgPool1d.add_module
-      ~FastGlobalAvgPool1d.apply
-      ~FastGlobalAvgPool1d.bfloat16
-      ~FastGlobalAvgPool1d.buffers
-      ~FastGlobalAvgPool1d.children
-      ~FastGlobalAvgPool1d.compile
-      ~FastGlobalAvgPool1d.cpu
-      ~FastGlobalAvgPool1d.cuda
-      ~FastGlobalAvgPool1d.double
-      ~FastGlobalAvgPool1d.eval
-      ~FastGlobalAvgPool1d.extra_repr
-      ~FastGlobalAvgPool1d.float
-      ~FastGlobalAvgPool1d.forward
-      ~FastGlobalAvgPool1d.get_buffer
-      ~FastGlobalAvgPool1d.get_extra_state
-      ~FastGlobalAvgPool1d.get_parameter
-      ~FastGlobalAvgPool1d.get_submodule
-      ~FastGlobalAvgPool1d.half
-      ~FastGlobalAvgPool1d.ipu
-      ~FastGlobalAvgPool1d.load_state_dict
-      ~FastGlobalAvgPool1d.modules
-      ~FastGlobalAvgPool1d.mtia
-      ~FastGlobalAvgPool1d.named_buffers
-      ~FastGlobalAvgPool1d.named_children
-      ~FastGlobalAvgPool1d.named_modules
-      ~FastGlobalAvgPool1d.named_parameters
-      ~FastGlobalAvgPool1d.parameters
-      ~FastGlobalAvgPool1d.register_backward_hook
-      ~FastGlobalAvgPool1d.register_buffer
-      ~FastGlobalAvgPool1d.register_forward_hook
-      ~FastGlobalAvgPool1d.register_forward_pre_hook
-      ~FastGlobalAvgPool1d.register_full_backward_hook
-      ~FastGlobalAvgPool1d.register_full_backward_pre_hook
-      ~FastGlobalAvgPool1d.register_load_state_dict_post_hook
-      ~FastGlobalAvgPool1d.register_load_state_dict_pre_hook
-      ~FastGlobalAvgPool1d.register_module
-      ~FastGlobalAvgPool1d.register_parameter
-      ~FastGlobalAvgPool1d.register_state_dict_post_hook
-      ~FastGlobalAvgPool1d.register_state_dict_pre_hook
-      ~FastGlobalAvgPool1d.requires_grad_
-      ~FastGlobalAvgPool1d.set_extra_state
-      ~FastGlobalAvgPool1d.set_submodule
-      ~FastGlobalAvgPool1d.share_memory
-      ~FastGlobalAvgPool1d.state_dict
-      ~FastGlobalAvgPool1d.to
-      ~FastGlobalAvgPool1d.to_empty
-      ~FastGlobalAvgPool1d.train
-      ~FastGlobalAvgPool1d.type
-      ~FastGlobalAvgPool1d.xpu
-      ~FastGlobalAvgPool1d.zero_grad
-   
-   
-
-   
-   
-   .. rubric:: Attributes
-
-   .. autosummary::
-   
-      ~FastGlobalAvgPool1d.T_destination
-      ~FastGlobalAvgPool1d.call_super_init
-      ~FastGlobalAvgPool1d.dump_patches
-      ~FastGlobalAvgPool1d.training
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.layers_1d.GBN1d.rst b/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.layers_1d.GBN1d.rst
deleted file mode 100644
index 6379f33b1..000000000
--- a/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.layers_1d.GBN1d.rst
+++ /dev/null
@@ -1,83 +0,0 @@
-torchsig.models.model\_utils.model\_utils\_1d.layers\_1d.GBN1d
-==============================================================
-
-.. currentmodule:: torchsig.models.model_utils.model_utils_1d.layers_1d
-
-.. autoclass:: GBN1d
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~GBN1d.add_module
-      ~GBN1d.apply
-      ~GBN1d.bfloat16
-      ~GBN1d.buffers
-      ~GBN1d.children
-      ~GBN1d.compile
-      ~GBN1d.cpu
-      ~GBN1d.cuda
-      ~GBN1d.double
-      ~GBN1d.eval
-      ~GBN1d.extra_repr
-      ~GBN1d.float
-      ~GBN1d.forward
-      ~GBN1d.get_buffer
-      ~GBN1d.get_extra_state
-      ~GBN1d.get_parameter
-      ~GBN1d.get_submodule
-      ~GBN1d.half
-      ~GBN1d.ipu
-      ~GBN1d.load_state_dict
-      ~GBN1d.modules
-      ~GBN1d.mtia
-      ~GBN1d.named_buffers
-      ~GBN1d.named_children
-      ~GBN1d.named_modules
-      ~GBN1d.named_parameters
-      ~GBN1d.parameters
-      ~GBN1d.register_backward_hook
-      ~GBN1d.register_buffer
-      ~GBN1d.register_forward_hook
-      ~GBN1d.register_forward_pre_hook
-      ~GBN1d.register_full_backward_hook
-      ~GBN1d.register_full_backward_pre_hook
-      ~GBN1d.register_load_state_dict_post_hook
-      ~GBN1d.register_load_state_dict_pre_hook
-      ~GBN1d.register_module
-      ~GBN1d.register_parameter
-      ~GBN1d.register_state_dict_post_hook
-      ~GBN1d.register_state_dict_pre_hook
-      ~GBN1d.requires_grad_
-      ~GBN1d.set_extra_state
-      ~GBN1d.set_submodule
-      ~GBN1d.share_memory
-      ~GBN1d.state_dict
-      ~GBN1d.to
-      ~GBN1d.to_empty
-      ~GBN1d.train
-      ~GBN1d.type
-      ~GBN1d.xpu
-      ~GBN1d.zero_grad
-   
-   
-
-   
-   
-   .. rubric:: Attributes
-
-   .. autosummary::
-   
-      ~GBN1d.T_destination
-      ~GBN1d.call_super_init
-      ~GBN1d.dump_patches
-      ~GBN1d.training
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.layers_1d.ImageFrom1D.rst b/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.layers_1d.ImageFrom1D.rst
deleted file mode 100644
index 2f89d6f40..000000000
--- a/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.layers_1d.ImageFrom1D.rst
+++ /dev/null
@@ -1,83 +0,0 @@
-torchsig.models.model\_utils.model\_utils\_1d.layers\_1d.ImageFrom1D
-====================================================================
-
-.. currentmodule:: torchsig.models.model_utils.model_utils_1d.layers_1d
-
-.. autoclass:: ImageFrom1D
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~ImageFrom1D.add_module
-      ~ImageFrom1D.apply
-      ~ImageFrom1D.bfloat16
-      ~ImageFrom1D.buffers
-      ~ImageFrom1D.children
-      ~ImageFrom1D.compile
-      ~ImageFrom1D.cpu
-      ~ImageFrom1D.cuda
-      ~ImageFrom1D.double
-      ~ImageFrom1D.eval
-      ~ImageFrom1D.extra_repr
-      ~ImageFrom1D.float
-      ~ImageFrom1D.forward
-      ~ImageFrom1D.get_buffer
-      ~ImageFrom1D.get_extra_state
-      ~ImageFrom1D.get_parameter
-      ~ImageFrom1D.get_submodule
-      ~ImageFrom1D.half
-      ~ImageFrom1D.ipu
-      ~ImageFrom1D.load_state_dict
-      ~ImageFrom1D.modules
-      ~ImageFrom1D.mtia
-      ~ImageFrom1D.named_buffers
-      ~ImageFrom1D.named_children
-      ~ImageFrom1D.named_modules
-      ~ImageFrom1D.named_parameters
-      ~ImageFrom1D.parameters
-      ~ImageFrom1D.register_backward_hook
-      ~ImageFrom1D.register_buffer
-      ~ImageFrom1D.register_forward_hook
-      ~ImageFrom1D.register_forward_pre_hook
-      ~ImageFrom1D.register_full_backward_hook
-      ~ImageFrom1D.register_full_backward_pre_hook
-      ~ImageFrom1D.register_load_state_dict_post_hook
-      ~ImageFrom1D.register_load_state_dict_pre_hook
-      ~ImageFrom1D.register_module
-      ~ImageFrom1D.register_parameter
-      ~ImageFrom1D.register_state_dict_post_hook
-      ~ImageFrom1D.register_state_dict_pre_hook
-      ~ImageFrom1D.requires_grad_
-      ~ImageFrom1D.set_extra_state
-      ~ImageFrom1D.set_submodule
-      ~ImageFrom1D.share_memory
-      ~ImageFrom1D.state_dict
-      ~ImageFrom1D.to
-      ~ImageFrom1D.to_empty
-      ~ImageFrom1D.train
-      ~ImageFrom1D.type
-      ~ImageFrom1D.xpu
-      ~ImageFrom1D.zero_grad
-   
-   
-
-   
-   
-   .. rubric:: Attributes
-
-   .. autosummary::
-   
-      ~ImageFrom1D.T_destination
-      ~ImageFrom1D.call_super_init
-      ~ImageFrom1D.dump_patches
-      ~ImageFrom1D.training
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.layers_1d.SqueezeExcite1d.rst b/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.layers_1d.SqueezeExcite1d.rst
deleted file mode 100644
index a4efd71fa..000000000
--- a/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.layers_1d.SqueezeExcite1d.rst
+++ /dev/null
@@ -1,83 +0,0 @@
-torchsig.models.model\_utils.model\_utils\_1d.layers\_1d.SqueezeExcite1d
-========================================================================
-
-.. currentmodule:: torchsig.models.model_utils.model_utils_1d.layers_1d
-
-.. autoclass:: SqueezeExcite1d
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~SqueezeExcite1d.add_module
-      ~SqueezeExcite1d.apply
-      ~SqueezeExcite1d.bfloat16
-      ~SqueezeExcite1d.buffers
-      ~SqueezeExcite1d.children
-      ~SqueezeExcite1d.compile
-      ~SqueezeExcite1d.cpu
-      ~SqueezeExcite1d.cuda
-      ~SqueezeExcite1d.double
-      ~SqueezeExcite1d.eval
-      ~SqueezeExcite1d.extra_repr
-      ~SqueezeExcite1d.float
-      ~SqueezeExcite1d.forward
-      ~SqueezeExcite1d.get_buffer
-      ~SqueezeExcite1d.get_extra_state
-      ~SqueezeExcite1d.get_parameter
-      ~SqueezeExcite1d.get_submodule
-      ~SqueezeExcite1d.half
-      ~SqueezeExcite1d.ipu
-      ~SqueezeExcite1d.load_state_dict
-      ~SqueezeExcite1d.modules
-      ~SqueezeExcite1d.mtia
-      ~SqueezeExcite1d.named_buffers
-      ~SqueezeExcite1d.named_children
-      ~SqueezeExcite1d.named_modules
-      ~SqueezeExcite1d.named_parameters
-      ~SqueezeExcite1d.parameters
-      ~SqueezeExcite1d.register_backward_hook
-      ~SqueezeExcite1d.register_buffer
-      ~SqueezeExcite1d.register_forward_hook
-      ~SqueezeExcite1d.register_forward_pre_hook
-      ~SqueezeExcite1d.register_full_backward_hook
-      ~SqueezeExcite1d.register_full_backward_pre_hook
-      ~SqueezeExcite1d.register_load_state_dict_post_hook
-      ~SqueezeExcite1d.register_load_state_dict_pre_hook
-      ~SqueezeExcite1d.register_module
-      ~SqueezeExcite1d.register_parameter
-      ~SqueezeExcite1d.register_state_dict_post_hook
-      ~SqueezeExcite1d.register_state_dict_pre_hook
-      ~SqueezeExcite1d.requires_grad_
-      ~SqueezeExcite1d.set_extra_state
-      ~SqueezeExcite1d.set_submodule
-      ~SqueezeExcite1d.share_memory
-      ~SqueezeExcite1d.state_dict
-      ~SqueezeExcite1d.to
-      ~SqueezeExcite1d.to_empty
-      ~SqueezeExcite1d.train
-      ~SqueezeExcite1d.type
-      ~SqueezeExcite1d.xpu
-      ~SqueezeExcite1d.zero_grad
-   
-   
-
-   
-   
-   .. rubric:: Attributes
-
-   .. autosummary::
-   
-      ~SqueezeExcite1d.T_destination
-      ~SqueezeExcite1d.call_super_init
-      ~SqueezeExcite1d.dump_patches
-      ~SqueezeExcite1d.training
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.layers_1d.rst b/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.layers_1d.rst
deleted file mode 100644
index 4f6ed2221..000000000
--- a/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.layers_1d.rst
+++ /dev/null
@@ -1,35 +0,0 @@
-torchsig.models.model\_utils.model\_utils\_1d.layers\_1d
-========================================================
-
-.. automodule:: torchsig.models.model_utils.model_utils_1d.layers_1d
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Classes
-
-   .. autosummary::
-      :toctree:
-      :template: custom_class_template.rst
-      :nosignatures:
-   
-      FastGlobalAvgPool1d
-      GBN1d
-      ImageFrom1D
-      SqueezeExcite1d
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.rst b/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.rst
deleted file mode 100644
index f0d932114..000000000
--- a/docs/_autosummary/torchsig.models.model_utils.model_utils_1d.rst
+++ /dev/null
@@ -1,32 +0,0 @@
-torchsig.models.model\_utils.model\_utils\_1d
-=============================================
-
-.. automodule:: torchsig.models.model_utils.model_utils_1d
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-
-
-.. autosummary::
-   :toctree:
-   :template: custom_module_template.rst
-   :recursive:
-
-   conversions_to_1d
-   iq_sampling
-   layers_1d
-
diff --git a/docs/_autosummary/torchsig.models.model_utils.rst b/docs/_autosummary/torchsig.models.model_utils.rst
deleted file mode 100644
index 9c26eb633..000000000
--- a/docs/_autosummary/torchsig.models.model_utils.rst
+++ /dev/null
@@ -1,33 +0,0 @@
-torchsig.models.model\_utils
-============================
-
-.. automodule:: torchsig.models.model_utils
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-
-
-.. autosummary::
-   :toctree:
-   :template: custom_module_template.rst
-   :recursive:
-
-   general_layers
-   layer_tools
-   model_utils_1d
-   simple_models
-
diff --git a/docs/_autosummary/torchsig.models.model_utils.simple_models.convnet_block_1d.rst b/docs/_autosummary/torchsig.models.model_utils.simple_models.convnet_block_1d.rst
deleted file mode 100644
index f986c2ea8..000000000
--- a/docs/_autosummary/torchsig.models.model_utils.simple_models.convnet_block_1d.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.models.model\_utils.simple\_models.convnet\_block\_1d
-==============================================================
-
-.. currentmodule:: torchsig.models.model_utils.simple_models
-
-.. autofunction:: convnet_block_1d
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.model_utils.simple_models.convnet_block_2d.rst b/docs/_autosummary/torchsig.models.model_utils.simple_models.convnet_block_2d.rst
deleted file mode 100644
index f33aa2f35..000000000
--- a/docs/_autosummary/torchsig.models.model_utils.simple_models.convnet_block_2d.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.models.model\_utils.simple\_models.convnet\_block\_2d
-==============================================================
-
-.. currentmodule:: torchsig.models.model_utils.simple_models
-
-.. autofunction:: convnet_block_2d
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.model_utils.simple_models.dense_block.rst b/docs/_autosummary/torchsig.models.model_utils.simple_models.dense_block.rst
deleted file mode 100644
index 9a1185c58..000000000
--- a/docs/_autosummary/torchsig.models.model_utils.simple_models.dense_block.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.models.model\_utils.simple\_models.dense\_block
-========================================================
-
-.. currentmodule:: torchsig.models.model_utils.simple_models
-
-.. autofunction:: dense_block
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.model_utils.simple_models.double_image_scale_2d.rst b/docs/_autosummary/torchsig.models.model_utils.simple_models.double_image_scale_2d.rst
deleted file mode 100644
index 0e054a1b3..000000000
--- a/docs/_autosummary/torchsig.models.model_utils.simple_models.double_image_scale_2d.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.models.model\_utils.simple\_models.double\_image\_scale\_2d
-====================================================================
-
-.. currentmodule:: torchsig.models.model_utils.simple_models
-
-.. autofunction:: double_image_scale_2d
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.model_utils.simple_models.rst b/docs/_autosummary/torchsig.models.model_utils.simple_models.rst
deleted file mode 100644
index 92d76f11c..000000000
--- a/docs/_autosummary/torchsig.models.model_utils.simple_models.rst
+++ /dev/null
@@ -1,37 +0,0 @@
-torchsig.models.model\_utils.simple\_models
-===========================================
-
-.. automodule:: torchsig.models.model_utils.simple_models
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Functions
-
-   .. autosummary::
-      :toctree:
-      :nosignatures:
-   
-      convnet_block_1d
-      convnet_block_2d
-      dense_block
-      double_image_scale_2d
-      simple_convnet_1d
-      simple_convnet_2d
-      simple_densenet
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.models.model_utils.simple_models.simple_convnet_1d.rst b/docs/_autosummary/torchsig.models.model_utils.simple_models.simple_convnet_1d.rst
deleted file mode 100644
index 4d2d7d4ca..000000000
--- a/docs/_autosummary/torchsig.models.model_utils.simple_models.simple_convnet_1d.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.models.model\_utils.simple\_models.simple\_convnet\_1d
-===============================================================
-
-.. currentmodule:: torchsig.models.model_utils.simple_models
-
-.. autofunction:: simple_convnet_1d
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.model_utils.simple_models.simple_convnet_2d.rst b/docs/_autosummary/torchsig.models.model_utils.simple_models.simple_convnet_2d.rst
deleted file mode 100644
index a808817dc..000000000
--- a/docs/_autosummary/torchsig.models.model_utils.simple_models.simple_convnet_2d.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.models.model\_utils.simple\_models.simple\_convnet\_2d
-===============================================================
-
-.. currentmodule:: torchsig.models.model_utils.simple_models
-
-.. autofunction:: simple_convnet_2d
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.model_utils.simple_models.simple_densenet.rst b/docs/_autosummary/torchsig.models.model_utils.simple_models.simple_densenet.rst
deleted file mode 100644
index afd1ef8c1..000000000
--- a/docs/_autosummary/torchsig.models.model_utils.simple_models.simple_densenet.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.models.model\_utils.simple\_models.simple\_densenet
-============================================================
-
-.. currentmodule:: torchsig.models.model_utils.simple_models
-
-.. autofunction:: simple_densenet
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.rst b/docs/_autosummary/torchsig.models.rst
deleted file mode 100644
index b213ed911..000000000
--- a/docs/_autosummary/torchsig.models.rst
+++ /dev/null
@@ -1,32 +0,0 @@
-torchsig.models
-===============
-
-.. automodule:: torchsig.models
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-
-
-.. autosummary::
-   :toctree:
-   :template: custom_module_template.rst
-   :recursive:
-
-   iq_models
-   model_utils
-   spectrogram_models
-
diff --git a/docs/_autosummary/torchsig.models.spectrogram_models.detr.criterion.HungarianMatcher.rst b/docs/_autosummary/torchsig.models.spectrogram_models.detr.criterion.HungarianMatcher.rst
deleted file mode 100644
index 87883b60b..000000000
--- a/docs/_autosummary/torchsig.models.spectrogram_models.detr.criterion.HungarianMatcher.rst
+++ /dev/null
@@ -1,84 +0,0 @@
-torchsig.models.spectrogram\_models.detr.criterion.HungarianMatcher
-===================================================================
-
-.. currentmodule:: torchsig.models.spectrogram_models.detr.criterion
-
-.. autoclass:: HungarianMatcher
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~HungarianMatcher.add_module
-      ~HungarianMatcher.apply
-      ~HungarianMatcher.bfloat16
-      ~HungarianMatcher.buffers
-      ~HungarianMatcher.children
-      ~HungarianMatcher.compile
-      ~HungarianMatcher.cpu
-      ~HungarianMatcher.cuda
-      ~HungarianMatcher.double
-      ~HungarianMatcher.eval
-      ~HungarianMatcher.extra_repr
-      ~HungarianMatcher.float
-      ~HungarianMatcher.forward
-      ~HungarianMatcher.get_buffer
-      ~HungarianMatcher.get_extra_state
-      ~HungarianMatcher.get_parameter
-      ~HungarianMatcher.get_submodule
-      ~HungarianMatcher.half
-      ~HungarianMatcher.ipu
-      ~HungarianMatcher.load_state_dict
-      ~HungarianMatcher.memory_efficient_forward
-      ~HungarianMatcher.modules
-      ~HungarianMatcher.mtia
-      ~HungarianMatcher.named_buffers
-      ~HungarianMatcher.named_children
-      ~HungarianMatcher.named_modules
-      ~HungarianMatcher.named_parameters
-      ~HungarianMatcher.parameters
-      ~HungarianMatcher.register_backward_hook
-      ~HungarianMatcher.register_buffer
-      ~HungarianMatcher.register_forward_hook
-      ~HungarianMatcher.register_forward_pre_hook
-      ~HungarianMatcher.register_full_backward_hook
-      ~HungarianMatcher.register_full_backward_pre_hook
-      ~HungarianMatcher.register_load_state_dict_post_hook
-      ~HungarianMatcher.register_load_state_dict_pre_hook
-      ~HungarianMatcher.register_module
-      ~HungarianMatcher.register_parameter
-      ~HungarianMatcher.register_state_dict_post_hook
-      ~HungarianMatcher.register_state_dict_pre_hook
-      ~HungarianMatcher.requires_grad_
-      ~HungarianMatcher.set_extra_state
-      ~HungarianMatcher.set_submodule
-      ~HungarianMatcher.share_memory
-      ~HungarianMatcher.state_dict
-      ~HungarianMatcher.to
-      ~HungarianMatcher.to_empty
-      ~HungarianMatcher.train
-      ~HungarianMatcher.type
-      ~HungarianMatcher.xpu
-      ~HungarianMatcher.zero_grad
-   
-   
-
-   
-   
-   .. rubric:: Attributes
-
-   .. autosummary::
-   
-      ~HungarianMatcher.T_destination
-      ~HungarianMatcher.call_super_init
-      ~HungarianMatcher.dump_patches
-      ~HungarianMatcher.training
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.spectrogram_models.detr.criterion.NestedTensor.rst b/docs/_autosummary/torchsig.models.spectrogram_models.detr.criterion.NestedTensor.rst
deleted file mode 100644
index 493597582..000000000
--- a/docs/_autosummary/torchsig.models.spectrogram_models.detr.criterion.NestedTensor.rst
+++ /dev/null
@@ -1,26 +0,0 @@
-torchsig.models.spectrogram\_models.detr.criterion.NestedTensor
-===============================================================
-
-.. currentmodule:: torchsig.models.spectrogram_models.detr.criterion
-
-.. autoclass:: NestedTensor
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~NestedTensor.decompose
-      ~NestedTensor.to
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.spectrogram_models.detr.criterion.SetCriterion.rst b/docs/_autosummary/torchsig.models.spectrogram_models.detr.criterion.SetCriterion.rst
deleted file mode 100644
index bb2b69e0e..000000000
--- a/docs/_autosummary/torchsig.models.spectrogram_models.detr.criterion.SetCriterion.rst
+++ /dev/null
@@ -1,86 +0,0 @@
-torchsig.models.spectrogram\_models.detr.criterion.SetCriterion
-===============================================================
-
-.. currentmodule:: torchsig.models.spectrogram_models.detr.criterion
-
-.. autoclass:: SetCriterion
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~SetCriterion.add_module
-      ~SetCriterion.apply
-      ~SetCriterion.bfloat16
-      ~SetCriterion.buffers
-      ~SetCriterion.children
-      ~SetCriterion.compile
-      ~SetCriterion.cpu
-      ~SetCriterion.cuda
-      ~SetCriterion.double
-      ~SetCriterion.eval
-      ~SetCriterion.extra_repr
-      ~SetCriterion.float
-      ~SetCriterion.forward
-      ~SetCriterion.get_buffer
-      ~SetCriterion.get_extra_state
-      ~SetCriterion.get_loss
-      ~SetCriterion.get_parameter
-      ~SetCriterion.get_submodule
-      ~SetCriterion.half
-      ~SetCriterion.ipu
-      ~SetCriterion.load_state_dict
-      ~SetCriterion.loss_labels
-      ~SetCriterion.loss_masks
-      ~SetCriterion.modules
-      ~SetCriterion.mtia
-      ~SetCriterion.named_buffers
-      ~SetCriterion.named_children
-      ~SetCriterion.named_modules
-      ~SetCriterion.named_parameters
-      ~SetCriterion.parameters
-      ~SetCriterion.register_backward_hook
-      ~SetCriterion.register_buffer
-      ~SetCriterion.register_forward_hook
-      ~SetCriterion.register_forward_pre_hook
-      ~SetCriterion.register_full_backward_hook
-      ~SetCriterion.register_full_backward_pre_hook
-      ~SetCriterion.register_load_state_dict_post_hook
-      ~SetCriterion.register_load_state_dict_pre_hook
-      ~SetCriterion.register_module
-      ~SetCriterion.register_parameter
-      ~SetCriterion.register_state_dict_post_hook
-      ~SetCriterion.register_state_dict_pre_hook
-      ~SetCriterion.requires_grad_
-      ~SetCriterion.set_extra_state
-      ~SetCriterion.set_submodule
-      ~SetCriterion.share_memory
-      ~SetCriterion.state_dict
-      ~SetCriterion.to
-      ~SetCriterion.to_empty
-      ~SetCriterion.train
-      ~SetCriterion.type
-      ~SetCriterion.xpu
-      ~SetCriterion.zero_grad
-   
-   
-
-   
-   
-   .. rubric:: Attributes
-
-   .. autosummary::
-   
-      ~SetCriterion.T_destination
-      ~SetCriterion.call_super_init
-      ~SetCriterion.dump_patches
-      ~SetCriterion.training
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.spectrogram_models.detr.criterion.batch_dice_loss.rst b/docs/_autosummary/torchsig.models.spectrogram_models.detr.criterion.batch_dice_loss.rst
deleted file mode 100644
index 2c54a3389..000000000
--- a/docs/_autosummary/torchsig.models.spectrogram_models.detr.criterion.batch_dice_loss.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.models.spectrogram\_models.detr.criterion.batch\_dice\_loss
-====================================================================
-
-.. currentmodule:: torchsig.models.spectrogram_models.detr.criterion
-
-.. autofunction:: batch_dice_loss
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.spectrogram_models.detr.criterion.batch_sigmoid_ce_loss.rst b/docs/_autosummary/torchsig.models.spectrogram_models.detr.criterion.batch_sigmoid_ce_loss.rst
deleted file mode 100644
index 579a92363..000000000
--- a/docs/_autosummary/torchsig.models.spectrogram_models.detr.criterion.batch_sigmoid_ce_loss.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.models.spectrogram\_models.detr.criterion.batch\_sigmoid\_ce\_loss
-===========================================================================
-
-.. currentmodule:: torchsig.models.spectrogram_models.detr.criterion
-
-.. autofunction:: batch_sigmoid_ce_loss
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.spectrogram_models.detr.criterion.calculate_uncertainty.rst b/docs/_autosummary/torchsig.models.spectrogram_models.detr.criterion.calculate_uncertainty.rst
deleted file mode 100644
index cf3dd1213..000000000
--- a/docs/_autosummary/torchsig.models.spectrogram_models.detr.criterion.calculate_uncertainty.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.models.spectrogram\_models.detr.criterion.calculate\_uncertainty
-=========================================================================
-
-.. currentmodule:: torchsig.models.spectrogram_models.detr.criterion
-
-.. autofunction:: calculate_uncertainty
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.spectrogram_models.detr.criterion.dice_loss.rst b/docs/_autosummary/torchsig.models.spectrogram_models.detr.criterion.dice_loss.rst
deleted file mode 100644
index 54620b339..000000000
--- a/docs/_autosummary/torchsig.models.spectrogram_models.detr.criterion.dice_loss.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.models.spectrogram\_models.detr.criterion.dice\_loss
-=============================================================
-
-.. currentmodule:: torchsig.models.spectrogram_models.detr.criterion
-
-.. autofunction:: dice_loss
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.spectrogram_models.detr.criterion.get_uncertain_point_coords_with_randomness.rst b/docs/_autosummary/torchsig.models.spectrogram_models.detr.criterion.get_uncertain_point_coords_with_randomness.rst
deleted file mode 100644
index f3c2b2d32..000000000
--- a/docs/_autosummary/torchsig.models.spectrogram_models.detr.criterion.get_uncertain_point_coords_with_randomness.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.models.spectrogram\_models.detr.criterion.get\_uncertain\_point\_coords\_with\_randomness
-==================================================================================================
-
-.. currentmodule:: torchsig.models.spectrogram_models.detr.criterion
-
-.. autofunction:: get_uncertain_point_coords_with_randomness
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.spectrogram_models.detr.criterion.get_world_size.rst b/docs/_autosummary/torchsig.models.spectrogram_models.detr.criterion.get_world_size.rst
deleted file mode 100644
index 2fadc1f3a..000000000
--- a/docs/_autosummary/torchsig.models.spectrogram_models.detr.criterion.get_world_size.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.models.spectrogram\_models.detr.criterion.get\_world\_size
-===================================================================
-
-.. currentmodule:: torchsig.models.spectrogram_models.detr.criterion
-
-.. autofunction:: get_world_size
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.spectrogram_models.detr.criterion.is_dist_avail_and_initialized.rst b/docs/_autosummary/torchsig.models.spectrogram_models.detr.criterion.is_dist_avail_and_initialized.rst
deleted file mode 100644
index dd57b0d46..000000000
--- a/docs/_autosummary/torchsig.models.spectrogram_models.detr.criterion.is_dist_avail_and_initialized.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.models.spectrogram\_models.detr.criterion.is\_dist\_avail\_and\_initialized
-====================================================================================
-
-.. currentmodule:: torchsig.models.spectrogram_models.detr.criterion
-
-.. autofunction:: is_dist_avail_and_initialized
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.spectrogram_models.detr.criterion.nested_tensor_from_tensor_list.rst b/docs/_autosummary/torchsig.models.spectrogram_models.detr.criterion.nested_tensor_from_tensor_list.rst
deleted file mode 100644
index d7a556635..000000000
--- a/docs/_autosummary/torchsig.models.spectrogram_models.detr.criterion.nested_tensor_from_tensor_list.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.models.spectrogram\_models.detr.criterion.nested\_tensor\_from\_tensor\_list
-=====================================================================================
-
-.. currentmodule:: torchsig.models.spectrogram_models.detr.criterion
-
-.. autofunction:: nested_tensor_from_tensor_list
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.spectrogram_models.detr.criterion.point_sample.rst b/docs/_autosummary/torchsig.models.spectrogram_models.detr.criterion.point_sample.rst
deleted file mode 100644
index 9c078a640..000000000
--- a/docs/_autosummary/torchsig.models.spectrogram_models.detr.criterion.point_sample.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.models.spectrogram\_models.detr.criterion.point\_sample
-================================================================
-
-.. currentmodule:: torchsig.models.spectrogram_models.detr.criterion
-
-.. autofunction:: point_sample
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.spectrogram_models.detr.criterion.rst b/docs/_autosummary/torchsig.models.spectrogram_models.detr.criterion.rst
deleted file mode 100644
index 76e8c75cf..000000000
--- a/docs/_autosummary/torchsig.models.spectrogram_models.detr.criterion.rst
+++ /dev/null
@@ -1,51 +0,0 @@
-torchsig.models.spectrogram\_models.detr.criterion
-==================================================
-
-.. automodule:: torchsig.models.spectrogram_models.detr.criterion
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Functions
-
-   .. autosummary::
-      :toctree:
-      :nosignatures:
-   
-      batch_dice_loss
-      batch_sigmoid_ce_loss
-      calculate_uncertainty
-      dice_loss
-      get_uncertain_point_coords_with_randomness
-      get_world_size
-      is_dist_avail_and_initialized
-      nested_tensor_from_tensor_list
-      point_sample
-      sigmoid_ce_loss
-   
-   
-
-   
-   
-   .. rubric:: Classes
-
-   .. autosummary::
-      :toctree:
-      :template: custom_class_template.rst
-      :nosignatures:
-   
-      HungarianMatcher
-      NestedTensor
-      SetCriterion
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.models.spectrogram_models.detr.criterion.sigmoid_ce_loss.rst b/docs/_autosummary/torchsig.models.spectrogram_models.detr.criterion.sigmoid_ce_loss.rst
deleted file mode 100644
index a5bf33aca..000000000
--- a/docs/_autosummary/torchsig.models.spectrogram_models.detr.criterion.sigmoid_ce_loss.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.models.spectrogram\_models.detr.criterion.sigmoid\_ce\_loss
-====================================================================
-
-.. currentmodule:: torchsig.models.spectrogram_models.detr.criterion
-
-.. autofunction:: sigmoid_ce_loss
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.spectrogram_models.detr.detr.DETR.rst b/docs/_autosummary/torchsig.models.spectrogram_models.detr.detr.DETR.rst
deleted file mode 100644
index 9ec9078e2..000000000
--- a/docs/_autosummary/torchsig.models.spectrogram_models.detr.detr.DETR.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.models.spectrogram\_models.detr.detr.DETR
-==================================================
-
-.. currentmodule:: torchsig.models.spectrogram_models.detr.detr
-
-.. autofunction:: DETR
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.spectrogram_models.detr.detr.rst b/docs/_autosummary/torchsig.models.spectrogram_models.detr.detr.rst
deleted file mode 100644
index 1156dd8bc..000000000
--- a/docs/_autosummary/torchsig.models.spectrogram_models.detr.detr.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.models.spectrogram\_models.detr.detr
-=============================================
-
-.. automodule:: torchsig.models.spectrogram_models.detr.detr
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Functions
-
-   .. autosummary::
-      :toctree:
-      :nosignatures:
-   
-      DETR
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.models.spectrogram_models.detr.modules.Chunker.rst b/docs/_autosummary/torchsig.models.spectrogram_models.detr.modules.Chunker.rst
deleted file mode 100644
index e326b2479..000000000
--- a/docs/_autosummary/torchsig.models.spectrogram_models.detr.modules.Chunker.rst
+++ /dev/null
@@ -1,83 +0,0 @@
-torchsig.models.spectrogram\_models.detr.modules.Chunker
-========================================================
-
-.. currentmodule:: torchsig.models.spectrogram_models.detr.modules
-
-.. autoclass:: Chunker
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~Chunker.add_module
-      ~Chunker.apply
-      ~Chunker.bfloat16
-      ~Chunker.buffers
-      ~Chunker.children
-      ~Chunker.compile
-      ~Chunker.cpu
-      ~Chunker.cuda
-      ~Chunker.double
-      ~Chunker.eval
-      ~Chunker.extra_repr
-      ~Chunker.float
-      ~Chunker.forward
-      ~Chunker.get_buffer
-      ~Chunker.get_extra_state
-      ~Chunker.get_parameter
-      ~Chunker.get_submodule
-      ~Chunker.half
-      ~Chunker.ipu
-      ~Chunker.load_state_dict
-      ~Chunker.modules
-      ~Chunker.mtia
-      ~Chunker.named_buffers
-      ~Chunker.named_children
-      ~Chunker.named_modules
-      ~Chunker.named_parameters
-      ~Chunker.parameters
-      ~Chunker.register_backward_hook
-      ~Chunker.register_buffer
-      ~Chunker.register_forward_hook
-      ~Chunker.register_forward_pre_hook
-      ~Chunker.register_full_backward_hook
-      ~Chunker.register_full_backward_pre_hook
-      ~Chunker.register_load_state_dict_post_hook
-      ~Chunker.register_load_state_dict_pre_hook
-      ~Chunker.register_module
-      ~Chunker.register_parameter
-      ~Chunker.register_state_dict_post_hook
-      ~Chunker.register_state_dict_pre_hook
-      ~Chunker.requires_grad_
-      ~Chunker.set_extra_state
-      ~Chunker.set_submodule
-      ~Chunker.share_memory
-      ~Chunker.state_dict
-      ~Chunker.to
-      ~Chunker.to_empty
-      ~Chunker.train
-      ~Chunker.type
-      ~Chunker.xpu
-      ~Chunker.zero_grad
-   
-   
-
-   
-   
-   .. rubric:: Attributes
-
-   .. autosummary::
-   
-      ~Chunker.T_destination
-      ~Chunker.call_super_init
-      ~Chunker.dump_patches
-      ~Chunker.training
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.spectrogram_models.detr.modules.ConvDownSampler.rst b/docs/_autosummary/torchsig.models.spectrogram_models.detr.modules.ConvDownSampler.rst
deleted file mode 100644
index b481cde56..000000000
--- a/docs/_autosummary/torchsig.models.spectrogram_models.detr.modules.ConvDownSampler.rst
+++ /dev/null
@@ -1,83 +0,0 @@
-torchsig.models.spectrogram\_models.detr.modules.ConvDownSampler
-================================================================
-
-.. currentmodule:: torchsig.models.spectrogram_models.detr.modules
-
-.. autoclass:: ConvDownSampler
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~ConvDownSampler.add_module
-      ~ConvDownSampler.apply
-      ~ConvDownSampler.bfloat16
-      ~ConvDownSampler.buffers
-      ~ConvDownSampler.children
-      ~ConvDownSampler.compile
-      ~ConvDownSampler.cpu
-      ~ConvDownSampler.cuda
-      ~ConvDownSampler.double
-      ~ConvDownSampler.eval
-      ~ConvDownSampler.extra_repr
-      ~ConvDownSampler.float
-      ~ConvDownSampler.forward
-      ~ConvDownSampler.get_buffer
-      ~ConvDownSampler.get_extra_state
-      ~ConvDownSampler.get_parameter
-      ~ConvDownSampler.get_submodule
-      ~ConvDownSampler.half
-      ~ConvDownSampler.ipu
-      ~ConvDownSampler.load_state_dict
-      ~ConvDownSampler.modules
-      ~ConvDownSampler.mtia
-      ~ConvDownSampler.named_buffers
-      ~ConvDownSampler.named_children
-      ~ConvDownSampler.named_modules
-      ~ConvDownSampler.named_parameters
-      ~ConvDownSampler.parameters
-      ~ConvDownSampler.register_backward_hook
-      ~ConvDownSampler.register_buffer
-      ~ConvDownSampler.register_forward_hook
-      ~ConvDownSampler.register_forward_pre_hook
-      ~ConvDownSampler.register_full_backward_hook
-      ~ConvDownSampler.register_full_backward_pre_hook
-      ~ConvDownSampler.register_load_state_dict_post_hook
-      ~ConvDownSampler.register_load_state_dict_pre_hook
-      ~ConvDownSampler.register_module
-      ~ConvDownSampler.register_parameter
-      ~ConvDownSampler.register_state_dict_post_hook
-      ~ConvDownSampler.register_state_dict_pre_hook
-      ~ConvDownSampler.requires_grad_
-      ~ConvDownSampler.set_extra_state
-      ~ConvDownSampler.set_submodule
-      ~ConvDownSampler.share_memory
-      ~ConvDownSampler.state_dict
-      ~ConvDownSampler.to
-      ~ConvDownSampler.to_empty
-      ~ConvDownSampler.train
-      ~ConvDownSampler.type
-      ~ConvDownSampler.xpu
-      ~ConvDownSampler.zero_grad
-   
-   
-
-   
-   
-   .. rubric:: Attributes
-
-   .. autosummary::
-   
-      ~ConvDownSampler.T_destination
-      ~ConvDownSampler.call_super_init
-      ~ConvDownSampler.dump_patches
-      ~ConvDownSampler.training
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.spectrogram_models.detr.modules.DETRModel.rst b/docs/_autosummary/torchsig.models.spectrogram_models.detr.modules.DETRModel.rst
deleted file mode 100644
index ab7cadeaf..000000000
--- a/docs/_autosummary/torchsig.models.spectrogram_models.detr.modules.DETRModel.rst
+++ /dev/null
@@ -1,83 +0,0 @@
-torchsig.models.spectrogram\_models.detr.modules.DETRModel
-==========================================================
-
-.. currentmodule:: torchsig.models.spectrogram_models.detr.modules
-
-.. autoclass:: DETRModel
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~DETRModel.add_module
-      ~DETRModel.apply
-      ~DETRModel.bfloat16
-      ~DETRModel.buffers
-      ~DETRModel.children
-      ~DETRModel.compile
-      ~DETRModel.cpu
-      ~DETRModel.cuda
-      ~DETRModel.double
-      ~DETRModel.eval
-      ~DETRModel.extra_repr
-      ~DETRModel.float
-      ~DETRModel.forward
-      ~DETRModel.get_buffer
-      ~DETRModel.get_extra_state
-      ~DETRModel.get_parameter
-      ~DETRModel.get_submodule
-      ~DETRModel.half
-      ~DETRModel.ipu
-      ~DETRModel.load_state_dict
-      ~DETRModel.modules
-      ~DETRModel.mtia
-      ~DETRModel.named_buffers
-      ~DETRModel.named_children
-      ~DETRModel.named_modules
-      ~DETRModel.named_parameters
-      ~DETRModel.parameters
-      ~DETRModel.register_backward_hook
-      ~DETRModel.register_buffer
-      ~DETRModel.register_forward_hook
-      ~DETRModel.register_forward_pre_hook
-      ~DETRModel.register_full_backward_hook
-      ~DETRModel.register_full_backward_pre_hook
-      ~DETRModel.register_load_state_dict_post_hook
-      ~DETRModel.register_load_state_dict_pre_hook
-      ~DETRModel.register_module
-      ~DETRModel.register_parameter
-      ~DETRModel.register_state_dict_post_hook
-      ~DETRModel.register_state_dict_pre_hook
-      ~DETRModel.requires_grad_
-      ~DETRModel.set_extra_state
-      ~DETRModel.set_submodule
-      ~DETRModel.share_memory
-      ~DETRModel.state_dict
-      ~DETRModel.to
-      ~DETRModel.to_empty
-      ~DETRModel.train
-      ~DETRModel.type
-      ~DETRModel.xpu
-      ~DETRModel.zero_grad
-   
-   
-
-   
-   
-   .. rubric:: Attributes
-
-   .. autosummary::
-   
-      ~DETRModel.T_destination
-      ~DETRModel.call_super_init
-      ~DETRModel.dump_patches
-      ~DETRModel.training
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.spectrogram_models.detr.modules.HungarianMatcher.rst b/docs/_autosummary/torchsig.models.spectrogram_models.detr.modules.HungarianMatcher.rst
deleted file mode 100644
index c6eaf2ebb..000000000
--- a/docs/_autosummary/torchsig.models.spectrogram_models.detr.modules.HungarianMatcher.rst
+++ /dev/null
@@ -1,83 +0,0 @@
-torchsig.models.spectrogram\_models.detr.modules.HungarianMatcher
-=================================================================
-
-.. currentmodule:: torchsig.models.spectrogram_models.detr.modules
-
-.. autoclass:: HungarianMatcher
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~HungarianMatcher.add_module
-      ~HungarianMatcher.apply
-      ~HungarianMatcher.bfloat16
-      ~HungarianMatcher.buffers
-      ~HungarianMatcher.children
-      ~HungarianMatcher.compile
-      ~HungarianMatcher.cpu
-      ~HungarianMatcher.cuda
-      ~HungarianMatcher.double
-      ~HungarianMatcher.eval
-      ~HungarianMatcher.extra_repr
-      ~HungarianMatcher.float
-      ~HungarianMatcher.forward
-      ~HungarianMatcher.get_buffer
-      ~HungarianMatcher.get_extra_state
-      ~HungarianMatcher.get_parameter
-      ~HungarianMatcher.get_submodule
-      ~HungarianMatcher.half
-      ~HungarianMatcher.ipu
-      ~HungarianMatcher.load_state_dict
-      ~HungarianMatcher.modules
-      ~HungarianMatcher.mtia
-      ~HungarianMatcher.named_buffers
-      ~HungarianMatcher.named_children
-      ~HungarianMatcher.named_modules
-      ~HungarianMatcher.named_parameters
-      ~HungarianMatcher.parameters
-      ~HungarianMatcher.register_backward_hook
-      ~HungarianMatcher.register_buffer
-      ~HungarianMatcher.register_forward_hook
-      ~HungarianMatcher.register_forward_pre_hook
-      ~HungarianMatcher.register_full_backward_hook
-      ~HungarianMatcher.register_full_backward_pre_hook
-      ~HungarianMatcher.register_load_state_dict_post_hook
-      ~HungarianMatcher.register_load_state_dict_pre_hook
-      ~HungarianMatcher.register_module
-      ~HungarianMatcher.register_parameter
-      ~HungarianMatcher.register_state_dict_post_hook
-      ~HungarianMatcher.register_state_dict_pre_hook
-      ~HungarianMatcher.requires_grad_
-      ~HungarianMatcher.set_extra_state
-      ~HungarianMatcher.set_submodule
-      ~HungarianMatcher.share_memory
-      ~HungarianMatcher.state_dict
-      ~HungarianMatcher.to
-      ~HungarianMatcher.to_empty
-      ~HungarianMatcher.train
-      ~HungarianMatcher.type
-      ~HungarianMatcher.xpu
-      ~HungarianMatcher.zero_grad
-   
-   
-
-   
-   
-   .. rubric:: Attributes
-
-   .. autosummary::
-   
-      ~HungarianMatcher.T_destination
-      ~HungarianMatcher.call_super_init
-      ~HungarianMatcher.dump_patches
-      ~HungarianMatcher.training
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.spectrogram_models.detr.modules.MLP.rst b/docs/_autosummary/torchsig.models.spectrogram_models.detr.modules.MLP.rst
deleted file mode 100644
index bcf65ad5a..000000000
--- a/docs/_autosummary/torchsig.models.spectrogram_models.detr.modules.MLP.rst
+++ /dev/null
@@ -1,83 +0,0 @@
-torchsig.models.spectrogram\_models.detr.modules.MLP
-====================================================
-
-.. currentmodule:: torchsig.models.spectrogram_models.detr.modules
-
-.. autoclass:: MLP
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~MLP.add_module
-      ~MLP.apply
-      ~MLP.bfloat16
-      ~MLP.buffers
-      ~MLP.children
-      ~MLP.compile
-      ~MLP.cpu
-      ~MLP.cuda
-      ~MLP.double
-      ~MLP.eval
-      ~MLP.extra_repr
-      ~MLP.float
-      ~MLP.forward
-      ~MLP.get_buffer
-      ~MLP.get_extra_state
-      ~MLP.get_parameter
-      ~MLP.get_submodule
-      ~MLP.half
-      ~MLP.ipu
-      ~MLP.load_state_dict
-      ~MLP.modules
-      ~MLP.mtia
-      ~MLP.named_buffers
-      ~MLP.named_children
-      ~MLP.named_modules
-      ~MLP.named_parameters
-      ~MLP.parameters
-      ~MLP.register_backward_hook
-      ~MLP.register_buffer
-      ~MLP.register_forward_hook
-      ~MLP.register_forward_pre_hook
-      ~MLP.register_full_backward_hook
-      ~MLP.register_full_backward_pre_hook
-      ~MLP.register_load_state_dict_post_hook
-      ~MLP.register_load_state_dict_pre_hook
-      ~MLP.register_module
-      ~MLP.register_parameter
-      ~MLP.register_state_dict_post_hook
-      ~MLP.register_state_dict_pre_hook
-      ~MLP.requires_grad_
-      ~MLP.set_extra_state
-      ~MLP.set_submodule
-      ~MLP.share_memory
-      ~MLP.state_dict
-      ~MLP.to
-      ~MLP.to_empty
-      ~MLP.train
-      ~MLP.type
-      ~MLP.xpu
-      ~MLP.zero_grad
-   
-   
-
-   
-   
-   .. rubric:: Attributes
-
-   .. autosummary::
-   
-      ~MLP.T_destination
-      ~MLP.call_super_init
-      ~MLP.dump_patches
-      ~MLP.training
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.spectrogram_models.detr.modules.SetCriterion.rst b/docs/_autosummary/torchsig.models.spectrogram_models.detr.modules.SetCriterion.rst
deleted file mode 100644
index 47c1eba46..000000000
--- a/docs/_autosummary/torchsig.models.spectrogram_models.detr.modules.SetCriterion.rst
+++ /dev/null
@@ -1,88 +0,0 @@
-torchsig.models.spectrogram\_models.detr.modules.SetCriterion
-=============================================================
-
-.. currentmodule:: torchsig.models.spectrogram_models.detr.modules
-
-.. autoclass:: SetCriterion
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~SetCriterion.add_module
-      ~SetCriterion.apply
-      ~SetCriterion.bfloat16
-      ~SetCriterion.buffers
-      ~SetCriterion.children
-      ~SetCriterion.compile
-      ~SetCriterion.cpu
-      ~SetCriterion.cuda
-      ~SetCriterion.double
-      ~SetCriterion.eval
-      ~SetCriterion.extra_repr
-      ~SetCriterion.float
-      ~SetCriterion.forward
-      ~SetCriterion.get_buffer
-      ~SetCriterion.get_extra_state
-      ~SetCriterion.get_loss
-      ~SetCriterion.get_parameter
-      ~SetCriterion.get_submodule
-      ~SetCriterion.half
-      ~SetCriterion.ipu
-      ~SetCriterion.load_state_dict
-      ~SetCriterion.loss_boxes
-      ~SetCriterion.loss_cardinality
-      ~SetCriterion.loss_labels
-      ~SetCriterion.loss_masks
-      ~SetCriterion.modules
-      ~SetCriterion.mtia
-      ~SetCriterion.named_buffers
-      ~SetCriterion.named_children
-      ~SetCriterion.named_modules
-      ~SetCriterion.named_parameters
-      ~SetCriterion.parameters
-      ~SetCriterion.register_backward_hook
-      ~SetCriterion.register_buffer
-      ~SetCriterion.register_forward_hook
-      ~SetCriterion.register_forward_pre_hook
-      ~SetCriterion.register_full_backward_hook
-      ~SetCriterion.register_full_backward_pre_hook
-      ~SetCriterion.register_load_state_dict_post_hook
-      ~SetCriterion.register_load_state_dict_pre_hook
-      ~SetCriterion.register_module
-      ~SetCriterion.register_parameter
-      ~SetCriterion.register_state_dict_post_hook
-      ~SetCriterion.register_state_dict_pre_hook
-      ~SetCriterion.requires_grad_
-      ~SetCriterion.set_extra_state
-      ~SetCriterion.set_submodule
-      ~SetCriterion.share_memory
-      ~SetCriterion.state_dict
-      ~SetCriterion.to
-      ~SetCriterion.to_empty
-      ~SetCriterion.train
-      ~SetCriterion.type
-      ~SetCriterion.xpu
-      ~SetCriterion.zero_grad
-   
-   
-
-   
-   
-   .. rubric:: Attributes
-
-   .. autosummary::
-   
-      ~SetCriterion.T_destination
-      ~SetCriterion.call_super_init
-      ~SetCriterion.dump_patches
-      ~SetCriterion.training
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.spectrogram_models.detr.modules.XCiT.rst b/docs/_autosummary/torchsig.models.spectrogram_models.detr.modules.XCiT.rst
deleted file mode 100644
index 2609470bd..000000000
--- a/docs/_autosummary/torchsig.models.spectrogram_models.detr.modules.XCiT.rst
+++ /dev/null
@@ -1,83 +0,0 @@
-torchsig.models.spectrogram\_models.detr.modules.XCiT
-=====================================================
-
-.. currentmodule:: torchsig.models.spectrogram_models.detr.modules
-
-.. autoclass:: XCiT
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~XCiT.add_module
-      ~XCiT.apply
-      ~XCiT.bfloat16
-      ~XCiT.buffers
-      ~XCiT.children
-      ~XCiT.compile
-      ~XCiT.cpu
-      ~XCiT.cuda
-      ~XCiT.double
-      ~XCiT.eval
-      ~XCiT.extra_repr
-      ~XCiT.float
-      ~XCiT.forward
-      ~XCiT.get_buffer
-      ~XCiT.get_extra_state
-      ~XCiT.get_parameter
-      ~XCiT.get_submodule
-      ~XCiT.half
-      ~XCiT.ipu
-      ~XCiT.load_state_dict
-      ~XCiT.modules
-      ~XCiT.mtia
-      ~XCiT.named_buffers
-      ~XCiT.named_children
-      ~XCiT.named_modules
-      ~XCiT.named_parameters
-      ~XCiT.parameters
-      ~XCiT.register_backward_hook
-      ~XCiT.register_buffer
-      ~XCiT.register_forward_hook
-      ~XCiT.register_forward_pre_hook
-      ~XCiT.register_full_backward_hook
-      ~XCiT.register_full_backward_pre_hook
-      ~XCiT.register_load_state_dict_post_hook
-      ~XCiT.register_load_state_dict_pre_hook
-      ~XCiT.register_module
-      ~XCiT.register_parameter
-      ~XCiT.register_state_dict_post_hook
-      ~XCiT.register_state_dict_pre_hook
-      ~XCiT.requires_grad_
-      ~XCiT.set_extra_state
-      ~XCiT.set_submodule
-      ~XCiT.share_memory
-      ~XCiT.state_dict
-      ~XCiT.to
-      ~XCiT.to_empty
-      ~XCiT.train
-      ~XCiT.type
-      ~XCiT.xpu
-      ~XCiT.zero_grad
-   
-   
-
-   
-   
-   .. rubric:: Attributes
-
-   .. autosummary::
-   
-      ~XCiT.T_destination
-      ~XCiT.call_super_init
-      ~XCiT.dump_patches
-      ~XCiT.training
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.spectrogram_models.detr.modules.create_detr.rst b/docs/_autosummary/torchsig.models.spectrogram_models.detr.modules.create_detr.rst
deleted file mode 100644
index 5215b2611..000000000
--- a/docs/_autosummary/torchsig.models.spectrogram_models.detr.modules.create_detr.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.models.spectrogram\_models.detr.modules.create\_detr
-=============================================================
-
-.. currentmodule:: torchsig.models.spectrogram_models.detr.modules
-
-.. autofunction:: create_detr
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.spectrogram_models.detr.modules.rst b/docs/_autosummary/torchsig.models.spectrogram_models.detr.modules.rst
deleted file mode 100644
index 8daaa4119..000000000
--- a/docs/_autosummary/torchsig.models.spectrogram_models.detr.modules.rst
+++ /dev/null
@@ -1,46 +0,0 @@
-torchsig.models.spectrogram\_models.detr.modules
-================================================
-
-.. automodule:: torchsig.models.spectrogram_models.detr.modules
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Functions
-
-   .. autosummary::
-      :toctree:
-      :nosignatures:
-   
-      create_detr
-   
-   
-
-   
-   
-   .. rubric:: Classes
-
-   .. autosummary::
-      :toctree:
-      :template: custom_class_template.rst
-      :nosignatures:
-   
-      Chunker
-      ConvDownSampler
-      DETRModel
-      HungarianMatcher
-      MLP
-      SetCriterion
-      XCiT
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.models.spectrogram_models.detr.rst b/docs/_autosummary/torchsig.models.spectrogram_models.detr.rst
deleted file mode 100644
index ffca79d1d..000000000
--- a/docs/_autosummary/torchsig.models.spectrogram_models.detr.rst
+++ /dev/null
@@ -1,33 +0,0 @@
-torchsig.models.spectrogram\_models.detr
-========================================
-
-.. automodule:: torchsig.models.spectrogram_models.detr
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-
-
-.. autosummary::
-   :toctree:
-   :template: custom_module_template.rst
-   :recursive:
-
-   criterion
-   detr
-   modules
-   utils
-
diff --git a/docs/_autosummary/torchsig.models.spectrogram_models.detr.utils.accuracy.rst b/docs/_autosummary/torchsig.models.spectrogram_models.detr.utils.accuracy.rst
deleted file mode 100644
index 5e5351623..000000000
--- a/docs/_autosummary/torchsig.models.spectrogram_models.detr.utils.accuracy.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.models.spectrogram\_models.detr.utils.accuracy
-=======================================================
-
-.. currentmodule:: torchsig.models.spectrogram_models.detr.utils
-
-.. autofunction:: accuracy
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.spectrogram_models.detr.utils.box_cxcywh_to_xyxy.rst b/docs/_autosummary/torchsig.models.spectrogram_models.detr.utils.box_cxcywh_to_xyxy.rst
deleted file mode 100644
index c97e2a8e9..000000000
--- a/docs/_autosummary/torchsig.models.spectrogram_models.detr.utils.box_cxcywh_to_xyxy.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.models.spectrogram\_models.detr.utils.box\_cxcywh\_to\_xyxy
-====================================================================
-
-.. currentmodule:: torchsig.models.spectrogram_models.detr.utils
-
-.. autofunction:: box_cxcywh_to_xyxy
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.spectrogram_models.detr.utils.box_iou.rst b/docs/_autosummary/torchsig.models.spectrogram_models.detr.utils.box_iou.rst
deleted file mode 100644
index 87653df3f..000000000
--- a/docs/_autosummary/torchsig.models.spectrogram_models.detr.utils.box_iou.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.models.spectrogram\_models.detr.utils.box\_iou
-=======================================================
-
-.. currentmodule:: torchsig.models.spectrogram_models.detr.utils
-
-.. autofunction:: box_iou
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.spectrogram_models.detr.utils.drop_classifier.rst b/docs/_autosummary/torchsig.models.spectrogram_models.detr.utils.drop_classifier.rst
deleted file mode 100644
index f5d1052d8..000000000
--- a/docs/_autosummary/torchsig.models.spectrogram_models.detr.utils.drop_classifier.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.models.spectrogram\_models.detr.utils.drop\_classifier
-===============================================================
-
-.. currentmodule:: torchsig.models.spectrogram_models.detr.utils
-
-.. autofunction:: drop_classifier
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.spectrogram_models.detr.utils.find_output_features.rst b/docs/_autosummary/torchsig.models.spectrogram_models.detr.utils.find_output_features.rst
deleted file mode 100644
index df9d5a853..000000000
--- a/docs/_autosummary/torchsig.models.spectrogram_models.detr.utils.find_output_features.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.models.spectrogram\_models.detr.utils.find\_output\_features
-=====================================================================
-
-.. currentmodule:: torchsig.models.spectrogram_models.detr.utils
-
-.. autofunction:: find_output_features
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.spectrogram_models.detr.utils.format_preds.rst b/docs/_autosummary/torchsig.models.spectrogram_models.detr.utils.format_preds.rst
deleted file mode 100644
index ebfec0580..000000000
--- a/docs/_autosummary/torchsig.models.spectrogram_models.detr.utils.format_preds.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.models.spectrogram\_models.detr.utils.format\_preds
-============================================================
-
-.. currentmodule:: torchsig.models.spectrogram_models.detr.utils
-
-.. autofunction:: format_preds
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.spectrogram_models.detr.utils.format_targets.rst b/docs/_autosummary/torchsig.models.spectrogram_models.detr.utils.format_targets.rst
deleted file mode 100644
index 5d1b1ac17..000000000
--- a/docs/_autosummary/torchsig.models.spectrogram_models.detr.utils.format_targets.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.models.spectrogram\_models.detr.utils.format\_targets
-==============================================================
-
-.. currentmodule:: torchsig.models.spectrogram_models.detr.utils
-
-.. autofunction:: format_targets
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.spectrogram_models.detr.utils.generalized_box_iou.rst b/docs/_autosummary/torchsig.models.spectrogram_models.detr.utils.generalized_box_iou.rst
deleted file mode 100644
index 6fc67dcb4..000000000
--- a/docs/_autosummary/torchsig.models.spectrogram_models.detr.utils.generalized_box_iou.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.models.spectrogram\_models.detr.utils.generalized\_box\_iou
-====================================================================
-
-.. currentmodule:: torchsig.models.spectrogram_models.detr.utils
-
-.. autofunction:: generalized_box_iou
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.spectrogram_models.detr.utils.get_world_size.rst b/docs/_autosummary/torchsig.models.spectrogram_models.detr.utils.get_world_size.rst
deleted file mode 100644
index aa1808353..000000000
--- a/docs/_autosummary/torchsig.models.spectrogram_models.detr.utils.get_world_size.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.models.spectrogram\_models.detr.utils.get\_world\_size
-===============================================================
-
-.. currentmodule:: torchsig.models.spectrogram_models.detr.utils
-
-.. autofunction:: get_world_size
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.spectrogram_models.detr.utils.is_dist_avail_and_initialized.rst b/docs/_autosummary/torchsig.models.spectrogram_models.detr.utils.is_dist_avail_and_initialized.rst
deleted file mode 100644
index d7a1c6af7..000000000
--- a/docs/_autosummary/torchsig.models.spectrogram_models.detr.utils.is_dist_avail_and_initialized.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.models.spectrogram\_models.detr.utils.is\_dist\_avail\_and\_initialized
-================================================================================
-
-.. currentmodule:: torchsig.models.spectrogram_models.detr.utils
-
-.. autofunction:: is_dist_avail_and_initialized
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.spectrogram_models.detr.utils.rst b/docs/_autosummary/torchsig.models.spectrogram_models.detr.utils.rst
deleted file mode 100644
index 231d30fd0..000000000
--- a/docs/_autosummary/torchsig.models.spectrogram_models.detr.utils.rst
+++ /dev/null
@@ -1,41 +0,0 @@
-torchsig.models.spectrogram\_models.detr.utils
-==============================================
-
-.. automodule:: torchsig.models.spectrogram_models.detr.utils
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Functions
-
-   .. autosummary::
-      :toctree:
-      :nosignatures:
-   
-      accuracy
-      box_cxcywh_to_xyxy
-      box_iou
-      drop_classifier
-      find_output_features
-      format_preds
-      format_targets
-      generalized_box_iou
-      get_world_size
-      is_dist_avail_and_initialized
-      xcit_name_to_timm_name
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.models.spectrogram_models.detr.utils.xcit_name_to_timm_name.rst b/docs/_autosummary/torchsig.models.spectrogram_models.detr.utils.xcit_name_to_timm_name.rst
deleted file mode 100644
index c67ac4cb2..000000000
--- a/docs/_autosummary/torchsig.models.spectrogram_models.detr.utils.xcit_name_to_timm_name.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.models.spectrogram\_models.detr.utils.xcit\_name\_to\_timm\_name
-=========================================================================
-
-.. currentmodule:: torchsig.models.spectrogram_models.detr.utils
-
-.. autofunction:: xcit_name_to_timm_name
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.spectrogram_models.efficientnet.efficientnet2d.EfficientNet2d.rst b/docs/_autosummary/torchsig.models.spectrogram_models.efficientnet.efficientnet2d.EfficientNet2d.rst
deleted file mode 100644
index 99044523e..000000000
--- a/docs/_autosummary/torchsig.models.spectrogram_models.efficientnet.efficientnet2d.EfficientNet2d.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.models.spectrogram\_models.efficientnet.efficientnet2d.EfficientNet2d
-==============================================================================
-
-.. currentmodule:: torchsig.models.spectrogram_models.efficientnet.efficientnet2d
-
-.. autofunction:: EfficientNet2d
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.models.spectrogram_models.efficientnet.efficientnet2d.rst b/docs/_autosummary/torchsig.models.spectrogram_models.efficientnet.efficientnet2d.rst
deleted file mode 100644
index 7dfd40175..000000000
--- a/docs/_autosummary/torchsig.models.spectrogram_models.efficientnet.efficientnet2d.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.models.spectrogram\_models.efficientnet.efficientnet2d
-===============================================================
-
-.. automodule:: torchsig.models.spectrogram_models.efficientnet.efficientnet2d
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Functions
-
-   .. autosummary::
-      :toctree:
-      :nosignatures:
-   
-      EfficientNet2d
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.models.spectrogram_models.efficientnet.rst b/docs/_autosummary/torchsig.models.spectrogram_models.efficientnet.rst
deleted file mode 100644
index 2699b4b1a..000000000
--- a/docs/_autosummary/torchsig.models.spectrogram_models.efficientnet.rst
+++ /dev/null
@@ -1,30 +0,0 @@
-torchsig.models.spectrogram\_models.efficientnet
-================================================
-
-.. automodule:: torchsig.models.spectrogram_models.efficientnet
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-
-
-.. autosummary::
-   :toctree:
-   :template: custom_module_template.rst
-   :recursive:
-
-   efficientnet2d
-
diff --git a/docs/_autosummary/torchsig.models.spectrogram_models.rst b/docs/_autosummary/torchsig.models.spectrogram_models.rst
deleted file mode 100644
index 7d187f415..000000000
--- a/docs/_autosummary/torchsig.models.spectrogram_models.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.models.spectrogram\_models
-===================================
-
-.. automodule:: torchsig.models.spectrogram_models
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-
-
-.. autosummary::
-   :toctree:
-   :template: custom_module_template.rst
-   :recursive:
-
-   detr
-   efficientnet
-
diff --git a/docs/_autosummary/torchsig.rst b/docs/_autosummary/torchsig.rst
deleted file mode 100644
index 54dbefe28..000000000
--- a/docs/_autosummary/torchsig.rst
+++ /dev/null
@@ -1,35 +0,0 @@
-﻿torchsig
-========
-
-.. automodule:: torchsig
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-
-
-.. autosummary::
-   :toctree:
-   :template: custom_module_template.rst
-   :recursive:
-
-   datasets
-   image_datasets
-   models
-   signals
-   transforms
-   utils
-
diff --git a/docs/_autosummary/torchsig.signals.builder.Builder.rst b/docs/_autosummary/torchsig.signals.builder.Builder.rst
deleted file mode 100644
index 540947dcc..000000000
--- a/docs/_autosummary/torchsig.signals.builder.Builder.rst
+++ /dev/null
@@ -1,26 +0,0 @@
-torchsig.signals.builder.Builder
-================================
-
-.. currentmodule:: torchsig.signals.builder
-
-.. autoclass:: Builder
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~Builder.build
-      ~Builder.reset
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.signals.builder.SignalBuilder.rst b/docs/_autosummary/torchsig.signals.builder.SignalBuilder.rst
deleted file mode 100644
index c325ed9d7..000000000
--- a/docs/_autosummary/torchsig.signals.builder.SignalBuilder.rst
+++ /dev/null
@@ -1,38 +0,0 @@
-torchsig.signals.builder.SignalBuilder
-======================================
-
-.. currentmodule:: torchsig.signals.builder
-
-.. autoclass:: SignalBuilder
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~SignalBuilder.add_parent
-      ~SignalBuilder.build
-      ~SignalBuilder.get_distribution
-      ~SignalBuilder.get_second_seed
-      ~SignalBuilder.reset
-      ~SignalBuilder.seed
-      ~SignalBuilder.setup_rngs
-      ~SignalBuilder.update_from_parent
-   
-   
-
-   
-   
-   .. rubric:: Attributes
-
-   .. autosummary::
-   
-      ~SignalBuilder.supported_classes
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.signals.builder.rst b/docs/_autosummary/torchsig.signals.builder.rst
deleted file mode 100644
index 3fb370174..000000000
--- a/docs/_autosummary/torchsig.signals.builder.rst
+++ /dev/null
@@ -1,33 +0,0 @@
-torchsig.signals.builder
-========================
-
-.. automodule:: torchsig.signals.builder
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Classes
-
-   .. autosummary::
-      :toctree:
-      :template: custom_class_template.rst
-      :nosignatures:
-   
-      Builder
-      SignalBuilder
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.signals.builders.am.AMSignalBuilder.rst b/docs/_autosummary/torchsig.signals.builders.am.AMSignalBuilder.rst
deleted file mode 100644
index cf2729cf4..000000000
--- a/docs/_autosummary/torchsig.signals.builders.am.AMSignalBuilder.rst
+++ /dev/null
@@ -1,38 +0,0 @@
-torchsig.signals.builders.am.AMSignalBuilder
-============================================
-
-.. currentmodule:: torchsig.signals.builders.am
-
-.. autoclass:: AMSignalBuilder
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~AMSignalBuilder.add_parent
-      ~AMSignalBuilder.build
-      ~AMSignalBuilder.get_distribution
-      ~AMSignalBuilder.get_second_seed
-      ~AMSignalBuilder.reset
-      ~AMSignalBuilder.seed
-      ~AMSignalBuilder.setup_rngs
-      ~AMSignalBuilder.update_from_parent
-   
-   
-
-   
-   
-   .. rubric:: Attributes
-
-   .. autosummary::
-   
-      ~AMSignalBuilder.supported_classes
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.signals.builders.am.am_modulator.rst b/docs/_autosummary/torchsig.signals.builders.am.am_modulator.rst
deleted file mode 100644
index 120f1bfb2..000000000
--- a/docs/_autosummary/torchsig.signals.builders.am.am_modulator.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.signals.builders.am.am\_modulator
-==========================================
-
-.. currentmodule:: torchsig.signals.builders.am
-
-.. autofunction:: am_modulator
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.signals.builders.am.rst b/docs/_autosummary/torchsig.signals.builders.am.rst
deleted file mode 100644
index a827f227b..000000000
--- a/docs/_autosummary/torchsig.signals.builders.am.rst
+++ /dev/null
@@ -1,40 +0,0 @@
-torchsig.signals.builders.am
-============================
-
-.. automodule:: torchsig.signals.builders.am
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Functions
-
-   .. autosummary::
-      :toctree:
-      :nosignatures:
-   
-      am_modulator
-   
-   
-
-   
-   
-   .. rubric:: Classes
-
-   .. autosummary::
-      :toctree:
-      :template: custom_class_template.rst
-      :nosignatures:
-   
-      AMSignalBuilder
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.signals.builders.chirp.chirp.rst b/docs/_autosummary/torchsig.signals.builders.chirp.chirp.rst
deleted file mode 100644
index 9cb5fc15a..000000000
--- a/docs/_autosummary/torchsig.signals.builders.chirp.chirp.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.signals.builders.chirp.chirp
-=====================================
-
-.. currentmodule:: torchsig.signals.builders.chirp
-
-.. autofunction:: chirp
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.signals.builders.chirp.rst b/docs/_autosummary/torchsig.signals.builders.chirp.rst
deleted file mode 100644
index 3708bd046..000000000
--- a/docs/_autosummary/torchsig.signals.builders.chirp.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.signals.builders.chirp
-===============================
-
-.. automodule:: torchsig.signals.builders.chirp
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Functions
-
-   .. autosummary::
-      :toctree:
-      :nosignatures:
-   
-      chirp
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.signals.builders.chirpss.ChirpSSSignalBuilder.rst b/docs/_autosummary/torchsig.signals.builders.chirpss.ChirpSSSignalBuilder.rst
deleted file mode 100644
index 6c02accd8..000000000
--- a/docs/_autosummary/torchsig.signals.builders.chirpss.ChirpSSSignalBuilder.rst
+++ /dev/null
@@ -1,38 +0,0 @@
-torchsig.signals.builders.chirpss.ChirpSSSignalBuilder
-======================================================
-
-.. currentmodule:: torchsig.signals.builders.chirpss
-
-.. autoclass:: ChirpSSSignalBuilder
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~ChirpSSSignalBuilder.add_parent
-      ~ChirpSSSignalBuilder.build
-      ~ChirpSSSignalBuilder.get_distribution
-      ~ChirpSSSignalBuilder.get_second_seed
-      ~ChirpSSSignalBuilder.reset
-      ~ChirpSSSignalBuilder.seed
-      ~ChirpSSSignalBuilder.setup_rngs
-      ~ChirpSSSignalBuilder.update_from_parent
-   
-   
-
-   
-   
-   .. rubric:: Attributes
-
-   .. autosummary::
-   
-      ~ChirpSSSignalBuilder.supported_classes
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.signals.builders.chirpss.chirpss_modulator.rst b/docs/_autosummary/torchsig.signals.builders.chirpss.chirpss_modulator.rst
deleted file mode 100644
index f01d29d59..000000000
--- a/docs/_autosummary/torchsig.signals.builders.chirpss.chirpss_modulator.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.signals.builders.chirpss.chirpss\_modulator
-====================================================
-
-.. currentmodule:: torchsig.signals.builders.chirpss
-
-.. autofunction:: chirpss_modulator
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.signals.builders.chirpss.chirpss_modulator_baseband.rst b/docs/_autosummary/torchsig.signals.builders.chirpss.chirpss_modulator_baseband.rst
deleted file mode 100644
index 4448eb80e..000000000
--- a/docs/_autosummary/torchsig.signals.builders.chirpss.chirpss_modulator_baseband.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.signals.builders.chirpss.chirpss\_modulator\_baseband
-==============================================================
-
-.. currentmodule:: torchsig.signals.builders.chirpss
-
-.. autofunction:: chirpss_modulator_baseband
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.signals.builders.chirpss.get_symbol_map.rst b/docs/_autosummary/torchsig.signals.builders.chirpss.get_symbol_map.rst
deleted file mode 100644
index 430a0587e..000000000
--- a/docs/_autosummary/torchsig.signals.builders.chirpss.get_symbol_map.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.signals.builders.chirpss.get\_symbol\_map
-==================================================
-
-.. currentmodule:: torchsig.signals.builders.chirpss
-
-.. autofunction:: get_symbol_map
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.signals.builders.chirpss.rst b/docs/_autosummary/torchsig.signals.builders.chirpss.rst
deleted file mode 100644
index 1b61b13ea..000000000
--- a/docs/_autosummary/torchsig.signals.builders.chirpss.rst
+++ /dev/null
@@ -1,42 +0,0 @@
-torchsig.signals.builders.chirpss
-=================================
-
-.. automodule:: torchsig.signals.builders.chirpss
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Functions
-
-   .. autosummary::
-      :toctree:
-      :nosignatures:
-   
-      chirpss_modulator
-      chirpss_modulator_baseband
-      get_symbol_map
-   
-   
-
-   
-   
-   .. rubric:: Classes
-
-   .. autosummary::
-      :toctree:
-      :template: custom_class_template.rst
-      :nosignatures:
-   
-      ChirpSSSignalBuilder
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.signals.builders.constellation.ConstellationSignalBuilder.rst b/docs/_autosummary/torchsig.signals.builders.constellation.ConstellationSignalBuilder.rst
deleted file mode 100644
index 2b289ab96..000000000
--- a/docs/_autosummary/torchsig.signals.builders.constellation.ConstellationSignalBuilder.rst
+++ /dev/null
@@ -1,38 +0,0 @@
-torchsig.signals.builders.constellation.ConstellationSignalBuilder
-==================================================================
-
-.. currentmodule:: torchsig.signals.builders.constellation
-
-.. autoclass:: ConstellationSignalBuilder
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~ConstellationSignalBuilder.add_parent
-      ~ConstellationSignalBuilder.build
-      ~ConstellationSignalBuilder.get_distribution
-      ~ConstellationSignalBuilder.get_second_seed
-      ~ConstellationSignalBuilder.reset
-      ~ConstellationSignalBuilder.seed
-      ~ConstellationSignalBuilder.setup_rngs
-      ~ConstellationSignalBuilder.update_from_parent
-   
-   
-
-   
-   
-   .. rubric:: Attributes
-
-   .. autosummary::
-   
-      ~ConstellationSignalBuilder.supported_classes
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.signals.builders.constellation.constellation_modulator.rst b/docs/_autosummary/torchsig.signals.builders.constellation.constellation_modulator.rst
deleted file mode 100644
index 608a33a46..000000000
--- a/docs/_autosummary/torchsig.signals.builders.constellation.constellation_modulator.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.signals.builders.constellation.constellation\_modulator
-================================================================
-
-.. currentmodule:: torchsig.signals.builders.constellation
-
-.. autofunction:: constellation_modulator
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.signals.builders.constellation.constellation_modulator_baseband.rst b/docs/_autosummary/torchsig.signals.builders.constellation.constellation_modulator_baseband.rst
deleted file mode 100644
index 2f4eb8ca4..000000000
--- a/docs/_autosummary/torchsig.signals.builders.constellation.constellation_modulator_baseband.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.signals.builders.constellation.constellation\_modulator\_baseband
-==========================================================================
-
-.. currentmodule:: torchsig.signals.builders.constellation
-
-.. autofunction:: constellation_modulator_baseband
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.signals.builders.constellation.rst b/docs/_autosummary/torchsig.signals.builders.constellation.rst
deleted file mode 100644
index f797bec24..000000000
--- a/docs/_autosummary/torchsig.signals.builders.constellation.rst
+++ /dev/null
@@ -1,41 +0,0 @@
-torchsig.signals.builders.constellation
-=======================================
-
-.. automodule:: torchsig.signals.builders.constellation
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Functions
-
-   .. autosummary::
-      :toctree:
-      :nosignatures:
-   
-      constellation_modulator
-      constellation_modulator_baseband
-   
-   
-
-   
-   
-   .. rubric:: Classes
-
-   .. autosummary::
-      :toctree:
-      :template: custom_class_template.rst
-      :nosignatures:
-   
-      ConstellationSignalBuilder
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.signals.builders.constellation_maps.remove_corners.rst b/docs/_autosummary/torchsig.signals.builders.constellation_maps.remove_corners.rst
deleted file mode 100644
index a4c7ce54b..000000000
--- a/docs/_autosummary/torchsig.signals.builders.constellation_maps.remove_corners.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.signals.builders.constellation\_maps.remove\_corners
-=============================================================
-
-.. currentmodule:: torchsig.signals.builders.constellation_maps
-
-.. autofunction:: remove_corners
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.signals.builders.constellation_maps.rst b/docs/_autosummary/torchsig.signals.builders.constellation_maps.rst
deleted file mode 100644
index a94129dff..000000000
--- a/docs/_autosummary/torchsig.signals.builders.constellation_maps.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.signals.builders.constellation\_maps
-=============================================
-
-.. automodule:: torchsig.signals.builders.constellation_maps
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Functions
-
-   .. autosummary::
-      :toctree:
-      :nosignatures:
-   
-      remove_corners
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.signals.builders.fm.FMSignalBuilder.rst b/docs/_autosummary/torchsig.signals.builders.fm.FMSignalBuilder.rst
deleted file mode 100644
index 0b69b4bf5..000000000
--- a/docs/_autosummary/torchsig.signals.builders.fm.FMSignalBuilder.rst
+++ /dev/null
@@ -1,38 +0,0 @@
-torchsig.signals.builders.fm.FMSignalBuilder
-============================================
-
-.. currentmodule:: torchsig.signals.builders.fm
-
-.. autoclass:: FMSignalBuilder
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~FMSignalBuilder.add_parent
-      ~FMSignalBuilder.build
-      ~FMSignalBuilder.get_distribution
-      ~FMSignalBuilder.get_second_seed
-      ~FMSignalBuilder.reset
-      ~FMSignalBuilder.seed
-      ~FMSignalBuilder.setup_rngs
-      ~FMSignalBuilder.update_from_parent
-   
-   
-
-   
-   
-   .. rubric:: Attributes
-
-   .. autosummary::
-   
-      ~FMSignalBuilder.supported_classes
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.signals.builders.fm.fm_modulator.rst b/docs/_autosummary/torchsig.signals.builders.fm.fm_modulator.rst
deleted file mode 100644
index a8d278846..000000000
--- a/docs/_autosummary/torchsig.signals.builders.fm.fm_modulator.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.signals.builders.fm.fm\_modulator
-==========================================
-
-.. currentmodule:: torchsig.signals.builders.fm
-
-.. autofunction:: fm_modulator
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.signals.builders.fm.rst b/docs/_autosummary/torchsig.signals.builders.fm.rst
deleted file mode 100644
index 72b6cf1ce..000000000
--- a/docs/_autosummary/torchsig.signals.builders.fm.rst
+++ /dev/null
@@ -1,40 +0,0 @@
-torchsig.signals.builders.fm
-============================
-
-.. automodule:: torchsig.signals.builders.fm
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Functions
-
-   .. autosummary::
-      :toctree:
-      :nosignatures:
-   
-      fm_modulator
-   
-   
-
-   
-   
-   .. rubric:: Classes
-
-   .. autosummary::
-      :toctree:
-      :template: custom_class_template.rst
-      :nosignatures:
-   
-      FMSignalBuilder
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.signals.builders.fsk.FSKSignalBuilder.rst b/docs/_autosummary/torchsig.signals.builders.fsk.FSKSignalBuilder.rst
deleted file mode 100644
index ecdc02a7b..000000000
--- a/docs/_autosummary/torchsig.signals.builders.fsk.FSKSignalBuilder.rst
+++ /dev/null
@@ -1,38 +0,0 @@
-torchsig.signals.builders.fsk.FSKSignalBuilder
-==============================================
-
-.. currentmodule:: torchsig.signals.builders.fsk
-
-.. autoclass:: FSKSignalBuilder
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~FSKSignalBuilder.add_parent
-      ~FSKSignalBuilder.build
-      ~FSKSignalBuilder.get_distribution
-      ~FSKSignalBuilder.get_second_seed
-      ~FSKSignalBuilder.reset
-      ~FSKSignalBuilder.seed
-      ~FSKSignalBuilder.setup_rngs
-      ~FSKSignalBuilder.update_from_parent
-   
-   
-
-   
-   
-   .. rubric:: Attributes
-
-   .. autosummary::
-   
-      ~FSKSignalBuilder.supported_classes
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.signals.builders.fsk.fsk_modulator.rst b/docs/_autosummary/torchsig.signals.builders.fsk.fsk_modulator.rst
deleted file mode 100644
index cfea794fe..000000000
--- a/docs/_autosummary/torchsig.signals.builders.fsk.fsk_modulator.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.signals.builders.fsk.fsk\_modulator
-============================================
-
-.. currentmodule:: torchsig.signals.builders.fsk
-
-.. autofunction:: fsk_modulator
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.signals.builders.fsk.fsk_modulator_baseband.rst b/docs/_autosummary/torchsig.signals.builders.fsk.fsk_modulator_baseband.rst
deleted file mode 100644
index 78ef239a7..000000000
--- a/docs/_autosummary/torchsig.signals.builders.fsk.fsk_modulator_baseband.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.signals.builders.fsk.fsk\_modulator\_baseband
-======================================================
-
-.. currentmodule:: torchsig.signals.builders.fsk
-
-.. autofunction:: fsk_modulator_baseband
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.signals.builders.fsk.gaussian_taps.rst b/docs/_autosummary/torchsig.signals.builders.fsk.gaussian_taps.rst
deleted file mode 100644
index 5f72e3f6c..000000000
--- a/docs/_autosummary/torchsig.signals.builders.fsk.gaussian_taps.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.signals.builders.fsk.gaussian\_taps
-============================================
-
-.. currentmodule:: torchsig.signals.builders.fsk
-
-.. autofunction:: gaussian_taps
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.signals.builders.fsk.get_fsk_freq_map.rst b/docs/_autosummary/torchsig.signals.builders.fsk.get_fsk_freq_map.rst
deleted file mode 100644
index 62600c56a..000000000
--- a/docs/_autosummary/torchsig.signals.builders.fsk.get_fsk_freq_map.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.signals.builders.fsk.get\_fsk\_freq\_map
-=================================================
-
-.. currentmodule:: torchsig.signals.builders.fsk
-
-.. autofunction:: get_fsk_freq_map
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.signals.builders.fsk.get_fsk_mod_index.rst b/docs/_autosummary/torchsig.signals.builders.fsk.get_fsk_mod_index.rst
deleted file mode 100644
index 768ea612c..000000000
--- a/docs/_autosummary/torchsig.signals.builders.fsk.get_fsk_mod_index.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.signals.builders.fsk.get\_fsk\_mod\_index
-==================================================
-
-.. currentmodule:: torchsig.signals.builders.fsk
-
-.. autofunction:: get_fsk_mod_index
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.signals.builders.fsk.rst b/docs/_autosummary/torchsig.signals.builders.fsk.rst
deleted file mode 100644
index 2ee7e1d6f..000000000
--- a/docs/_autosummary/torchsig.signals.builders.fsk.rst
+++ /dev/null
@@ -1,44 +0,0 @@
-torchsig.signals.builders.fsk
-=============================
-
-.. automodule:: torchsig.signals.builders.fsk
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Functions
-
-   .. autosummary::
-      :toctree:
-      :nosignatures:
-   
-      fsk_modulator
-      fsk_modulator_baseband
-      gaussian_taps
-      get_fsk_freq_map
-      get_fsk_mod_index
-   
-   
-
-   
-   
-   .. rubric:: Classes
-
-   .. autosummary::
-      :toctree:
-      :template: custom_class_template.rst
-      :nosignatures:
-   
-      FSKSignalBuilder
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.signals.builders.lfm.LFMSignalBuilder.rst b/docs/_autosummary/torchsig.signals.builders.lfm.LFMSignalBuilder.rst
deleted file mode 100644
index db4f3d711..000000000
--- a/docs/_autosummary/torchsig.signals.builders.lfm.LFMSignalBuilder.rst
+++ /dev/null
@@ -1,38 +0,0 @@
-torchsig.signals.builders.lfm.LFMSignalBuilder
-==============================================
-
-.. currentmodule:: torchsig.signals.builders.lfm
-
-.. autoclass:: LFMSignalBuilder
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~LFMSignalBuilder.add_parent
-      ~LFMSignalBuilder.build
-      ~LFMSignalBuilder.get_distribution
-      ~LFMSignalBuilder.get_second_seed
-      ~LFMSignalBuilder.reset
-      ~LFMSignalBuilder.seed
-      ~LFMSignalBuilder.setup_rngs
-      ~LFMSignalBuilder.update_from_parent
-   
-   
-
-   
-   
-   .. rubric:: Attributes
-
-   .. autosummary::
-   
-      ~LFMSignalBuilder.supported_classes
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.signals.builders.lfm.get_symbol_map.rst b/docs/_autosummary/torchsig.signals.builders.lfm.get_symbol_map.rst
deleted file mode 100644
index eeec6719b..000000000
--- a/docs/_autosummary/torchsig.signals.builders.lfm.get_symbol_map.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.signals.builders.lfm.get\_symbol\_map
-==============================================
-
-.. currentmodule:: torchsig.signals.builders.lfm
-
-.. autofunction:: get_symbol_map
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.signals.builders.lfm.lfm_modulator.rst b/docs/_autosummary/torchsig.signals.builders.lfm.lfm_modulator.rst
deleted file mode 100644
index 9eab0bc8c..000000000
--- a/docs/_autosummary/torchsig.signals.builders.lfm.lfm_modulator.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.signals.builders.lfm.lfm\_modulator
-============================================
-
-.. currentmodule:: torchsig.signals.builders.lfm
-
-.. autofunction:: lfm_modulator
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.signals.builders.lfm.lfm_modulator_baseband.rst b/docs/_autosummary/torchsig.signals.builders.lfm.lfm_modulator_baseband.rst
deleted file mode 100644
index 7e0f63d68..000000000
--- a/docs/_autosummary/torchsig.signals.builders.lfm.lfm_modulator_baseband.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.signals.builders.lfm.lfm\_modulator\_baseband
-======================================================
-
-.. currentmodule:: torchsig.signals.builders.lfm
-
-.. autofunction:: lfm_modulator_baseband
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.signals.builders.lfm.rst b/docs/_autosummary/torchsig.signals.builders.lfm.rst
deleted file mode 100644
index b2779b20b..000000000
--- a/docs/_autosummary/torchsig.signals.builders.lfm.rst
+++ /dev/null
@@ -1,42 +0,0 @@
-torchsig.signals.builders.lfm
-=============================
-
-.. automodule:: torchsig.signals.builders.lfm
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Functions
-
-   .. autosummary::
-      :toctree:
-      :nosignatures:
-   
-      get_symbol_map
-      lfm_modulator
-      lfm_modulator_baseband
-   
-   
-
-   
-   
-   .. rubric:: Classes
-
-   .. autosummary::
-      :toctree:
-      :template: custom_class_template.rst
-      :nosignatures:
-   
-      LFMSignalBuilder
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.signals.builders.ofdm.OFDMSignalBuilder.rst b/docs/_autosummary/torchsig.signals.builders.ofdm.OFDMSignalBuilder.rst
deleted file mode 100644
index 17f22322a..000000000
--- a/docs/_autosummary/torchsig.signals.builders.ofdm.OFDMSignalBuilder.rst
+++ /dev/null
@@ -1,38 +0,0 @@
-torchsig.signals.builders.ofdm.OFDMSignalBuilder
-================================================
-
-.. currentmodule:: torchsig.signals.builders.ofdm
-
-.. autoclass:: OFDMSignalBuilder
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~OFDMSignalBuilder.add_parent
-      ~OFDMSignalBuilder.build
-      ~OFDMSignalBuilder.get_distribution
-      ~OFDMSignalBuilder.get_second_seed
-      ~OFDMSignalBuilder.reset
-      ~OFDMSignalBuilder.seed
-      ~OFDMSignalBuilder.setup_rngs
-      ~OFDMSignalBuilder.update_from_parent
-   
-   
-
-   
-   
-   .. rubric:: Attributes
-
-   .. autosummary::
-   
-      ~OFDMSignalBuilder.supported_classes
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.signals.builders.ofdm.ofdm_modulator.rst b/docs/_autosummary/torchsig.signals.builders.ofdm.ofdm_modulator.rst
deleted file mode 100644
index d3342a574..000000000
--- a/docs/_autosummary/torchsig.signals.builders.ofdm.ofdm_modulator.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.signals.builders.ofdm.ofdm\_modulator
-==============================================
-
-.. currentmodule:: torchsig.signals.builders.ofdm
-
-.. autofunction:: ofdm_modulator
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.signals.builders.ofdm.ofdm_modulator_baseband.rst b/docs/_autosummary/torchsig.signals.builders.ofdm.ofdm_modulator_baseband.rst
deleted file mode 100644
index 13f703a3a..000000000
--- a/docs/_autosummary/torchsig.signals.builders.ofdm.ofdm_modulator_baseband.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.signals.builders.ofdm.ofdm\_modulator\_baseband
-========================================================
-
-.. currentmodule:: torchsig.signals.builders.ofdm
-
-.. autofunction:: ofdm_modulator_baseband
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.signals.builders.ofdm.rst b/docs/_autosummary/torchsig.signals.builders.ofdm.rst
deleted file mode 100644
index 8241602b5..000000000
--- a/docs/_autosummary/torchsig.signals.builders.ofdm.rst
+++ /dev/null
@@ -1,41 +0,0 @@
-torchsig.signals.builders.ofdm
-==============================
-
-.. automodule:: torchsig.signals.builders.ofdm
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Functions
-
-   .. autosummary::
-      :toctree:
-      :nosignatures:
-   
-      ofdm_modulator
-      ofdm_modulator_baseband
-   
-   
-
-   
-   
-   .. rubric:: Classes
-
-   .. autosummary::
-      :toctree:
-      :template: custom_class_template.rst
-      :nosignatures:
-   
-      OFDMSignalBuilder
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.signals.builders.rst b/docs/_autosummary/torchsig.signals.builders.rst
deleted file mode 100644
index 202e92a2e..000000000
--- a/docs/_autosummary/torchsig.signals.builders.rst
+++ /dev/null
@@ -1,40 +0,0 @@
-torchsig.signals.builders
-=========================
-
-.. automodule:: torchsig.signals.builders
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-
-
-.. autosummary::
-   :toctree:
-   :template: custom_module_template.rst
-   :recursive:
-
-   am
-   chirp
-   chirpss
-   constellation
-   constellation_maps
-   fm
-   fsk
-   lfm
-   ofdm
-   test
-   tone
-
diff --git a/docs/_autosummary/torchsig.signals.builders.test.TestSignalBuilder.rst b/docs/_autosummary/torchsig.signals.builders.test.TestSignalBuilder.rst
deleted file mode 100644
index cb88c74df..000000000
--- a/docs/_autosummary/torchsig.signals.builders.test.TestSignalBuilder.rst
+++ /dev/null
@@ -1,38 +0,0 @@
-torchsig.signals.builders.test.TestSignalBuilder
-================================================
-
-.. currentmodule:: torchsig.signals.builders.test
-
-.. autoclass:: TestSignalBuilder
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~TestSignalBuilder.add_parent
-      ~TestSignalBuilder.build
-      ~TestSignalBuilder.get_distribution
-      ~TestSignalBuilder.get_second_seed
-      ~TestSignalBuilder.reset
-      ~TestSignalBuilder.seed
-      ~TestSignalBuilder.setup_rngs
-      ~TestSignalBuilder.update_from_parent
-   
-   
-
-   
-   
-   .. rubric:: Attributes
-
-   .. autosummary::
-   
-      ~TestSignalBuilder.supported_classes
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.signals.builders.test.rst b/docs/_autosummary/torchsig.signals.builders.test.rst
deleted file mode 100644
index 8b6c8d2bd..000000000
--- a/docs/_autosummary/torchsig.signals.builders.test.rst
+++ /dev/null
@@ -1,40 +0,0 @@
-torchsig.signals.builders.test
-==============================
-
-.. automodule:: torchsig.signals.builders.test
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Functions
-
-   .. autosummary::
-      :toctree:
-      :nosignatures:
-   
-      shaped_noise_modulator
-   
-   
-
-   
-   
-   .. rubric:: Classes
-
-   .. autosummary::
-      :toctree:
-      :template: custom_class_template.rst
-      :nosignatures:
-   
-      TestSignalBuilder
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.signals.builders.test.shaped_noise_modulator.rst b/docs/_autosummary/torchsig.signals.builders.test.shaped_noise_modulator.rst
deleted file mode 100644
index 057516b2b..000000000
--- a/docs/_autosummary/torchsig.signals.builders.test.shaped_noise_modulator.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.signals.builders.test.shaped\_noise\_modulator
-=======================================================
-
-.. currentmodule:: torchsig.signals.builders.test
-
-.. autofunction:: shaped_noise_modulator
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.signals.builders.tone.ToneSignalBuilder.rst b/docs/_autosummary/torchsig.signals.builders.tone.ToneSignalBuilder.rst
deleted file mode 100644
index 11a92bc0f..000000000
--- a/docs/_autosummary/torchsig.signals.builders.tone.ToneSignalBuilder.rst
+++ /dev/null
@@ -1,38 +0,0 @@
-torchsig.signals.builders.tone.ToneSignalBuilder
-================================================
-
-.. currentmodule:: torchsig.signals.builders.tone
-
-.. autoclass:: ToneSignalBuilder
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~ToneSignalBuilder.add_parent
-      ~ToneSignalBuilder.build
-      ~ToneSignalBuilder.get_distribution
-      ~ToneSignalBuilder.get_second_seed
-      ~ToneSignalBuilder.reset
-      ~ToneSignalBuilder.seed
-      ~ToneSignalBuilder.setup_rngs
-      ~ToneSignalBuilder.update_from_parent
-   
-   
-
-   
-   
-   .. rubric:: Attributes
-
-   .. autosummary::
-   
-      ~ToneSignalBuilder.supported_classes
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.signals.builders.tone.rst b/docs/_autosummary/torchsig.signals.builders.tone.rst
deleted file mode 100644
index c64e0ecdf..000000000
--- a/docs/_autosummary/torchsig.signals.builders.tone.rst
+++ /dev/null
@@ -1,40 +0,0 @@
-torchsig.signals.builders.tone
-==============================
-
-.. automodule:: torchsig.signals.builders.tone
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Functions
-
-   .. autosummary::
-      :toctree:
-      :nosignatures:
-   
-      tone_modulator
-   
-   
-
-   
-   
-   .. rubric:: Classes
-
-   .. autosummary::
-      :toctree:
-      :template: custom_class_template.rst
-      :nosignatures:
-   
-      ToneSignalBuilder
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.signals.builders.tone.tone_modulator.rst b/docs/_autosummary/torchsig.signals.builders.tone.tone_modulator.rst
deleted file mode 100644
index 405573041..000000000
--- a/docs/_autosummary/torchsig.signals.builders.tone.tone_modulator.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.signals.builders.tone.tone\_modulator
-==============================================
-
-.. currentmodule:: torchsig.signals.builders.tone
-
-.. autofunction:: tone_modulator
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.signals.rst b/docs/_autosummary/torchsig.signals.rst
deleted file mode 100644
index 3ae834172..000000000
--- a/docs/_autosummary/torchsig.signals.rst
+++ /dev/null
@@ -1,34 +0,0 @@
-torchsig.signals
-================
-
-.. automodule:: torchsig.signals
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-
-
-.. autosummary::
-   :toctree:
-   :template: custom_module_template.rst
-   :recursive:
-
-   builder
-   builders
-   signal_lists
-   signal_types
-   signal_utils
-
diff --git a/docs/_autosummary/torchsig.signals.signal_lists.TorchSigSignalLists.rst b/docs/_autosummary/torchsig.signals.signal_lists.TorchSigSignalLists.rst
deleted file mode 100644
index e02989e41..000000000
--- a/docs/_autosummary/torchsig.signals.signal_lists.TorchSigSignalLists.rst
+++ /dev/null
@@ -1,47 +0,0 @@
-torchsig.signals.signal\_lists.TorchSigSignalLists
-==================================================
-
-.. currentmodule:: torchsig.signals.signal_lists
-
-.. autoclass:: TorchSigSignalLists
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-   
-   
-
-   
-   
-   .. rubric:: Attributes
-
-   .. autosummary::
-   
-      ~TorchSigSignalLists.all_signals
-      ~TorchSigSignalLists.am_names
-      ~TorchSigSignalLists.am_signals
-      ~TorchSigSignalLists.chirpss_signals
-      ~TorchSigSignalLists.constellation_names
-      ~TorchSigSignalLists.constellation_signals
-      ~TorchSigSignalLists.family_dict
-      ~TorchSigSignalLists.family_list
-      ~TorchSigSignalLists.fm_signals
-      ~TorchSigSignalLists.fsk_names
-      ~TorchSigSignalLists.fsk_signals
-      ~TorchSigSignalLists.lfm_names
-      ~TorchSigSignalLists.lfm_signals
-      ~TorchSigSignalLists.name
-      ~TorchSigSignalLists.ofdm_names
-      ~TorchSigSignalLists.ofdm_signals
-      ~TorchSigSignalLists.ofdm_subcarrier_modulations
-      ~TorchSigSignalLists.tone_signals
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.signals.signal_lists.rst b/docs/_autosummary/torchsig.signals.signal_lists.rst
deleted file mode 100644
index c359c9bf8..000000000
--- a/docs/_autosummary/torchsig.signals.signal_lists.rst
+++ /dev/null
@@ -1,32 +0,0 @@
-torchsig.signals.signal\_lists
-==============================
-
-.. automodule:: torchsig.signals.signal_lists
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Classes
-
-   .. autosummary::
-      :toctree:
-      :template: custom_class_template.rst
-      :nosignatures:
-   
-      TorchSigSignalLists
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.signals.signal_types.DatasetDict.rst b/docs/_autosummary/torchsig.signals.signal_types.DatasetDict.rst
deleted file mode 100644
index 46b6a8d94..000000000
--- a/docs/_autosummary/torchsig.signals.signal_types.DatasetDict.rst
+++ /dev/null
@@ -1,25 +0,0 @@
-torchsig.signals.signal\_types.DatasetDict
-==========================================
-
-.. currentmodule:: torchsig.signals.signal_types
-
-.. autoclass:: DatasetDict
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~DatasetDict.verify
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.signals.signal_types.DatasetSignal.rst b/docs/_autosummary/torchsig.signals.signal_types.DatasetSignal.rst
deleted file mode 100644
index cf2206837..000000000
--- a/docs/_autosummary/torchsig.signals.signal_types.DatasetSignal.rst
+++ /dev/null
@@ -1,25 +0,0 @@
-torchsig.signals.signal\_types.DatasetSignal
-============================================
-
-.. currentmodule:: torchsig.signals.signal_types
-
-.. autoclass:: DatasetSignal
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~DatasetSignal.verify
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.signals.signal_types.Signal.rst b/docs/_autosummary/torchsig.signals.signal_types.Signal.rst
deleted file mode 100644
index d9174b25b..000000000
--- a/docs/_autosummary/torchsig.signals.signal_types.Signal.rst
+++ /dev/null
@@ -1,25 +0,0 @@
-torchsig.signals.signal\_types.Signal
-=====================================
-
-.. currentmodule:: torchsig.signals.signal_types
-
-.. autoclass:: Signal
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~Signal.verify
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.signals.signal_types.SignalMetadata.rst b/docs/_autosummary/torchsig.signals.signal_types.SignalMetadata.rst
deleted file mode 100644
index 9bb22441c..000000000
--- a/docs/_autosummary/torchsig.signals.signal_types.SignalMetadata.rst
+++ /dev/null
@@ -1,42 +0,0 @@
-torchsig.signals.signal\_types.SignalMetadata
-=============================================
-
-.. currentmodule:: torchsig.signals.signal_types
-
-.. autoclass:: SignalMetadata
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~SignalMetadata.deepcopy
-      ~SignalMetadata.to_dict
-      ~SignalMetadata.verify
-   
-   
-
-   
-   
-   .. rubric:: Attributes
-
-   .. autosummary::
-   
-      ~SignalMetadata.dataset_metadata
-      ~SignalMetadata.duration
-      ~SignalMetadata.lower_freq
-      ~SignalMetadata.num_samples
-      ~SignalMetadata.oversampling_rate
-      ~SignalMetadata.sample_rate
-      ~SignalMetadata.start
-      ~SignalMetadata.stop
-      ~SignalMetadata.stop_in_samples
-      ~SignalMetadata.upper_freq
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.signals.signal_types.rst b/docs/_autosummary/torchsig.signals.signal_types.rst
deleted file mode 100644
index 1343711a6..000000000
--- a/docs/_autosummary/torchsig.signals.signal_types.rst
+++ /dev/null
@@ -1,35 +0,0 @@
-torchsig.signals.signal\_types
-==============================
-
-.. automodule:: torchsig.signals.signal_types
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Classes
-
-   .. autosummary::
-      :toctree:
-      :template: custom_class_template.rst
-      :nosignatures:
-   
-      DatasetDict
-      DatasetSignal
-      Signal
-      SignalMetadata
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.signals.signal_utils.check_signal_class.rst b/docs/_autosummary/torchsig.signals.signal_utils.check_signal_class.rst
deleted file mode 100644
index f74d108ab..000000000
--- a/docs/_autosummary/torchsig.signals.signal_utils.check_signal_class.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.signals.signal\_utils.check\_signal\_class
-===================================================
-
-.. currentmodule:: torchsig.signals.signal_utils
-
-.. autofunction:: check_signal_class
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.signals.signal_utils.rst b/docs/_autosummary/torchsig.signals.signal_utils.rst
deleted file mode 100644
index 579451bfb..000000000
--- a/docs/_autosummary/torchsig.signals.signal_utils.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.signals.signal\_utils
-==============================
-
-.. automodule:: torchsig.signals.signal_utils
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Functions
-
-   .. autosummary::
-      :toctree:
-      :nosignatures:
-   
-      check_signal_class
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.transforms.base_transforms.Compose.rst b/docs/_autosummary/torchsig.transforms.base_transforms.Compose.rst
deleted file mode 100644
index 1294551c7..000000000
--- a/docs/_autosummary/torchsig.transforms.base_transforms.Compose.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.base\_transforms.Compose
-============================================
-
-.. currentmodule:: torchsig.transforms.base_transforms
-
-.. autoclass:: Compose
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~Compose.add_parent
-      ~Compose.get_distribution
-      ~Compose.get_second_seed
-      ~Compose.seed
-      ~Compose.setup_rngs
-      ~Compose.update
-      ~Compose.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.base_transforms.Lambda.rst b/docs/_autosummary/torchsig.transforms.base_transforms.Lambda.rst
deleted file mode 100644
index 8687350e0..000000000
--- a/docs/_autosummary/torchsig.transforms.base_transforms.Lambda.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.base\_transforms.Lambda
-===========================================
-
-.. currentmodule:: torchsig.transforms.base_transforms
-
-.. autoclass:: Lambda
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~Lambda.add_parent
-      ~Lambda.get_distribution
-      ~Lambda.get_second_seed
-      ~Lambda.seed
-      ~Lambda.setup_rngs
-      ~Lambda.update
-      ~Lambda.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.base_transforms.Normalize.rst b/docs/_autosummary/torchsig.transforms.base_transforms.Normalize.rst
deleted file mode 100644
index cf1697444..000000000
--- a/docs/_autosummary/torchsig.transforms.base_transforms.Normalize.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.base\_transforms.Normalize
-==============================================
-
-.. currentmodule:: torchsig.transforms.base_transforms
-
-.. autoclass:: Normalize
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~Normalize.add_parent
-      ~Normalize.get_distribution
-      ~Normalize.get_second_seed
-      ~Normalize.seed
-      ~Normalize.setup_rngs
-      ~Normalize.update
-      ~Normalize.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.base_transforms.RandAugment.rst b/docs/_autosummary/torchsig.transforms.base_transforms.RandAugment.rst
deleted file mode 100644
index 786ce8b02..000000000
--- a/docs/_autosummary/torchsig.transforms.base_transforms.RandAugment.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.base\_transforms.RandAugment
-================================================
-
-.. currentmodule:: torchsig.transforms.base_transforms
-
-.. autoclass:: RandAugment
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~RandAugment.add_parent
-      ~RandAugment.get_distribution
-      ~RandAugment.get_second_seed
-      ~RandAugment.seed
-      ~RandAugment.setup_rngs
-      ~RandAugment.update
-      ~RandAugment.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.base_transforms.RandomApply.rst b/docs/_autosummary/torchsig.transforms.base_transforms.RandomApply.rst
deleted file mode 100644
index 6fb024246..000000000
--- a/docs/_autosummary/torchsig.transforms.base_transforms.RandomApply.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.base\_transforms.RandomApply
-================================================
-
-.. currentmodule:: torchsig.transforms.base_transforms
-
-.. autoclass:: RandomApply
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~RandomApply.add_parent
-      ~RandomApply.get_distribution
-      ~RandomApply.get_second_seed
-      ~RandomApply.seed
-      ~RandomApply.setup_rngs
-      ~RandomApply.update
-      ~RandomApply.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.base_transforms.Transform.rst b/docs/_autosummary/torchsig.transforms.base_transforms.Transform.rst
deleted file mode 100644
index ee4fe697c..000000000
--- a/docs/_autosummary/torchsig.transforms.base_transforms.Transform.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.base\_transforms.Transform
-==============================================
-
-.. currentmodule:: torchsig.transforms.base_transforms
-
-.. autoclass:: Transform
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~Transform.add_parent
-      ~Transform.get_distribution
-      ~Transform.get_second_seed
-      ~Transform.seed
-      ~Transform.setup_rngs
-      ~Transform.update
-      ~Transform.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.base_transforms.rst b/docs/_autosummary/torchsig.transforms.base_transforms.rst
deleted file mode 100644
index 990bfa822..000000000
--- a/docs/_autosummary/torchsig.transforms.base_transforms.rst
+++ /dev/null
@@ -1,37 +0,0 @@
-torchsig.transforms.base\_transforms
-====================================
-
-.. automodule:: torchsig.transforms.base_transforms
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Classes
-
-   .. autosummary::
-      :toctree:
-      :template: custom_class_template.rst
-      :nosignatures:
-   
-      Compose
-      Lambda
-      Normalize
-      RandAugment
-      RandomApply
-      Transform
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.transforms.dataset_transforms.AGC.rst b/docs/_autosummary/torchsig.transforms.dataset_transforms.AGC.rst
deleted file mode 100644
index fec8bb88c..000000000
--- a/docs/_autosummary/torchsig.transforms.dataset_transforms.AGC.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.dataset\_transforms.AGC
-===========================================
-
-.. currentmodule:: torchsig.transforms.dataset_transforms
-
-.. autoclass:: AGC
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~AGC.add_parent
-      ~AGC.get_distribution
-      ~AGC.get_second_seed
-      ~AGC.seed
-      ~AGC.setup_rngs
-      ~AGC.update
-      ~AGC.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.dataset_transforms.AWGN.rst b/docs/_autosummary/torchsig.transforms.dataset_transforms.AWGN.rst
deleted file mode 100644
index 8151e4a35..000000000
--- a/docs/_autosummary/torchsig.transforms.dataset_transforms.AWGN.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.dataset\_transforms.AWGN
-============================================
-
-.. currentmodule:: torchsig.transforms.dataset_transforms
-
-.. autoclass:: AWGN
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~AWGN.add_parent
-      ~AWGN.get_distribution
-      ~AWGN.get_second_seed
-      ~AWGN.seed
-      ~AWGN.setup_rngs
-      ~AWGN.update
-      ~AWGN.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.dataset_transforms.AddSlope.rst b/docs/_autosummary/torchsig.transforms.dataset_transforms.AddSlope.rst
deleted file mode 100644
index 001afd910..000000000
--- a/docs/_autosummary/torchsig.transforms.dataset_transforms.AddSlope.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.dataset\_transforms.AddSlope
-================================================
-
-.. currentmodule:: torchsig.transforms.dataset_transforms
-
-.. autoclass:: AddSlope
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~AddSlope.add_parent
-      ~AddSlope.get_distribution
-      ~AddSlope.get_second_seed
-      ~AddSlope.seed
-      ~AddSlope.setup_rngs
-      ~AddSlope.update
-      ~AddSlope.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.dataset_transforms.AdditiveNoiseDatasetTransform.rst b/docs/_autosummary/torchsig.transforms.dataset_transforms.AdditiveNoiseDatasetTransform.rst
deleted file mode 100644
index db671b324..000000000
--- a/docs/_autosummary/torchsig.transforms.dataset_transforms.AdditiveNoiseDatasetTransform.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.dataset\_transforms.AdditiveNoiseDatasetTransform
-=====================================================================
-
-.. currentmodule:: torchsig.transforms.dataset_transforms
-
-.. autoclass:: AdditiveNoiseDatasetTransform
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~AdditiveNoiseDatasetTransform.add_parent
-      ~AdditiveNoiseDatasetTransform.get_distribution
-      ~AdditiveNoiseDatasetTransform.get_second_seed
-      ~AdditiveNoiseDatasetTransform.seed
-      ~AdditiveNoiseDatasetTransform.setup_rngs
-      ~AdditiveNoiseDatasetTransform.update
-      ~AdditiveNoiseDatasetTransform.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.dataset_transforms.BlockAGC.rst b/docs/_autosummary/torchsig.transforms.dataset_transforms.BlockAGC.rst
deleted file mode 100644
index 4d5820133..000000000
--- a/docs/_autosummary/torchsig.transforms.dataset_transforms.BlockAGC.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.dataset\_transforms.BlockAGC
-================================================
-
-.. currentmodule:: torchsig.transforms.dataset_transforms
-
-.. autoclass:: BlockAGC
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~BlockAGC.add_parent
-      ~BlockAGC.get_distribution
-      ~BlockAGC.get_second_seed
-      ~BlockAGC.seed
-      ~BlockAGC.setup_rngs
-      ~BlockAGC.update
-      ~BlockAGC.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.dataset_transforms.CarrierPhaseOffsetDatasetTransform.rst b/docs/_autosummary/torchsig.transforms.dataset_transforms.CarrierPhaseOffsetDatasetTransform.rst
deleted file mode 100644
index 2bb8cde60..000000000
--- a/docs/_autosummary/torchsig.transforms.dataset_transforms.CarrierPhaseOffsetDatasetTransform.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.dataset\_transforms.CarrierPhaseOffsetDatasetTransform
-==========================================================================
-
-.. currentmodule:: torchsig.transforms.dataset_transforms
-
-.. autoclass:: CarrierPhaseOffsetDatasetTransform
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~CarrierPhaseOffsetDatasetTransform.add_parent
-      ~CarrierPhaseOffsetDatasetTransform.get_distribution
-      ~CarrierPhaseOffsetDatasetTransform.get_second_seed
-      ~CarrierPhaseOffsetDatasetTransform.seed
-      ~CarrierPhaseOffsetDatasetTransform.setup_rngs
-      ~CarrierPhaseOffsetDatasetTransform.update
-      ~CarrierPhaseOffsetDatasetTransform.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.dataset_transforms.ChannelSwap.rst b/docs/_autosummary/torchsig.transforms.dataset_transforms.ChannelSwap.rst
deleted file mode 100644
index 183977b59..000000000
--- a/docs/_autosummary/torchsig.transforms.dataset_transforms.ChannelSwap.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.dataset\_transforms.ChannelSwap
-===================================================
-
-.. currentmodule:: torchsig.transforms.dataset_transforms
-
-.. autoclass:: ChannelSwap
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~ChannelSwap.add_parent
-      ~ChannelSwap.get_distribution
-      ~ChannelSwap.get_second_seed
-      ~ChannelSwap.seed
-      ~ChannelSwap.setup_rngs
-      ~ChannelSwap.update
-      ~ChannelSwap.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.dataset_transforms.ComplexTo2D.rst b/docs/_autosummary/torchsig.transforms.dataset_transforms.ComplexTo2D.rst
deleted file mode 100644
index 90f790750..000000000
--- a/docs/_autosummary/torchsig.transforms.dataset_transforms.ComplexTo2D.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.dataset\_transforms.ComplexTo2D
-===================================================
-
-.. currentmodule:: torchsig.transforms.dataset_transforms
-
-.. autoclass:: ComplexTo2D
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~ComplexTo2D.add_parent
-      ~ComplexTo2D.get_distribution
-      ~ComplexTo2D.get_second_seed
-      ~ComplexTo2D.seed
-      ~ComplexTo2D.setup_rngs
-      ~ComplexTo2D.update
-      ~ComplexTo2D.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.dataset_transforms.CutOut.rst b/docs/_autosummary/torchsig.transforms.dataset_transforms.CutOut.rst
deleted file mode 100644
index 36749349f..000000000
--- a/docs/_autosummary/torchsig.transforms.dataset_transforms.CutOut.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.dataset\_transforms.CutOut
-==============================================
-
-.. currentmodule:: torchsig.transforms.dataset_transforms
-
-.. autoclass:: CutOut
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~CutOut.add_parent
-      ~CutOut.get_distribution
-      ~CutOut.get_second_seed
-      ~CutOut.seed
-      ~CutOut.setup_rngs
-      ~CutOut.update
-      ~CutOut.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.dataset_transforms.DatasetTransform.rst b/docs/_autosummary/torchsig.transforms.dataset_transforms.DatasetTransform.rst
deleted file mode 100644
index 36eb2ec9f..000000000
--- a/docs/_autosummary/torchsig.transforms.dataset_transforms.DatasetTransform.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.dataset\_transforms.DatasetTransform
-========================================================
-
-.. currentmodule:: torchsig.transforms.dataset_transforms
-
-.. autoclass:: DatasetTransform
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~DatasetTransform.add_parent
-      ~DatasetTransform.get_distribution
-      ~DatasetTransform.get_second_seed
-      ~DatasetTransform.seed
-      ~DatasetTransform.setup_rngs
-      ~DatasetTransform.update
-      ~DatasetTransform.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.dataset_transforms.IQImbalanceDatasetTransform.rst b/docs/_autosummary/torchsig.transforms.dataset_transforms.IQImbalanceDatasetTransform.rst
deleted file mode 100644
index 8f2baf183..000000000
--- a/docs/_autosummary/torchsig.transforms.dataset_transforms.IQImbalanceDatasetTransform.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.dataset\_transforms.IQImbalanceDatasetTransform
-===================================================================
-
-.. currentmodule:: torchsig.transforms.dataset_transforms
-
-.. autoclass:: IQImbalanceDatasetTransform
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~IQImbalanceDatasetTransform.add_parent
-      ~IQImbalanceDatasetTransform.get_distribution
-      ~IQImbalanceDatasetTransform.get_second_seed
-      ~IQImbalanceDatasetTransform.seed
-      ~IQImbalanceDatasetTransform.setup_rngs
-      ~IQImbalanceDatasetTransform.update
-      ~IQImbalanceDatasetTransform.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.dataset_transforms.LocalOscillatorFrequencyDriftDatasetTransform.rst b/docs/_autosummary/torchsig.transforms.dataset_transforms.LocalOscillatorFrequencyDriftDatasetTransform.rst
deleted file mode 100644
index 53e0f4c9c..000000000
--- a/docs/_autosummary/torchsig.transforms.dataset_transforms.LocalOscillatorFrequencyDriftDatasetTransform.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.dataset\_transforms.LocalOscillatorFrequencyDriftDatasetTransform
-=====================================================================================
-
-.. currentmodule:: torchsig.transforms.dataset_transforms
-
-.. autoclass:: LocalOscillatorFrequencyDriftDatasetTransform
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~LocalOscillatorFrequencyDriftDatasetTransform.add_parent
-      ~LocalOscillatorFrequencyDriftDatasetTransform.get_distribution
-      ~LocalOscillatorFrequencyDriftDatasetTransform.get_second_seed
-      ~LocalOscillatorFrequencyDriftDatasetTransform.seed
-      ~LocalOscillatorFrequencyDriftDatasetTransform.setup_rngs
-      ~LocalOscillatorFrequencyDriftDatasetTransform.update
-      ~LocalOscillatorFrequencyDriftDatasetTransform.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.dataset_transforms.LocalOscillatorPhaseNoiseDatasetTransform.rst b/docs/_autosummary/torchsig.transforms.dataset_transforms.LocalOscillatorPhaseNoiseDatasetTransform.rst
deleted file mode 100644
index def583a36..000000000
--- a/docs/_autosummary/torchsig.transforms.dataset_transforms.LocalOscillatorPhaseNoiseDatasetTransform.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.dataset\_transforms.LocalOscillatorPhaseNoiseDatasetTransform
-=================================================================================
-
-.. currentmodule:: torchsig.transforms.dataset_transforms
-
-.. autoclass:: LocalOscillatorPhaseNoiseDatasetTransform
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~LocalOscillatorPhaseNoiseDatasetTransform.add_parent
-      ~LocalOscillatorPhaseNoiseDatasetTransform.get_distribution
-      ~LocalOscillatorPhaseNoiseDatasetTransform.get_second_seed
-      ~LocalOscillatorPhaseNoiseDatasetTransform.seed
-      ~LocalOscillatorPhaseNoiseDatasetTransform.setup_rngs
-      ~LocalOscillatorPhaseNoiseDatasetTransform.update
-      ~LocalOscillatorPhaseNoiseDatasetTransform.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.dataset_transforms.NonlinearAmplifierDatasetTransform.rst b/docs/_autosummary/torchsig.transforms.dataset_transforms.NonlinearAmplifierDatasetTransform.rst
deleted file mode 100644
index 0921cbad7..000000000
--- a/docs/_autosummary/torchsig.transforms.dataset_transforms.NonlinearAmplifierDatasetTransform.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.dataset\_transforms.NonlinearAmplifierDatasetTransform
-==========================================================================
-
-.. currentmodule:: torchsig.transforms.dataset_transforms
-
-.. autoclass:: NonlinearAmplifierDatasetTransform
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~NonlinearAmplifierDatasetTransform.add_parent
-      ~NonlinearAmplifierDatasetTransform.get_distribution
-      ~NonlinearAmplifierDatasetTransform.get_second_seed
-      ~NonlinearAmplifierDatasetTransform.seed
-      ~NonlinearAmplifierDatasetTransform.setup_rngs
-      ~NonlinearAmplifierDatasetTransform.update
-      ~NonlinearAmplifierDatasetTransform.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.dataset_transforms.PassbandRippleDatasetTransform.rst b/docs/_autosummary/torchsig.transforms.dataset_transforms.PassbandRippleDatasetTransform.rst
deleted file mode 100644
index 54985a43c..000000000
--- a/docs/_autosummary/torchsig.transforms.dataset_transforms.PassbandRippleDatasetTransform.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.dataset\_transforms.PassbandRippleDatasetTransform
-======================================================================
-
-.. currentmodule:: torchsig.transforms.dataset_transforms
-
-.. autoclass:: PassbandRippleDatasetTransform
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~PassbandRippleDatasetTransform.add_parent
-      ~PassbandRippleDatasetTransform.get_distribution
-      ~PassbandRippleDatasetTransform.get_second_seed
-      ~PassbandRippleDatasetTransform.seed
-      ~PassbandRippleDatasetTransform.setup_rngs
-      ~PassbandRippleDatasetTransform.update
-      ~PassbandRippleDatasetTransform.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.dataset_transforms.PatchShuffle.rst b/docs/_autosummary/torchsig.transforms.dataset_transforms.PatchShuffle.rst
deleted file mode 100644
index cd9e9e5ef..000000000
--- a/docs/_autosummary/torchsig.transforms.dataset_transforms.PatchShuffle.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.dataset\_transforms.PatchShuffle
-====================================================
-
-.. currentmodule:: torchsig.transforms.dataset_transforms
-
-.. autoclass:: PatchShuffle
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~PatchShuffle.add_parent
-      ~PatchShuffle.get_distribution
-      ~PatchShuffle.get_second_seed
-      ~PatchShuffle.seed
-      ~PatchShuffle.setup_rngs
-      ~PatchShuffle.update
-      ~PatchShuffle.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.dataset_transforms.QuantizeDatasetTransform.rst b/docs/_autosummary/torchsig.transforms.dataset_transforms.QuantizeDatasetTransform.rst
deleted file mode 100644
index f239429bb..000000000
--- a/docs/_autosummary/torchsig.transforms.dataset_transforms.QuantizeDatasetTransform.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.dataset\_transforms.QuantizeDatasetTransform
-================================================================
-
-.. currentmodule:: torchsig.transforms.dataset_transforms
-
-.. autoclass:: QuantizeDatasetTransform
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~QuantizeDatasetTransform.add_parent
-      ~QuantizeDatasetTransform.get_distribution
-      ~QuantizeDatasetTransform.get_second_seed
-      ~QuantizeDatasetTransform.seed
-      ~QuantizeDatasetTransform.setup_rngs
-      ~QuantizeDatasetTransform.update
-      ~QuantizeDatasetTransform.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.dataset_transforms.RandomDropSamples.rst b/docs/_autosummary/torchsig.transforms.dataset_transforms.RandomDropSamples.rst
deleted file mode 100644
index 28457586f..000000000
--- a/docs/_autosummary/torchsig.transforms.dataset_transforms.RandomDropSamples.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.dataset\_transforms.RandomDropSamples
-=========================================================
-
-.. currentmodule:: torchsig.transforms.dataset_transforms
-
-.. autoclass:: RandomDropSamples
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~RandomDropSamples.add_parent
-      ~RandomDropSamples.get_distribution
-      ~RandomDropSamples.get_second_seed
-      ~RandomDropSamples.seed
-      ~RandomDropSamples.setup_rngs
-      ~RandomDropSamples.update
-      ~RandomDropSamples.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.dataset_transforms.RandomMagRescale.rst b/docs/_autosummary/torchsig.transforms.dataset_transforms.RandomMagRescale.rst
deleted file mode 100644
index 0178c04bc..000000000
--- a/docs/_autosummary/torchsig.transforms.dataset_transforms.RandomMagRescale.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.dataset\_transforms.RandomMagRescale
-========================================================
-
-.. currentmodule:: torchsig.transforms.dataset_transforms
-
-.. autoclass:: RandomMagRescale
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~RandomMagRescale.add_parent
-      ~RandomMagRescale.get_distribution
-      ~RandomMagRescale.get_second_seed
-      ~RandomMagRescale.seed
-      ~RandomMagRescale.setup_rngs
-      ~RandomMagRescale.update
-      ~RandomMagRescale.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.dataset_transforms.SpectralInversionDatasetTransform.rst b/docs/_autosummary/torchsig.transforms.dataset_transforms.SpectralInversionDatasetTransform.rst
deleted file mode 100644
index 2517b7211..000000000
--- a/docs/_autosummary/torchsig.transforms.dataset_transforms.SpectralInversionDatasetTransform.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.dataset\_transforms.SpectralInversionDatasetTransform
-=========================================================================
-
-.. currentmodule:: torchsig.transforms.dataset_transforms
-
-.. autoclass:: SpectralInversionDatasetTransform
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~SpectralInversionDatasetTransform.add_parent
-      ~SpectralInversionDatasetTransform.get_distribution
-      ~SpectralInversionDatasetTransform.get_second_seed
-      ~SpectralInversionDatasetTransform.seed
-      ~SpectralInversionDatasetTransform.setup_rngs
-      ~SpectralInversionDatasetTransform.update
-      ~SpectralInversionDatasetTransform.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.dataset_transforms.Spectrogram.rst b/docs/_autosummary/torchsig.transforms.dataset_transforms.Spectrogram.rst
deleted file mode 100644
index 13da35caf..000000000
--- a/docs/_autosummary/torchsig.transforms.dataset_transforms.Spectrogram.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.dataset\_transforms.Spectrogram
-===================================================
-
-.. currentmodule:: torchsig.transforms.dataset_transforms
-
-.. autoclass:: Spectrogram
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~Spectrogram.add_parent
-      ~Spectrogram.get_distribution
-      ~Spectrogram.get_second_seed
-      ~Spectrogram.seed
-      ~Spectrogram.setup_rngs
-      ~Spectrogram.update
-      ~Spectrogram.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.dataset_transforms.SpectrogramDropSamples.rst b/docs/_autosummary/torchsig.transforms.dataset_transforms.SpectrogramDropSamples.rst
deleted file mode 100644
index 52cda6d4a..000000000
--- a/docs/_autosummary/torchsig.transforms.dataset_transforms.SpectrogramDropSamples.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.dataset\_transforms.SpectrogramDropSamples
-==============================================================
-
-.. currentmodule:: torchsig.transforms.dataset_transforms
-
-.. autoclass:: SpectrogramDropSamples
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~SpectrogramDropSamples.add_parent
-      ~SpectrogramDropSamples.get_distribution
-      ~SpectrogramDropSamples.get_second_seed
-      ~SpectrogramDropSamples.seed
-      ~SpectrogramDropSamples.setup_rngs
-      ~SpectrogramDropSamples.update
-      ~SpectrogramDropSamples.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.dataset_transforms.TimeReversal.rst b/docs/_autosummary/torchsig.transforms.dataset_transforms.TimeReversal.rst
deleted file mode 100644
index fab21ca6f..000000000
--- a/docs/_autosummary/torchsig.transforms.dataset_transforms.TimeReversal.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.dataset\_transforms.TimeReversal
-====================================================
-
-.. currentmodule:: torchsig.transforms.dataset_transforms
-
-.. autoclass:: TimeReversal
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~TimeReversal.add_parent
-      ~TimeReversal.get_distribution
-      ~TimeReversal.get_second_seed
-      ~TimeReversal.seed
-      ~TimeReversal.setup_rngs
-      ~TimeReversal.update
-      ~TimeReversal.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.dataset_transforms.TimeVaryingNoise.rst b/docs/_autosummary/torchsig.transforms.dataset_transforms.TimeVaryingNoise.rst
deleted file mode 100644
index 8e5fc3cd6..000000000
--- a/docs/_autosummary/torchsig.transforms.dataset_transforms.TimeVaryingNoise.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.dataset\_transforms.TimeVaryingNoise
-========================================================
-
-.. currentmodule:: torchsig.transforms.dataset_transforms
-
-.. autoclass:: TimeVaryingNoise
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~TimeVaryingNoise.add_parent
-      ~TimeVaryingNoise.get_distribution
-      ~TimeVaryingNoise.get_second_seed
-      ~TimeVaryingNoise.seed
-      ~TimeVaryingNoise.setup_rngs
-      ~TimeVaryingNoise.update
-      ~TimeVaryingNoise.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.dataset_transforms.rst b/docs/_autosummary/torchsig.transforms.dataset_transforms.rst
deleted file mode 100644
index 57a6826f4..000000000
--- a/docs/_autosummary/torchsig.transforms.dataset_transforms.rst
+++ /dev/null
@@ -1,55 +0,0 @@
-torchsig.transforms.dataset\_transforms
-=======================================
-
-.. automodule:: torchsig.transforms.dataset_transforms
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Classes
-
-   .. autosummary::
-      :toctree:
-      :template: custom_class_template.rst
-      :nosignatures:
-   
-      AGC
-      AWGN
-      AddSlope
-      AdditiveNoiseDatasetTransform
-      BlockAGC
-      CarrierPhaseOffsetDatasetTransform
-      ChannelSwap
-      ComplexTo2D
-      CutOut
-      DatasetTransform
-      IQImbalanceDatasetTransform
-      LocalOscillatorFrequencyDriftDatasetTransform
-      LocalOscillatorPhaseNoiseDatasetTransform
-      NonlinearAmplifierDatasetTransform
-      PassbandRippleDatasetTransform
-      PatchShuffle
-      QuantizeDatasetTransform
-      RandomDropSamples
-      RandomMagRescale
-      SpectralInversionDatasetTransform
-      Spectrogram
-      SpectrogramDropSamples
-      TimeReversal
-      TimeVaryingNoise
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.transforms.functional.add_slope.rst b/docs/_autosummary/torchsig.transforms.functional.add_slope.rst
deleted file mode 100644
index a345563ea..000000000
--- a/docs/_autosummary/torchsig.transforms.functional.add_slope.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.transforms.functional.add\_slope
-=========================================
-
-.. currentmodule:: torchsig.transforms.functional
-
-.. autofunction:: add_slope
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.functional.additive_noise.rst b/docs/_autosummary/torchsig.transforms.functional.additive_noise.rst
deleted file mode 100644
index 696b6b193..000000000
--- a/docs/_autosummary/torchsig.transforms.functional.additive_noise.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.transforms.functional.additive\_noise
-==============================================
-
-.. currentmodule:: torchsig.transforms.functional
-
-.. autofunction:: additive_noise
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.functional.adjacent_channel_interference.rst b/docs/_autosummary/torchsig.transforms.functional.adjacent_channel_interference.rst
deleted file mode 100644
index 3ee3241eb..000000000
--- a/docs/_autosummary/torchsig.transforms.functional.adjacent_channel_interference.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.transforms.functional.adjacent\_channel\_interference
-==============================================================
-
-.. currentmodule:: torchsig.transforms.functional
-
-.. autofunction:: adjacent_channel_interference
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.functional.agc.rst b/docs/_autosummary/torchsig.transforms.functional.agc.rst
deleted file mode 100644
index 2b94ee416..000000000
--- a/docs/_autosummary/torchsig.transforms.functional.agc.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.transforms.functional.agc
-==================================
-
-.. currentmodule:: torchsig.transforms.functional
-
-.. autofunction:: agc
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.functional.awgn.rst b/docs/_autosummary/torchsig.transforms.functional.awgn.rst
deleted file mode 100644
index 9abde54cc..000000000
--- a/docs/_autosummary/torchsig.transforms.functional.awgn.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.transforms.functional.awgn
-===================================
-
-.. currentmodule:: torchsig.transforms.functional
-
-.. autofunction:: awgn
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.functional.block_agc.rst b/docs/_autosummary/torchsig.transforms.functional.block_agc.rst
deleted file mode 100644
index 033a02b41..000000000
--- a/docs/_autosummary/torchsig.transforms.functional.block_agc.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.transforms.functional.block\_agc
-=========================================
-
-.. currentmodule:: torchsig.transforms.functional
-
-.. autofunction:: block_agc
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.functional.channel_swap.rst b/docs/_autosummary/torchsig.transforms.functional.channel_swap.rst
deleted file mode 100644
index ffd94d390..000000000
--- a/docs/_autosummary/torchsig.transforms.functional.channel_swap.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.transforms.functional.channel\_swap
-============================================
-
-.. currentmodule:: torchsig.transforms.functional
-
-.. autofunction:: channel_swap
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.functional.cochannel_interference.rst b/docs/_autosummary/torchsig.transforms.functional.cochannel_interference.rst
deleted file mode 100644
index 72ae07c9c..000000000
--- a/docs/_autosummary/torchsig.transforms.functional.cochannel_interference.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.transforms.functional.cochannel\_interference
-======================================================
-
-.. currentmodule:: torchsig.transforms.functional
-
-.. autofunction:: cochannel_interference
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.functional.complex_to_2d.rst b/docs/_autosummary/torchsig.transforms.functional.complex_to_2d.rst
deleted file mode 100644
index a7c304a0c..000000000
--- a/docs/_autosummary/torchsig.transforms.functional.complex_to_2d.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.transforms.functional.complex\_to\_2d
-==============================================
-
-.. currentmodule:: torchsig.transforms.functional
-
-.. autofunction:: complex_to_2d
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.functional.cut_out.rst b/docs/_autosummary/torchsig.transforms.functional.cut_out.rst
deleted file mode 100644
index d23348667..000000000
--- a/docs/_autosummary/torchsig.transforms.functional.cut_out.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.transforms.functional.cut\_out
-=======================================
-
-.. currentmodule:: torchsig.transforms.functional
-
-.. autofunction:: cut_out
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.functional.doppler.rst b/docs/_autosummary/torchsig.transforms.functional.doppler.rst
deleted file mode 100644
index c04b357be..000000000
--- a/docs/_autosummary/torchsig.transforms.functional.doppler.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.transforms.functional.doppler
-======================================
-
-.. currentmodule:: torchsig.transforms.functional
-
-.. autofunction:: doppler
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.functional.drop_samples.rst b/docs/_autosummary/torchsig.transforms.functional.drop_samples.rst
deleted file mode 100644
index 9b9a38a6c..000000000
--- a/docs/_autosummary/torchsig.transforms.functional.drop_samples.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.transforms.functional.drop\_samples
-============================================
-
-.. currentmodule:: torchsig.transforms.functional
-
-.. autofunction:: drop_samples
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.functional.fading.rst b/docs/_autosummary/torchsig.transforms.functional.fading.rst
deleted file mode 100644
index acea12833..000000000
--- a/docs/_autosummary/torchsig.transforms.functional.fading.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.transforms.functional.fading
-=====================================
-
-.. currentmodule:: torchsig.transforms.functional
-
-.. autofunction:: fading
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.functional.intermodulation_products.rst b/docs/_autosummary/torchsig.transforms.functional.intermodulation_products.rst
deleted file mode 100644
index d9f66b28e..000000000
--- a/docs/_autosummary/torchsig.transforms.functional.intermodulation_products.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.transforms.functional.intermodulation\_products
-========================================================
-
-.. currentmodule:: torchsig.transforms.functional
-
-.. autofunction:: intermodulation_products
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.functional.iq_imbalance.rst b/docs/_autosummary/torchsig.transforms.functional.iq_imbalance.rst
deleted file mode 100644
index e1f58dfc7..000000000
--- a/docs/_autosummary/torchsig.transforms.functional.iq_imbalance.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.transforms.functional.iq\_imbalance
-============================================
-
-.. currentmodule:: torchsig.transforms.functional
-
-.. autofunction:: iq_imbalance
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.functional.local_oscillator_frequency_drift.rst b/docs/_autosummary/torchsig.transforms.functional.local_oscillator_frequency_drift.rst
deleted file mode 100644
index a6c43e63b..000000000
--- a/docs/_autosummary/torchsig.transforms.functional.local_oscillator_frequency_drift.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.transforms.functional.local\_oscillator\_frequency\_drift
-==================================================================
-
-.. currentmodule:: torchsig.transforms.functional
-
-.. autofunction:: local_oscillator_frequency_drift
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.functional.mag_rescale.rst b/docs/_autosummary/torchsig.transforms.functional.mag_rescale.rst
deleted file mode 100644
index 3b9e4899f..000000000
--- a/docs/_autosummary/torchsig.transforms.functional.mag_rescale.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.transforms.functional.mag\_rescale
-===========================================
-
-.. currentmodule:: torchsig.transforms.functional
-
-.. autofunction:: mag_rescale
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.functional.nonlinear_amplifier.rst b/docs/_autosummary/torchsig.transforms.functional.nonlinear_amplifier.rst
deleted file mode 100644
index 7dfce552d..000000000
--- a/docs/_autosummary/torchsig.transforms.functional.nonlinear_amplifier.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.transforms.functional.nonlinear\_amplifier
-===================================================
-
-.. currentmodule:: torchsig.transforms.functional
-
-.. autofunction:: nonlinear_amplifier
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.functional.nonlinear_amplifier_table.rst b/docs/_autosummary/torchsig.transforms.functional.nonlinear_amplifier_table.rst
deleted file mode 100644
index b83eee131..000000000
--- a/docs/_autosummary/torchsig.transforms.functional.nonlinear_amplifier_table.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.transforms.functional.nonlinear\_amplifier\_table
-==========================================================
-
-.. currentmodule:: torchsig.transforms.functional
-
-.. autofunction:: nonlinear_amplifier_table
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.functional.normalize.rst b/docs/_autosummary/torchsig.transforms.functional.normalize.rst
deleted file mode 100644
index b702ab186..000000000
--- a/docs/_autosummary/torchsig.transforms.functional.normalize.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.transforms.functional.normalize
-========================================
-
-.. currentmodule:: torchsig.transforms.functional
-
-.. autofunction:: normalize
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.functional.passband_ripple.rst b/docs/_autosummary/torchsig.transforms.functional.passband_ripple.rst
deleted file mode 100644
index eaa2e657a..000000000
--- a/docs/_autosummary/torchsig.transforms.functional.passband_ripple.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.transforms.functional.passband\_ripple
-===============================================
-
-.. currentmodule:: torchsig.transforms.functional
-
-.. autofunction:: passband_ripple
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.functional.patch_shuffle.rst b/docs/_autosummary/torchsig.transforms.functional.patch_shuffle.rst
deleted file mode 100644
index 6856482b0..000000000
--- a/docs/_autosummary/torchsig.transforms.functional.patch_shuffle.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.transforms.functional.patch\_shuffle
-=============================================
-
-.. currentmodule:: torchsig.transforms.functional
-
-.. autofunction:: patch_shuffle
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.functional.phase_noise.rst b/docs/_autosummary/torchsig.transforms.functional.phase_noise.rst
deleted file mode 100644
index ae0d269c5..000000000
--- a/docs/_autosummary/torchsig.transforms.functional.phase_noise.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.transforms.functional.phase\_noise
-===========================================
-
-.. currentmodule:: torchsig.transforms.functional
-
-.. autofunction:: phase_noise
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.functional.phase_offset.rst b/docs/_autosummary/torchsig.transforms.functional.phase_offset.rst
deleted file mode 100644
index 968b9263c..000000000
--- a/docs/_autosummary/torchsig.transforms.functional.phase_offset.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.transforms.functional.phase\_offset
-============================================
-
-.. currentmodule:: torchsig.transforms.functional
-
-.. autofunction:: phase_offset
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.functional.quantize.rst b/docs/_autosummary/torchsig.transforms.functional.quantize.rst
deleted file mode 100644
index 493d18bc1..000000000
--- a/docs/_autosummary/torchsig.transforms.functional.quantize.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.transforms.functional.quantize
-=======================================
-
-.. currentmodule:: torchsig.transforms.functional
-
-.. autofunction:: quantize
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.functional.rst b/docs/_autosummary/torchsig.transforms.functional.rst
deleted file mode 100644
index 120267339..000000000
--- a/docs/_autosummary/torchsig.transforms.functional.rst
+++ /dev/null
@@ -1,61 +0,0 @@
-torchsig.transforms.functional
-==============================
-
-.. automodule:: torchsig.transforms.functional
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Functions
-
-   .. autosummary::
-      :toctree:
-      :nosignatures:
-   
-      add_slope
-      additive_noise
-      adjacent_channel_interference
-      agc
-      awgn
-      block_agc
-      channel_swap
-      cochannel_interference
-      complex_to_2d
-      cut_out
-      doppler
-      drop_samples
-      fading
-      intermodulation_products
-      iq_imbalance
-      local_oscillator_frequency_drift
-      mag_rescale
-      nonlinear_amplifier
-      nonlinear_amplifier_table
-      normalize
-      passband_ripple
-      patch_shuffle
-      phase_noise
-      phase_offset
-      quantize
-      shadowing
-      spectral_inversion
-      spectrogram
-      spectrogram_drop_samples
-      time_reversal
-      time_varying_noise
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.transforms.functional.shadowing.rst b/docs/_autosummary/torchsig.transforms.functional.shadowing.rst
deleted file mode 100644
index 6b03a5df1..000000000
--- a/docs/_autosummary/torchsig.transforms.functional.shadowing.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.transforms.functional.shadowing
-========================================
-
-.. currentmodule:: torchsig.transforms.functional
-
-.. autofunction:: shadowing
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.functional.spectral_inversion.rst b/docs/_autosummary/torchsig.transforms.functional.spectral_inversion.rst
deleted file mode 100644
index 67367195b..000000000
--- a/docs/_autosummary/torchsig.transforms.functional.spectral_inversion.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.transforms.functional.spectral\_inversion
-==================================================
-
-.. currentmodule:: torchsig.transforms.functional
-
-.. autofunction:: spectral_inversion
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.functional.spectrogram.rst b/docs/_autosummary/torchsig.transforms.functional.spectrogram.rst
deleted file mode 100644
index 953fcfc11..000000000
--- a/docs/_autosummary/torchsig.transforms.functional.spectrogram.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.transforms.functional.spectrogram
-==========================================
-
-.. currentmodule:: torchsig.transforms.functional
-
-.. autofunction:: spectrogram
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.functional.spectrogram_drop_samples.rst b/docs/_autosummary/torchsig.transforms.functional.spectrogram_drop_samples.rst
deleted file mode 100644
index 3b85b140e..000000000
--- a/docs/_autosummary/torchsig.transforms.functional.spectrogram_drop_samples.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.transforms.functional.spectrogram\_drop\_samples
-=========================================================
-
-.. currentmodule:: torchsig.transforms.functional
-
-.. autofunction:: spectrogram_drop_samples
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.functional.time_reversal.rst b/docs/_autosummary/torchsig.transforms.functional.time_reversal.rst
deleted file mode 100644
index 5e6f4ab10..000000000
--- a/docs/_autosummary/torchsig.transforms.functional.time_reversal.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.transforms.functional.time\_reversal
-=============================================
-
-.. currentmodule:: torchsig.transforms.functional
-
-.. autofunction:: time_reversal
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.functional.time_varying_noise.rst b/docs/_autosummary/torchsig.transforms.functional.time_varying_noise.rst
deleted file mode 100644
index 08161b9eb..000000000
--- a/docs/_autosummary/torchsig.transforms.functional.time_varying_noise.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.transforms.functional.time\_varying\_noise
-===================================================
-
-.. currentmodule:: torchsig.transforms.functional
-
-.. autofunction:: time_varying_noise
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.impairments.Impairments.rst b/docs/_autosummary/torchsig.transforms.impairments.Impairments.rst
deleted file mode 100644
index 3d1ce4df2..000000000
--- a/docs/_autosummary/torchsig.transforms.impairments.Impairments.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.impairments.Impairments
-===========================================
-
-.. currentmodule:: torchsig.transforms.impairments
-
-.. autoclass:: Impairments
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~Impairments.add_parent
-      ~Impairments.get_distribution
-      ~Impairments.get_second_seed
-      ~Impairments.seed
-      ~Impairments.setup_rngs
-      ~Impairments.update
-      ~Impairments.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.impairments.rst b/docs/_autosummary/torchsig.transforms.impairments.rst
deleted file mode 100644
index 121905c37..000000000
--- a/docs/_autosummary/torchsig.transforms.impairments.rst
+++ /dev/null
@@ -1,32 +0,0 @@
-torchsig.transforms.impairments
-===============================
-
-.. automodule:: torchsig.transforms.impairments
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Classes
-
-   .. autosummary::
-      :toctree:
-      :template: custom_class_template.rst
-      :nosignatures:
-   
-      Impairments
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.transforms.impairments_narrowband.NarrowbandImpairments.rst b/docs/_autosummary/torchsig.transforms.impairments_narrowband.NarrowbandImpairments.rst
deleted file mode 100644
index ea575ea89..000000000
--- a/docs/_autosummary/torchsig.transforms.impairments_narrowband.NarrowbandImpairments.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.impairments\_narrowband.NarrowbandImpairments
-=================================================================
-
-.. currentmodule:: torchsig.transforms.impairments_narrowband
-
-.. autoclass:: NarrowbandImpairments
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~NarrowbandImpairments.add_parent
-      ~NarrowbandImpairments.get_distribution
-      ~NarrowbandImpairments.get_second_seed
-      ~NarrowbandImpairments.seed
-      ~NarrowbandImpairments.setup_rngs
-      ~NarrowbandImpairments.update
-      ~NarrowbandImpairments.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.impairments_narrowband.rst b/docs/_autosummary/torchsig.transforms.impairments_narrowband.rst
deleted file mode 100644
index 5a849ca79..000000000
--- a/docs/_autosummary/torchsig.transforms.impairments_narrowband.rst
+++ /dev/null
@@ -1,32 +0,0 @@
-torchsig.transforms.impairments\_narrowband
-===========================================
-
-.. automodule:: torchsig.transforms.impairments_narrowband
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Classes
-
-   .. autosummary::
-      :toctree:
-      :template: custom_class_template.rst
-      :nosignatures:
-   
-      NarrowbandImpairments
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.transforms.impairments_wideband.WidebandImpairments.rst b/docs/_autosummary/torchsig.transforms.impairments_wideband.WidebandImpairments.rst
deleted file mode 100644
index e6b8850a7..000000000
--- a/docs/_autosummary/torchsig.transforms.impairments_wideband.WidebandImpairments.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.impairments\_wideband.WidebandImpairments
-=============================================================
-
-.. currentmodule:: torchsig.transforms.impairments_wideband
-
-.. autoclass:: WidebandImpairments
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~WidebandImpairments.add_parent
-      ~WidebandImpairments.get_distribution
-      ~WidebandImpairments.get_second_seed
-      ~WidebandImpairments.seed
-      ~WidebandImpairments.setup_rngs
-      ~WidebandImpairments.update
-      ~WidebandImpairments.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.impairments_wideband.rst b/docs/_autosummary/torchsig.transforms.impairments_wideband.rst
deleted file mode 100644
index 04e819770..000000000
--- a/docs/_autosummary/torchsig.transforms.impairments_wideband.rst
+++ /dev/null
@@ -1,32 +0,0 @@
-torchsig.transforms.impairments\_wideband
-=========================================
-
-.. automodule:: torchsig.transforms.impairments_wideband
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Classes
-
-   .. autosummary::
-      :toctree:
-      :template: custom_class_template.rst
-      :nosignatures:
-   
-      WidebandImpairments
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.transforms.rst b/docs/_autosummary/torchsig.transforms.rst
deleted file mode 100644
index 736feee8f..000000000
--- a/docs/_autosummary/torchsig.transforms.rst
+++ /dev/null
@@ -1,37 +0,0 @@
-torchsig.transforms
-===================
-
-.. automodule:: torchsig.transforms
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-
-
-.. autosummary::
-   :toctree:
-   :template: custom_module_template.rst
-   :recursive:
-
-   base_transforms
-   dataset_transforms
-   functional
-   impairments
-   impairments_narrowband
-   impairments_wideband
-   signal_transforms
-   target_transforms
-
diff --git a/docs/_autosummary/torchsig.transforms.signal_transforms.AdditiveNoiseSignalTransform.rst b/docs/_autosummary/torchsig.transforms.signal_transforms.AdditiveNoiseSignalTransform.rst
deleted file mode 100644
index afcae770a..000000000
--- a/docs/_autosummary/torchsig.transforms.signal_transforms.AdditiveNoiseSignalTransform.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.signal\_transforms.AdditiveNoiseSignalTransform
-===================================================================
-
-.. currentmodule:: torchsig.transforms.signal_transforms
-
-.. autoclass:: AdditiveNoiseSignalTransform
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~AdditiveNoiseSignalTransform.add_parent
-      ~AdditiveNoiseSignalTransform.get_distribution
-      ~AdditiveNoiseSignalTransform.get_second_seed
-      ~AdditiveNoiseSignalTransform.seed
-      ~AdditiveNoiseSignalTransform.setup_rngs
-      ~AdditiveNoiseSignalTransform.update
-      ~AdditiveNoiseSignalTransform.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.signal_transforms.AdjacentChannelInterference.rst b/docs/_autosummary/torchsig.transforms.signal_transforms.AdjacentChannelInterference.rst
deleted file mode 100644
index 03969dbd5..000000000
--- a/docs/_autosummary/torchsig.transforms.signal_transforms.AdjacentChannelInterference.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.signal\_transforms.AdjacentChannelInterference
-==================================================================
-
-.. currentmodule:: torchsig.transforms.signal_transforms
-
-.. autoclass:: AdjacentChannelInterference
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~AdjacentChannelInterference.add_parent
-      ~AdjacentChannelInterference.get_distribution
-      ~AdjacentChannelInterference.get_second_seed
-      ~AdjacentChannelInterference.seed
-      ~AdjacentChannelInterference.setup_rngs
-      ~AdjacentChannelInterference.update
-      ~AdjacentChannelInterference.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.signal_transforms.CarrierPhaseOffsetSignalTransform.rst b/docs/_autosummary/torchsig.transforms.signal_transforms.CarrierPhaseOffsetSignalTransform.rst
deleted file mode 100644
index 64cce2a0b..000000000
--- a/docs/_autosummary/torchsig.transforms.signal_transforms.CarrierPhaseOffsetSignalTransform.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.signal\_transforms.CarrierPhaseOffsetSignalTransform
-========================================================================
-
-.. currentmodule:: torchsig.transforms.signal_transforms
-
-.. autoclass:: CarrierPhaseOffsetSignalTransform
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~CarrierPhaseOffsetSignalTransform.add_parent
-      ~CarrierPhaseOffsetSignalTransform.get_distribution
-      ~CarrierPhaseOffsetSignalTransform.get_second_seed
-      ~CarrierPhaseOffsetSignalTransform.seed
-      ~CarrierPhaseOffsetSignalTransform.setup_rngs
-      ~CarrierPhaseOffsetSignalTransform.update
-      ~CarrierPhaseOffsetSignalTransform.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.signal_transforms.CochannelInterference.rst b/docs/_autosummary/torchsig.transforms.signal_transforms.CochannelInterference.rst
deleted file mode 100644
index 66a5d8526..000000000
--- a/docs/_autosummary/torchsig.transforms.signal_transforms.CochannelInterference.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.signal\_transforms.CochannelInterference
-============================================================
-
-.. currentmodule:: torchsig.transforms.signal_transforms
-
-.. autoclass:: CochannelInterference
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~CochannelInterference.add_parent
-      ~CochannelInterference.get_distribution
-      ~CochannelInterference.get_second_seed
-      ~CochannelInterference.seed
-      ~CochannelInterference.setup_rngs
-      ~CochannelInterference.update
-      ~CochannelInterference.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.signal_transforms.DopplerSignalTransform.rst b/docs/_autosummary/torchsig.transforms.signal_transforms.DopplerSignalTransform.rst
deleted file mode 100644
index 26404103b..000000000
--- a/docs/_autosummary/torchsig.transforms.signal_transforms.DopplerSignalTransform.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.signal\_transforms.DopplerSignalTransform
-=============================================================
-
-.. currentmodule:: torchsig.transforms.signal_transforms
-
-.. autoclass:: DopplerSignalTransform
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~DopplerSignalTransform.add_parent
-      ~DopplerSignalTransform.get_distribution
-      ~DopplerSignalTransform.get_second_seed
-      ~DopplerSignalTransform.seed
-      ~DopplerSignalTransform.setup_rngs
-      ~DopplerSignalTransform.update
-      ~DopplerSignalTransform.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.signal_transforms.Fading.rst b/docs/_autosummary/torchsig.transforms.signal_transforms.Fading.rst
deleted file mode 100644
index 3d449291a..000000000
--- a/docs/_autosummary/torchsig.transforms.signal_transforms.Fading.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.signal\_transforms.Fading
-=============================================
-
-.. currentmodule:: torchsig.transforms.signal_transforms
-
-.. autoclass:: Fading
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~Fading.add_parent
-      ~Fading.get_distribution
-      ~Fading.get_second_seed
-      ~Fading.seed
-      ~Fading.setup_rngs
-      ~Fading.update
-      ~Fading.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.signal_transforms.IQImbalanceSignalTransform.rst b/docs/_autosummary/torchsig.transforms.signal_transforms.IQImbalanceSignalTransform.rst
deleted file mode 100644
index 48e509042..000000000
--- a/docs/_autosummary/torchsig.transforms.signal_transforms.IQImbalanceSignalTransform.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.signal\_transforms.IQImbalanceSignalTransform
-=================================================================
-
-.. currentmodule:: torchsig.transforms.signal_transforms
-
-.. autoclass:: IQImbalanceSignalTransform
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~IQImbalanceSignalTransform.add_parent
-      ~IQImbalanceSignalTransform.get_distribution
-      ~IQImbalanceSignalTransform.get_second_seed
-      ~IQImbalanceSignalTransform.seed
-      ~IQImbalanceSignalTransform.setup_rngs
-      ~IQImbalanceSignalTransform.update
-      ~IQImbalanceSignalTransform.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.signal_transforms.IntermodulationProductsSignalTransform.rst b/docs/_autosummary/torchsig.transforms.signal_transforms.IntermodulationProductsSignalTransform.rst
deleted file mode 100644
index caeb426d0..000000000
--- a/docs/_autosummary/torchsig.transforms.signal_transforms.IntermodulationProductsSignalTransform.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.signal\_transforms.IntermodulationProductsSignalTransform
-=============================================================================
-
-.. currentmodule:: torchsig.transforms.signal_transforms
-
-.. autoclass:: IntermodulationProductsSignalTransform
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~IntermodulationProductsSignalTransform.add_parent
-      ~IntermodulationProductsSignalTransform.get_distribution
-      ~IntermodulationProductsSignalTransform.get_second_seed
-      ~IntermodulationProductsSignalTransform.seed
-      ~IntermodulationProductsSignalTransform.setup_rngs
-      ~IntermodulationProductsSignalTransform.update
-      ~IntermodulationProductsSignalTransform.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.signal_transforms.LocalOscillatorFrequencyDriftSignalTransform.rst b/docs/_autosummary/torchsig.transforms.signal_transforms.LocalOscillatorFrequencyDriftSignalTransform.rst
deleted file mode 100644
index b33690d78..000000000
--- a/docs/_autosummary/torchsig.transforms.signal_transforms.LocalOscillatorFrequencyDriftSignalTransform.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.signal\_transforms.LocalOscillatorFrequencyDriftSignalTransform
-===================================================================================
-
-.. currentmodule:: torchsig.transforms.signal_transforms
-
-.. autoclass:: LocalOscillatorFrequencyDriftSignalTransform
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~LocalOscillatorFrequencyDriftSignalTransform.add_parent
-      ~LocalOscillatorFrequencyDriftSignalTransform.get_distribution
-      ~LocalOscillatorFrequencyDriftSignalTransform.get_second_seed
-      ~LocalOscillatorFrequencyDriftSignalTransform.seed
-      ~LocalOscillatorFrequencyDriftSignalTransform.setup_rngs
-      ~LocalOscillatorFrequencyDriftSignalTransform.update
-      ~LocalOscillatorFrequencyDriftSignalTransform.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.signal_transforms.LocalOscillatorPhaseNoiseSignalTransform.rst b/docs/_autosummary/torchsig.transforms.signal_transforms.LocalOscillatorPhaseNoiseSignalTransform.rst
deleted file mode 100644
index 1b6aa6eb7..000000000
--- a/docs/_autosummary/torchsig.transforms.signal_transforms.LocalOscillatorPhaseNoiseSignalTransform.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.signal\_transforms.LocalOscillatorPhaseNoiseSignalTransform
-===============================================================================
-
-.. currentmodule:: torchsig.transforms.signal_transforms
-
-.. autoclass:: LocalOscillatorPhaseNoiseSignalTransform
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~LocalOscillatorPhaseNoiseSignalTransform.add_parent
-      ~LocalOscillatorPhaseNoiseSignalTransform.get_distribution
-      ~LocalOscillatorPhaseNoiseSignalTransform.get_second_seed
-      ~LocalOscillatorPhaseNoiseSignalTransform.seed
-      ~LocalOscillatorPhaseNoiseSignalTransform.setup_rngs
-      ~LocalOscillatorPhaseNoiseSignalTransform.update
-      ~LocalOscillatorPhaseNoiseSignalTransform.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.signal_transforms.NonlinearAmplifierSignalTransform.rst b/docs/_autosummary/torchsig.transforms.signal_transforms.NonlinearAmplifierSignalTransform.rst
deleted file mode 100644
index 1edfa2977..000000000
--- a/docs/_autosummary/torchsig.transforms.signal_transforms.NonlinearAmplifierSignalTransform.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.signal\_transforms.NonlinearAmplifierSignalTransform
-========================================================================
-
-.. currentmodule:: torchsig.transforms.signal_transforms
-
-.. autoclass:: NonlinearAmplifierSignalTransform
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~NonlinearAmplifierSignalTransform.add_parent
-      ~NonlinearAmplifierSignalTransform.get_distribution
-      ~NonlinearAmplifierSignalTransform.get_second_seed
-      ~NonlinearAmplifierSignalTransform.seed
-      ~NonlinearAmplifierSignalTransform.setup_rngs
-      ~NonlinearAmplifierSignalTransform.update
-      ~NonlinearAmplifierSignalTransform.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.signal_transforms.PassbandRippleSignalTransform.rst b/docs/_autosummary/torchsig.transforms.signal_transforms.PassbandRippleSignalTransform.rst
deleted file mode 100644
index f07c8450c..000000000
--- a/docs/_autosummary/torchsig.transforms.signal_transforms.PassbandRippleSignalTransform.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.signal\_transforms.PassbandRippleSignalTransform
-====================================================================
-
-.. currentmodule:: torchsig.transforms.signal_transforms
-
-.. autoclass:: PassbandRippleSignalTransform
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~PassbandRippleSignalTransform.add_parent
-      ~PassbandRippleSignalTransform.get_distribution
-      ~PassbandRippleSignalTransform.get_second_seed
-      ~PassbandRippleSignalTransform.seed
-      ~PassbandRippleSignalTransform.setup_rngs
-      ~PassbandRippleSignalTransform.update
-      ~PassbandRippleSignalTransform.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.signal_transforms.QuantizeSignalTransform.rst b/docs/_autosummary/torchsig.transforms.signal_transforms.QuantizeSignalTransform.rst
deleted file mode 100644
index 4bd58b39c..000000000
--- a/docs/_autosummary/torchsig.transforms.signal_transforms.QuantizeSignalTransform.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.signal\_transforms.QuantizeSignalTransform
-==============================================================
-
-.. currentmodule:: torchsig.transforms.signal_transforms
-
-.. autoclass:: QuantizeSignalTransform
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~QuantizeSignalTransform.add_parent
-      ~QuantizeSignalTransform.get_distribution
-      ~QuantizeSignalTransform.get_second_seed
-      ~QuantizeSignalTransform.seed
-      ~QuantizeSignalTransform.setup_rngs
-      ~QuantizeSignalTransform.update
-      ~QuantizeSignalTransform.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.signal_transforms.Shadowing.rst b/docs/_autosummary/torchsig.transforms.signal_transforms.Shadowing.rst
deleted file mode 100644
index 28a138680..000000000
--- a/docs/_autosummary/torchsig.transforms.signal_transforms.Shadowing.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.signal\_transforms.Shadowing
-================================================
-
-.. currentmodule:: torchsig.transforms.signal_transforms
-
-.. autoclass:: Shadowing
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~Shadowing.add_parent
-      ~Shadowing.get_distribution
-      ~Shadowing.get_second_seed
-      ~Shadowing.seed
-      ~Shadowing.setup_rngs
-      ~Shadowing.update
-      ~Shadowing.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.signal_transforms.SignalTransform.rst b/docs/_autosummary/torchsig.transforms.signal_transforms.SignalTransform.rst
deleted file mode 100644
index cb821adab..000000000
--- a/docs/_autosummary/torchsig.transforms.signal_transforms.SignalTransform.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.signal\_transforms.SignalTransform
-======================================================
-
-.. currentmodule:: torchsig.transforms.signal_transforms
-
-.. autoclass:: SignalTransform
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~SignalTransform.add_parent
-      ~SignalTransform.get_distribution
-      ~SignalTransform.get_second_seed
-      ~SignalTransform.seed
-      ~SignalTransform.setup_rngs
-      ~SignalTransform.update
-      ~SignalTransform.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.signal_transforms.SpectralInversionSignalTransform.rst b/docs/_autosummary/torchsig.transforms.signal_transforms.SpectralInversionSignalTransform.rst
deleted file mode 100644
index 316d3568c..000000000
--- a/docs/_autosummary/torchsig.transforms.signal_transforms.SpectralInversionSignalTransform.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.signal\_transforms.SpectralInversionSignalTransform
-=======================================================================
-
-.. currentmodule:: torchsig.transforms.signal_transforms
-
-.. autoclass:: SpectralInversionSignalTransform
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~SpectralInversionSignalTransform.add_parent
-      ~SpectralInversionSignalTransform.get_distribution
-      ~SpectralInversionSignalTransform.get_second_seed
-      ~SpectralInversionSignalTransform.seed
-      ~SpectralInversionSignalTransform.setup_rngs
-      ~SpectralInversionSignalTransform.update
-      ~SpectralInversionSignalTransform.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.signal_transforms.rst b/docs/_autosummary/torchsig.transforms.signal_transforms.rst
deleted file mode 100644
index 1e70b2b97..000000000
--- a/docs/_autosummary/torchsig.transforms.signal_transforms.rst
+++ /dev/null
@@ -1,47 +0,0 @@
-torchsig.transforms.signal\_transforms
-======================================
-
-.. automodule:: torchsig.transforms.signal_transforms
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Classes
-
-   .. autosummary::
-      :toctree:
-      :template: custom_class_template.rst
-      :nosignatures:
-   
-      AdditiveNoiseSignalTransform
-      AdjacentChannelInterference
-      CarrierPhaseOffsetSignalTransform
-      CochannelInterference
-      DopplerSignalTransform
-      Fading
-      IQImbalanceSignalTransform
-      IntermodulationProductsSignalTransform
-      LocalOscillatorFrequencyDriftSignalTransform
-      LocalOscillatorPhaseNoiseSignalTransform
-      NonlinearAmplifierSignalTransform
-      PassbandRippleSignalTransform
-      QuantizeSignalTransform
-      Shadowing
-      SignalTransform
-      SpectralInversionSignalTransform
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.transforms.target_transforms.Bandwidth.rst b/docs/_autosummary/torchsig.transforms.target_transforms.Bandwidth.rst
deleted file mode 100644
index 05bc92f19..000000000
--- a/docs/_autosummary/torchsig.transforms.target_transforms.Bandwidth.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.target\_transforms.Bandwidth
-================================================
-
-.. currentmodule:: torchsig.transforms.target_transforms
-
-.. autoclass:: Bandwidth
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~Bandwidth.add_parent
-      ~Bandwidth.get_distribution
-      ~Bandwidth.get_second_seed
-      ~Bandwidth.seed
-      ~Bandwidth.setup_rngs
-      ~Bandwidth.update
-      ~Bandwidth.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.target_transforms.CenterFreq.rst b/docs/_autosummary/torchsig.transforms.target_transforms.CenterFreq.rst
deleted file mode 100644
index 1e94cebf4..000000000
--- a/docs/_autosummary/torchsig.transforms.target_transforms.CenterFreq.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.target\_transforms.CenterFreq
-=================================================
-
-.. currentmodule:: torchsig.transforms.target_transforms
-
-.. autoclass:: CenterFreq
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~CenterFreq.add_parent
-      ~CenterFreq.get_distribution
-      ~CenterFreq.get_second_seed
-      ~CenterFreq.seed
-      ~CenterFreq.setup_rngs
-      ~CenterFreq.update
-      ~CenterFreq.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.target_transforms.ClassIndex.rst b/docs/_autosummary/torchsig.transforms.target_transforms.ClassIndex.rst
deleted file mode 100644
index a7f8cde8a..000000000
--- a/docs/_autosummary/torchsig.transforms.target_transforms.ClassIndex.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.target\_transforms.ClassIndex
-=================================================
-
-.. currentmodule:: torchsig.transforms.target_transforms
-
-.. autoclass:: ClassIndex
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~ClassIndex.add_parent
-      ~ClassIndex.get_distribution
-      ~ClassIndex.get_second_seed
-      ~ClassIndex.seed
-      ~ClassIndex.setup_rngs
-      ~ClassIndex.update
-      ~ClassIndex.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.target_transforms.ClassName.rst b/docs/_autosummary/torchsig.transforms.target_transforms.ClassName.rst
deleted file mode 100644
index 4605a46d5..000000000
--- a/docs/_autosummary/torchsig.transforms.target_transforms.ClassName.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.target\_transforms.ClassName
-================================================
-
-.. currentmodule:: torchsig.transforms.target_transforms
-
-.. autoclass:: ClassName
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~ClassName.add_parent
-      ~ClassName.get_distribution
-      ~ClassName.get_second_seed
-      ~ClassName.seed
-      ~ClassName.setup_rngs
-      ~ClassName.update
-      ~ClassName.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.target_transforms.CustomLabel.rst b/docs/_autosummary/torchsig.transforms.target_transforms.CustomLabel.rst
deleted file mode 100644
index 7410a07c4..000000000
--- a/docs/_autosummary/torchsig.transforms.target_transforms.CustomLabel.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.target\_transforms.CustomLabel
-==================================================
-
-.. currentmodule:: torchsig.transforms.target_transforms
-
-.. autoclass:: CustomLabel
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~CustomLabel.add_parent
-      ~CustomLabel.get_distribution
-      ~CustomLabel.get_second_seed
-      ~CustomLabel.seed
-      ~CustomLabel.setup_rngs
-      ~CustomLabel.update
-      ~CustomLabel.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.target_transforms.Duration.rst b/docs/_autosummary/torchsig.transforms.target_transforms.Duration.rst
deleted file mode 100644
index 872725833..000000000
--- a/docs/_autosummary/torchsig.transforms.target_transforms.Duration.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.target\_transforms.Duration
-===============================================
-
-.. currentmodule:: torchsig.transforms.target_transforms
-
-.. autoclass:: Duration
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~Duration.add_parent
-      ~Duration.get_distribution
-      ~Duration.get_second_seed
-      ~Duration.seed
-      ~Duration.setup_rngs
-      ~Duration.update
-      ~Duration.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.target_transforms.DurationInSamples.rst b/docs/_autosummary/torchsig.transforms.target_transforms.DurationInSamples.rst
deleted file mode 100644
index 145df1653..000000000
--- a/docs/_autosummary/torchsig.transforms.target_transforms.DurationInSamples.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.target\_transforms.DurationInSamples
-========================================================
-
-.. currentmodule:: torchsig.transforms.target_transforms
-
-.. autoclass:: DurationInSamples
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~DurationInSamples.add_parent
-      ~DurationInSamples.get_distribution
-      ~DurationInSamples.get_second_seed
-      ~DurationInSamples.seed
-      ~DurationInSamples.setup_rngs
-      ~DurationInSamples.update
-      ~DurationInSamples.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.target_transforms.FamilyIndex.rst b/docs/_autosummary/torchsig.transforms.target_transforms.FamilyIndex.rst
deleted file mode 100644
index bfe865096..000000000
--- a/docs/_autosummary/torchsig.transforms.target_transforms.FamilyIndex.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.target\_transforms.FamilyIndex
-==================================================
-
-.. currentmodule:: torchsig.transforms.target_transforms
-
-.. autoclass:: FamilyIndex
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~FamilyIndex.add_parent
-      ~FamilyIndex.get_distribution
-      ~FamilyIndex.get_second_seed
-      ~FamilyIndex.seed
-      ~FamilyIndex.setup_rngs
-      ~FamilyIndex.update
-      ~FamilyIndex.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.target_transforms.FamilyName.rst b/docs/_autosummary/torchsig.transforms.target_transforms.FamilyName.rst
deleted file mode 100644
index 81c595767..000000000
--- a/docs/_autosummary/torchsig.transforms.target_transforms.FamilyName.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.target\_transforms.FamilyName
-=================================================
-
-.. currentmodule:: torchsig.transforms.target_transforms
-
-.. autoclass:: FamilyName
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~FamilyName.add_parent
-      ~FamilyName.get_distribution
-      ~FamilyName.get_second_seed
-      ~FamilyName.seed
-      ~FamilyName.setup_rngs
-      ~FamilyName.update
-      ~FamilyName.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.target_transforms.LowerFreq.rst b/docs/_autosummary/torchsig.transforms.target_transforms.LowerFreq.rst
deleted file mode 100644
index c0c0ca158..000000000
--- a/docs/_autosummary/torchsig.transforms.target_transforms.LowerFreq.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.target\_transforms.LowerFreq
-================================================
-
-.. currentmodule:: torchsig.transforms.target_transforms
-
-.. autoclass:: LowerFreq
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~LowerFreq.add_parent
-      ~LowerFreq.get_distribution
-      ~LowerFreq.get_second_seed
-      ~LowerFreq.seed
-      ~LowerFreq.setup_rngs
-      ~LowerFreq.update
-      ~LowerFreq.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.target_transforms.NumSamples.rst b/docs/_autosummary/torchsig.transforms.target_transforms.NumSamples.rst
deleted file mode 100644
index feb2aeeda..000000000
--- a/docs/_autosummary/torchsig.transforms.target_transforms.NumSamples.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.target\_transforms.NumSamples
-=================================================
-
-.. currentmodule:: torchsig.transforms.target_transforms
-
-.. autoclass:: NumSamples
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~NumSamples.add_parent
-      ~NumSamples.get_distribution
-      ~NumSamples.get_second_seed
-      ~NumSamples.seed
-      ~NumSamples.setup_rngs
-      ~NumSamples.update
-      ~NumSamples.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.target_transforms.OversamplingRate.rst b/docs/_autosummary/torchsig.transforms.target_transforms.OversamplingRate.rst
deleted file mode 100644
index 1a1bc8e02..000000000
--- a/docs/_autosummary/torchsig.transforms.target_transforms.OversamplingRate.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.target\_transforms.OversamplingRate
-=======================================================
-
-.. currentmodule:: torchsig.transforms.target_transforms
-
-.. autoclass:: OversamplingRate
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~OversamplingRate.add_parent
-      ~OversamplingRate.get_distribution
-      ~OversamplingRate.get_second_seed
-      ~OversamplingRate.seed
-      ~OversamplingRate.setup_rngs
-      ~OversamplingRate.update
-      ~OversamplingRate.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.target_transforms.PassThrough.rst b/docs/_autosummary/torchsig.transforms.target_transforms.PassThrough.rst
deleted file mode 100644
index 0dddb486f..000000000
--- a/docs/_autosummary/torchsig.transforms.target_transforms.PassThrough.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.target\_transforms.PassThrough
-==================================================
-
-.. currentmodule:: torchsig.transforms.target_transforms
-
-.. autoclass:: PassThrough
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~PassThrough.add_parent
-      ~PassThrough.get_distribution
-      ~PassThrough.get_second_seed
-      ~PassThrough.seed
-      ~PassThrough.setup_rngs
-      ~PassThrough.update
-      ~PassThrough.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.target_transforms.SNR.rst b/docs/_autosummary/torchsig.transforms.target_transforms.SNR.rst
deleted file mode 100644
index 58e6e0cbf..000000000
--- a/docs/_autosummary/torchsig.transforms.target_transforms.SNR.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.target\_transforms.SNR
-==========================================
-
-.. currentmodule:: torchsig.transforms.target_transforms
-
-.. autoclass:: SNR
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~SNR.add_parent
-      ~SNR.get_distribution
-      ~SNR.get_second_seed
-      ~SNR.seed
-      ~SNR.setup_rngs
-      ~SNR.update
-      ~SNR.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.target_transforms.SampleRate.rst b/docs/_autosummary/torchsig.transforms.target_transforms.SampleRate.rst
deleted file mode 100644
index 9b9947b7b..000000000
--- a/docs/_autosummary/torchsig.transforms.target_transforms.SampleRate.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.target\_transforms.SampleRate
-=================================================
-
-.. currentmodule:: torchsig.transforms.target_transforms
-
-.. autoclass:: SampleRate
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~SampleRate.add_parent
-      ~SampleRate.get_distribution
-      ~SampleRate.get_second_seed
-      ~SampleRate.seed
-      ~SampleRate.setup_rngs
-      ~SampleRate.update
-      ~SampleRate.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.target_transforms.Start.rst b/docs/_autosummary/torchsig.transforms.target_transforms.Start.rst
deleted file mode 100644
index a8e3228d0..000000000
--- a/docs/_autosummary/torchsig.transforms.target_transforms.Start.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.target\_transforms.Start
-============================================
-
-.. currentmodule:: torchsig.transforms.target_transforms
-
-.. autoclass:: Start
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~Start.add_parent
-      ~Start.get_distribution
-      ~Start.get_second_seed
-      ~Start.seed
-      ~Start.setup_rngs
-      ~Start.update
-      ~Start.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.target_transforms.StartInSamples.rst b/docs/_autosummary/torchsig.transforms.target_transforms.StartInSamples.rst
deleted file mode 100644
index 9f6ef72b6..000000000
--- a/docs/_autosummary/torchsig.transforms.target_transforms.StartInSamples.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.target\_transforms.StartInSamples
-=====================================================
-
-.. currentmodule:: torchsig.transforms.target_transforms
-
-.. autoclass:: StartInSamples
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~StartInSamples.add_parent
-      ~StartInSamples.get_distribution
-      ~StartInSamples.get_second_seed
-      ~StartInSamples.seed
-      ~StartInSamples.setup_rngs
-      ~StartInSamples.update
-      ~StartInSamples.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.target_transforms.Stop.rst b/docs/_autosummary/torchsig.transforms.target_transforms.Stop.rst
deleted file mode 100644
index d09415931..000000000
--- a/docs/_autosummary/torchsig.transforms.target_transforms.Stop.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.target\_transforms.Stop
-===========================================
-
-.. currentmodule:: torchsig.transforms.target_transforms
-
-.. autoclass:: Stop
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~Stop.add_parent
-      ~Stop.get_distribution
-      ~Stop.get_second_seed
-      ~Stop.seed
-      ~Stop.setup_rngs
-      ~Stop.update
-      ~Stop.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.target_transforms.StopInSamples.rst b/docs/_autosummary/torchsig.transforms.target_transforms.StopInSamples.rst
deleted file mode 100644
index 6671a5015..000000000
--- a/docs/_autosummary/torchsig.transforms.target_transforms.StopInSamples.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.target\_transforms.StopInSamples
-====================================================
-
-.. currentmodule:: torchsig.transforms.target_transforms
-
-.. autoclass:: StopInSamples
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~StopInSamples.add_parent
-      ~StopInSamples.get_distribution
-      ~StopInSamples.get_second_seed
-      ~StopInSamples.seed
-      ~StopInSamples.setup_rngs
-      ~StopInSamples.update
-      ~StopInSamples.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.target_transforms.TargetTransform.rst b/docs/_autosummary/torchsig.transforms.target_transforms.TargetTransform.rst
deleted file mode 100644
index 5662aed47..000000000
--- a/docs/_autosummary/torchsig.transforms.target_transforms.TargetTransform.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.target\_transforms.TargetTransform
-======================================================
-
-.. currentmodule:: torchsig.transforms.target_transforms
-
-.. autoclass:: TargetTransform
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~TargetTransform.add_parent
-      ~TargetTransform.get_distribution
-      ~TargetTransform.get_second_seed
-      ~TargetTransform.seed
-      ~TargetTransform.setup_rngs
-      ~TargetTransform.update
-      ~TargetTransform.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.target_transforms.UpperFreq.rst b/docs/_autosummary/torchsig.transforms.target_transforms.UpperFreq.rst
deleted file mode 100644
index ea44ab1c0..000000000
--- a/docs/_autosummary/torchsig.transforms.target_transforms.UpperFreq.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.transforms.target\_transforms.UpperFreq
-================================================
-
-.. currentmodule:: torchsig.transforms.target_transforms
-
-.. autoclass:: UpperFreq
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~UpperFreq.add_parent
-      ~UpperFreq.get_distribution
-      ~UpperFreq.get_second_seed
-      ~UpperFreq.seed
-      ~UpperFreq.setup_rngs
-      ~UpperFreq.update
-      ~UpperFreq.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.target_transforms.YOLOLabel.rst b/docs/_autosummary/torchsig.transforms.target_transforms.YOLOLabel.rst
deleted file mode 100644
index fcaa9de2d..000000000
--- a/docs/_autosummary/torchsig.transforms.target_transforms.YOLOLabel.rst
+++ /dev/null
@@ -1,37 +0,0 @@
-torchsig.transforms.target\_transforms.YOLOLabel
-================================================
-
-.. currentmodule:: torchsig.transforms.target_transforms
-
-.. autoclass:: YOLOLabel
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~YOLOLabel.add_parent
-      ~YOLOLabel.get_distribution
-      ~YOLOLabel.get_second_seed
-      ~YOLOLabel.seed
-      ~YOLOLabel.setup_rngs
-      ~YOLOLabel.update
-      ~YOLOLabel.update_from_parent
-   
-   
-
-   
-   
-   .. rubric:: Attributes
-
-   .. autosummary::
-   
-      ~YOLOLabel.output_list
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.transforms.target_transforms.rst b/docs/_autosummary/torchsig.transforms.target_transforms.rst
deleted file mode 100644
index 84a29a496..000000000
--- a/docs/_autosummary/torchsig.transforms.target_transforms.rst
+++ /dev/null
@@ -1,53 +0,0 @@
-torchsig.transforms.target\_transforms
-======================================
-
-.. automodule:: torchsig.transforms.target_transforms
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Classes
-
-   .. autosummary::
-      :toctree:
-      :template: custom_class_template.rst
-      :nosignatures:
-   
-      Bandwidth
-      CenterFreq
-      ClassIndex
-      ClassName
-      CustomLabel
-      Duration
-      DurationInSamples
-      FamilyIndex
-      FamilyName
-      LowerFreq
-      NumSamples
-      OversamplingRate
-      PassThrough
-      SNR
-      SampleRate
-      Start
-      StartInSamples
-      Stop
-      StopInSamples
-      TargetTransform
-      UpperFreq
-      YOLOLabel
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.utils.data_loading.WorkerSeedingDataLoader.rst b/docs/_autosummary/torchsig.utils.data_loading.WorkerSeedingDataLoader.rst
deleted file mode 100644
index e624aca47..000000000
--- a/docs/_autosummary/torchsig.utils.data_loading.WorkerSeedingDataLoader.rst
+++ /dev/null
@@ -1,47 +0,0 @@
-torchsig.utils.data\_loading.WorkerSeedingDataLoader
-====================================================
-
-.. currentmodule:: torchsig.utils.data_loading
-
-.. autoclass:: WorkerSeedingDataLoader
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~WorkerSeedingDataLoader.add_parent
-      ~WorkerSeedingDataLoader.check_worker_number_rationality
-      ~WorkerSeedingDataLoader.get_distribution
-      ~WorkerSeedingDataLoader.get_second_seed
-      ~WorkerSeedingDataLoader.init_worker_seed
-      ~WorkerSeedingDataLoader.seed
-      ~WorkerSeedingDataLoader.setup_rngs
-      ~WorkerSeedingDataLoader.update_from_parent
-   
-   
-
-   
-   
-   .. rubric:: Attributes
-
-   .. autosummary::
-   
-      ~WorkerSeedingDataLoader.multiprocessing_context
-      ~WorkerSeedingDataLoader.dataset
-      ~WorkerSeedingDataLoader.batch_size
-      ~WorkerSeedingDataLoader.num_workers
-      ~WorkerSeedingDataLoader.pin_memory
-      ~WorkerSeedingDataLoader.drop_last
-      ~WorkerSeedingDataLoader.timeout
-      ~WorkerSeedingDataLoader.sampler
-      ~WorkerSeedingDataLoader.pin_memory_device
-      ~WorkerSeedingDataLoader.prefetch_factor
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.data_loading.rst b/docs/_autosummary/torchsig.utils.data_loading.rst
deleted file mode 100644
index 33dd1726c..000000000
--- a/docs/_autosummary/torchsig.utils.data_loading.rst
+++ /dev/null
@@ -1,32 +0,0 @@
-torchsig.utils.data\_loading
-============================
-
-.. automodule:: torchsig.utils.data_loading
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Classes
-
-   .. autosummary::
-      :toctree:
-      :template: custom_class_template.rst
-      :nosignatures:
-   
-      WorkerSeedingDataLoader
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.utils.dsp.bandwidth_from_lower_upper_freq.rst b/docs/_autosummary/torchsig.utils.dsp.bandwidth_from_lower_upper_freq.rst
deleted file mode 100644
index ea3437e19..000000000
--- a/docs/_autosummary/torchsig.utils.dsp.bandwidth_from_lower_upper_freq.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.utils.dsp.bandwidth\_from\_lower\_upper\_freq
-======================================================
-
-.. currentmodule:: torchsig.utils.dsp
-
-.. autofunction:: bandwidth_from_lower_upper_freq
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.dsp.center_freq_from_lower_upper_freq.rst b/docs/_autosummary/torchsig.utils.dsp.center_freq_from_lower_upper_freq.rst
deleted file mode 100644
index 05db388ff..000000000
--- a/docs/_autosummary/torchsig.utils.dsp.center_freq_from_lower_upper_freq.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.utils.dsp.center\_freq\_from\_lower\_upper\_freq
-=========================================================
-
-.. currentmodule:: torchsig.utils.dsp
-
-.. autofunction:: center_freq_from_lower_upper_freq
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.dsp.compute_spectrogram.rst b/docs/_autosummary/torchsig.utils.dsp.compute_spectrogram.rst
deleted file mode 100644
index 7d6875747..000000000
--- a/docs/_autosummary/torchsig.utils.dsp.compute_spectrogram.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.utils.dsp.compute\_spectrogram
-=======================================
-
-.. currentmodule:: torchsig.utils.dsp
-
-.. autofunction:: compute_spectrogram
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.dsp.convolve.rst b/docs/_autosummary/torchsig.utils.dsp.convolve.rst
deleted file mode 100644
index e8cca8de8..000000000
--- a/docs/_autosummary/torchsig.utils.dsp.convolve.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.utils.dsp.convolve
-===========================
-
-.. currentmodule:: torchsig.utils.dsp
-
-.. autofunction:: convolve
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.dsp.design_half_band_filter.rst b/docs/_autosummary/torchsig.utils.dsp.design_half_band_filter.rst
deleted file mode 100644
index f8e15e14e..000000000
--- a/docs/_autosummary/torchsig.utils.dsp.design_half_band_filter.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.utils.dsp.design\_half\_band\_filter
-=============================================
-
-.. currentmodule:: torchsig.utils.dsp
-
-.. autofunction:: design_half_band_filter
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.dsp.estimate_filter_length.rst b/docs/_autosummary/torchsig.utils.dsp.estimate_filter_length.rst
deleted file mode 100644
index 1b2eb8119..000000000
--- a/docs/_autosummary/torchsig.utils.dsp.estimate_filter_length.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.utils.dsp.estimate\_filter\_length
-===========================================
-
-.. currentmodule:: torchsig.utils.dsp
-
-.. autofunction:: estimate_filter_length
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.dsp.estimate_tone_bandwidth.rst b/docs/_autosummary/torchsig.utils.dsp.estimate_tone_bandwidth.rst
deleted file mode 100644
index 6cd7666fa..000000000
--- a/docs/_autosummary/torchsig.utils.dsp.estimate_tone_bandwidth.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.utils.dsp.estimate\_tone\_bandwidth
-============================================
-
-.. currentmodule:: torchsig.utils.dsp
-
-.. autofunction:: estimate_tone_bandwidth
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.dsp.frequency_shift.rst b/docs/_autosummary/torchsig.utils.dsp.frequency_shift.rst
deleted file mode 100644
index ffc0cf44e..000000000
--- a/docs/_autosummary/torchsig.utils.dsp.frequency_shift.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.utils.dsp.frequency\_shift
-===================================
-
-.. currentmodule:: torchsig.utils.dsp
-
-.. autofunction:: frequency_shift
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.dsp.gaussian_taps.rst b/docs/_autosummary/torchsig.utils.dsp.gaussian_taps.rst
deleted file mode 100644
index 98e298c11..000000000
--- a/docs/_autosummary/torchsig.utils.dsp.gaussian_taps.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.utils.dsp.gaussian\_taps
-=================================
-
-.. currentmodule:: torchsig.utils.dsp
-
-.. autofunction:: gaussian_taps
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.dsp.interpolate_power_of_2_resampler.rst b/docs/_autosummary/torchsig.utils.dsp.interpolate_power_of_2_resampler.rst
deleted file mode 100644
index b02933bd3..000000000
--- a/docs/_autosummary/torchsig.utils.dsp.interpolate_power_of_2_resampler.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.utils.dsp.interpolate\_power\_of\_2\_resampler
-=======================================================
-
-.. currentmodule:: torchsig.utils.dsp
-
-.. autofunction:: interpolate_power_of_2_resampler
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.dsp.is_even.rst b/docs/_autosummary/torchsig.utils.dsp.is_even.rst
deleted file mode 100644
index 606ca8c67..000000000
--- a/docs/_autosummary/torchsig.utils.dsp.is_even.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.utils.dsp.is\_even
-===========================
-
-.. currentmodule:: torchsig.utils.dsp
-
-.. autofunction:: is_even
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.dsp.is_multiple_of_4.rst b/docs/_autosummary/torchsig.utils.dsp.is_multiple_of_4.rst
deleted file mode 100644
index 94720fa66..000000000
--- a/docs/_autosummary/torchsig.utils.dsp.is_multiple_of_4.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.utils.dsp.is\_multiple\_of\_4
-======================================
-
-.. currentmodule:: torchsig.utils.dsp
-
-.. autofunction:: is_multiple_of_4
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.dsp.is_odd.rst b/docs/_autosummary/torchsig.utils.dsp.is_odd.rst
deleted file mode 100644
index 05a080f7a..000000000
--- a/docs/_autosummary/torchsig.utils.dsp.is_odd.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.utils.dsp.is\_odd
-==========================
-
-.. currentmodule:: torchsig.utils.dsp
-
-.. autofunction:: is_odd
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.dsp.low_pass.rst b/docs/_autosummary/torchsig.utils.dsp.low_pass.rst
deleted file mode 100644
index 9c349e9de..000000000
--- a/docs/_autosummary/torchsig.utils.dsp.low_pass.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.utils.dsp.low\_pass
-============================
-
-.. currentmodule:: torchsig.utils.dsp
-
-.. autofunction:: low_pass
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.dsp.low_pass_iterative_design.rst b/docs/_autosummary/torchsig.utils.dsp.low_pass_iterative_design.rst
deleted file mode 100644
index acba3ac25..000000000
--- a/docs/_autosummary/torchsig.utils.dsp.low_pass_iterative_design.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.utils.dsp.low\_pass\_iterative\_design
-===============================================
-
-.. currentmodule:: torchsig.utils.dsp
-
-.. autofunction:: low_pass_iterative_design
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.dsp.lower_freq_from_center_freq_bandwidth.rst b/docs/_autosummary/torchsig.utils.dsp.lower_freq_from_center_freq_bandwidth.rst
deleted file mode 100644
index 3f8cbf074..000000000
--- a/docs/_autosummary/torchsig.utils.dsp.lower_freq_from_center_freq_bandwidth.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.utils.dsp.lower\_freq\_from\_center\_freq\_bandwidth
-=============================================================
-
-.. currentmodule:: torchsig.utils.dsp
-
-.. autofunction:: lower_freq_from_center_freq_bandwidth
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.dsp.multistage_polyphase_decimator.rst b/docs/_autosummary/torchsig.utils.dsp.multistage_polyphase_decimator.rst
deleted file mode 100644
index e19b46ce3..000000000
--- a/docs/_autosummary/torchsig.utils.dsp.multistage_polyphase_decimator.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.utils.dsp.multistage\_polyphase\_decimator
-===================================================
-
-.. currentmodule:: torchsig.utils.dsp
-
-.. autofunction:: multistage_polyphase_decimator
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.dsp.multistage_polyphase_interpolator.rst b/docs/_autosummary/torchsig.utils.dsp.multistage_polyphase_interpolator.rst
deleted file mode 100644
index a954feb5f..000000000
--- a/docs/_autosummary/torchsig.utils.dsp.multistage_polyphase_interpolator.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.utils.dsp.multistage\_polyphase\_interpolator
-======================================================
-
-.. currentmodule:: torchsig.utils.dsp
-
-.. autofunction:: multistage_polyphase_interpolator
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.dsp.multistage_polyphase_resampler.rst b/docs/_autosummary/torchsig.utils.dsp.multistage_polyphase_resampler.rst
deleted file mode 100644
index e4cc334f8..000000000
--- a/docs/_autosummary/torchsig.utils.dsp.multistage_polyphase_resampler.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.utils.dsp.multistage\_polyphase\_resampler
-===================================================
-
-.. currentmodule:: torchsig.utils.dsp
-
-.. autofunction:: multistage_polyphase_resampler
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.dsp.noise_generator.rst b/docs/_autosummary/torchsig.utils.dsp.noise_generator.rst
deleted file mode 100644
index 874fed93c..000000000
--- a/docs/_autosummary/torchsig.utils.dsp.noise_generator.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.utils.dsp.noise\_generator
-===================================
-
-.. currentmodule:: torchsig.utils.dsp
-
-.. autofunction:: noise_generator
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.dsp.pad_head_tail_to_length.rst b/docs/_autosummary/torchsig.utils.dsp.pad_head_tail_to_length.rst
deleted file mode 100644
index cc412bbe7..000000000
--- a/docs/_autosummary/torchsig.utils.dsp.pad_head_tail_to_length.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.utils.dsp.pad\_head\_tail\_to\_length
-==============================================
-
-.. currentmodule:: torchsig.utils.dsp
-
-.. autofunction:: pad_head_tail_to_length
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.dsp.polyphase_decimator.rst b/docs/_autosummary/torchsig.utils.dsp.polyphase_decimator.rst
deleted file mode 100644
index 4b1720e94..000000000
--- a/docs/_autosummary/torchsig.utils.dsp.polyphase_decimator.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.utils.dsp.polyphase\_decimator
-=======================================
-
-.. currentmodule:: torchsig.utils.dsp
-
-.. autofunction:: polyphase_decimator
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.dsp.polyphase_fractional_resampler.rst b/docs/_autosummary/torchsig.utils.dsp.polyphase_fractional_resampler.rst
deleted file mode 100644
index 01abfaf2f..000000000
--- a/docs/_autosummary/torchsig.utils.dsp.polyphase_fractional_resampler.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.utils.dsp.polyphase\_fractional\_resampler
-===================================================
-
-.. currentmodule:: torchsig.utils.dsp
-
-.. autofunction:: polyphase_fractional_resampler
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.dsp.polyphase_integer_interpolator.rst b/docs/_autosummary/torchsig.utils.dsp.polyphase_integer_interpolator.rst
deleted file mode 100644
index 094b5ab8e..000000000
--- a/docs/_autosummary/torchsig.utils.dsp.polyphase_integer_interpolator.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.utils.dsp.polyphase\_integer\_interpolator
-===================================================
-
-.. currentmodule:: torchsig.utils.dsp
-
-.. autofunction:: polyphase_integer_interpolator
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.dsp.prototype_polyphase_filter.rst b/docs/_autosummary/torchsig.utils.dsp.prototype_polyphase_filter.rst
deleted file mode 100644
index 060d71a97..000000000
--- a/docs/_autosummary/torchsig.utils.dsp.prototype_polyphase_filter.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.utils.dsp.prototype\_polyphase\_filter
-===============================================
-
-.. currentmodule:: torchsig.utils.dsp
-
-.. autofunction:: prototype_polyphase_filter
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.dsp.prototype_polyphase_filter_decimation.rst b/docs/_autosummary/torchsig.utils.dsp.prototype_polyphase_filter_decimation.rst
deleted file mode 100644
index e8984f325..000000000
--- a/docs/_autosummary/torchsig.utils.dsp.prototype_polyphase_filter_decimation.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.utils.dsp.prototype\_polyphase\_filter\_decimation
-===========================================================
-
-.. currentmodule:: torchsig.utils.dsp
-
-.. autofunction:: prototype_polyphase_filter_decimation
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.dsp.prototype_polyphase_filter_interpolation.rst b/docs/_autosummary/torchsig.utils.dsp.prototype_polyphase_filter_interpolation.rst
deleted file mode 100644
index c053dd1d1..000000000
--- a/docs/_autosummary/torchsig.utils.dsp.prototype_polyphase_filter_interpolation.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.utils.dsp.prototype\_polyphase\_filter\_interpolation
-==============================================================
-
-.. currentmodule:: torchsig.utils.dsp
-
-.. autofunction:: prototype_polyphase_filter_interpolation
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.dsp.read_pickle.rst b/docs/_autosummary/torchsig.utils.dsp.read_pickle.rst
deleted file mode 100644
index e66c7eac7..000000000
--- a/docs/_autosummary/torchsig.utils.dsp.read_pickle.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.utils.dsp.read\_pickle
-===============================
-
-.. currentmodule:: torchsig.utils.dsp
-
-.. autofunction:: read_pickle
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.dsp.rst b/docs/_autosummary/torchsig.utils.dsp.rst
deleted file mode 100644
index aa02bc8e9..000000000
--- a/docs/_autosummary/torchsig.utils.dsp.rst
+++ /dev/null
@@ -1,65 +0,0 @@
-torchsig.utils.dsp
-==================
-
-.. automodule:: torchsig.utils.dsp
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Functions
-
-   .. autosummary::
-      :toctree:
-      :nosignatures:
-   
-      bandwidth_from_lower_upper_freq
-      center_freq_from_lower_upper_freq
-      compute_spectrogram
-      convolve
-      design_half_band_filter
-      estimate_filter_length
-      estimate_tone_bandwidth
-      frequency_shift
-      gaussian_taps
-      interpolate_power_of_2_resampler
-      is_even
-      is_multiple_of_4
-      is_odd
-      low_pass
-      low_pass_iterative_design
-      lower_freq_from_center_freq_bandwidth
-      multistage_polyphase_decimator
-      multistage_polyphase_interpolator
-      multistage_polyphase_resampler
-      noise_generator
-      pad_head_tail_to_length
-      polyphase_decimator
-      polyphase_fractional_resampler
-      polyphase_integer_interpolator
-      prototype_polyphase_filter
-      prototype_polyphase_filter_decimation
-      prototype_polyphase_filter_interpolation
-      read_pickle
-      slice_head_tail_to_length
-      slice_tail_to_length
-      srrc_taps
-      upconversion_anti_aliasing_filter
-      upper_freq_from_center_freq_bandwidth
-      upsample
-      write_pickle
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.utils.dsp.slice_head_tail_to_length.rst b/docs/_autosummary/torchsig.utils.dsp.slice_head_tail_to_length.rst
deleted file mode 100644
index 4fef6750b..000000000
--- a/docs/_autosummary/torchsig.utils.dsp.slice_head_tail_to_length.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.utils.dsp.slice\_head\_tail\_to\_length
-================================================
-
-.. currentmodule:: torchsig.utils.dsp
-
-.. autofunction:: slice_head_tail_to_length
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.dsp.slice_tail_to_length.rst b/docs/_autosummary/torchsig.utils.dsp.slice_tail_to_length.rst
deleted file mode 100644
index 3023fb8fc..000000000
--- a/docs/_autosummary/torchsig.utils.dsp.slice_tail_to_length.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.utils.dsp.slice\_tail\_to\_length
-==========================================
-
-.. currentmodule:: torchsig.utils.dsp
-
-.. autofunction:: slice_tail_to_length
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.dsp.srrc_taps.rst b/docs/_autosummary/torchsig.utils.dsp.srrc_taps.rst
deleted file mode 100644
index 31b6a8547..000000000
--- a/docs/_autosummary/torchsig.utils.dsp.srrc_taps.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.utils.dsp.srrc\_taps
-=============================
-
-.. currentmodule:: torchsig.utils.dsp
-
-.. autofunction:: srrc_taps
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.dsp.upconversion_anti_aliasing_filter.rst b/docs/_autosummary/torchsig.utils.dsp.upconversion_anti_aliasing_filter.rst
deleted file mode 100644
index fd15d287d..000000000
--- a/docs/_autosummary/torchsig.utils.dsp.upconversion_anti_aliasing_filter.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.utils.dsp.upconversion\_anti\_aliasing\_filter
-=======================================================
-
-.. currentmodule:: torchsig.utils.dsp
-
-.. autofunction:: upconversion_anti_aliasing_filter
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.dsp.upper_freq_from_center_freq_bandwidth.rst b/docs/_autosummary/torchsig.utils.dsp.upper_freq_from_center_freq_bandwidth.rst
deleted file mode 100644
index 4dc10e54e..000000000
--- a/docs/_autosummary/torchsig.utils.dsp.upper_freq_from_center_freq_bandwidth.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.utils.dsp.upper\_freq\_from\_center\_freq\_bandwidth
-=============================================================
-
-.. currentmodule:: torchsig.utils.dsp
-
-.. autofunction:: upper_freq_from_center_freq_bandwidth
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.dsp.upsample.rst b/docs/_autosummary/torchsig.utils.dsp.upsample.rst
deleted file mode 100644
index 77041e01b..000000000
--- a/docs/_autosummary/torchsig.utils.dsp.upsample.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.utils.dsp.upsample
-===========================
-
-.. currentmodule:: torchsig.utils.dsp
-
-.. autofunction:: upsample
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.dsp.write_pickle.rst b/docs/_autosummary/torchsig.utils.dsp.write_pickle.rst
deleted file mode 100644
index 8aead9a6d..000000000
--- a/docs/_autosummary/torchsig.utils.dsp.write_pickle.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.utils.dsp.write\_pickle
-================================
-
-.. currentmodule:: torchsig.utils.dsp
-
-.. autofunction:: write_pickle
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.file_handlers.base_handler.BaseFileHandler.rst b/docs/_autosummary/torchsig.utils.file_handlers.base_handler.BaseFileHandler.rst
deleted file mode 100644
index 94f8cb112..000000000
--- a/docs/_autosummary/torchsig.utils.file_handlers.base_handler.BaseFileHandler.rst
+++ /dev/null
@@ -1,30 +0,0 @@
-torchsig.utils.file\_handlers.base\_handler.BaseFileHandler
-===========================================================
-
-.. currentmodule:: torchsig.utils.file_handlers.base_handler
-
-.. autoclass:: BaseFileHandler
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~BaseFileHandler.exists
-      ~BaseFileHandler.load
-      ~BaseFileHandler.setup
-      ~BaseFileHandler.static_load
-      ~BaseFileHandler.teardown
-      ~BaseFileHandler.write
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.file_handlers.base_handler.TorchSigFileHandler.rst b/docs/_autosummary/torchsig.utils.file_handlers.base_handler.TorchSigFileHandler.rst
deleted file mode 100644
index 7ba6fc1be..000000000
--- a/docs/_autosummary/torchsig.utils.file_handlers.base_handler.TorchSigFileHandler.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.utils.file\_handlers.base\_handler.TorchSigFileHandler
-===============================================================
-
-.. currentmodule:: torchsig.utils.file_handlers.base_handler
-
-.. autoclass:: TorchSigFileHandler
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~TorchSigFileHandler.exists
-      ~TorchSigFileHandler.load
-      ~TorchSigFileHandler.setup
-      ~TorchSigFileHandler.size
-      ~TorchSigFileHandler.static_load
-      ~TorchSigFileHandler.teardown
-      ~TorchSigFileHandler.write
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.file_handlers.base_handler.rst b/docs/_autosummary/torchsig.utils.file_handlers.base_handler.rst
deleted file mode 100644
index 14d8af7ec..000000000
--- a/docs/_autosummary/torchsig.utils.file_handlers.base_handler.rst
+++ /dev/null
@@ -1,33 +0,0 @@
-torchsig.utils.file\_handlers.base\_handler
-===========================================
-
-.. automodule:: torchsig.utils.file_handlers.base_handler
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Classes
-
-   .. autosummary::
-      :toctree:
-      :template: custom_class_template.rst
-      :nosignatures:
-   
-      BaseFileHandler
-      TorchSigFileHandler
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.utils.file_handlers.rst b/docs/_autosummary/torchsig.utils.file_handlers.rst
deleted file mode 100644
index 47b909553..000000000
--- a/docs/_autosummary/torchsig.utils.file_handlers.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.utils.file\_handlers
-=============================
-
-.. automodule:: torchsig.utils.file_handlers
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-
-
-.. autosummary::
-   :toctree:
-   :template: custom_module_template.rst
-   :recursive:
-
-   base_handler
-   zarr
-
diff --git a/docs/_autosummary/torchsig.utils.file_handlers.zarr.ZarrFileHandler.rst b/docs/_autosummary/torchsig.utils.file_handlers.zarr.ZarrFileHandler.rst
deleted file mode 100644
index cd75ee59b..000000000
--- a/docs/_autosummary/torchsig.utils.file_handlers.zarr.ZarrFileHandler.rst
+++ /dev/null
@@ -1,37 +0,0 @@
-torchsig.utils.file\_handlers.zarr.ZarrFileHandler
-==================================================
-
-.. currentmodule:: torchsig.utils.file_handlers.zarr
-
-.. autoclass:: ZarrFileHandler
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~ZarrFileHandler.exists
-      ~ZarrFileHandler.load
-      ~ZarrFileHandler.setup
-      ~ZarrFileHandler.size
-      ~ZarrFileHandler.static_load
-      ~ZarrFileHandler.teardown
-      ~ZarrFileHandler.write
-   
-   
-
-   
-   
-   .. rubric:: Attributes
-
-   .. autosummary::
-   
-      ~ZarrFileHandler.datapath_filename_base
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.file_handlers.zarr.rst b/docs/_autosummary/torchsig.utils.file_handlers.zarr.rst
deleted file mode 100644
index c3b868d66..000000000
--- a/docs/_autosummary/torchsig.utils.file_handlers.zarr.rst
+++ /dev/null
@@ -1,32 +0,0 @@
-torchsig.utils.file\_handlers.zarr
-==================================
-
-.. automodule:: torchsig.utils.file_handlers.zarr
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Classes
-
-   .. autosummary::
-      :toctree:
-      :template: custom_class_template.rst
-      :nosignatures:
-   
-      ZarrFileHandler
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.utils.generate.generate.rst b/docs/_autosummary/torchsig.utils.generate.generate.rst
deleted file mode 100644
index 680de5c4a..000000000
--- a/docs/_autosummary/torchsig.utils.generate.generate.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.utils.generate.generate
-================================
-
-.. currentmodule:: torchsig.utils.generate
-
-.. autofunction:: generate
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.generate.rst b/docs/_autosummary/torchsig.utils.generate.rst
deleted file mode 100644
index e731dbd9d..000000000
--- a/docs/_autosummary/torchsig.utils.generate.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.utils.generate
-=======================
-
-.. automodule:: torchsig.utils.generate
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Functions
-
-   .. autosummary::
-      :toctree:
-      :nosignatures:
-   
-      generate
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.utils.printing.dataset_metadata_repr.rst b/docs/_autosummary/torchsig.utils.printing.dataset_metadata_repr.rst
deleted file mode 100644
index 7c6284933..000000000
--- a/docs/_autosummary/torchsig.utils.printing.dataset_metadata_repr.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.utils.printing.dataset\_metadata\_repr
-===============================================
-
-.. currentmodule:: torchsig.utils.printing
-
-.. autofunction:: dataset_metadata_repr
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.printing.dataset_metadata_str.rst b/docs/_autosummary/torchsig.utils.printing.dataset_metadata_str.rst
deleted file mode 100644
index b289f4788..000000000
--- a/docs/_autosummary/torchsig.utils.printing.dataset_metadata_str.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.utils.printing.dataset\_metadata\_str
-==============================================
-
-.. currentmodule:: torchsig.utils.printing
-
-.. autofunction:: dataset_metadata_str
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.printing.generate_repr_str.rst b/docs/_autosummary/torchsig.utils.printing.generate_repr_str.rst
deleted file mode 100644
index 445fd0450..000000000
--- a/docs/_autosummary/torchsig.utils.printing.generate_repr_str.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.utils.printing.generate\_repr\_str
-===========================================
-
-.. currentmodule:: torchsig.utils.printing
-
-.. autofunction:: generate_repr_str
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.printing.rst b/docs/_autosummary/torchsig.utils.printing.rst
deleted file mode 100644
index e3ecd24dd..000000000
--- a/docs/_autosummary/torchsig.utils.printing.rst
+++ /dev/null
@@ -1,33 +0,0 @@
-torchsig.utils.printing
-=======================
-
-.. automodule:: torchsig.utils.printing
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Functions
-
-   .. autosummary::
-      :toctree:
-      :nosignatures:
-   
-      dataset_metadata_repr
-      dataset_metadata_str
-      generate_repr_str
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.utils.random.ChoiceDistribution.rst b/docs/_autosummary/torchsig.utils.random.ChoiceDistribution.rst
deleted file mode 100644
index 445ae7581..000000000
--- a/docs/_autosummary/torchsig.utils.random.ChoiceDistribution.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.utils.random.ChoiceDistribution
-========================================
-
-.. currentmodule:: torchsig.utils.random
-
-.. autoclass:: ChoiceDistribution
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~ChoiceDistribution.add_parent
-      ~ChoiceDistribution.get_distribution
-      ~ChoiceDistribution.get_second_seed
-      ~ChoiceDistribution.get_value
-      ~ChoiceDistribution.seed
-      ~ChoiceDistribution.setup_rngs
-      ~ChoiceDistribution.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.random.Distribution.rst b/docs/_autosummary/torchsig.utils.random.Distribution.rst
deleted file mode 100644
index 3a7820a01..000000000
--- a/docs/_autosummary/torchsig.utils.random.Distribution.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.utils.random.Distribution
-==================================
-
-.. currentmodule:: torchsig.utils.random
-
-.. autoclass:: Distribution
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~Distribution.add_parent
-      ~Distribution.get_distribution
-      ~Distribution.get_second_seed
-      ~Distribution.get_value
-      ~Distribution.seed
-      ~Distribution.setup_rngs
-      ~Distribution.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.random.Log10UniformRangeDistribution.rst b/docs/_autosummary/torchsig.utils.random.Log10UniformRangeDistribution.rst
deleted file mode 100644
index 4462f49f4..000000000
--- a/docs/_autosummary/torchsig.utils.random.Log10UniformRangeDistribution.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.utils.random.Log10UniformRangeDistribution
-===================================================
-
-.. currentmodule:: torchsig.utils.random
-
-.. autoclass:: Log10UniformRangeDistribution
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~Log10UniformRangeDistribution.add_parent
-      ~Log10UniformRangeDistribution.get_distribution
-      ~Log10UniformRangeDistribution.get_second_seed
-      ~Log10UniformRangeDistribution.get_value
-      ~Log10UniformRangeDistribution.seed
-      ~Log10UniformRangeDistribution.setup_rngs
-      ~Log10UniformRangeDistribution.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.random.Seedable.rst b/docs/_autosummary/torchsig.utils.random.Seedable.rst
deleted file mode 100644
index 6f308ce11..000000000
--- a/docs/_autosummary/torchsig.utils.random.Seedable.rst
+++ /dev/null
@@ -1,30 +0,0 @@
-torchsig.utils.random.Seedable
-==============================
-
-.. currentmodule:: torchsig.utils.random
-
-.. autoclass:: Seedable
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~Seedable.add_parent
-      ~Seedable.get_distribution
-      ~Seedable.get_second_seed
-      ~Seedable.seed
-      ~Seedable.setup_rngs
-      ~Seedable.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.random.UniformDistribution.rst b/docs/_autosummary/torchsig.utils.random.UniformDistribution.rst
deleted file mode 100644
index c0bfe1c9d..000000000
--- a/docs/_autosummary/torchsig.utils.random.UniformDistribution.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.utils.random.UniformDistribution
-=========================================
-
-.. currentmodule:: torchsig.utils.random
-
-.. autoclass:: UniformDistribution
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~UniformDistribution.add_parent
-      ~UniformDistribution.get_distribution
-      ~UniformDistribution.get_second_seed
-      ~UniformDistribution.get_value
-      ~UniformDistribution.seed
-      ~UniformDistribution.setup_rngs
-      ~UniformDistribution.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.random.UniformRangeDistribution.rst b/docs/_autosummary/torchsig.utils.random.UniformRangeDistribution.rst
deleted file mode 100644
index d2cb16d16..000000000
--- a/docs/_autosummary/torchsig.utils.random.UniformRangeDistribution.rst
+++ /dev/null
@@ -1,31 +0,0 @@
-torchsig.utils.random.UniformRangeDistribution
-==============================================
-
-.. currentmodule:: torchsig.utils.random
-
-.. autoclass:: UniformRangeDistribution
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~UniformRangeDistribution.add_parent
-      ~UniformRangeDistribution.get_distribution
-      ~UniformRangeDistribution.get_second_seed
-      ~UniformRangeDistribution.get_value
-      ~UniformRangeDistribution.seed
-      ~UniformRangeDistribution.setup_rngs
-      ~UniformRangeDistribution.update_from_parent
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.random.make_distribution.rst b/docs/_autosummary/torchsig.utils.random.make_distribution.rst
deleted file mode 100644
index 09229f12f..000000000
--- a/docs/_autosummary/torchsig.utils.random.make_distribution.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.utils.random.make\_distribution
-========================================
-
-.. currentmodule:: torchsig.utils.random
-
-.. autofunction:: make_distribution
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.random.rst b/docs/_autosummary/torchsig.utils.random.rst
deleted file mode 100644
index ae9b75fb1..000000000
--- a/docs/_autosummary/torchsig.utils.random.rst
+++ /dev/null
@@ -1,45 +0,0 @@
-torchsig.utils.random
-=====================
-
-.. automodule:: torchsig.utils.random
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Functions
-
-   .. autosummary::
-      :toctree:
-      :nosignatures:
-   
-      make_distribution
-   
-   
-
-   
-   
-   .. rubric:: Classes
-
-   .. autosummary::
-      :toctree:
-      :template: custom_class_template.rst
-      :nosignatures:
-   
-      ChoiceDistribution
-      Distribution
-      Log10UniformRangeDistribution
-      Seedable
-      UniformDistribution
-      UniformRangeDistribution
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.utils.rst b/docs/_autosummary/torchsig.utils.rst
deleted file mode 100644
index 5d3b53b8f..000000000
--- a/docs/_autosummary/torchsig.utils.rst
+++ /dev/null
@@ -1,38 +0,0 @@
-torchsig.utils
-==============
-
-.. automodule:: torchsig.utils
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-
-
-.. autosummary::
-   :toctree:
-   :template: custom_module_template.rst
-   :recursive:
-
-   data_loading
-   dsp
-   file_handlers
-   generate
-   printing
-   random
-   verify
-   writer
-   yaml
-
diff --git a/docs/_autosummary/torchsig.utils.verify.rst b/docs/_autosummary/torchsig.utils.verify.rst
deleted file mode 100644
index 9405f6634..000000000
--- a/docs/_autosummary/torchsig.utils.verify.rst
+++ /dev/null
@@ -1,40 +0,0 @@
-torchsig.utils.verify
-=====================
-
-.. automodule:: torchsig.utils.verify
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Functions
-
-   .. autosummary::
-      :toctree:
-      :nosignatures:
-   
-      verify_bounds
-      verify_dict
-      verify_distribution_list
-      verify_float
-      verify_int
-      verify_list
-      verify_numpy_array
-      verify_str
-      verify_target_transforms
-      verify_transforms
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.utils.verify.verify_bounds.rst b/docs/_autosummary/torchsig.utils.verify.verify_bounds.rst
deleted file mode 100644
index 940c2de8f..000000000
--- a/docs/_autosummary/torchsig.utils.verify.verify_bounds.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.utils.verify.verify\_bounds
-====================================
-
-.. currentmodule:: torchsig.utils.verify
-
-.. autofunction:: verify_bounds
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.verify.verify_dict.rst b/docs/_autosummary/torchsig.utils.verify.verify_dict.rst
deleted file mode 100644
index 4401dcbd4..000000000
--- a/docs/_autosummary/torchsig.utils.verify.verify_dict.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.utils.verify.verify\_dict
-==================================
-
-.. currentmodule:: torchsig.utils.verify
-
-.. autofunction:: verify_dict
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.verify.verify_distribution_list.rst b/docs/_autosummary/torchsig.utils.verify.verify_distribution_list.rst
deleted file mode 100644
index 9d9f1bfc7..000000000
--- a/docs/_autosummary/torchsig.utils.verify.verify_distribution_list.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.utils.verify.verify\_distribution\_list
-================================================
-
-.. currentmodule:: torchsig.utils.verify
-
-.. autofunction:: verify_distribution_list
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.verify.verify_float.rst b/docs/_autosummary/torchsig.utils.verify.verify_float.rst
deleted file mode 100644
index beda335a7..000000000
--- a/docs/_autosummary/torchsig.utils.verify.verify_float.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.utils.verify.verify\_float
-===================================
-
-.. currentmodule:: torchsig.utils.verify
-
-.. autofunction:: verify_float
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.verify.verify_int.rst b/docs/_autosummary/torchsig.utils.verify.verify_int.rst
deleted file mode 100644
index 84e51bae6..000000000
--- a/docs/_autosummary/torchsig.utils.verify.verify_int.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.utils.verify.verify\_int
-=================================
-
-.. currentmodule:: torchsig.utils.verify
-
-.. autofunction:: verify_int
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.verify.verify_list.rst b/docs/_autosummary/torchsig.utils.verify.verify_list.rst
deleted file mode 100644
index c6b384350..000000000
--- a/docs/_autosummary/torchsig.utils.verify.verify_list.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.utils.verify.verify\_list
-==================================
-
-.. currentmodule:: torchsig.utils.verify
-
-.. autofunction:: verify_list
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.verify.verify_numpy_array.rst b/docs/_autosummary/torchsig.utils.verify.verify_numpy_array.rst
deleted file mode 100644
index bacd719e1..000000000
--- a/docs/_autosummary/torchsig.utils.verify.verify_numpy_array.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.utils.verify.verify\_numpy\_array
-==========================================
-
-.. currentmodule:: torchsig.utils.verify
-
-.. autofunction:: verify_numpy_array
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.verify.verify_str.rst b/docs/_autosummary/torchsig.utils.verify.verify_str.rst
deleted file mode 100644
index b83ec2644..000000000
--- a/docs/_autosummary/torchsig.utils.verify.verify_str.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.utils.verify.verify\_str
-=================================
-
-.. currentmodule:: torchsig.utils.verify
-
-.. autofunction:: verify_str
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.verify.verify_target_transforms.rst b/docs/_autosummary/torchsig.utils.verify.verify_target_transforms.rst
deleted file mode 100644
index 923d7cbd7..000000000
--- a/docs/_autosummary/torchsig.utils.verify.verify_target_transforms.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.utils.verify.verify\_target\_transforms
-================================================
-
-.. currentmodule:: torchsig.utils.verify
-
-.. autofunction:: verify_target_transforms
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.verify.verify_transforms.rst b/docs/_autosummary/torchsig.utils.verify.verify_transforms.rst
deleted file mode 100644
index 4f0a25f3c..000000000
--- a/docs/_autosummary/torchsig.utils.verify.verify_transforms.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.utils.verify.verify\_transforms
-========================================
-
-.. currentmodule:: torchsig.utils.verify
-
-.. autofunction:: verify_transforms
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.writer.DatasetCreator.rst b/docs/_autosummary/torchsig.utils.writer.DatasetCreator.rst
deleted file mode 100644
index a4174defa..000000000
--- a/docs/_autosummary/torchsig.utils.writer.DatasetCreator.rst
+++ /dev/null
@@ -1,27 +0,0 @@
-torchsig.utils.writer.DatasetCreator
-====================================
-
-.. currentmodule:: torchsig.utils.writer
-
-.. autoclass:: DatasetCreator
-   :members:
-   :show-inheritance:
-   :inherited-members:
-   :special-members: __call__, __repr__, __str__, __init__
-
-   
-   
-   .. rubric:: Methods
-
-   .. autosummary::
-      :nosignatures:
-   
-      ~DatasetCreator.check_yamls
-      ~DatasetCreator.create
-      ~DatasetCreator.get_writing_info_dict
-   
-   
-
-   
-   
-   
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.writer.rst b/docs/_autosummary/torchsig.utils.writer.rst
deleted file mode 100644
index 849eb64db..000000000
--- a/docs/_autosummary/torchsig.utils.writer.rst
+++ /dev/null
@@ -1,32 +0,0 @@
-torchsig.utils.writer
-=====================
-
-.. automodule:: torchsig.utils.writer
-
-   
-   
-   
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Classes
-
-   .. autosummary::
-      :toctree:
-      :template: custom_class_template.rst
-      :nosignatures:
-   
-      DatasetCreator
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.utils.yaml.custom_representer.rst b/docs/_autosummary/torchsig.utils.yaml.custom_representer.rst
deleted file mode 100644
index 51772f7af..000000000
--- a/docs/_autosummary/torchsig.utils.yaml.custom_representer.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.utils.yaml.custom\_representer
-=======================================
-
-.. currentmodule:: torchsig.utils.yaml
-
-.. autofunction:: custom_representer
\ No newline at end of file
diff --git a/docs/_autosummary/torchsig.utils.yaml.rst b/docs/_autosummary/torchsig.utils.yaml.rst
deleted file mode 100644
index 0b7c7545c..000000000
--- a/docs/_autosummary/torchsig.utils.yaml.rst
+++ /dev/null
@@ -1,32 +0,0 @@
-torchsig.utils.yaml
-===================
-
-.. automodule:: torchsig.utils.yaml
-
-   
-   
-   
-
-   
-   
-   .. rubric:: Functions
-
-   .. autosummary::
-      :toctree:
-      :nosignatures:
-   
-      custom_representer
-      write_dict_to_yaml
-   
-   
-
-   
-   
-   
-
-   
-   
-   
-
-
-
diff --git a/docs/_autosummary/torchsig.utils.yaml.write_dict_to_yaml.rst b/docs/_autosummary/torchsig.utils.yaml.write_dict_to_yaml.rst
deleted file mode 100644
index 2d2d7bf04..000000000
--- a/docs/_autosummary/torchsig.utils.yaml.write_dict_to_yaml.rst
+++ /dev/null
@@ -1,6 +0,0 @@
-torchsig.utils.yaml.write\_dict\_to\_yaml
-=========================================
-
-.. currentmodule:: torchsig.utils.yaml
-
-.. autofunction:: write_dict_to_yaml
\ No newline at end of file
diff --git a/docs/datasets.rst b/docs/datasets.rst
index 42d393f14..085ea1bf6 100644
--- a/docs/datasets.rst
+++ b/docs/datasets.rst
@@ -1,19 +1,18 @@
 Datasets
 ====================
 
-There are two main types of datasets: :class:`torchsig.datasets.datasets.NewDataset` and :class:`torchsig.datasets.datasets.StaticDataset`.
+There are two main types of datasets: :class:`torchsig.datasets.datasets.TorchSigIterableDataset` and :class:`torchsig.datasets.datasets.StaticDataset`.
 
-`NewDataset` and its counterparts :class:`torchsig.datasets.narrowband.NewDataset` and :class:`torchsig.datasets.wideband.NewWideband` are for generating synthetic data in memory (infinitely).
-Samples are not saved after being returned, and previous samples are inaccesible. 
+`TorchSigIterableDataset` is for generating synthetic data in memory (infinitely).
 
-To then save a dataset to disk, use a :class:`torchsig.utils.writer.DatasetCreator` which accepts a `NewDataset`` object.
+To then save a dataset to disk, use a :class:`torchsig.utils.writer.DatasetCreator` which accepts a `TorchSigIterableDataset` object.
 
-`StaticDataset` (:class:`torchsig.datasets.narrowband.StaticNarrowband` and :class:`torchsig.datasets.wideband.StaticWideband`) are for loading a saved dataset to disk.
+`StaticTorchSigDataset` (:class:`torchsig.datasets.StaticTorchSigDataset`) is for loading a saved dataset from disk.
 Samples can be accessed in any order and previously generated samples are accesible.
 
-Note: If a `NewDataset` is written to disk with no transforms and target transforms, it is considered `raw`. 
+Note: If a `TorchSigIterableDataset` is written to disk with no transforms and target transforms, it is considered `raw`. 
 Otherwise, it is considered to `processed`.
-`raw` means when the dataset is loaded back in using a `StaticDataset` object, users can define transforms and target transforms to be applied.
+`raw` means when the dataset is loaded back in using a `StaticTorchSigDataset` object, users can define transforms and target transforms to be applied.
 When a `processed` dataset is loaded back in, users cannot define any transforms and target transform to be applied.
 
 
@@ -38,22 +37,6 @@ Dataset Metadata
     :undoc-members:
     :show-inheritance:
 
-
-Narrowband
----------------------
-.. automodule:: torchsig.datasets.narrowband
-    :members:
-    :undoc-members:
-    :show-inheritance:
-
-
-Wideband
----------------------
-.. automodule:: torchsig.datasets.wideband
-    :members:
-    :undoc-members:
-    :show-inheritance:
-
 Datamodules
 ---------------------
 .. automodule:: torchsig.datasets.datamodules
diff --git a/docs/rust_fft_design.md b/docs/rust_fft_design.md
new file mode 100644
index 000000000..5a7d11897
--- /dev/null
+++ b/docs/rust_fft_design.md
@@ -0,0 +1,245 @@
+# Rust FFT Processing Module Design
+
+## Overview
+Optional Rust module for ultra-high performance FFT processing to further accelerate real-time spectrogram generation. This is designed to be a future enhancement when maximum performance is needed.
+
+## Performance Targets
+- **Sub-millisecond spectrogram generation** for typical RF signals
+- **10-100x faster** than current Python implementation
+- **Memory efficient** with zero-copy operations where possible
+- **SIMD optimized** for modern processors
+
+## Architecture
+
+### Rust Crate Structure
+```
+torchsig_fft/
+├── Cargo.toml
+├── src/
+│   ├── lib.rs              # Main library interface
+│   ├── fft.rs              # Core FFT implementations
+│   ├── spectrogram.rs      # Spectrogram computation
+│   ├── windowing.rs        # Window functions (Hann, Hamming, etc.)
+│   └── python_bindings.rs  # PyO3 Python bindings
+└── benches/
+    └── performance.rs      # Performance benchmarks
+```
+
+### Dependencies
+```toml
+[dependencies]
+pyo3 = "0.20"
+numpy = "0.20"
+rustfft = "6.1"      # High-performance FFT
+rayon = "1.7"        # Data parallelism
+num-complex = "0.4"  # Complex number support
+```
+
+### Core API Design
+
+```rust
+use pyo3::prelude::*;
+use numpy::{PyArray2, PyReadonlyArray1};
+
+#[pyclass]
+pub struct RustSpectrogramProcessor {
+    // Pre-allocated FFT planner for different sizes
+    fft_cache: FftCache,
+    // Thread pool for parallel processing
+    thread_pool: rayon::ThreadPool,
+}
+
+#[pymethods]
+impl RustSpectrogramProcessor {
+    #[new]
+    pub fn new(max_fft_size: usize, num_threads: Option<usize>) -> Self {
+        // Initialize with optimized thread count and FFT cache
+    }
+    
+    #[pyo3(signature = (signal, n_fft, hop_length, window_type, normalize=true))]
+    pub fn compute_spectrogram<'py>(
+        &self,
+        py: Python<'py>,
+        signal: PyReadonlyArray1<num_complex::Complex<f32>>,
+        n_fft: usize,
+        hop_length: usize,
+        window_type: &str,
+        normalize: bool,
+    ) -> PyResult<&'py PyArray2<f32>> {
+        // Ultra-fast spectrogram computation with SIMD optimization
+    }
+    
+    pub fn compute_spectrogram_streaming(
+        &self,
+        signal_chunk: PyReadonlyArray1<num_complex::Complex<f32>>,
+        // ... parameters
+    ) -> PyResult<()> {
+        // Real-time streaming spectrogram for continuous processing
+    }
+}
+```
+
+### Key Optimizations
+
+#### 1. FFT Optimization
+```rust
+use rustfft::{FftPlanner, Fft};
+
+struct FftCache {
+    planners: HashMap<usize, Arc<dyn Fft<f32>>>,
+}
+
+impl FftCache {
+    fn get_or_create(&mut self, n_fft: usize) -> Arc<dyn Fft<f32>> {
+        // Cache FFT planners for different sizes
+        // Use SIMD-optimized implementations
+    }
+}
+```
+
+#### 2. Parallel Processing
+```rust
+use rayon::prelude::*;
+
+fn compute_parallel_stft(
+    signal: &[Complex<f32>],
+    n_fft: usize,
+    hop_length: usize,
+    window: &[f32],
+) -> Vec<Vec<Complex<f32>>> {
+    // Parallel computation of STFT frames
+    (0..num_frames)
+        .into_par_iter()
+        .map(|frame_idx| {
+            // Process each frame in parallel
+            compute_fft_frame(signal, frame_idx, n_fft, hop_length, window)
+        })
+        .collect()
+}
+```
+
+#### 3. SIMD Window Functions
+```rust
+use std::arch::x86_64::*;
+
+#[target_feature(enable = "avx2")]
+unsafe fn apply_hann_window_avx2(signal: &mut [f32], window: &[f32]) {
+    // Vectorized window application using AVX2
+    for (signal_chunk, window_chunk) in 
+        signal.chunks_exact_mut(8).zip(window.chunks_exact(8)) {
+        
+        let sig = _mm256_loadu_ps(signal_chunk.as_ptr());
+        let win = _mm256_loadu_ps(window_chunk.as_ptr());
+        let result = _mm256_mul_ps(sig, win);
+        _mm256_storeu_ps(signal_chunk.as_mut_ptr(), result);
+    }
+}
+```
+
+### Python Integration
+
+```python
+# torchsig/utils/rust_fft.py
+from typing import Optional
+import numpy as np
+
+try:
+    from torchsig_fft import RustSpectrogramProcessor
+    RUST_FFT_AVAILABLE = True
+except ImportError:
+    RUST_FFT_AVAILABLE = False
+    RustSpectrogramProcessor = None
+
+class FastSpectrogramProcessor:
+    def __init__(self, use_rust: bool = True, max_fft_size: int = 8192):
+        self.use_rust = use_rust and RUST_FFT_AVAILABLE
+        
+        if self.use_rust:
+            self.rust_processor = RustSpectrogramProcessor(
+                max_fft_size=max_fft_size,
+                num_threads=None  # Auto-detect optimal thread count
+            )
+    
+    def compute_spectrogram(
+        self,
+        signal: np.ndarray,
+        n_fft: int,
+        hop_length: int,
+        window: str = 'hann',
+        normalize: bool = True
+    ) -> np.ndarray:
+        
+        if self.use_rust:
+            # Ultra-fast Rust implementation
+            return self.rust_processor.compute_spectrogram(
+                signal, n_fft, hop_length, window, normalize
+            )
+        else:
+            # Fallback to PyTorch/SciPy
+            return self._fallback_spectrogram(signal, n_fft, hop_length, window)
+```
+
+### Integration with Real-time Service
+
+```python
+# In services/realtime_spectrogram.py
+from torchsig.utils.rust_fft import FastSpectrogramProcessor
+
+class RealtimeSpectrogramService:
+    def __init__(self):
+        # Try to use Rust FFT for maximum performance
+        self.spectrogram_processor = FastSpectrogramProcessor(use_rust=True)
+        # ... rest of initialization
+    
+    def compute_spectrogram_fast(self, iq_data: np.ndarray, params: SpectrogramParams):
+        # Use Rust implementation if available, fallback to Python
+        return self.spectrogram_processor.compute_spectrogram(
+            iq_data, params.n_fft, params.hop_length, params.window
+        )
+```
+
+## Performance Expectations
+
+### Benchmarks (Estimated)
+| Implementation | Signal Length | FFT Size | Computation Time |
+|---------------|---------------|----------|------------------|
+| Current Scipy | 1M samples    | 1024     | ~50ms           |
+| Current PyTorch| 1M samples    | 1024     | ~15ms (GPU)     |
+| **Rust + SIMD** | 1M samples  | 1024     | **~2ms**        |
+| **Rust Parallel**| 1M samples  | 1024     | **~0.5ms**      |
+
+### Memory Usage
+- **Zero-copy** where possible using PyO3
+- **In-place** FFT computations
+- **Optimized allocation** patterns
+
+## Implementation Priority
+
+**Phase 1 (Optional Enhancement)**
+- Basic Rust FFT implementation with PyO3 bindings
+- Integration with existing Python service
+- Performance benchmarking
+
+**Phase 2 (Future)**  
+- SIMD optimizations for specific architectures
+- Streaming/real-time processing capabilities
+- Multi-GPU support for batch processing
+
+## Build Integration
+
+```toml
+# Add to pyproject.toml for optional Rust acceleration
+[tool.setuptools.packages.find]
+exclude = ["torchsig_fft*"]  # Exclude Rust crate from Python package
+
+[build-system]
+requires = ["setuptools", "wheel", "setuptools-rust"]
+build-backend = "setuptools.build_meta"
+
+[[tool.setuptools-rust.ext-modules]]
+target = "torchsig.utils._rust_fft"
+path = "torchsig_fft/Cargo.toml"
+binding = "PyO3"
+```
+
+This design provides a path for ultra-high performance when needed, while maintaining compatibility with the current Python-based system.
\ No newline at end of file
diff --git a/docs/signals.rst b/docs/signals.rst
index c03259527..bdb6b4ebc 100644
--- a/docs/signals.rst
+++ b/docs/signals.rst
@@ -1,8 +1,7 @@
 Signals
 ======================
 
-Synthetic signal creation tools and builders used by both :class:`torchsig.datasets.wideband.NewWideband` 
-and :class:`torchsig.datasets.narrowband.NewNarrowband` for dataset creation.
+Synthetic signal creation tools and builders used by :class:`torchsig.datasets.datasets.TorchSigIterableDataset` for dataset creation.
 
 .. contents:: Signals
     :local:
diff --git a/docs/target_transforms.rst b/docs/target_transforms.rst
index 209b5370e..1d8ad3485 100644
--- a/docs/target_transforms.rst
+++ b/docs/target_transforms.rst
@@ -1,15 +1,15 @@
-Target Transforms
+Metadata Transforms
 ======================
 
-.. currentmodule:: torchsig.transforms.target_transforms
+.. currentmodule:: torchsig.transforms.metadata_transforms
 
-Target Transforms are used to alter the output of the datasets which can be certain labels, class names, or bounding box information.
+Metadata Transforms are used to alter the output of the datasets which can be certain labels, class names, or bounding box information.
 They only read and add the signal metadata, and do not change the signal data.
 
-.. contents:: Target Transforms
+.. contents:: Metadata Transforms
     :local:
 
-.. automodule:: torchsig.transforms.target_transforms
+.. automodule:: torchsig.transforms.metadata_transforms
     :members:
     :undoc-members:
     :show-inheritance:
\ No newline at end of file
diff --git a/docs/transforms.rst b/docs/transforms.rst
index 99de1fabc..77ab30de7 100644
--- a/docs/transforms.rst
+++ b/docs/transforms.rst
@@ -6,10 +6,9 @@ Transforms
 Transforms are applied to signals or samples to emulate transmitter and reciever effects, as well as tools for machine learning.
 There are four types of transforms, that differ in purpose and scope.
 
-1. :class:`torchsig.transforms.signal_transforms.SignalTransform` - applied to isolated signals from the signal builder, and typically represent transmitter effects.
-2. :class:`torchsig.transforms.dataset_transforms.DatasetTransform` - applied to samples, after isolated signals are placed onto a noise floor. Typically represents reciever effects and other machine learning transforms.
-3. Functionals - core logic of both Signal Transforms and Dataset Transforms. Users can use for more fine-grained control of the transform.
-4. :class:`torchsig.transforms.impairments.DatasetImpairments` - a collection of Signal Transforms and Dastaset Transforms that represent an environment, such as wireless.
+1. :class:`torchsig.transforms.transforms.Transform` - may be applied to isolated signals from the signal builder (typically representing transmitter effects), or may be applied to samples, after isolated signals are placed onto a noise floor *typically represents receiver effects and other machine learning transforms).
+3. Functionals - core logic of Transforms. Users can use for more fine-grained control of the transform.
+4. :class:`torchsig.transforms.impairments.Impairments` - special collections of Transforms that represent an environment.
 
 .. contents:: Transforms
     :local:
@@ -26,14 +25,7 @@ Base Transforms
 
 Signal Transforms
 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-.. automodule:: torchsig.transforms.signal_transforms
-    :members:
-    :undoc-members:
-    :show-inheritance:
-
-Dataset Transforms
-~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-.. automodule:: torchsig.transforms.dataset_transforms
+.. automodule:: torchsig.transforms.transforms
     :members:
     :undoc-members:
     :show-inheritance:
@@ -49,20 +41,6 @@ Base Impairments
     :undoc-members:
     :show-inheritance:
 
-Narrowband Impairments
-~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-.. automodule:: torchsig.transforms.impairments_narrowband
-    :members:
-    :undoc-members:
-    :show-inheritance:
-
-Wideband Impairments
-~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-.. automodule:: torchsig.transforms.impairments_wideband
-    :members:
-    :undoc-members:
-    :show-inheritance:
-
 
 Functional Transforms
 ----------------------
diff --git a/docs/utils.rst b/docs/utils.rst
index c831b3d9d..0905990bc 100644
--- a/docs/utils.rst
+++ b/docs/utils.rst
@@ -17,10 +17,9 @@ Digital Signal Processing Utils
     :show-inheritance:
 
 
-Dataset Utils
+Data Coordinate System
 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-.. automodule:: torchsig.utils.generate
+.. automodule:: torchsig.utils.coordinate_system
     :members:
     :undoc-members:
     :show-inheritance:
@@ -36,6 +35,13 @@ Writer
     :undoc-members:
     :show-inheritance:
 
+Data Loading
+-------------------------------------
+.. automodule:: torchsig.utils.data_loading
+    :members:
+    :undoc-members:
+    :show-inheritance:
+
 YAML Utils
 -------------------------------------
 .. automodule:: torchsig.utils.yaml
@@ -50,7 +56,7 @@ File Handlers
     :undoc-members:
     :show-inheritance:
 
-.. automodule:: torchsig.utils.file_handlers.zarr
+.. automodule:: torchsig.utils.file_handlers.hdf5
     :members:
     :undoc-members:
     :show-inheritance:
diff --git a/docs/workflow.svg b/docs/workflow.svg
deleted file mode 100644
index 6152ed9e3..000000000
--- a/docs/workflow.svg
+++ /dev/null
@@ -1,58 +0,0 @@
-<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" width="831px" height="898px" viewBox="-0.5 -0.5 831 898" content="&lt;mxfile&gt;&lt;diagram id=&quot;laA0arsnX7Pyb7320zwb&quot; name=&quot;Page-1&quot;&gt;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&lt;/diagram&gt;&lt;/mxfile&gt;" style="background-color: rgb(255, 255, 255);"><defs><style type="text/css">/* cyrillic-ext */
-@font-face {
-  font-family: 'Source Code Pro';
-  font-style: normal;
-  font-weight: 400;
-  src: url("data:application/font-woff2;charset=utf-8;base64,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") format('woff2');
-  unicode-range: U+0460-052F, U+1C80-1C8A, U+20B4, U+2DE0-2DFF, U+A640-A69F, U+FE2E-FE2F;
-}
-/* cyrillic */
-@font-face {
-  font-family: 'Source Code Pro';
-  font-style: normal;
-  font-weight: 400;
-  src: url("data:application/font-woff2;charset=utf-8;base64,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") format('woff2');
-  unicode-range: U+0301, U+0400-045F, U+0490-0491, U+04B0-04B1, U+2116;
-}
-/* greek-ext */
-@font-face {
-  font-family: 'Source Code Pro';
-  font-style: normal;
-  font-weight: 400;
-  src: url("data:application/font-woff2;charset=utf-8;base64,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") format('woff2');
-  unicode-range: U+1F00-1FFF;
-}
-/* greek */
-@font-face {
-  font-family: 'Source Code Pro';
-  font-style: normal;
-  font-weight: 400;
-  src: url("data:application/font-woff2;charset=utf-8;base64,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") format('woff2');
-  unicode-range: U+0370-0377, U+037A-037F, U+0384-038A, U+038C, U+038E-03A1, U+03A3-03FF;
-}
-/* vietnamese */
-@font-face {
-  font-family: 'Source Code Pro';
-  font-style: normal;
-  font-weight: 400;
-  src: url("data:application/font-woff2;charset=utf-8;base64,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") format('woff2');
-  unicode-range: U+0102-0103, U+0110-0111, U+0128-0129, U+0168-0169, U+01A0-01A1, U+01AF-01B0, U+0300-0301, U+0303-0304, U+0308-0309, U+0323, U+0329, U+1EA0-1EF9, U+20AB;
-}
-/* latin-ext */
-@font-face {
-  font-family: 'Source Code Pro';
-  font-style: normal;
-  font-weight: 400;
-  src: url("data:application/font-woff2;charset=utf-8;base64,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") format('woff2');
-  unicode-range: U+0100-02BA, U+02BD-02C5, U+02C7-02CC, U+02CE-02D7, U+02DD-02FF, U+0304, U+0308, U+0329, U+1D00-1DBF, U+1E00-1E9F, U+1EF2-1EFF, U+2020, U+20A0-20AB, U+20AD-20C0, U+2113, U+2C60-2C7F, U+A720-A7FF;
-}
-/* latin */
-@font-face {
-  font-family: 'Source Code Pro';
-  font-style: normal;
-  font-weight: 400;
-  src: url("data:application/font-woff2;charset=utf-8;base64,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") format('woff2');
-  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+0304, U+0308, U+0329, U+2000-206F, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
-}
-
-</style></defs><g><rect x="30" y="100" width="770" height="350" fill="rgb(255, 255, 255)" stroke="rgb(0, 0, 0)" pointer-events="all"/><g transform="translate(-0.5 -0.5)"><switch><foreignObject pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility" style="overflow: visible; text-align: left;"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe flex-end; justify-content: unsafe center; width: 768px; height: 1px; padding-top: 97px; margin-left: 31px;"><div data-drawio-colors="color: rgb(0, 0, 0); " style="box-sizing: border-box; font-size: 0px; text-align: center;"><div style="display: inline-block; font-size: 36px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; pointer-events: all; white-space: normal; overflow-wrap: normal;"><p style="line-height: 100%; font-size: 12px;"><font face="Source Code Pro" data-font-src="https://fonts.googleapis.com/css?family=Source+Code+Pro">self.__generate_new_signal__()</font></p></div></div></div></foreignObject><text x="415" y="97" fill="rgb(0, 0, 0)" font-family="Helvetica" font-size="36px" text-anchor="middle">self.__generate_new_signal__()</text></switch></g><rect x="10" y="0" width="820" height="60" fill="none" stroke="none" pointer-events="all"/><g transform="translate(-0.5 -0.5)"><switch><foreignObject pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility" style="overflow: visible; text-align: left;"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 818px; height: 1px; padding-top: 30px; margin-left: 11px;"><div data-drawio-colors="color: rgb(0, 0, 0); " style="box-sizing: border-box; font-size: 0px; text-align: center;"><div style="display: inline-block; font-size: 36px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; pointer-events: all; white-space: normal; overflow-wrap: normal;">__getitem__ Workflow</div></div></div></foreignObject><text x="420" y="41" fill="rgb(0, 0, 0)" font-family="Helvetica" font-size="36px" text-anchor="middle">__getitem__ Workflow</text></switch></g><path d="M 351.25 840 L 394.25 840" fill="none" stroke="rgb(0, 0, 0)" stroke-miterlimit="10" pointer-events="stroke"/><path d="M 399.5 840 L 392.5 843.5 L 394.25 840 L 392.5 836.5 Z" fill="rgb(0, 0, 0)" stroke="rgb(0, 0, 0)" stroke-miterlimit="10" pointer-events="all"/><rect x="0" y="800" width="351.25" height="80" fill="rgb(255, 255, 255)" stroke="rgb(0, 0, 0)" pointer-events="all"/><g transform="translate(-0.5 -0.5)"><switch><foreignObject pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility" style="overflow: visible; text-align: left;"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 349px; height: 1px; padding-top: 840px; margin-left: 1px;"><div data-drawio-colors="color: rgb(0, 0, 0); " style="box-sizing: border-box; font-size: 0px; text-align: center;"><div style="display: inline-block; font-size: 36px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; pointer-events: all; white-space: normal; overflow-wrap: normal;"><p style="line-height: 100%; font-size: 12px;">Target Transforms: produce labels requested from user</p><p style="line-height: 100%; font-size: 12px;"><span style="font-size: 10px; background-color: initial; font-family: &quot;Source Code Pro&quot;;">targets = self.dataset_metadata.target_transforms(sample)</span></p><p style="line-height: 100%;"></p><p style="line-height: 100%;"></p></div></div></div></foreignObject><text x="176" y="851" fill="rgb(0, 0, 0)" font-family="Helvetica" font-size="36px" text-anchor="middle">Target Transforms: p...</text></switch></g><path d="M 722.63 230.9 L 722.51 293.63" fill="none" stroke="rgb(0, 0, 0)" stroke-miterlimit="10" pointer-events="stroke"/><path d="M 722.5 298.88 L 719.02 291.88 L 722.51 293.63 L 726.02 291.89 Z" fill="rgb(0, 0, 0)" stroke="rgb(0, 0, 0)" stroke-miterlimit="10" pointer-events="all"/><g transform="translate(-0.5 -0.5)"><switch><foreignObject pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility" style="overflow: visible; text-align: left;"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 1px; height: 1px; padding-top: 259px; margin-left: 721px;"><div data-drawio-colors="color: rgb(0, 0, 0); background-color: rgb(255, 255, 255); " style="box-sizing: border-box; font-size: 0px; text-align: center;"><div style="display: inline-block; font-size: 9px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; pointer-events: all; background-color: rgb(255, 255, 255); white-space: nowrap;">apply</div></div></div></foreignObject><text x="721" y="262" fill="rgb(0, 0, 0)" font-family="Helvetica" font-size="9px" text-anchor="middle">apply</text></switch></g><path d="M 650 180 L 650 150 L 785 150 L 785 180" fill="rgb(255, 255, 255)" stroke="rgb(0, 0, 0)" stroke-miterlimit="10" pointer-events="all"/><path d="M 650 180 L 650 230 L 785 230 L 785 180" fill="none" stroke="rgb(0, 0, 0)" stroke-miterlimit="10" pointer-events="none"/><path d="M 650 180 L 785 180" fill="none" stroke="rgb(0, 0, 0)" stroke-miterlimit="10" pointer-events="none"/><g transform="translate(-0.5 -0.5)"><switch><foreignObject pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility" style="overflow: visible; text-align: left;"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 133px; height: 1px; padding-top: 165px; margin-left: 651px;"><div data-drawio-colors="color: rgb(0, 0, 0); " style="box-sizing: border-box; font-size: 0px; text-align: center;"><div style="display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; pointer-events: none; white-space: normal; overflow-wrap: normal;">Signal</div></div></div></foreignObject><text x="718" y="169" fill="rgb(0, 0, 0)" font-family="Helvetica" font-size="12px" text-anchor="middle">Signal</text></switch></g><g transform="translate(-0.5 -0.5)"><switch><foreignObject pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility" style="overflow: visible; text-align: left;"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe flex-start; width: 125px; height: 1px; padding-top: 205px; margin-left: 656px;"><div data-drawio-colors="color: rgb(0, 0, 0); " style="box-sizing: border-box; font-size: 0px; text-align: left; max-height: 46px; overflow: hidden;"><div style="display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; pointer-events: none; white-space: normal; overflow-wrap: normal;">data: np.ndarray<br />metadata: SignalMetadata</div></div></div></foreignObject><text x="656" y="209" fill="rgb(0, 0, 0)" font-family="Helvetica" font-size="12px">data: np.ndarray...</text></switch></g><rect x="400.62" y="800" width="220" height="80" fill="rgb(255, 255, 255)" stroke="rgb(0, 0, 0)" pointer-events="none"/><g transform="translate(-0.5 -0.5)"><switch><foreignObject pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility" style="overflow: visible; text-align: left;"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 218px; height: 1px; padding-top: 840px; margin-left: 402px;"><div data-drawio-colors="color: rgb(0, 0, 0); " style="box-sizing: border-box; font-size: 0px; text-align: center;"><div style="display: inline-block; font-size: 36px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; pointer-events: none; white-space: normal; overflow-wrap: normal;"><p style="line-height: 100%;"><span style="font-size: 12px;"><font face="Source Code Pro" data-font-src="https://fonts.googleapis.com/css?family=Source+Code+Pro">return sample.data, targets</font></span></p></div></div></div></foreignObject><text x="511" y="851" fill="rgb(0, 0, 0)" font-family="Helvetica" font-size="36px" text-anchor="middle">return sampl...</text></switch></g><path d="M 175.62 730.85 L 175.62 793.63" fill="none" stroke="rgb(0, 0, 0)" stroke-miterlimit="10" pointer-events="none"/><path d="M 175.62 798.88 L 172.12 791.88 L 175.62 793.63 L 179.12 791.88 Z" fill="rgb(0, 0, 0)" stroke="rgb(0, 0, 0)" stroke-miterlimit="10" pointer-events="none"/><g transform="translate(-0.5 -0.5)"><switch><foreignObject pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility" style="overflow: visible; text-align: left;"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 1px; height: 1px; padding-top: 751px; margin-left: 176px;"><div data-drawio-colors="color: rgb(0, 0, 0); background-color: rgb(255, 255, 255); " style="box-sizing: border-box; font-size: 0px; text-align: center;"><div style="display: inline-block; font-size: 9px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; pointer-events: none; background-color: rgb(255, 255, 255); white-space: nowrap;">apply</div></div></div></foreignObject><text x="176" y="754" fill="rgb(0, 0, 0)" font-family="Helvetica" font-size="9px" text-anchor="middle">apply</text></switch></g><path d="M 85.62 680 L 85.62 650 L 265.62 650 L 265.62 680" fill="rgb(255, 255, 255)" stroke="rgb(0, 0, 0)" stroke-miterlimit="10" pointer-events="none"/><path d="M 85.62 680 L 85.62 730 L 265.62 730 L 265.62 680" fill="none" stroke="rgb(0, 0, 0)" stroke-miterlimit="10" pointer-events="none"/><path d="M 85.62 680 L 265.62 680" fill="none" stroke="rgb(0, 0, 0)" stroke-miterlimit="10" pointer-events="none"/><g transform="translate(-0.5 -0.5)"><switch><foreignObject pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility" style="overflow: visible; text-align: left;"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 178px; height: 1px; padding-top: 665px; margin-left: 87px;"><div data-drawio-colors="color: rgb(0, 0, 0); " style="box-sizing: border-box; font-size: 0px; text-align: center;"><div style="display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; pointer-events: none; white-space: normal; overflow-wrap: normal;">DatasetDict</div></div></div></foreignObject><text x="176" y="669" fill="rgb(0, 0, 0)" font-family="Helvetica" font-size="12px" text-anchor="middle">DatasetDict</text></switch></g><g transform="translate(-0.5 -0.5)"><switch><foreignObject pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility" style="overflow: visible; text-align: left;"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe flex-start; width: 170px; height: 1px; padding-top: 705px; margin-left: 92px;"><div data-drawio-colors="color: rgb(0, 0, 0); " style="box-sizing: border-box; font-size: 0px; text-align: left; max-height: 46px; overflow: hidden;"><div style="display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; pointer-events: none; white-space: normal; overflow-wrap: normal;">data: np.ndarray<br />metadata: [dict]</div></div></div></foreignObject><text x="92" y="709" fill="rgb(0, 0, 0)" font-family="Helvetica" font-size="12px">data: np.ndarray...</text></switch></g><path d="M 175 390 L 175.58 493.63" fill="none" stroke="rgb(0, 0, 0)" stroke-miterlimit="10" pointer-events="none"/><path d="M 175.61 498.88 L 172.07 491.9 L 175.58 493.63 L 179.07 491.86 Z" fill="rgb(0, 0, 0)" stroke="rgb(0, 0, 0)" stroke-miterlimit="10" pointer-events="none"/><g transform="translate(-0.5 -0.5)"><switch><foreignObject pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility" style="overflow: visible; text-align: left;"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 1px; height: 1px; padding-top: 433px; margin-left: 178px;"><div data-drawio-colors="color: rgb(0, 0, 0); background-color: rgb(255, 255, 255); " style="box-sizing: border-box; font-size: 0px; text-align: center;"><div style="display: inline-block; font-size: 9px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; pointer-events: none; background-color: rgb(255, 255, 255); white-space: nowrap;">create</div></div></div></foreignObject><text x="178" y="436" fill="rgb(0, 0, 0)" font-family="Helvetica" font-size="9px" text-anchor="middle">create</text></switch></g><path d="M 535 345 L 306.37 345" fill="none" stroke="rgb(0, 0, 0)" stroke-miterlimit="10" pointer-events="none"/><path d="M 301.12 345 L 308.12 341.5 L 306.37 345 L 308.12 348.5 Z" fill="rgb(0, 0, 0)" stroke="rgb(0, 0, 0)" stroke-miterlimit="10" pointer-events="none"/><rect x="535" y="300" width="250" height="90" fill="rgb(255, 255, 255)" stroke="rgb(0, 0, 0)" pointer-events="none"/><g transform="translate(-0.5 -0.5)"><switch><foreignObject pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility" style="overflow: visible; text-align: left;"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 248px; height: 1px; padding-top: 345px; margin-left: 536px;"><div data-drawio-colors="color: rgb(0, 0, 0); " style="box-sizing: border-box; font-size: 0px; text-align: center;"><div style="display: inline-block; font-size: 36px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; pointer-events: none; white-space: normal; overflow-wrap: normal;"><p style="line-height: 100%; font-size: 12px;">Signal Transforms: applied to isolated signals</p><p style="line-height: 100%; font-size: 12px;"></p><p style="line-height: 100%; font-size: 12px;"><span style="background-color: initial; font-family: &quot;Source Code Pro&quot;; font-size: 10px;">new_signal = self.impairments(new_signal)</span></p><p style="line-height: 100%;"></p><p style="line-height: 100%;"></p></div></div></div></foreignObject><text x="660" y="356" fill="rgb(0, 0, 0)" font-family="Helvetica" font-size="36px" text-anchor="middle">Signal Transfo...</text></switch></g><path d="M 331.87 690 L 272.71 689.73" fill="none" stroke="rgb(0, 0, 0)" stroke-miterlimit="10" pointer-events="none"/><path d="M 267.46 689.71 L 274.47 686.24 L 272.71 689.73 L 274.44 693.24 Z" fill="rgb(0, 0, 0)" stroke="rgb(0, 0, 0)" stroke-miterlimit="10" pointer-events="none"/><g transform="translate(-0.5 -0.5)"><switch><foreignObject pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility" style="overflow: visible; text-align: left;"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 1px; height: 1px; padding-top: 689px; margin-left: 309px;"><div data-drawio-colors="color: rgb(0, 0, 0); background-color: rgb(255, 255, 255); " style="box-sizing: border-box; font-size: 0px; text-align: center;"><div style="display: inline-block; font-size: 9px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; pointer-events: none; background-color: rgb(255, 255, 255); white-space: nowrap;">convert to</div></div></div></foreignObject><text x="309" y="692" fill="rgb(0, 0, 0)" font-family="Helvetica" font-size="9px" text-anchor="middle">convert to</text></switch></g><rect x="331.87" y="650" width="307.5" height="80" fill="rgb(255, 255, 255)" stroke="rgb(0, 0, 0)" pointer-events="none"/><g transform="translate(-0.5 -0.5)"><switch><foreignObject pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility" style="overflow: visible; text-align: left;"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 306px; height: 1px; padding-top: 690px; margin-left: 333px;"><div data-drawio-colors="color: rgb(0, 0, 0); " style="box-sizing: border-box; font-size: 0px; text-align: center;"><div style="display: inline-block; font-size: 36px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; pointer-events: none; white-space: normal; overflow-wrap: normal;"><p style="line-height: 100%; font-size: 12px;">User Transforms: defined by user, applied to whole IQ cut, includes ML transforms</p><p style="line-height: 100%; font-size: 12px;"><span style="font-size: 10px; font-family: &quot;Source Code Pro&quot;; background-color: initial;">sample = self.dataset_metadata.transforms(sample)</span></p><p style="line-height: 100%;"></p></div></div></div></foreignObject><text x="486" y="701" fill="rgb(0, 0, 0)" font-family="Helvetica" font-size="36px" text-anchor="middle">User Transforms:...</text></switch></g><path d="M 265.44 539.45 L 334.25 539.95" fill="none" stroke="rgb(0, 0, 0)" stroke-miterlimit="10" pointer-events="none"/><path d="M 339.5 539.99 L 332.48 543.44 L 334.25 539.95 L 332.53 536.44 Z" fill="rgb(0, 0, 0)" stroke="rgb(0, 0, 0)" stroke-miterlimit="10" pointer-events="none"/><g transform="translate(-0.5 -0.5)"><switch><foreignObject pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility" style="overflow: visible; text-align: left;"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 1px; height: 1px; padding-top: 540px; margin-left: 292px;"><div data-drawio-colors="color: rgb(0, 0, 0); background-color: rgb(255, 255, 255); " style="box-sizing: border-box; font-size: 0px; text-align: center;"><div style="display: inline-block; font-size: 9px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; pointer-events: none; background-color: rgb(255, 255, 255); white-space: nowrap;">apply</div></div></div></foreignObject><text x="292" y="543" fill="rgb(0, 0, 0)" font-family="Helvetica" font-size="9px" text-anchor="middle">apply</text></switch></g><path d="M 85.62 530 L 85.62 500 L 265.62 500 L 265.62 530" fill="rgb(255, 255, 255)" stroke="rgb(0, 0, 0)" stroke-miterlimit="10" pointer-events="none"/><path d="M 85.62 530 L 85.62 580 L 265.62 580 L 265.62 530" fill="none" stroke="rgb(0, 0, 0)" stroke-miterlimit="10" pointer-events="none"/><path d="M 85.62 530 L 265.62 530" fill="none" stroke="rgb(0, 0, 0)" stroke-miterlimit="10" pointer-events="none"/><g transform="translate(-0.5 -0.5)"><switch><foreignObject pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility" style="overflow: visible; text-align: left;"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 178px; height: 1px; padding-top: 515px; margin-left: 87px;"><div data-drawio-colors="color: rgb(0, 0, 0); " style="box-sizing: border-box; font-size: 0px; text-align: center;"><div style="display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; pointer-events: none; white-space: normal; overflow-wrap: normal;">DatasetSignal</div></div></div></foreignObject><text x="176" y="519" fill="rgb(0, 0, 0)" font-family="Helvetica" font-size="12px" text-anchor="middle">DatasetSignal</text></switch></g><g transform="translate(-0.5 -0.5)"><switch><foreignObject pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility" style="overflow: visible; text-align: left;"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe flex-start; width: 170px; height: 1px; padding-top: 555px; margin-left: 92px;"><div data-drawio-colors="color: rgb(0, 0, 0); " style="box-sizing: border-box; font-size: 0px; text-align: left; max-height: 46px; overflow: hidden;"><div style="display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; pointer-events: none; white-space: normal; overflow-wrap: normal;">data: np.ndarray<br />metadata: [SignalMetadata]</div></div></div></foreignObject><text x="92" y="559" fill="rgb(0, 0, 0)" font-family="Helvetica" font-size="12px">data: np.ndarray...</text></switch></g><path d="M 590 179.16 L 643.77 178.75" fill="none" stroke="rgb(0, 0, 0)" stroke-miterlimit="10" pointer-events="none"/><path d="M 649.02 178.71 L 642.04 182.26 L 643.77 178.75 L 641.99 175.26 Z" fill="rgb(0, 0, 0)" stroke="rgb(0, 0, 0)" stroke-miterlimit="10" pointer-events="none"/><g transform="translate(-0.5 -0.5)"><switch><foreignObject pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility" style="overflow: visible; text-align: left;"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 1px; height: 1px; padding-top: 177px; margin-left: 613px;"><div data-drawio-colors="color: rgb(0, 0, 0); background-color: rgb(255, 255, 255); " style="box-sizing: border-box; font-size: 0px; text-align: center;"><div style="display: inline-block; font-size: 9px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; pointer-events: none; background-color: rgb(255, 255, 255); white-space: nowrap;">returns</div></div></div></foreignObject><text x="613" y="180" fill="rgb(0, 0, 0)" font-family="Helvetica" font-size="9px" text-anchor="middle">returns</text></switch></g><path d="M 370 155 L 370 125 L 590 125 L 590 155" fill="rgb(255, 255, 255)" stroke="rgb(0, 0, 0)" stroke-miterlimit="10" pointer-events="none"/><path d="M 370 155 L 370 235 L 590 235 L 590 155" fill="none" stroke="rgb(0, 0, 0)" stroke-miterlimit="10" pointer-events="none"/><path d="M 370 155 L 590 155" fill="none" stroke="rgb(0, 0, 0)" stroke-miterlimit="10" pointer-events="none"/><g transform="translate(-0.5 -0.5)"><switch><foreignObject pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility" style="overflow: visible; text-align: left;"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 218px; height: 1px; padding-top: 140px; margin-left: 371px;"><div data-drawio-colors="color: rgb(0, 0, 0); " style="box-sizing: border-box; font-size: 0px; text-align: center;"><div style="display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; pointer-events: none; white-space: normal; overflow-wrap: normal;">SignalBuilder</div></div></div></foreignObject><text x="480" y="144" fill="rgb(0, 0, 0)" font-family="Helvetica" font-size="12px" text-anchor="middle">SignalBuilder</text></switch></g><g transform="translate(-0.5 -0.5)"><switch><foreignObject pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility" style="overflow: visible; text-align: left;"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe flex-start; width: 210px; height: 1px; padding-top: 195px; margin-left: 376px;"><div data-drawio-colors="color: rgb(0, 0, 0); " style="box-sizing: border-box; font-size: 0px; text-align: left; max-height: 76px; overflow: hidden;"><div style="display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; pointer-events: none; white-space: normal; overflow-wrap: normal;">1) Modulator -&gt; clean basebanded signal<br />2) apply signal impairments (that belong here)<br /><br /><font face="Source Code Pro" data-font-src="https://fonts.googleapis.com/css?family=Source+Code+Pro" style="font-size: 10px;">builder.build()</font></div></div></div></foreignObject><text x="376" y="199" fill="rgb(0, 0, 0)" font-family="Helvetica" font-size="12px">1) Modulator -&gt; clean basebanded si...</text></switch></g><path d="M 310 180 L 363.63 180" fill="none" stroke="rgb(0, 0, 0)" stroke-miterlimit="10" pointer-events="none"/><path d="M 368.88 180 L 361.88 183.5 L 363.63 180 L 361.88 176.5 Z" fill="rgb(0, 0, 0)" stroke="rgb(0, 0, 0)" stroke-miterlimit="10" pointer-events="none"/><g transform="translate(-0.5 -0.5)"><switch><foreignObject pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility" style="overflow: visible; text-align: left;"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 1px; height: 1px; padding-top: 181px; margin-left: 335px;"><div data-drawio-colors="color: rgb(0, 0, 0); background-color: rgb(255, 255, 255); " style="box-sizing: border-box; font-size: 0px; text-align: center;"><div style="display: inline-block; font-size: 9px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; pointer-events: none; background-color: rgb(255, 255, 255); white-space: nowrap;">choose</div></div></div></foreignObject><text x="335" y="183" fill="rgb(0, 0, 0)" font-family="Helvetica" font-size="9px" text-anchor="middle">choose</text></switch></g><rect x="40" y="117.5" width="270" height="125" fill="rgb(255, 255, 255)" stroke="rgb(0, 0, 0)" pointer-events="none"/><g transform="translate(-0.5 -0.5)"><switch><foreignObject pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility" style="overflow: visible; text-align: left;"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 268px; height: 1px; padding-top: 180px; margin-left: 41px;"><div data-drawio-colors="color: rgb(0, 0, 0); " style="box-sizing: border-box; font-size: 0px; text-align: center;"><div style="display: inline-block; font-size: 36px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; pointer-events: none; white-space: normal; overflow-wrap: normal;"><p style="line-height: 100%; font-size: 12px;">Choose random signal to generate</p><p style="line-height: 100%; font-size: 12px;">(user can define signal distribution/number of signals for wideband)</p><p style="line-height: 100%; font-size: 12px;"><span style="font-size: 10px; font-family: &quot;Source Code Pro&quot;; background-color: initial;">class_name = self._random_signal_class()</span></p><p style="line-height: 100%; font-size: 12px;"><span style="font-size: 10px; font-family: &quot;Source Code Pro&quot;; background-color: initial;">builder = self.builders[class_name]</span></p><p style="line-height: 100%;"></p><p style="line-height: 100%;"></p><p style="line-height: 100%; font-size: 12px;"></p><p style="line-height: 100%;"></p></div></div></div></foreignObject><text x="175" y="191" fill="rgb(0, 0, 0)" font-family="Helvetica" font-size="36px" text-anchor="middle">Choose random s...</text></switch></g><rect x="50" y="300" width="250" height="90" fill="rgb(255, 255, 255)" stroke="rgb(0, 0, 0)" pointer-events="none"/><g transform="translate(-0.5 -0.5)"><switch><foreignObject pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility" style="overflow: visible; text-align: left;"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 248px; height: 1px; padding-top: 345px; margin-left: 51px;"><div data-drawio-colors="color: rgb(0, 0, 0); " style="box-sizing: border-box; font-size: 0px; text-align: center;"><div style="display: inline-block; font-size: 36px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; pointer-events: none; white-space: normal; overflow-wrap: normal;"><p style="line-height: 100%; font-size: 12px;">place on narrowband/wideband cut</p><p style="line-height: 100%; font-size: 12px;"><span style="font-size: 10px; background-color: initial; font-family: &quot;Source Code Pro&quot;;">iq_samples[start:stop] += new_signal.data</span></p><p style="line-height: 100%;"></p><p style="line-height: 100%;"></p></div></div></div></foreignObject><text x="175" y="356" fill="rgb(0, 0, 0)" font-family="Helvetica" font-size="36px" text-anchor="middle">place on narro...</text></switch></g><rect x="340.62" y="500" width="290" height="80" fill="rgb(255, 255, 255)" stroke="rgb(0, 0, 0)" pointer-events="none"/><g transform="translate(-0.5 -0.5)"><switch><foreignObject pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility" style="overflow: visible; text-align: left;"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 288px; height: 1px; padding-top: 540px; margin-left: 342px;"><div data-drawio-colors="color: rgb(0, 0, 0); " style="box-sizing: border-box; font-size: 0px; text-align: center;"><div style="display: inline-block; font-size: 36px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; pointer-events: none; white-space: normal; overflow-wrap: normal;"><p style="line-height: 100%; font-size: 12px;">Dataset Transforms: applied to whole IQ cut</p><p style="line-height: 100%; font-size: 12px;"><span style="font-size: 10px; font-family: &quot;Source Code Pro&quot;; background-color: initial;">sample = self.impairment_transforms(sample)</span></p><p style="line-height: 100%;"></p><p style="line-height: 100%;"></p></div></div></div></foreignObject><text x="486" y="551" fill="rgb(0, 0, 0)" font-family="Helvetica" font-size="36px" text-anchor="middle">Dataset Transfor...</text></switch></g><path d="M 485.62 580 L 485.62 643.63" fill="none" stroke="rgb(0, 0, 0)" stroke-miterlimit="10" pointer-events="none"/><path d="M 485.62 648.88 L 482.12 641.88 L 485.62 643.63 L 489.12 641.88 Z" fill="rgb(0, 0, 0)" stroke="rgb(0, 0, 0)" stroke-miterlimit="10" pointer-events="none"/><g transform="translate(-0.5 -0.5)"><switch><foreignObject pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility" style="overflow: visible; text-align: left;"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 1px; height: 1px; padding-top: 605px; margin-left: 486px;"><div data-drawio-colors="color: rgb(0, 0, 0); background-color: rgb(255, 255, 255); " style="box-sizing: border-box; font-size: 0px; text-align: center;"><div style="display: inline-block; font-size: 9px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; pointer-events: none; background-color: rgb(255, 255, 255); white-space: nowrap;">apply</div></div></div></foreignObject><text x="486" y="607" fill="rgb(0, 0, 0)" font-family="Helvetica" font-size="9px" text-anchor="middle">apply</text></switch></g></g><switch><g requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"/><a transform="translate(0,-5)" xlink:href="https://www.diagrams.net/doc/faq/svg-export-text-problems" target="_blank"><text text-anchor="middle" font-size="10px" x="50%" y="100%">Text is not SVG - cannot display</text></a></switch></svg>
\ No newline at end of file
diff --git a/examples/README.md b/examples/README.md
index 0ce454c81..c5e21ac14 100644
--- a/examples/README.md
+++ b/examples/README.md
@@ -1,13 +1,21 @@
 # TorchSig Examples
-This folder contains sample Jupyter Notebooks that demonstrate some of the capabilities of TorchSig.
+This folder contains sample Jupyter Notebooks that demonstrate the capabilities of TorchSig 2.0 with unified dataset architecture.
 
 | Notebook | Description  |
 | -------- | -----------  |
 | getting_started.ipynb | TorchSig overview, description, and terms. |
-| narrowband_example.ipynb | Introduction to Narrowband. |
-| narrowband_classifier_example.ipynb | Training a model for modulation recognition on Narrowband. |
-| wideband_example.ipynb | Introduction to Wideband. |
-| wideband_detector_example.ipynb | Training a YOLO model for signal detection on Wideband. |
-| filehandler_example.ipynb | How to create custom file hander, using image writer as example. |
-| reproducibility_example.ipynb | How to create a reproducible dataset and dataloader. |
+| bring_your_own_data_npy_example.ipynb | How to read custom NumPy NPZ files into a TorchSig dataset. |
+| bring_your_own_data_sigmf_example.ipynb | How to read custom SigMF files into a TorchSig dataset. |
+| create_dataset_example.ipynb | Creating and customizing datasets. |
+| classifier_example.ipynb | Training a PyTorch model on IQ Samples for modulation recognition. |
+| defaults_example.ipynb | Demonstrates creating a default dataset and dataloader without any parameterization. |
+| detector_example.ipynb| Training a YOLO model on spectrograms for energy detection using spectrograms. |
+| filehandler_example.ipynb | How to create and use a custom file handler for writing data to disk in a custom format. |
+| reproducibility_example.ipynb | How to create a reproducible dataset and dataloader using random number generator seeding. |
+| yaml_dataset_example.ipynb | Saving and loading datasets using YAML configuration files. |
 | transforms/ | Showcases some advanced transforms and how they work. |
+
+
+
+
+
diff --git a/examples/bring_your_own_data_npy_example.ipynb b/examples/bring_your_own_data_npy_example.ipynb
new file mode 100644
index 000000000..453476279
--- /dev/null
+++ b/examples/bring_your_own_data_npy_example.ipynb
@@ -0,0 +1,381 @@
+{
+ "cells": [
+  {
+   "cell_type": "markdown",
+   "id": "04b0d326",
+   "metadata": {},
+   "source": [
+    "# Importing External Data into TorchSig: Bring Your Own Data (BYOD) NumPy\n",
+    "This notebook shows how to import externally created data into TorchSig using a basic NumPy data plus JSON metadata example file format.\n",
+    "\n",
+    "---\n",
+    "\n",
+    "The main code that the user must write is a subclass of `ExternalFileHandler`, which will be passed into a `ExternalTorchSigDataset`. The `ExternalFileHandler` class must implement 3 methods:\n",
+    "| Method | Arguments | Return | Description |\n",
+    "| ------ | --------- | ------ | ----------- |\n",
+    "| `size` | N/A | int | Number of data samples, dataset size |\n",
+    "| `load_dataset_metadata` | N/A | `ExternalDatasetMetadata` | Dataset information, see `datasets/dataset_metadata.py` for more information. |\n",
+    "| `load` | idx: int | (np.ndarray, List[Any]) | Load sample `idx`, which includes data as np.ndarray and taregts as a list. |\n",
+    "\n",
+    "If you want to apply TorchSig's transforms and impairments to your data, note that `load` must return targets that are in `List[Dict]` format, where each dict describes a signal. Additionally, the dict must have the fields required by each transform, e.g., `FamilyName` target transform requires the signal to have `class_name` in its metadata. It is up to the user to figure out what metadata is needed for what transforms/target transforms they wish to use."
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 1,
+   "id": "06acb66e",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "import numpy as np\n",
+    "import os\n",
+    "import csv\n",
+    "import json\n",
+    "from typing import Tuple, Dict, List, Any\n",
+    "import itertools\n",
+    "import pprint\n",
+    "\n",
+    "# TorchSig\n",
+    "from torchsig.datasets.datasets import ExternalTorchSigDataset\n",
+    "from torchsig.datasets.dataset_metadata import ExternalDatasetMetadata\n",
+    "from torchsig.utils.file_handlers import ExternalFileHandler\n",
+    "from torchsig.transforms.transforms import ComplexTo2D"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "id": "db11e075-256b-4847-add2-f1fbb512f2f0",
+   "metadata": {},
+   "source": [
+    "## Step 1: External Data Generation Process: create synthetic data outside TorchSig workflow\n",
+    "\n",
+    "If your data already exists somewhere, you can skip to Step 2.\n",
+    "\n",
+    "We will write a sample dataset using Numpy's npy for signal data and and csv for metadata. "
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "id": "e8e6981f-7ac9-4635-8849-d5df6d7281f5",
+   "metadata": {},
+   "source": [
+    "### External Synthetic Data and Metadata Generation"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 2,
+   "id": "ae5a6f1f",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "# configuration parameters\n",
+    "root = 'datasets/byod_npy_example'   # data file top-level folder \n",
+    "seed = 1234567890                    # rng seed\n",
+    "\n",
+    "os.makedirs(root, exist_ok=True)     # directory for files"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "id": "98fabf89",
+   "metadata": {},
+   "source": [
+    "Below, we generate some signals (outside of TorchSig)."
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 3,
+   "id": "1be33642-0514-4eae-8552-b7ddc8eb4183",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "# Parameters\n",
+    "fs = 1_000_000                              # 1 MHz sample-rate (fixed rate)\n",
+    "num_samples = 1024                          # samples per data (fixed size)\n",
+    "dataset_size = 8                            # dataset size\n",
+    "labels = ['BPSK', 'QPSK', 'Noise']          # three arbitrary metadata class labels (strings)\n",
+    "modcod = [0, 1, 2]                          # three arbitrary metadata integers\n",
+    "rng = np.random.default_rng(seed)           # random number generator"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 4,
+   "id": "f4801f20-ff14-4265-94b6-78cef460d9f8",
+   "metadata": {},
+   "outputs": [
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Synthetic signals + metadata staged in datasets/byod_npy_example\n"
+     ]
+    }
+   ],
+   "source": [
+    "# Create user's external data: non-TorchSig synthetic data along with metadata\n",
+    "\n",
+    "signals_array = np.empty((dataset_size, num_samples), dtype=np.complex64)  # store all data in memory\n",
+    "meta_rows = []                                           # store all metadata in memory\n",
+    "\n",
+    "t = np.arange(num_samples) / fs  # timesteps\n",
+    "\n",
+    "# create dataset\n",
+    "for idx in range(dataset_size):\n",
+    "    label = rng.choice(labels)\n",
+    "    mc = rng.choice(modcod)\n",
+    "    \n",
+    "    if label == \"BPSK\":\n",
+    "        bits   = rng.integers(0, 2, num_samples)\n",
+    "        sig    = (2*bits-1) + 0j\n",
+    "    elif label == \"QPSK\":\n",
+    "        bits   = rng.integers(0, 4, num_samples)\n",
+    "        table  = {0:1+1j, 1:1-1j, 2:-1+1j, 3:-1-1j}\n",
+    "        sig    = np.vectorize(table.get)(bits)\n",
+    "    else:  # white noise\n",
+    "        sig = (rng.normal(size=num_samples) + 1j*rng.normal(size=num_samples)) * 0.1\n",
+    "    \n",
+    "    sig /= np.sqrt((np.abs(sig)**2).mean()) # normalize power for consistency\n",
+    "    signals_array[idx] = sig.astype(np.complex64)\n",
+    "    \n",
+    "    # add to metadata\n",
+    "    meta_rows.append(\n",
+    "        dict(\n",
+    "            index=idx, \n",
+    "            label=label, \n",
+    "            modcod=mc, \n",
+    "            sample_rate=fs\n",
+    "        )\n",
+    "    )\n",
+    "\n",
+    "# write information about dataset\n",
+    "global_metadata = {\n",
+    "    \"size\": dataset_size,\n",
+    "    \"num_samples\": num_samples,\n",
+    "    \"class_labels\": labels,\n",
+    "    \"sample_rate\": fs\n",
+    "}\n",
+    "with open(f\"{root}/info.json\", 'w') as f:\n",
+    "    json.dump(global_metadata, f, indent=4)\n",
+    "\n",
+    "# write data as npy\n",
+    "np.save(f\"{root}/data.npy\", signals_array)\n",
+    "\n",
+    "# write metadata\n",
+    "with open(f\"{root}/metadata.csv\", 'w', newline='') as f:\n",
+    "    csv.DictWriter(f, fieldnames=meta_rows[0].keys()).writerows(meta_rows)\n",
+    "\n",
+    "print(f\"Synthetic signals + metadata staged in {root}\")"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "id": "8869659d-2933-4d72-8de8-318aeae9db3b",
+   "metadata": {},
+   "source": [
+    "## Step 2. ExternalFileHandler\n",
+    "\n",
+    "To have your data on disk interface with TorchSig, you must write your own `ExternalFileHandler` so TorchSig knows how to handle your data. Make sure to call `super()`.\n",
+    "\n",
+    "Note that the metadata must at least have:\n",
+    "- `class_name`\n",
+    "- `class_index`"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 5,
+   "id": "77031156",
+   "metadata": {},
+   "outputs": [
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Size: 8\n",
+      "Metadata: ExternalDatasetMetadata\n",
+      "Load element 2: (array([ 1.+0.j,  1.+0.j, -1.+0.j, ...,  1.+0.j, -1.+0.j,  1.+0.j],\n",
+      "      dtype=complex64), [{'index': 2, 'label': 'BPSK', 'modcod': '0', 'sample_rate': 1000000.0, 'class_name': 'bpsk', 'class_index': 0}])\n"
+     ]
+    }
+   ],
+   "source": [
+    "class BYODExampleFileHandler(ExternalFileHandler):\n",
+    "\n",
+    "    def __init__(\n",
+    "        self,\n",
+    "        root: str\n",
+    "    ):\n",
+    "        super().__init__(root=root)\n",
+    "\n",
+    "        self.class_list = ['BPSK', 'QPSK', 'Noise']  \n",
+    "\n",
+    "    def size(self) -> int:\n",
+    "        try:\n",
+    "            with open(f\"{self.root}/info.json\", \"r\") as f:\n",
+    "                dataset_info = json.load(f)\n",
+    "\n",
+    "            return dataset_info[\"size\"]\n",
+    "        except:\n",
+    "            raise ValueError(f\"Error loading {root}/info.json\")\n",
+    "    \n",
+    "    def load_dataset_metadata(self) -> ExternalDatasetMetadata:\n",
+    "        try:\n",
+    "            with open(f\"{self.root}/info.json\", \"r\") as f:\n",
+    "                dataset_info = json.load(f)\n",
+    "\n",
+    "            return ExternalDatasetMetadata(\n",
+    "                # minimum fields required for ExternalDatasetMetadata\n",
+    "                num_iq_samples_dataset = dataset_info[\"num_samples\"],\n",
+    "                sample_rate = dataset_info[\"sample_rate\"],\n",
+    "                class_list = dataset_info[\"class_labels\"],\n",
+    "                num_samples = dataset_info[\"size\"]\n",
+    "            )\n",
+    "        except:\n",
+    "            raise ValueError(f\"Error loading {self.root}/info.json\")\n",
+    "\n",
+    "    def load(self, idx: int) -> Tuple[np.ndarray, List[Dict]]:\n",
+    "        try:\n",
+    "            # loads entire data to access an element: inefficient, but acceptable for a\n",
+    "            # small basic example - use memory mapping or another format for better efficiency\n",
+    "            data = np.load(f\"{self.root}/data.npy\")[idx]\n",
+    "\n",
+    "            with open(f\"{self.root}/metadata.csv\", \"r\") as f:\n",
+    "                reader = csv.DictReader(f, fieldnames=[\"index\", \"label\", \"modcod\", \"sample_rate\"])\n",
+    "                # get to idx row\n",
+    "                row = next(itertools.islice(reader, idx, idx+1), None)\n",
+    "                if row is None:\n",
+    "                    raise IndexError(f\"Metadata idx {idx} is out of bounds\")\n",
+    "\n",
+    "                row[\"index\"] = int(row[\"index\"])\n",
+    "                row[\"sample_rate\"] = float(row[\"sample_rate\"])\n",
+    "                # add class_name\n",
+    "                row[\"class_name\"] = row[\"label\"].lower()\n",
+    "                # add class index\n",
+    "                row[\"class_index\"] = self.class_list.index(row[\"label\"])\n",
+    "\n",
+    "                metadata = row\n",
+    "\n",
+    "            return data, [metadata]\n",
+    "        except:\n",
+    "            raise ValueError(f\"Error loading {root}/info.json\")\n",
+    "\n",
+    "test = BYODExampleFileHandler(root)\n",
+    "print(f'Size: {test.size()}')\n",
+    "print(f'Metadata: {test.load_dataset_metadata()}')\n",
+    "print(f'Load element 2: {test.load(2)}')"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "id": "7bd0e530-9864-475b-8ef1-eee3df5751e6",
+   "metadata": {},
+   "source": [
+    "## Step 3: ExternalTorchSigDataset\n",
+    "\n",
+    "Use `ExternalTorchSigDataset` and custom file handler (above) to load in data."
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 6,
+   "id": "b885c0fc",
+   "metadata": {},
+   "outputs": [
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Dataset size: 8\n",
+      "data: [ 1.+0.j -1.+0.j  1.+0.j ... -1.+0.j -1.+0.j -1.+0.j]\n",
+      "metadata: [{'index': 4, 'label': 'BPSK', 'modcod': '1', 'class_name': 'bpsk', 'class_index': 0, 'sample_rate': 1000000}]\n"
+     ]
+    }
+   ],
+   "source": [
+    "root = 'datasets/byod_npy_example'    \n",
+    "\n",
+    "custom_dataset = ExternalTorchSigDataset(\n",
+    "    file_handler = BYODExampleFileHandler(root),\n",
+    "    target_labels = None\n",
+    ")\n",
+    "print(f\"Dataset size: {len(custom_dataset)}\")\n",
+    "\n",
+    "sample = custom_dataset[4]\n",
+    "print(f\"data: {sample.data}\")\n",
+    "print(f\"metadata: {[meta.to_dict() for meta in sample.get_full_metadata()]}\")"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 7,
+   "id": "3fe6d733",
+   "metadata": {},
+   "outputs": [
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Dataset size: 8\n",
+      "data: (2, 1024)\n",
+      "metadata: ['1']\n"
+     ]
+    }
+   ],
+   "source": [
+    "# can apply transforms and metadata transforms\n",
+    "root = 'datasets/byod_npy_example'    \n",
+    "\n",
+    "custom_dataset_2 = ExternalTorchSigDataset(\n",
+    "    file_handler = BYODExampleFileHandler(root),\n",
+    "    transforms = [ComplexTo2D()],\n",
+    "    target_labels = [\"modcod\"]\n",
+    ")\n",
+    "print(f\"Dataset size: {len(custom_dataset_2)}\")\n",
+    "\n",
+    "data, metadata = custom_dataset_2[4]\n",
+    "print(f\"data: {data.shape}\")\n",
+    "print(f\"metadata: {metadata}\")"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "905bda01-1ced-4485-b5ab-1381ce2dc8b0",
+   "metadata": {},
+   "outputs": [],
+   "source": []
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "d49d2518-4ae1-4fa2-922d-54129cd4bc6f",
+   "metadata": {},
+   "outputs": [],
+   "source": []
+  }
+ ],
+ "metadata": {
+  "kernelspec": {
+   "display_name": "Python 3 (ipykernel)",
+   "language": "python",
+   "name": "python3"
+  },
+  "language_info": {
+   "codemirror_mode": {
+    "name": "ipython",
+    "version": 3
+   },
+   "file_extension": ".py",
+   "mimetype": "text/x-python",
+   "name": "python",
+   "nbconvert_exporter": "python",
+   "pygments_lexer": "ipython3",
+   "version": "3.12.3"
+  }
+ },
+ "nbformat": 4,
+ "nbformat_minor": 5
+}
diff --git a/examples/bring_your_own_data_sigmf_example.ipynb b/examples/bring_your_own_data_sigmf_example.ipynb
new file mode 100644
index 000000000..fd7a2f057
--- /dev/null
+++ b/examples/bring_your_own_data_sigmf_example.ipynb
@@ -0,0 +1,452 @@
+{
+ "cells": [
+  {
+   "cell_type": "markdown",
+   "id": "04b0d326",
+   "metadata": {},
+   "source": [
+    "# Importing External Data into TorchSig: Bring Your Own Data (BYOD) SigMF\n",
+    "This notebook shows how to import externally created data into TorchSig using a basic SigMF example file format.\n",
+    "\n",
+    "---\n",
+    "\n",
+    "The main code that the user must write is a subclass of `ExternalFileHandler`, which will be passed into a `ExternalTorchSigDataset`. The `ExternalFileHandler` class must implement 3 methods:\n",
+    "| Method | Arguments | Return | Description |\n",
+    "| ------ | --------- | ------ | ----------- |\n",
+    "| `size` | N/A | int | Number of data samples, dataset size |\n",
+    "| `load_dataset_metadata` | N/A | `ExternalDatasetMetadata` | Dataset information, see `datasets/dataset_metadata.py` for more information. |\n",
+    "| `load` | idx: int | (np.ndarray, List[Any]) | Load sample `idx`, which includes data as np.ndarray and taregts as a list. |\n",
+    "\n",
+    "If you want to apply TorchSig's transforms and impairments to your data, note that `load` must return targets that are in `List[Dict]` format, where each dict describes a signal. Additionally, the dict must have the fields required by each transform, e.g., `FamilyName` target transform requires the signal to have `class_name` in its metadata. It is up to the user to figure out what metadata is needed for what transforms/target transforms they wish to use."
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 1,
+   "id": "06acb66e",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "import numpy as np\n",
+    "import datetime as dt\n",
+    "import os\n",
+    "from sigmf import SigMFFile, sigmffile\n",
+    "from typing import Tuple, Dict, List, Any\n",
+    "\n",
+    "# TorchSig\n",
+    "from torchsig.datasets.datasets import ExternalTorchSigDataset\n",
+    "from torchsig.datasets.dataset_metadata import ExternalDatasetMetadata\n",
+    "from torchsig.utils.file_handlers import ExternalFileHandler\n",
+    "from torchsig.transforms.transforms import ComplexTo2D"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "id": "db11e075-256b-4847-add2-f1fbb512f2f0",
+   "metadata": {},
+   "source": [
+    "## Step 1: External Data Generation Process: create synthetic data outside TorchSig workflow\n",
+    "\n",
+    "If your data already exists somewhere, you can skip to Step 2.\n",
+    "\n",
+    "We will write a sample dataset using Numpy's npy for signal data and and csv for metadata. "
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "id": "e8e6981f-7ac9-4635-8849-d5df6d7281f5",
+   "metadata": {},
+   "source": [
+    "### External Synthetic Data and Metadata Generation"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 2,
+   "id": "ae5a6f1f",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "# configuration parameters\n",
+    "root = 'datasets/byod_sigmf_example'      # data file top-level folder \n",
+    "seed = 1234567890                         # rng seed\n",
+    "\n",
+    "os.makedirs(root, exist_ok=True)          # directory for files"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "id": "98fabf89",
+   "metadata": {},
+   "source": [
+    "Below, we generate some signals (outside of TorchSig)."
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 3,
+   "id": "1be33642-0514-4eae-8552-b7ddc8eb4183",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "# Parameters\n",
+    "fs = 1_000_000                              # 1 MHz sample-rate (fixed rate)\n",
+    "num_samples = 1024                          # samples per data (fixed size)\n",
+    "dataset_size = 8                            # dataset size\n",
+    "labels = ['BPSK', 'QPSK', 'Noise']          # three arbitrary metadata class labels (strings)\n",
+    "modcod = [0, 1, 2]                          # three arbitrary metadata integers\n",
+    "rng = np.random.default_rng(seed)           # random number generator"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 4,
+   "id": "f4801f20-ff14-4265-94b6-78cef460d9f8",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "# Create user's external data: non-TorchSig synthetic data along with metadata\n",
+    "\n",
+    "signals_array = np.empty((dataset_size, num_samples), dtype=np.complex64)  # data\n",
+    "meta_rows = [] # metadata                                           \n",
+    "\n",
+    "t = np.arange(num_samples) / fs  # timesteps\n",
+    "\n",
+    "# create synthetic dataset elements\n",
+    "for idx in range(dataset_size):\n",
+    "    label = rng.choice(labels)\n",
+    "    mc = rng.choice(modcod)\n",
+    "    \n",
+    "    if label == \"BPSK\":\n",
+    "        bits   = rng.integers(0, 2, num_samples)\n",
+    "        sig    = (2*bits-1) + 0j\n",
+    "    elif label == \"QPSK\":\n",
+    "        bits   = rng.integers(0, 4, num_samples)\n",
+    "        table  = {0:1+1j, 1:1-1j, 2:-1+1j, 3:-1-1j}\n",
+    "        sig    = np.vectorize(table.get)(bits)\n",
+    "    else:  # white noise\n",
+    "        sig = (rng.normal(size=num_samples) + 1j*rng.normal(size=num_samples)) * 0.1\n",
+    "\n",
+    "    sig /= np.sqrt((np.abs(sig)**2).mean()) # normalize power for consistency\n",
+    "    signals_array[idx] = sig.astype(np.complex64)\n",
+    "    \n",
+    "    # add to metadata\n",
+    "    meta_rows.append(\n",
+    "        dict(\n",
+    "            index=idx, \n",
+    "            label=label, \n",
+    "            modcod=mc, \n",
+    "            sample_rate=fs\n",
+    "        )\n",
+    "    )"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 5,
+   "id": "0bcaa12b-ecf4-4827-a247-cde946383324",
+   "metadata": {},
+   "outputs": [
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "SigMF files created:\n",
+      "  Data: datasets/byod_sigmf_example/byod.sigmf-data\n",
+      "  Metadata: datasets/byod_sigmf_example/byod.sigmf-meta\n",
+      "Meta data size verified: True\n",
+      "Data verified: True\n",
+      "Synthetic signals + metadata staged in datasets/byod_sigmf_example\n"
+     ]
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "/tmp/ipykernel_1058596/323869635.py:30: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
+      "  SigMFFile.DATETIME_KEY: dt.datetime.utcnow().isoformat() + 'Z',\n"
+     ]
+    }
+   ],
+   "source": [
+    "# Write and verify basic example SigMF data and metadata files\n",
+    "\n",
+    "# SigMF stores samples sequentially, so we flatten the 2D\n",
+    "# data row-wise to simulate a wideband datastream\n",
+    "data_flattened = signals_array.flatten()\n",
+    "\n",
+    "# write the aggregate binary data file (.sigmf-data)\n",
+    "data_filename = f'{root}/byod.sigmf-data'\n",
+    "meta_filename = f'{root}/byod.sigmf-meta'\n",
+    "data_flattened.tofile(data_filename)\n",
+    "\n",
+    "# create the metadata file (.sigmf-meta)\n",
+    "meta = SigMFFile(\n",
+    "    data_file=data_filename,                # Link to the data file\n",
+    "    global_info={\n",
+    "        SigMFFile.DATATYPE_KEY: 'cf32_le',  # Complex float32, little-endian\n",
+    "        SigMFFile.SAMPLE_RATE_KEY: fs,      # Sample rate in Hz\n",
+    "        SigMFFile.VERSION_KEY: '1.2.0',     # SigMF version\n",
+    "        SigMFFile.AUTHOR_KEY: 'https://github.com/torchdsp/torchsig',\n",
+    "        SigMFFile.DESCRIPTION_KEY: 'BYOD SigMF Example',\n",
+    "        'core:num_channels': 1,             # Specify number of channels\n",
+    "        'core:signal_length': num_samples,  # Number of I/Q samples in each signal\n",
+    "        'core:signal_count': dataset_size   # Number of signals in data\n",
+    "    }\n",
+    ")\n",
+    "\n",
+    "# add capture information (required)\n",
+    "meta.add_capture(0, metadata={\n",
+    "    SigMFFile.FREQUENCY_KEY: 2_450_000_000,  # specify some arbitrary center frequency in Hz\n",
+    "    SigMFFile.DATETIME_KEY: dt.datetime.utcnow().isoformat() + 'Z',\n",
+    "})\n",
+    "\n",
+    "# save signal-specific metadata as annotations\n",
+    "for i, m in enumerate(meta_rows):\n",
+    "    generated_metadata = meta_rows[i]   # metadata for signal i\n",
+    "    sample_start_idx = i * num_samples  # signal's I/Q start index in data file\n",
+    "    meta.add_annotation(\n",
+    "        sample_start_idx,\n",
+    "        num_samples,\n",
+    "        metadata = {\n",
+    "            SigMFFile.LABEL_KEY: generated_metadata['label'],\n",
+    "            SigMFFile.COMMENT_KEY: str(generated_metadata['modcod'])\n",
+    "        }\n",
+    "    )\n",
+    "            \n",
+    "# Validate and write the metadata file (.sigmf-meta)\n",
+    "assert not meta.validate()               # sigmf check\n",
+    "meta.tofile(f'{root}/byod.sigmf-meta') \n",
+    "\n",
+    "print(f\"SigMF files created:\")\n",
+    "print(f\"  Data: {data_filename}\")\n",
+    "print(f\"  Metadata: {meta_filename}\")\n",
+    "\n",
+    "# check files\n",
+    "loaded_sigmf = sigmffile.fromfile(meta_filename)\n",
+    "M = loaded_sigmf.get_global_field('core:signal_count')\n",
+    "N = loaded_sigmf.get_global_field('core:signal_length')\n",
+    "loaded_data = loaded_sigmf.read_samples()   # read all samples\n",
+    "print(f\"Meta data size verified: {loaded_data.shape[0] == (M*N)}\")\n",
+    "print(f\"Data verified: {np.allclose(data_flattened, loaded_data)}\")\n",
+    "print(f\"Synthetic signals + metadata staged in {root}\")"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "id": "8869659d-2933-4d72-8de8-318aeae9db3b",
+   "metadata": {},
+   "source": [
+    "## Step 2. ExternalFileHandler\n",
+    "\n",
+    "To have your data on disk interface with TorchSig, you must write your own `ExternalFileHandler` so TorchSig knows how to handle your data. Make sure to call `super()`.\n",
+    "\n",
+    "Note that the metadata must at least have:\n",
+    "- `class_name`\n",
+    "- `class_index`"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 6,
+   "id": "77031156",
+   "metadata": {},
+   "outputs": [
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Size: 8\n",
+      "Metadata: ExternalDatasetMetadata\n",
+      "Load element 2: (memmap([ 1.+0.j,  1.+0.j, -1.+0.j, ..., -1.+0.j,  1.+0.j, -1.+0.j],\n",
+      "       dtype=complex64), [{'index': 2, 'sample_rate': 1000000, 'class_name': 'BPSK', 'class_index': 0, 'modcod': '0'}])\n"
+     ]
+    }
+   ],
+   "source": [
+    "class BYODExampleFileHandler(ExternalFileHandler):\n",
+    "\n",
+    "    def __init__(\n",
+    "        self,\n",
+    "        root: str\n",
+    "    ):\n",
+    "        super().__init__(root=root)\n",
+    "        \n",
+    "        self.data_filename = f'{root}/byod.sigmf-data'\n",
+    "        self.meta_filename = f'{root}/byod.sigmf-meta'\n",
+    "        self.data_size = None\n",
+    "        self.class_list = ['BPSK', 'QPSK', 'Noise'] \n",
+    "\n",
+    "\n",
+    "    def size(self) -> int:\n",
+    "        if self.data_size is None:\n",
+    "            try:\n",
+    "                loaded_sigmf = sigmffile.fromfile(self.meta_filename)\n",
+    "                self.data_size = loaded_sigmf.get_global_field('core:signal_count')\n",
+    "            except:\n",
+    "                raise ValueError(f\"Error loading {self.meta_filename}\")\n",
+    "                \n",
+    "        return self.data_size\n",
+    "\n",
+    "    \n",
+    "    def load_dataset_metadata(self) -> ExternalDatasetMetadata:\n",
+    "        try:\n",
+    "            loaded_sigmf = sigmffile.fromfile(self.meta_filename)\n",
+    "            num_iq_samples_dataset = loaded_sigmf.get_global_field('core:signal_length')\n",
+    "            sample_rate = loaded_sigmf.get_global_field(SigMFFile.SAMPLE_RATE_KEY)\n",
+    "            class_list = self.class_list\n",
+    "            num_samples = loaded_sigmf.get_global_field('core:signal_count')\n",
+    "\n",
+    "            \n",
+    "            return ExternalDatasetMetadata(\n",
+    "                # minimum fields required for ExternalDatasetMetadata\n",
+    "                num_iq_samples_dataset = num_iq_samples_dataset,\n",
+    "                sample_rate = sample_rate,\n",
+    "                class_list = class_list,\n",
+    "                num_samples = num_samples\n",
+    "            )           \n",
+    "        except:\n",
+    "            raise ValueError(f\"Error loading {self.meta_filename}\")\n",
+    "\n",
+    "\n",
+    "    def load(self, idx: int) -> Tuple[np.ndarray, List[Dict]]:\n",
+    "        try:\n",
+    "            sigmf_file = sigmffile.fromfile(self.meta_filename)   # creates data memory map access\n",
+    "            sample_rate = sigmf_file.get_global_field(SigMFFile.SAMPLE_RATE_KEY)\n",
+    "            annotations = sigmf_file.get_annotations()            # load metadata annotations\n",
+    "            \n",
+    "            sigmf_signal_meta = annotations[idx]\n",
+    "            meta = {}\n",
+    "            meta[\"index\"] = idx\n",
+    "            meta[\"sample_rate\"] = sample_rate\n",
+    "            meta[\"class_name\"] = sigmf_signal_meta[\"core:label\"]\n",
+    "            meta[\"class_index\"] = self.class_list.index(meta[\"class_name\"])\n",
+    "            meta[\"modcod\"] = sigmf_signal_meta[\"core:comment\"]\n",
+    "            \n",
+    "            start_idx = sigmf_signal_meta['core:sample_start']\n",
+    "            stop_idx = start_idx + sigmf_signal_meta['core:sample_count'] - 1\n",
+    "            data = sigmf_file[start_idx:stop_idx]\n",
+    "\n",
+    "            return data, [meta]\n",
+    "        \n",
+    "        except:\n",
+    "            raise ValueError(f\"Error loading {self.meta_filename}\")            \n",
+    "\n",
+    "\n",
+    "test = BYODExampleFileHandler(root)\n",
+    "print(f'Size: {test.size()}')\n",
+    "print(f'Metadata: {test.load_dataset_metadata()}')\n",
+    "print(f'Load element 2: {test.load(2)}')"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "id": "7bd0e530-9864-475b-8ef1-eee3df5751e6",
+   "metadata": {},
+   "source": [
+    "## Step 3: ExternalTorchSigDataset\n",
+    "\n",
+    "Use `ExternalTorchSigDataset` and custom file handler (above) to load in data."
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 7,
+   "id": "b885c0fc",
+   "metadata": {},
+   "outputs": [
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Dataset size: 8\n",
+      "data: [ 1.+0.j -1.+0.j  1.+0.j ...  1.+0.j -1.+0.j -1.+0.j]\n",
+      "metadata: [{'index': 4, 'class_name': 'BPSK', 'class_index': 0, 'modcod': '1', 'sample_rate': 1000000}]\n"
+     ]
+    }
+   ],
+   "source": [
+    "root = 'datasets/byod_sigmf_example'    \n",
+    "\n",
+    "custom_dataset = ExternalTorchSigDataset(\n",
+    "    file_handler = BYODExampleFileHandler(root),\n",
+    "    target_labels = None\n",
+    ")\n",
+    "print(f\"Dataset size: {len(custom_dataset)}\")\n",
+    "\n",
+    "sample = custom_dataset[4]\n",
+    "print(f\"data: {sample.data}\")\n",
+    "print(f\"metadata: {[meta.to_dict() for meta in sample.get_full_metadata()]}\")"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 8,
+   "id": "3fe6d733",
+   "metadata": {},
+   "outputs": [
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Dataset size: 8\n",
+      "data: (2, 1023)\n",
+      "metadata: ['1']\n"
+     ]
+    }
+   ],
+   "source": [
+    "# can apply transforms and metadata transforms\n",
+    "root = 'datasets/byod_sigmf_example'    \n",
+    "\n",
+    "custom_dataset_2 = ExternalTorchSigDataset(\n",
+    "    file_handler = BYODExampleFileHandler(root),\n",
+    "    transforms = [ComplexTo2D()],\n",
+    "    target_labels = [\"modcod\"]\n",
+    ")\n",
+    "print(f\"Dataset size: {len(custom_dataset_2)}\")\n",
+    "\n",
+    "data, metadata = custom_dataset_2[4]\n",
+    "print(f\"data: {data.shape}\")\n",
+    "print(f\"metadata: {metadata}\")"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "4c7f853c-d45a-4a6f-b488-c6e9eb2e36b8",
+   "metadata": {},
+   "outputs": [],
+   "source": []
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "aec2a7a2-b13c-4dbd-88a1-4b6c9796f998",
+   "metadata": {},
+   "outputs": [],
+   "source": []
+  }
+ ],
+ "metadata": {
+  "kernelspec": {
+   "display_name": "Python 3 (ipykernel)",
+   "language": "python",
+   "name": "python3"
+  },
+  "language_info": {
+   "codemirror_mode": {
+    "name": "ipython",
+    "version": 3
+   },
+   "file_extension": ".py",
+   "mimetype": "text/x-python",
+   "name": "python",
+   "nbconvert_exporter": "python",
+   "pygments_lexer": "ipython3",
+   "version": "3.12.3"
+  }
+ },
+ "nbformat": 4,
+ "nbformat_minor": 5
+}
diff --git a/examples/classifier_example.ipynb b/examples/classifier_example.ipynb
index c027e4b76..7625d9fcf 100644
--- a/examples/classifier_example.ipynb
+++ b/examples/classifier_example.ipynb
@@ -22,9 +22,15 @@
     "# Variables\n",
     "from torchsig.signals.signal_lists import TorchSigSignalLists\n",
     "from torchsig.transforms.transforms import ComplexTo2D\n",
-    "from torchsig.transforms.target_transforms import ClassIndex\n",
+    "import os\n",
+    "\n",
+    "from torch import Tensor\n",
     "\n",
     "root = \"./datasets/classifier_example\"\n",
+    "os.makedirs(root, exist_ok=True)\n",
+    "os.makedirs(root + \"/train\", exist_ok=True)\n",
+    "os.makedirs(root + \"/val\", exist_ok=True)\n",
+    "os.makedirs(root + \"/test\", exist_ok=True)\n",
     "fft_size = 256\n",
     "num_iq_samples_dataset = fft_size ** 2\n",
     "class_list = TorchSigSignalLists.all_signals\n",
@@ -39,9 +45,7 @@
     "num_signals_min = 1\n",
     "\n",
     "# ComplexTo2D turns a IQ array of complex values into a 2D array, with one channel for the real component, while the other is for the imaginary component\n",
-    "transforms = [ComplexTo2D()]\n",
-    "# ClassIndex turns our target labels into the index of the class according to class_list\n",
-    "target_transforms = [ClassIndex()]"
+    "transforms = [ComplexTo2D()]"
    ]
   },
   {
@@ -60,48 +64,76 @@
    "outputs": [],
    "source": [
     "from torchsig.datasets.dataset_metadata import DatasetMetadata\n",
-    "from torchsig.datasets.datamodules import TorchSigDataModule\n",
+    "from torchsig.datasets.datasets import TorchSigIterableDataset, StaticTorchSigDataset\n",
+    "from torchsig.utils.data_loading import WorkerSeedingDataLoader\n",
+    "from torchsig.utils.writer import DatasetCreator\n",
     "\n",
-    "train_metadata = DatasetMetadata(\n",
+    "dataset_metadata = DatasetMetadata(\n",
     "    num_iq_samples_dataset = num_iq_samples_dataset,\n",
     "    fft_size = fft_size,\n",
-    "    impairment_level = impairment_level,\n",
     "    class_list = class_list,\n",
-    "    seed = seed,\n",
     "    num_signals_max = num_signals_max,\n",
     "    num_signals_min = num_signals_min,\n",
-    "    num_samples = num_samples_train\n",
     ")\n",
     "\n",
-    "val_metadata = DatasetMetadata(\n",
-    "    num_iq_samples_dataset = num_iq_samples_dataset,\n",
-    "    fft_size = fft_size,\n",
-    "    impairment_level = impairment_level,\n",
-    "    class_list = class_list,\n",
-    "    seed = seed,\n",
-    "    num_signals_max = num_signals_max,\n",
-    "    num_signals_min = num_signals_min,\n",
-    "    num_samples = num_samples_val\n",
+    "train_dataset = TorchSigIterableDataset(dataset_metadata, transforms=transforms, target_labels=None)\n",
+    "val_dataset = TorchSigIterableDataset(dataset_metadata, transforms=transforms, target_labels=None)\n",
+    "\n",
+    "train_dataloader = WorkerSeedingDataLoader(train_dataset, batch_size=4, collate_fn = lambda x: x)\n",
+    "val_dataloader = WorkerSeedingDataLoader(val_dataset, collate_fn = lambda x: x)\n",
+    "\n",
+    "#print(f\"Data shape: {data.shape}\")\n",
+    "#print(f\"Targets: {targets}\")\n",
+    "# next(train_dataset)\n",
+    "\n",
+    "dc = DatasetCreator(\n",
+    "    dataloader=train_dataloader,\n",
+    "    root = f\"{root}/train\",\n",
+    "    overwrite=True,\n",
+    "    dataset_length=num_samples_train\n",
     ")\n",
+    "dc.create()\n",
+    "\n",
     "\n",
-    "datamodule = TorchSigDataModule(\n",
-    "    root = root,\n",
-    "    train_metadata = train_metadata,\n",
-    "    val_metadata = val_metadata,\n",
-    "    transforms = transforms,\n",
-    "    target_transforms = target_transforms,\n",
-    "    create_batch_size = 4,\n",
-    "    create_num_workers = 4,\n",
-    "    batch_size=4,\n",
-    "    num_workers=4,\n",
-    "    overwrite = True\n",
+    "dc = DatasetCreator(\n",
+    "    dataloader=val_dataloader,\n",
+    "    root = f\"{root}/val\",\n",
+    "    overwrite=True,\n",
+    "    dataset_length=num_samples_val\n",
+    ")\n",
+    "dc.create()\n"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "cbefb65c",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "train_dataset = StaticTorchSigDataset(\n",
+    "    root = f\"{root}/train\",\n",
+    "    target_labels=[\"class_index\"]\n",
+    ")\n",
+    "val_dataset = StaticTorchSigDataset(\n",
+    "    root = f\"{root}/val\",\n",
+    "    target_labels=[\"class_index\"]\n",
     ")\n",
-    "datamodule.prepare_data()\n",
-    "datamodule.setup()\n",
     "\n",
-    "data, targets = datamodule.train[0]\n",
-    "print(f\"Data shape: {data.shape}\")\n",
-    "print(f\"Targets: {targets}\")"
+    "train_dataloader = WorkerSeedingDataLoader(train_dataset, batch_size=4)\n",
+    "val_dataloader = WorkerSeedingDataLoader(val_dataset)\n",
+    "\n",
+    "print(train_dataset[0])"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "cc103624-047a-4628-a439-d9c259fdcf51",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "next(iter(train_dataloader))"
    ]
   },
   {
@@ -160,9 +192,8 @@
     "    accelerator =  'gpu' if torch.cuda.is_available() else 'cpu',\n",
     "    devices = 1\n",
     ")\n",
-    "# print(trainer)\n",
     "\n",
-    "trainer.fit(model, datamodule)"
+    "trainer.fit(model, train_dataloader)"
    ]
   },
   {
@@ -182,8 +213,8 @@
    "metadata": {},
    "outputs": [],
    "source": [
-    "from torchsig.datasets.datasets import NewTorchSigDataset, StaticTorchSigDataset\n",
-    "from torchsig.utils.writer import DatasetCreator\n",
+    "from torchsig.datasets.datasets import TorchSigIterableDataset, StaticTorchSigDataset\n",
+    "from torchsig.utils.writer import DatasetCreator, default_collate_fn\n",
     "import torch\n",
     "\n",
     "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
@@ -197,37 +228,33 @@
     "dataset_metadata_test = DatasetMetadata(\n",
     "    num_iq_samples_dataset = num_iq_samples_dataset,\n",
     "    fft_size = fft_size,\n",
-    "    impairment_level = impairment_level,\n",
     "    class_list = class_list,\n",
     "    num_samples=test_dataset_size,\n",
-    "    transforms=transforms,\n",
-    "    target_transforms=target_transforms,\n",
     "    seed = 123456788, # different than train\n",
     "    num_signals_max = num_signals_max,\n",
     "    num_signals_min = num_signals_min\n",
     ")\n",
     "# print(dataset_metadata_test)\n",
+    "dataset = TorchSigIterableDataset(dataset_metadata_test, transforms=transforms, target_labels=None,)#[\"class_index\"])\n",
+    "\n",
+    "dataloader = WorkerSeedingDataLoader(dataset, num_workers=1, batch_size=1, collate_fn = lambda x: x)#default_collate_fn)\n",
     "\n",
     "dc = DatasetCreator(\n",
-    "    dataset = NewTorchSigDataset(\n",
-    "        dataset_metadata = dataset_metadata_test,\n",
-    "    ),\n",
+    "    dataloader=dataloader,\n",
     "    root = f\"{root}/test\",\n",
     "    overwrite=True,\n",
-    "    batch_size=1,\n",
-    "    num_workers=1,\n",
+    "    dataset_length=100\n",
     ")\n",
     "dc.create()\n",
     "\n",
     "test_dataset = StaticTorchSigDataset(\n",
     "    root = f\"{root}/test\",\n",
-    "    impairment_level = impairment_level\n",
+    "    target_labels=[\"class_index\"]\n",
     ")\n",
     "\n",
-    "\n",
     "data, class_index = test_dataset[0]\n",
     "print(f\"Data shape: {data.shape}\")\n",
-    "print(f\"Targets: {targets}\")"
+    "print(f\"Targets: {class_index}\")"
    ]
   },
   {
@@ -303,6 +330,14 @@
     "disp = ConfusionMatrixDisplay(matrix, display_labels=family_list)\n",
     "disp.plot()"
    ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "fbaef25d-e62d-4deb-a197-c3724e0ff47e",
+   "metadata": {},
+   "outputs": [],
+   "source": []
   }
  ],
  "metadata": {
@@ -310,9 +345,9 @@
    "formats": "py:percent,ipynb"
   },
   "kernelspec": {
-   "display_name": "tsg",
+   "display_name": "venv",
    "language": "python",
-   "name": "tsg"
+   "name": "python3"
   },
   "language_info": {
    "codemirror_mode": {
@@ -324,7 +359,7 @@
    "name": "python",
    "nbconvert_exporter": "python",
    "pygments_lexer": "ipython3",
-   "version": "3.10.12"
+   "version": "3.12.3"
   }
  },
  "nbformat": 4,
diff --git a/examples/create_dataset_example.ipynb b/examples/create_dataset_example.ipynb
index 9ba302156..516c01799 100644
--- a/examples/create_dataset_example.ipynb
+++ b/examples/create_dataset_example.ipynb
@@ -4,8 +4,8 @@
    "cell_type": "markdown",
    "metadata": {},
    "source": [
-    "# Wideband Dataset\n",
-    "This notebook showcases the Wideband dataset.\n",
+    "# TorchSig Iterable Dataset Example\n",
+    "This notebook showcases the TorchSigIterableDataset dataset.\n",
     "\n",
     "---"
    ]
@@ -20,7 +20,6 @@
     "\n",
     "num_iq_samples_dataset = 4096 # 64^2\n",
     "fft_size = 64\n",
-    "impairment_level = 0 # clean\n",
     "num_signals_max = 5\n",
     "num_signals_min = 1"
    ]
@@ -30,15 +29,14 @@
    "metadata": {},
    "source": [
     "## Dataset Metadata\n",
-    "In order to create a NewTorchSigDataset, you must define parameters in DatasetMetadata. This can be done either in code or inside a YAML file. Below we show how to do both. Look at `create_dataset_example.yaml` for a sample YAML file.\n",
+    "In order to create a TorchSigIterableDataset, you must define parameters in DatasetMetadata. This can be done either in code or inside a YAML file. Below we show how to do both. Look at `create_dataset_example.yaml` for a sample YAML file.\n",
     "\n",
-    "There are four required parameters: \n",
+    "There are three required parameters: \n",
     "1. `num_iq_samples_dataset` -> how much IQ data per sample\n",
     "2. `fft_size` -> Size of FFT (number of bins) to be used in spectrogram.\n",
-    "3. `impairment_level` -> what environment impairment to simulate.\n",
-    "4. `num_signals_max` -> maximum number of signals per sample.\n",
+    "3. `num_signals_max` -> maximum number of signals per sample.\n",
     "\n",
-    "Additionally, there are several optional parameters that can be overriden."
+    "Additionally, there are several optional parameters that can be overridden."
    ]
   },
   {
@@ -53,9 +51,8 @@
     "dataset_metadata_1 = DatasetMetadata(\n",
     "    num_iq_samples_dataset = num_iq_samples_dataset,\n",
     "    fft_size = fft_size,\n",
-    "    impairment_level = impairment_level,\n",
     "    num_signals_max = num_signals_max,\n",
-    "    num_signals_min = num_signals_min\n",
+    "    num_signals_min = num_signals_min,\n",
     ")\n",
     "print(dataset_metadata_1)"
    ]
@@ -69,43 +66,21 @@
     "# Option 2: Instantiate as a dictionary object\n",
     "\n",
     "dataset_metadata_2 = dict(\n",
-    "    num_iq_samples = num_iq_samples_dataset,\n",
+    "    num_iq_samples_dataset = num_iq_samples_dataset,\n",
     "    fft_size = fft_size,\n",
-    "    impairment_level = impairment_level,\n",
     "    num_signals_max = num_signals_max,\n",
-    "    num_signals_min = num_signals_min\n",
+    "    num_signals_min = num_signals_min,\n",
+    "    impairment_level = 0  # Added required parameter\n",
     ")\n",
     "print(dataset_metadata_2)"
    ]
   },
-  {
-   "cell_type": "code",
-   "execution_count": null,
-   "metadata": {},
-   "outputs": [],
-   "source": [
-    "# Option 3: Instantiate from YAML file\n",
-    "# see dataset_metadata_example.yaml\n",
-    "import yaml\n",
-    "\n",
-    "dataset_metadata_3_file = \"create_dataset_example.yaml\"\n",
-    "\n",
-    "with open(dataset_metadata_3_file, 'r') as f:\n",
-    "    dataset_metadata_3 = yaml.load(f,Loader=yaml.SafeLoader)\n",
-    "\n",
-    "print(dataset_metadata_3)"
-   ]
-  },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
-    "## Infinite Dataset\n",
-    "To create an infinite dataset, simply instantiate a NewTorchSigDataset object. Ensure the `num_samples` field inside the DatasetMetadata is set to None.\n",
-    "\n",
-    "Notes:\n",
-    "* You will not be able to access previously generated samples.\n",
-    "* You cannot save an infinite dataset to disk."
+    "## Synthetic Dataset\n",
+    "To create a new dataset, simply instantiate a TorchSigIterableDataset object."
    ]
   },
   {
@@ -120,22 +95,25 @@
     "dataset_infinite_metadata = DatasetMetadata(\n",
     "    num_iq_samples_dataset = num_iq_samples_dataset,\n",
     "    fft_size = fft_size,\n",
-    "    impairment_level = impairment_level,\n",
     "    num_signals_max = num_signals_max,\n",
-    "    num_signals_min = num_signals_min,\n",
-    "    num_samples = None\n",
+    "    num_signals_min = num_signals_min\n",
     ")\n",
     "\n",
+    "# Without target_labels, returns Signal objects with rich metadata\n",
     "dataset_infinite = TorchSigIterableDataset(\n",
     "    dataset_metadata = dataset_infinite_metadata\n",
     ")\n",
     "\n",
     "for i in range(5):\n",
-    "    data, metadata = next(dataset_infinite)\n",
-    "\n",
-    "    print(f\"IQ Data shape: {data.shape}\")\n",
-    "    print(f\"Signal Metadata: {metadata}\\n\")\n",
-    "\n"
+    "    signal = next(dataset_infinite)\n",
+    "    \n",
+    "    print(f\"IQ Data shape: {signal.data.shape}\")\n",
+    "    print(f\"Component Signals: {len(signal.component_signals)}\")\n",
+    "    \n",
+    "    # Access metadata from component signals\n",
+    "    for j, comp_signal in enumerate(signal.component_signals):\n",
+    "        print(f\"  Signal {j}: {comp_signal.metadata.class_name}, SNR: {comp_signal.metadata.snr_db:.1f}dB\")\n",
+    "    print()"
    ]
   },
   {
@@ -155,19 +133,17 @@
     "import matplotlib.pyplot as plt\n",
     "import numpy as np\n",
     "\n",
-    "num_samples = 10\n",
-    "\n",
     "dataset_finite_time_series_metadata = DatasetMetadata(\n",
     "    num_iq_samples_dataset = num_iq_samples_dataset,\n",
     "    fft_size = fft_size,\n",
-    "    impairment_level = impairment_level,\n",
     "    num_signals_max = num_signals_max,\n",
-    "    num_signals_min = num_signals_min,\n",
-    "    num_samples = num_samples,\n",
+    "    num_signals_min = num_signals_min\n",
     ")\n",
     "\n",
+    "# With target_labels, returns (data, metadata) tuples\n",
     "dataset_finite_time_series = TorchSigIterableDataset(\n",
-    "    dataset_metadata = dataset_finite_time_series_metadata\n",
+    "    dataset_metadata = dataset_finite_time_series_metadata,\n",
+    "    target_labels=[\"class_index\"]\n",
     ")\n",
     "\n",
     "data, metadata = next(dataset_finite_time_series)\n",
@@ -200,20 +176,17 @@
    "source": [
     "from torchsig.transforms.transforms import Spectrogram\n",
     "\n",
-    "num_samples = 10\n",
-    "\n",
     "dataset_finite_spectrogram_metadata = DatasetMetadata(\n",
     "    num_iq_samples_dataset = num_iq_samples_dataset,\n",
     "    fft_size = fft_size,\n",
-    "    impairment_level = impairment_level,\n",
     "    num_signals_max = num_signals_max,\n",
-    "    num_signals_min = num_signals_min,\n",
-    "    num_samples = num_samples,\n",
-    "    transforms = Spectrogram(fft_size=fft_size)\n",
+    "    num_signals_min = num_signals_min\n",
     ")\n",
     "\n",
     "dataset_finite_spectrogram = TorchSigIterableDataset(\n",
-    "    dataset_metadata = dataset_finite_spectrogram_metadata\n",
+    "    dataset_metadata = dataset_finite_spectrogram_metadata,\n",
+    "    target_labels=[\"class_index\"],\n",
+    "    transforms = [Spectrogram(fft_size=fft_size)]\n",
     ")\n",
     "\n",
     "data, metadata = next(dataset_finite_spectrogram)\n",
@@ -230,7 +203,9 @@
    "metadata": {},
    "source": [
     "### Writing Dataset to Disk\n",
-    "In order to access previosuly generated examples, or save the finite dataset for later, use the `DatasetCreator`. Pass in the Dataset to be saved, where to write the dataset (root), and whether to overwrite any exisitng datasets. `num_samples` must be defined, otherwise the `DatasetCreator` will attempt to create an infinite dataset."
+    "In order to access previously generated examples, or save the finite dataset for later, use the `DatasetCreator`. Pass in the Dataset to be saved, where to write the dataset (root), and whether to overwrite any existing datasets. `num_samples` must be defined, otherwise the `DatasetCreator` will attempt to create an infinite dataset.\n",
+    "\n",
+    "**Note:** The new DatasetCreator API is simpler and uses HDF5 storage only."
    ]
   },
   {
@@ -240,36 +215,40 @@
    "outputs": [],
    "source": [
     "from torchsig.datasets.dataset_metadata import DatasetMetadata\n",
-    "from torchsig.utils.writer import DatasetCreator\n",
+    "from torchsig.utils.writer import DatasetCreator, default_collate_fn\n",
     "from torchsig.signals.signal_lists import TorchSigSignalLists\n",
     "from torchsig.datasets.datasets import TorchSigIterableDataset\n",
+    "from torchsig.utils.data_loading import WorkerSeedingDataLoader\n",
+    "from torchsig.transforms.transforms import Spectrogram\n",
     "\n",
     "root = \"./datasets/create_dataset_example\"\n",
     "class_list = TorchSigSignalLists.all_signals\n",
-    "num_samples = len(class_list) * 10\n",
+    "dataset_length = len(class_list) * 10\n",
     "seed = 123456789\n",
     "\n",
     "dataset_finite_metadata = DatasetMetadata(\n",
     "    num_iq_samples_dataset = num_iq_samples_dataset,\n",
     "    fft_size = fft_size,\n",
-    "    impairment_level = impairment_level,\n",
     "    num_signals_max = num_signals_max,\n",
     "    num_signals_min = num_signals_min,\n",
-    "    num_samples = num_samples,\n",
-    "    seed = seed\n",
     ")\n",
     "\n",
-    "dataset_finite = TorchSigIterableDataset(\n",
-    "    dataset_metadata = dataset_finite_metadata\n",
+    "# Don't use target_labels to get Signal objects with rich metadata\n",
+    "dataset = TorchSigIterableDataset(\n",
+    "    dataset_metadata = dataset_finite_metadata,\n",
+    "    transforms = [Spectrogram(fft_size = fft_size)],\n",
+    "    target_labels = [\"class_name\", \"start\", \"stop\", \"lower_freq\", \"upper_freq\", \"snr_db\"],\n",
     ")\n",
     "\n",
+    "dataloader = WorkerSeedingDataLoader(dataset, batch_size=11, num_workers=4, collate_fn=default_collate_fn)\n",
+    "dataloader.seed(seed)\n",
+    "\n",
+    "# New simplified DatasetCreator API\n",
     "dataset_creator = DatasetCreator(\n",
-    "    dataset = dataset_finite,\n",
+    "    dataset_length=dataset_length,\n",
+    "    dataloader = dataloader,\n",
     "    root = root,\n",
     "    overwrite = True,\n",
-    "    # increase the batch size and num_workers to speed up\n",
-    "    # batch_size = 16,\n",
-    "    # num_workers = 16,\n",
     "    multithreading=False\n",
     ")\n",
     "\n",
@@ -296,11 +275,11 @@
     "\n",
     "static_dataset = StaticTorchSigDataset(\n",
     "    root = root,\n",
-    "    impairment_level = impairment_level\n",
+    "    target_labels=dataset.target_labels\n",
     ")\n",
     "\n",
     "# can access any sample\n",
-    "print(static_dataset[0])\n",
+    "print(static_dataset[0][1])\n",
     "print(static_dataset[5])"
    ]
   },
@@ -308,7 +287,7 @@
    "cell_type": "markdown",
    "metadata": {},
    "source": [
-    "If the dataset writtent to disk is raw (aka no Transforms or Target Transforms were applied to it before writing to disk), then you can define whatever transforms and target transforms inside the StaticWideband."
+    "If the dataset written to disk is raw (aka no Transforms or Target Transforms were applied to it before writing to disk), then you can define whatever transforms and target transforms for use by the static dataset."
    ]
   },
   {
@@ -317,7 +296,7 @@
    "metadata": {},
    "outputs": [],
    "source": [
-    "print(f\"Dataset Raw: {static_dataset.raw}\")"
+    "static_dataset[10]"
    ]
   },
   {
@@ -327,7 +306,10 @@
    "outputs": [],
    "source": [
     "def update_spectrogram ( ax, start_time, stop_time, lower, upper):\n",
-    "\n",
+    "    start_time = float(start_time)\n",
+    "    stop_time = float(stop_time)\n",
+    "    lower = float(lower)\n",
+    "    upper = float(upper)\n",
     "    ax.plot([start_time,start_time],[lower,upper],'b',alpha=0.5)\n",
     "    ax.plot([stop_time, stop_time],[lower,upper],'b',alpha=0.5)\n",
     "    ax.plot([start_time,stop_time],[lower,lower],'b',alpha=0.5)\n",
@@ -349,34 +331,14 @@
    "outputs": [],
    "source": [
     "from torchsig.datasets.datasets import StaticTorchSigDataset\n",
-    "from torchsig.transforms.transforms import Spectrogram\n",
-    "from torchsig.transforms.target_transforms import (\n",
-    "    ClassName,\n",
-    "    Start,\n",
-    "    Stop,\n",
-    "    LowerFreq,\n",
-    "    UpperFreq,\n",
-    "    SNR\n",
-    ")\n",
     "import matplotlib.pyplot as plt\n",
     "\n",
-    "target_transform = [\n",
-    "    ClassName(),\n",
-    "    Start(),\n",
-    "    Stop(),\n",
-    "    LowerFreq(),\n",
-    "    UpperFreq(),\n",
-    "    SNR()\n",
-    "]\n",
-    "\n",
     "static_dataset = StaticTorchSigDataset(\n",
     "    root = root,\n",
-    "    impairment_level = impairment_level,\n",
-    "    transforms = Spectrogram(fft_size = fft_size),\n",
-    "    target_transforms = target_transform,\n",
+    "    target_labels=dataset.target_labels\n",
     ")\n",
-    "sample_rate = static_dataset.dataset_metadata.sample_rate\n",
-    "noise_power_db = static_dataset.dataset_metadata.noise_power_db\n",
+    "sample_rate = dataset.dataset_metadata.sample_rate\n",
+    "noise_power_db = dataset.dataset_metadata.noise_power_db\n",
     "\n",
     "num_show = 4\n",
     "num_cols = 2\n",
@@ -414,31 +376,19 @@
     "for i in range(num_show):\n",
     "\n",
     "    data, targets = static_dataset[i]\n",
+    "    print(targets)\n",
     "    ax = fig.add_subplot(num_rows,num_cols,i + 1)\n",
-    "\n",
     "    pos = ax.imshow(data,extent=[xmin,xmax,ymin,ymax],aspect='auto',cmap='Wistia',vmin=noise_power_db)\n",
     "    fig.colorbar(pos, ax=ax, label='SNR')\n",
     "\n",
-    "    if (isinstance(targets,tuple)):\n",
-    "        t = targets\n",
+    "    for t in targets:\n",
     "        classname, start, stop, lower, upper, snr = t\n",
     "\n",
     "        # convert normalized time into real-world time\n",
-    "        start_time = start * max_time\n",
-    "        stop_time = stop * max_time\n",
+    "        start_time = float(start) * max_time\n",
+    "        stop_time = float(stop) * max_time\n",
     "\n",
-    "        update_spectrogram ( ax, start_time, stop_time, lower, upper)\n",
-    "\n",
-    "    elif (isinstance(targets,list)):\n",
-    "        for t in targets:\n",
-    "            classname, start, stop, lower, upper, snr = t\n",
-    "\n",
-    "            # convert normalized time into real-world time\n",
-    "            start_time = start * max_time\n",
-    "            stop_time = stop * max_time\n",
-    "\n",
-    "            update_spectrogram ( ax, start_time, stop_time, lower, upper)\n",
-    "            "
+    "        update_spectrogram( ax, start_time, stop_time, lower, upper)"
    ]
   },
   {
@@ -459,7 +409,7 @@
     "import matplotlib.pyplot as plt\n",
     "from tqdm.notebook import tqdm\n",
     "\n",
-    "class_list = static_dataset.dataset_metadata.class_list\n",
+    "class_list = dataset.dataset_metadata.class_list\n",
     "class_counter = {class_name: 0 for class_name in class_list}\n",
     "snr_list = []\n",
     "num_signals_per_sample = []\n",
@@ -494,7 +444,7 @@
    "source": [
     "# Class Distribution Pie Chart\n",
     "# by default, the class distribution is None aka uniform\n",
-    "print(f\"Class Distribution Setting: {static_dataset.dataset_metadata.class_distribution}\")\n",
+    "print(f\"Class Distribution Setting: {dataset.dataset_metadata.class_distribution}\")\n",
     "plt.figure(figsize=(15, 15))\n",
     "plt.pie(class_counts, labels = class_names)\n",
     "plt.title(\"Class Distribution Pie Chart\")"
@@ -523,9 +473,9 @@
    "source": [
     "# Number of signals per sample Distribution\n",
     "import numpy as np\n",
-    "# Wideband's default number of signals per sample is 3\n",
-    "print(f\"Min num signals Setting: {static_dataset.dataset_metadata.num_signals_min}\")\n",
-    "print(f\"Max num signals Setting: {static_dataset.dataset_metadata.num_signals_max}\")\n",
+    "# Default number of signals per sample is 3\n",
+    "print(f\"Min num signals Setting: {dataset.dataset_metadata.num_signals_min}\")\n",
+    "print(f\"Max num signals Setting: {dataset.dataset_metadata.num_signals_max}\")\n",
     "\n",
     "total = sum(num_signals_per_sample)\n",
     "avg = np.mean(np.asarray(num_signals_per_sample))\n",
@@ -546,8 +496,8 @@
    "source": [
     "# SNR Distributions\n",
     "# Default min = 0 db and max = 50 db\n",
-    "print(f\"Min SNR Setting: {static_dataset.dataset_metadata.snr_db_min}\")\n",
-    "print(f\"Max SNR Setting: {static_dataset.dataset_metadata.snr_db_max}\")\n",
+    "print(f\"Min SNR Setting: {dataset.dataset_metadata.snr_db_min}\")\n",
+    "print(f\"Max SNR Setting: {dataset.dataset_metadata.snr_db_max}\")\n",
     "plt.figure(figsize=(11, 4))\n",
     "plt.hist(x=snr_list, bins=100)\n",
     "plt.title(\"SNR Distribution\")\n",
@@ -559,8 +509,10 @@
    "cell_type": "markdown",
    "metadata": {},
    "source": [
-    "### Customizing Datasets\n",
-    "In order to access previosuly generated examples, or save the finite dataset for later, use the `DatasetCreator`. Pass in the Dataset to be saved, where to write the dataset (root), and whether to overwrite any exisitng datasets. `num_samples` must be defined, otherwise the `DatasetCreator` will attempt to create an infinite dataset."
+    "## Applying Impairments to datasets\n",
+    "To add realism to synthetic datasets, we've created some sets of transforms that simulate real world signal impairments on the data. These can be found in `transforms/impairments.py`, and come in multiple impairment 'levels' which determine how much the signal is being impaired. More on impairments can be found in the `examples/transforms/impairments notebook`.\n",
+    "\n",
+    "In the example below, we are applying level 1 impairments to a dataset."
    ]
   },
   {
@@ -569,57 +521,7 @@
    "metadata": {},
    "outputs": [],
    "source": [
-    "from torchsig.datasets.dataset_metadata import DatasetMetadata\n",
-    "from torchsig.utils.writer import DatasetCreator\n",
-    "from torchsig.signals.signal_lists import TorchSigSignalLists\n",
-    "from torchsig.datasets.datasets import TorchSigIterableDataset\n",
-    "\n",
-    "root = \"./datasets/create_dataset_example_custom\"\n",
-    "#class_list = TorchSigSignalLists.all_signals # all signals\n",
-    "#class_list = TorchSigSignalLists.fsk_signals # FSK only\n",
-    "#class_list = TorchSigSignalLists.constellation_signals # QAM/PSK/ASK/OOK only\n",
-    "class_list = TorchSigSignalLists.ofdm_signals + TorchSigSignalLists.fsk_signals\n",
-    "\n",
-    "num_samples = 4 # minimum needed for plot below\n",
-    "num_signals_max = 10\n",
-    "num_signals_min = 5\n",
-    "\n",
-    "sample_rate = 10e6\n",
-    "dataset_finite_metadata = DatasetMetadata(\n",
-    "    sample_rate = sample_rate,\n",
-    "    num_iq_samples_dataset = num_iq_samples_dataset,\n",
-    "    fft_size = fft_size,\n",
-    "    impairment_level = impairment_level,\n",
-    "    num_signals_max = num_signals_max,\n",
-    "    num_signals_min = num_signals_min,\n",
-    "    snr_db_min=10,\n",
-    "    snr_db_max=20,\n",
-    "    signal_bandwidth_min=sample_rate/6,\n",
-    "    signal_bandwidth_max=sample_rate/5,\n",
-    "    signal_duration_min=0.05*num_iq_samples_dataset/sample_rate, # 5% of full duration\n",
-    "    signal_duration_max=0.10*num_iq_samples_dataset/sample_rate, # 10% of full duration\n",
-    "    signal_center_freq_min=(sample_rate/4)*0.9, # CFO is centered around sample_rate/4 with 20% error\n",
-    "    signal_center_freq_max=(sample_rate/4)*1.1,\n",
-    "    cochannel_overlap_probability=0, # enforce no co-channel interference\n",
-    "    num_samples = num_samples,\n",
-    "    class_list = class_list\n",
-    ")\n",
-    "\n",
-    "dataset_finite = TorchSigIterableDataset(\n",
-    "    dataset_metadata = dataset_finite_metadata\n",
-    ")\n",
-    "\n",
-    "dataset_creator = DatasetCreator(\n",
-    "    dataset = dataset_finite,\n",
-    "    root = root,\n",
-    "    overwrite = True,\n",
-    "    # increase the batch size and num_workers to speed up\n",
-    "    # batch_size = 16,\n",
-    "    # num_workers = 16,\n",
-    "    multithreading=False\n",
-    ")\n",
-    "\n",
-    "dataset_creator.create()"
+    "from torchsig.transforms.impairments import Impairments"
    ]
   },
   {
@@ -628,26 +530,33 @@
    "metadata": {},
    "outputs": [],
    "source": [
-    "def update_spectrogram ( ax, start_time, stop_time, lower, upper):\n",
+    "impairments = Impairments(level=1)\n",
+    "burst_impairments = impairments.signal_transforms\n",
+    "whole_signal_impairments = impairments.dataset_transforms\n",
     "\n",
-    "    ax.plot([start_time,start_time],[lower,upper],'b',alpha=0.5)\n",
-    "    ax.plot([stop_time, stop_time],[lower,upper],'b',alpha=0.5)\n",
-    "    ax.plot([start_time,stop_time],[lower,lower],'b',alpha=0.5)\n",
-    "    ax.plot([start_time,stop_time],[upper,upper],'b',alpha=0.5)\n",
-    "    textDisplay = str(classname) + ', SNR = ' + str(snr) + ' dB'\n",
-    "    ax.text(start_time,lower,textDisplay, bbox=dict(facecolor='w', alpha=0.5, linewidth=0))\n",
-    "    ax.set_xlim([xmin,xmax])\n",
-    "    ax.set_ylim([ymin,ymax])\n",
-    "    ax.set_ylabel(\"Frequency (Hz)\")\n",
-    "    ax.set_xlabel(f\"Time ({xunits})\")"
+    "burst_impairments, whole_signal_impairments"
    ]
   },
   {
-   "cell_type": "markdown",
+   "cell_type": "code",
+   "execution_count": null,
    "metadata": {},
+   "outputs": [],
    "source": [
-    "### Read and Display Customized Results\n",
-    "The following code reads back the customized dataset "
+    "dataset_impaired = TorchSigIterableDataset(\n",
+    "    dataset_metadata=dataset_finite_metadata, \n",
+    "    transforms=[whole_signal_impairments, Spectrogram(fft_size=fft_size)], \n",
+    "    component_transforms=[burst_impairments], \n",
+    "    target_labels=[])\n",
+    "\n",
+    "dataset_unimpaired = TorchSigIterableDataset(\n",
+    "    dataset_metadata=dataset_finite_metadata, \n",
+    "    transforms=[Spectrogram(fft_size=fft_size)], \n",
+    "    component_transforms=[], \n",
+    "    target_labels=[])\n",
+    "\n",
+    "dataset_impaired.seed(seed)\n",
+    "dataset_unimpaired.seed(seed)"
    ]
   },
   {
@@ -656,98 +565,34 @@
    "metadata": {},
    "outputs": [],
    "source": [
-    "from torchsig.datasets.datasets import StaticTorchSigDataset\n",
-    "from torchsig.transforms.transforms import Spectrogram\n",
-    "from torchsig.transforms.target_transforms import (\n",
-    "    ClassName,\n",
-    "    Start,\n",
-    "    Stop,\n",
-    "    LowerFreq,\n",
-    "    UpperFreq,\n",
-    "    SNR\n",
-    ")\n",
-    "import matplotlib.pyplot as plt\n",
-    "\n",
-    "target_transform = [\n",
-    "    ClassName(),\n",
-    "    Start(),\n",
-    "    Stop(),\n",
-    "    LowerFreq(),\n",
-    "    UpperFreq(),\n",
-    "    SNR()\n",
-    "]\n",
-    "\n",
-    "static_dataset = StaticTorchSigDataset(\n",
-    "    root = root,\n",
-    "    impairment_level = impairment_level,\n",
-    "    transforms = Spectrogram(fft_size = fft_size),\n",
-    "    target_transforms = target_transform,\n",
-    ")\n",
-    "sample_rate = static_dataset.dataset_metadata.sample_rate\n",
-    "noise_power_db = static_dataset.dataset_metadata.noise_power_db\n",
-    "\n",
-    "num_show = 4\n",
-    "num_cols = 2\n",
-    "num_rows = num_show // num_cols\n",
-    "\n",
-    "fig = plt.figure(figsize=(18,12))\n",
-    "fig.tight_layout()\n",
-    "\n",
-    "max_time = num_iq_samples_dataset / sample_rate\n",
-    "\n",
-    "ns_time = 1e-9\n",
-    "us_time = 1e-6\n",
-    "ms_time = 1e-3\n",
-    "s_time = 1\n",
-    "\n",
-    "if (max_time < ns_time):\n",
-    "    max_time /= ns_time\n",
-    "    xunits = 'ns'\n",
-    "elif (max_time < us_time):\n",
-    "    max_time /= us_time\n",
-    "    xunits = 'us'\n",
-    "elif (max_time < ms_time):\n",
-    "    max_time /= ms_time\n",
-    "    xunits = 'ms'\n",
-    "else:\n",
-    "    max_time /= s_time\n",
-    "    xunits = 's'\n",
     "\n",
-    "xmin = 0 * max_time\n",
-    "xmax = 1 * max_time\n",
-    "\n",
-    "ymin = -sample_rate / 2\n",
-    "ymax = sample_rate / 2\n",
-    "\n",
-    "for i in range(num_show):\n",
-    "\n",
-    "    data, targets = static_dataset[i]\n",
-    "    ax = fig.add_subplot(num_rows,num_cols,i + 1)\n",
-    "\n",
-    "    pos = ax.imshow(data,extent=[xmin,xmax,ymin,ymax],aspect='auto',cmap='Wistia',vmin=noise_power_db)\n",
-    "    fig.colorbar(pos, ax=ax, label='SNR')\n",
-    "\n",
-    "    if (isinstance(targets,tuple)):\n",
-    "        t = targets\n",
-    "        classname, start, stop, lower, upper, snr = t\n",
-    "\n",
-    "        # convert normalized time into real-world time\n",
-    "        start_time = start * max_time\n",
-    "        stop_time = stop * max_time\n",
-    "\n",
-    "        update_spectrogram ( ax, start_time, stop_time, lower, upper)\n",
-    "\n",
-    "    elif (isinstance(targets,list)):\n",
-    "        for t in targets:\n",
-    "            classname, start, stop, lower, upper, snr = t\n",
-    "\n",
-    "            # convert normalized time into real-world time\n",
-    "            start_time = start * max_time\n",
-    "            stop_time = stop * max_time\n",
-    "\n",
-    "            update_spectrogram ( ax, start_time, stop_time, lower, upper)\n",
-    "            "
+    "fig = plt.figure(figsize=(12,12))\n",
+    "ax = fig.add_subplot(1,2,1)\n",
+    "ax.imshow(next(dataset_unimpaired),cmap='Wistia',vmin=0)\n",
+    "ax.set_xlabel('Time Axis')\n",
+    "ax.set_ylabel('Frequency Axis')\n",
+    "ax.set_title('Un-Impaired Data')\n",
+    "\n",
+    "ax2 = fig.add_subplot(1,2,2)\n",
+    "ax2.imshow(next(dataset_impaired),cmap='Wistia',vmin=0)\n",
+    "ax2.set_xlabel('Time Axis')\n",
+    "ax2.set_ylabel('Frequency Axis')\n",
+    "ax2.set_title('Impaired Data')"
    ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": []
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": []
   }
  ],
  "metadata": {
@@ -755,7 +600,7 @@
    "formats": "ipynb,py:percent"
   },
   "kernelspec": {
-   "display_name": "Python 3",
+   "display_name": "venv",
    "language": "python",
    "name": "python3"
   },
@@ -769,9 +614,9 @@
    "name": "python",
    "nbconvert_exporter": "python",
    "pygments_lexer": "ipython3",
-   "version": "3.10.12"
+   "version": "3.12.3"
   }
  },
  "nbformat": 4,
- "nbformat_minor": 2
+ "nbformat_minor": 4
 }
diff --git a/examples/create_dataset_example.yaml b/examples/create_dataset_example.yaml
index 28f50d85f..e16d3682b 100644
--- a/examples/create_dataset_example.yaml
+++ b/examples/create_dataset_example.yaml
@@ -2,7 +2,6 @@ required:
   num_iq_samples_dataset: 4096
   fft_size: 64
   num_signals_max: 5
-  impairment_level: 1
 
 overrides:
   num_samples: 10
diff --git a/examples/defaults_example.ipynb b/examples/defaults_example.ipynb
new file mode 100644
index 000000000..8ae8e36ae
--- /dev/null
+++ b/examples/defaults_example.ipynb
@@ -0,0 +1,151 @@
+{
+ "cells": [
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "# Default Datasets\n",
+    "This notebook showcases how to quickly make data using the default_dataset and deefault_dataloader utils.\n",
+    "\n",
+    "---"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "## Dataset Dataset \n",
+    "default_dataset returns a TorchsigIterableDataset, with plausible default arguments for any fields not directly provided. It takes lists of transforms and component transforms, and a list of target_labels like a normal TorchsigIterableDataset, and can also be given an impairment_level, which will load and add in some signal impairments we've found useful for simulating RF signals for machine learning. All arguments are optional. default_dataset() will return a TorchsigIterableDataset that outputs single Signal objects no impairmen_level=0 and no transforms."
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "from torchsig.utils.defaults import default_dataset"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "dataset = default_dataset(target_labels=[\"class_name\"])"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "next(dataset)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "dataset = default_dataset(target_labels=[\"class_name\"], num_signals_max=5, num_signals_min=2)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "next(dataset)"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "## Dataset Dataloader \n",
+    "default_dataloader returns a WorkerSeedingDataloader, with plausible default arguments for any fields not directly provided. It takes a seed to use for randomness, and a num_workers, collate_fn, and batch_size for the dataloader. All other arguments passed in will be passed down to the dataset it creates, so default_dataloader(target_labels=\\[\"snr_db\"\\]) is valid and will return the snr_db field of each signal from the dataset. All arguments are optional. There is currently no default way to collate Signal objects into Tensors in a dataloader, so in general you should pass target_labels into the function. A custom collate_fn could also be passed in to handle Signal objects as needed."
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "from torchsig.utils.defaults import default_dataloader"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "dataloader = default_dataloader(target_labels=[\"class_name\"])"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "next(iter(dataloader))"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "dataloader = default_dataloader(collate_fn=lambda x: x)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "next(iter(dataloader))"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": []
+  }
+ ],
+ "metadata": {
+  "jupytext": {
+   "formats": "ipynb,py:percent"
+  },
+  "kernelspec": {
+   "display_name": "Python 3 (ipykernel)",
+   "language": "python",
+   "name": "python3"
+  },
+  "language_info": {
+   "codemirror_mode": {
+    "name": "ipython",
+    "version": 3
+   },
+   "file_extension": ".py",
+   "mimetype": "text/x-python",
+   "name": "python",
+   "nbconvert_exporter": "python",
+   "pygments_lexer": "ipython3",
+   "version": "3.12.3"
+  }
+ },
+ "nbformat": 4,
+ "nbformat_minor": 4
+}
diff --git a/examples/detector_example.ipynb b/examples/detector_example.ipynb
index a16a05415..5b8a27979 100644
--- a/examples/detector_example.ipynb
+++ b/examples/detector_example.ipynb
@@ -11,15 +11,6 @@
     "---"
    ]
   },
-  {
-   "cell_type": "code",
-   "execution_count": null,
-   "metadata": {},
-   "outputs": [],
-   "source": [
-    "%matplotlib inline"
-   ]
-  },
   {
    "cell_type": "markdown",
    "metadata": {},
@@ -37,7 +28,7 @@
    "source": [
     "# Variables\n",
     "from torchsig.transforms.transforms import Spectrogram\n",
-    "from torchsig.transforms.target_transforms import YOLOLabel\n",
+    "from torchsig.transforms.metadata_transforms import YOLOLabel\n",
     "from torchsig.signals.signal_lists import TorchSigSignalLists\n",
     "from tqdm.notebook import tqdm\n",
     "\n",
@@ -46,14 +37,13 @@
     "num_iq_samples_dataset = fft_size ** 2\n",
     "class_list = TorchSigSignalLists.all_signals\n",
     "num_classes = len(class_list)\n",
-    "num_train = 100 # size of train dataset\n",
-    "num_val = 10 # size of validation dataset\n",
+    "num_train = 20 # size of train dataset\n",
+    "num_val = 5 # size of validation dataset\n",
     "\n",
     "# transform data into a spectrogram image\n",
-    "transforms = [Spectrogram(fft_size=fft_size)]\n",
+    "transforms = [Spectrogram(fft_size=fft_size), YOLOLabel()]\n",
     "# YOLO labels are expected to be (class index, x center, y center, width, height)\n",
-    "# all normalized to zero, with (0,0) being upper left corner\n",
-    "target_transforms = [YOLOLabel()]"
+    "# all normalized to zero, with (0,0) being upper left corner"
    ]
   },
   {
@@ -75,12 +65,12 @@
     "    impairment_level = 2,\n",
     "    num_signals_min = 1,\n",
     "    num_signals_max = 3,\n",
-    "    transforms=transforms,\n",
-    "    target_transforms=target_transforms,\n",
     ")\n",
     "\n",
     "dataset = TorchSigIterableDataset(\n",
-    "    dataset_metadata = dataset_metadata\n",
+    "    dataset_metadata = dataset_metadata,\n",
+    "    transforms=transforms,\n",
+    "    target_labels=[\"yolo_label\"]\n",
     ")\n",
     "\n",
     "# show sample from dataset\n",
@@ -257,7 +247,7 @@
    "source": [
     "results = model.train(\n",
     "    data=config_name, \n",
-    "    epochs=5,\n",
+    "    epochs=3,\n",
     "    batch=1,\n",
     "    imgsz=fft_size,\n",
     "    device=0 if torch.cuda.is_available() else \"cpu\",\n",
@@ -329,5 +319,5 @@
   }
  },
  "nbformat": 4,
- "nbformat_minor": 2
+ "nbformat_minor": 4
 }
diff --git a/examples/filehandler_example.ipynb b/examples/filehandler_example.ipynb
index a3c67b879..b66b91ca5 100644
--- a/examples/filehandler_example.ipynb
+++ b/examples/filehandler_example.ipynb
@@ -6,7 +6,7 @@
    "source": [
     "# Custom File Handler Example\n",
     "\n",
-    "This notebook shows how to create a custom file handler to write the datasets in a different format. For this example, we will show how to write data as a PNG image.\n",
+    "This notebook shows how to create a custom file handler to write the datasets in a different format. For this example, we will show how to write data as a PNG image and target labels as a yaml file.\n",
     "\n",
     "---"
    ]
@@ -15,37 +15,9 @@
    "cell_type": "markdown",
    "metadata": {},
    "source": [
-    "The `DatasetCreator` and any `StaticDatasets` use a `TorchSigFileHandler` to write and read data, respectively. By default, they both use the `ZarrFileHandler` class. But if you want the dataset to be written and read differently, you can create a subclass of `TorchSigFileHandler`. \n",
+    "The `DatasetCreator` and any `StaticDatasets` use a `BaseFileHandler` to write and read data, respectively. By default, they both use the `HDF5FileHandler` class. But if you want the dataset to be written and read differently, you can create a subclass of `BaseFileHandler`. \n",
     "\n",
-    "\n",
-    "---\n",
-    "\n",
-    "There are 3 functions you are required to implement:\n",
-    "```\n",
-    "# writes a batch of data to disk\n",
-    "def write(self, batch_idx: int, batch: Any) -> None:\n",
-    "\n",
-    "# determines size of dataset on disk\n",
-    "@staticmethod\n",
-    "def size(dataset_path: str) -> int:\n",
-    "\n",
-    "# loads idx into memory\n",
-    "@staticmethod\n",
-    "def static_load(filename:str, idx: int) -> Tuple[np.ndarray, List[Dict[str, Any]]]:\n",
-    "\n",
-    "```\n",
-    "\n",
-    "You can override these functions as needed:\n",
-    "```\n",
-    "# any pre-requisite set up before the file handler writers\n",
-    "def _setup(self) -> None:\n",
-    "\n",
-    "# any post processes to run after all the data is writtern to disk\n",
-    "def teardown(self) -> None:\n",
-    "\n",
-    "# determine if a dataset exists on disk\n",
-    "def exists(self) -> bool:\n",
-    "```"
+    "**Note**: As of TorchSig 2.0, the default file handler is HDF5-based for improved performance and metadata storage."
    ]
   },
   {
@@ -54,113 +26,106 @@
    "metadata": {},
    "outputs": [],
    "source": [
-    "from torchsig.utils.file_handlers.base_handler import TorchSigFileHandler\n",
-    "\n",
+    "from torchsig.datasets.dataset_metadata import load_dataset_metadata\n",
+    "from torchsig.utils.file_handlers.base_handler import FileWriter, FileReader, BaseFileHandler\n",
     "import cv2\n",
+    "import yaml\n",
+    "import pathlib\n",
     "import numpy as np\n",
     "\n",
-    "import os\n",
-    "from typing import List, Any, Tuple, Dict\n",
-    "import pickle\n",
+    "class SpectrogramWriter(FileWriter):\n",
     "\n",
+    "    def _setup(self) -> None:\n",
+    "        \"\"\"Setup directory for storing spectrogram images and targets.\"\"\"\n",
+    "        self.spectrogram_dir = self.root.joinpath(\"spectrograms\")\n",
+    "        self.target_dir = self.root.joinpath(\"targets\")\n",
+    "        self.spectrogram_dir.mkdir(parents=True, exist_ok=True)\n",
+    "        self.target_dir.mkdir(parents=True, exist_ok=True)\n",
+    "\n",
+    "    def write(self, batch_idx: int, batch: list) -> None:\n",
+    "        \"\"\"Write a single batch of Signals as spectrograms and targets to disk.\n",
+    "\n",
+    "        Args:\n",
+    "            batch_idx (int): Index of the batch being written.\n",
+    "            batch (tuple): List of Signal objects in batch\n",
+    "\n",
+    "        \"\"\"\n",
+    "        for idx, sig in enumerate(batch):\n",
+    "\n",
+    "            spectrogram = sig.data\n",
+    "\n",
+    "            metadatas = sig.get_full_metadata()\n",
+    "            targets = {i: [] for i in range(len(metadatas))}\n",
+    "            for i, m in enumerate(metadatas):\n",
+    "                for k, v in m.to_dict().items():\n",
+    "                    if v is not None:\n",
+    "                        targets[i].append(v)\n",
+    "\n",
+    "            # First normalize data from (0-255)\n",
+    "            mi = spectrogram.min()\n",
+    "            ma = spectrogram.max()\n",
+    "            spectrogram = ((spectrogram - mi) / (ma - mi)) * 255\n",
+    "            # convert to 8-bit\n",
+    "            spectrogram = spectrogram.astype(np.uint8)\n",
     "\n",
-    "class ImageFileHandler(TorchSigFileHandler):\n",
+    "            # apply colormap\n",
+    "            spectrogram = cv2.applyColorMap(spectrogram, cv2.COLORMAP_HOT)\n",
     "\n",
-    "    file_ext = \".png\"\n",
+    "            # Save spectrogram as PNG\n",
+    "            spectrogram_path = self.spectrogram_dir.joinpath(f\"spectrogram_{batch_idx * len(batch) + idx}.png\")\n",
+    "            cv2.imwrite(str(spectrogram_path), spectrogram)\n",
     "\n",
-    "    def __init__(\n",
-    "        self,\n",
-    "        root: str,\n",
-    "        train: bool = None,\n",
-    "        batch_size: int = 1\n",
-    "    ):\n",
-    "        super().__init__(\n",
-    "            root = root,\n",
-    "            batch_size = batch_size\n",
-    "        )\n",
+    "            # Save target as YAML\n",
+    "            target_path = self.target_dir.joinpath(f\"target_{batch_idx * len(batch) + idx}.yaml\")\n",
+    "            with open(target_path, \"w\") as f:\n",
+    "                yaml.dump(targets, f, default_flow_style=False)\n",
     "\n",
-    "        # define a colormap for the image\n",
-    "        self.colormap = cv2.COLORMAP_HOT\n",
+    "    def __len__(self) -> int:\n",
+    "        \"\"\"Return the number of saved spectrograms.\"\"\"\n",
+    "        return len(list(self.spectrogram_dir.glob(\"spectrogram_*.png\")))\n",
     "\n",
-    "    def _setup(self) -> None:\n",
-    "        # create images and targets folder\n",
-    "        os.makedirs(f\"{self.root}/images\", exist_ok=True)\n",
-    "        os.makedirs(f\"{self.root}/targets\", exist_ok=True)\n",
-    "\n",
-    "    def exists(self) -> bool:\n",
-    "        # checks images/ and targets/ folders are created\n",
-    "        # and not empty\n",
-    "        images_path =f\"{self.root}/images\"\n",
-    "        targets_path = f\"{self.root}/targets\"\n",
-    "\n",
-    "        images_exist = os.path.exists(images_path) and len(os.listdir(images_path)) > 0\n",
-    "        targets_exist = os.path.exists(targets_path) and len(os.listdir(targets_path)) > 0\n",
-    "\n",
-    "        return images_exist and targets_exist\n",
-    "\n",
-    "    @staticmethod\n",
-    "    def size(dataset_path: str) -> int:\n",
-    "        # given path to dataset on disk\n",
-    "        # return dataset size\n",
-    "        # return how many files in images/ or targets (min)\n",
-    "        images_path =f\"{dataset_path}/images\"\n",
-    "        targets_path = f\"{dataset_path}/targets\"\n",
-    "\n",
-    "        num_images = len(os.listdir(images_path))\n",
-    "        num_targets = len(os.listdir(targets_path))\n",
-    "\n",
-    "        return min(num_images, num_targets)\n",
-    "\n",
-    "    def write(self, batch_idx: int, batch: Any) -> None:\n",
-    "        # writes a batch from dataset's __getitem__\n",
-    "        start_idx = batch_idx * len(batch[0])\n",
-    "        stop_idx = start_idx + len(batch[0])\n",
-    "\n",
-    "        data, targets = batch\n",
-    "        \n",
-    "        for i,(d,t) in enumerate(zip(data, targets)):\n",
-    "            # convert data (H,W) `-> (H,W,3) with 3 channels RGB\n",
-    "            # first normalize data from (0-255)\n",
-    "            mi = d.min()\n",
-    "            ma = d.max()\n",
-    "\n",
-    "            d = ((d - mi) / (ma - mi)) * 255\n",
-    "            # convert to ints\n",
-    "            d = d.astype(np.uint8)\n",
+    "class SpectrogramReader(FileReader):\n",
     "\n",
-    "            # apply colormap\n",
-    "            if self.colormap:\n",
-    "                d = cv2.applyColorMap(d, self.colormap)\n",
-    "            \n",
-    "            self._write_image(d, start_idx+i)\n",
-    "            self._write_targets(t, start_idx+i)\n",
-    "\n",
-    "    @staticmethod\n",
-    "    def static_load(filename:str, idx: int) -> Tuple[np.ndarray, List[Dict[str, Any]]]:\n",
-    "        # loads sample `idx` from `filename` into memory\n",
-    "        # method can be used without instantiating class\n",
-    "        # used for just reading\n",
-    "        image = cv2.imread(f\"{filename}/images/{idx}{ImageFileHandler.file_ext}\")\n",
-    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
-    "\n",
-    "        with open(f\"{filename}/targets/{idx}.pkl\", 'rb') as f:\n",
-    "            targets = pickle.load(f)\n",
-    "        \n",
-    "        return image, targets\n",
-    "\n",
-    "    # Helper Functions\n",
-    "\n",
-    "    def _write_image(self, data: np.ndarray, idx: int) -> None:\n",
-    "        # convert from RGB to BGR\n",
-    "        # data = cv2.cvtColor(data, cv2.COLOR_RGB2BGR)\n",
-    "        filename = f\"{self.root}/images/{idx}{self.file_ext}\"\n",
-    "        cv2.imwrite(filename, data)\n",
-    "\n",
-    "    def _write_targets(self, targets: Any, idx: int) -> None:\n",
-    "        # pickle targets\n",
-    "        filename = f\"{self.root}/targets/{idx}.pkl\"\n",
-    "        with open(filename, 'wb') as f:\n",
-    "            pickle.dump(targets, f)"
+    "\n",
+    "    def __init__(self, root):\n",
+    "        super().__init__(root=root)\n",
+    "        self.spectrogram_dir = self.root.joinpath(\"spectrograms\")\n",
+    "        self.target_dir = self.root.joinpath(\"targets\")\n",
+    "        self.dataset_metadata = load_dataset_metadata(self.dataset_info_filepath)\n",
+    "\n",
+    "\n",
+    "    def read(self, idx: int) -> tuple:\n",
+    "        \"\"\"Read a spectrogram and target by index.\n",
+    "\n",
+    "        Args:\n",
+    "            idx (int): Index of the data to read.\n",
+    "\n",
+    "        Returns:\n",
+    "            tuple: (spectrogram, target)\n",
+    "        \"\"\"\n",
+    "        # Read the spectrogram as a NumPy array\n",
+    "        spectrogram_path = self.root.joinpath(\"spectrograms\", f\"spectrogram_{idx}.png\")\n",
+    "        spectrogram = cv2.imread(str(spectrogram_path), cv2.IMREAD_GRAYSCALE)\n",
+    "\n",
+    "        # Read the target as a dictionary\n",
+    "        target_path = self.root.joinpath(\"targets\", f\"target_{idx}.yaml\")\n",
+    "        targets = []\n",
+    "        with open(target_path, \"r\") as f:\n",
+    "            raw_targets = yaml.load(f, Loader=yaml.FullLoader)\n",
+    "            for item in raw_targets.keys():\n",
+    "                t = raw_targets[item]\n",
+    "                targets.append(t)\n",
+    "\n",
+    "        return spectrogram, targets\n",
+    "\n",
+    "    def size(self) -> int:\n",
+    "        \"\"\"Return the total number of spectrograms in the dataset.\"\"\"\n",
+    "        spectrograms_path = self.root.joinpath(\"spectrograms\")\n",
+    "        return len(list(spectrograms_path.glob(\"spectrogram_*.png\")))\n",
+    "\n",
+    "    def __len__(self) -> int:\n",
+    "        \"\"\"Return the total number of spectrograms in the dataset.\"\"\"\n",
+    "        return self.size()\n"
    ]
   },
   {
@@ -172,46 +137,48 @@
     "# Use this file handler\n",
     "from torchsig.datasets.dataset_metadata import DatasetMetadata\n",
     "from torchsig.datasets.datasets import TorchSigIterableDataset, StaticTorchSigDataset\n",
-    "from torchsig.utils.writer import DatasetCreator\n",
+    "from torchsig.utils.writer import DatasetCreator, default_collate_fn\n",
     "from torchsig.transforms.transforms import Spectrogram\n",
-    "from torchsig.transforms.target_transforms import ClassName\n",
+    "from torchsig.utils.data_loading import WorkerSeedingDataLoader\n",
     "\n",
     "root = \"./datasets/filehandler_example\"\n",
     "fft_size = 512\n",
     "num_iq_samples_dataset = fft_size ** 2\n",
-    "impairment_level = 0\n",
-    "num_samples = 10\n",
+    "dataset_length = 10\n",
     "num_signals_min = 1\n",
-    "num_signals_max = 1\n",
+    "num_signals_max = 4\n",
     "\n",
     "transforms = [Spectrogram(fft_size=fft_size)]\n",
-    "target_transforms = [ClassName()]\n",
     "\n",
     "md = DatasetMetadata(\n",
     "    num_iq_samples_dataset=num_iq_samples_dataset,\n",
     "    fft_size=fft_size,\n",
-    "    impairment_level=impairment_level,\n",
-    "    num_samples=num_samples,\n",
-    "    transforms=transforms,\n",
-    "    target_transforms=target_transforms,\n",
     "    num_signals_min = num_signals_min,\n",
     "    num_signals_max = num_signals_max\n",
     ")\n",
     "\n",
+    "dataset = TorchSigIterableDataset(\n",
+    "    dataset_metadata=md, \n",
+    "    transforms=transforms, \n",
+    "    \n",
+    "    target_labels=[\"class_name\",\"class_index\"]\n",
+    ")\n",
+    "dataloader = WorkerSeedingDataLoader(dataset, collate_fn=default_collate_fn)\n",
+    "\n",
     "dc = DatasetCreator(\n",
-    "    dataset=TorchSigIterableDataset(dataset_metadata=md),\n",
+    "    dataloader=dataloader,\n",
+    "    dataset_length=dataset_length,\n",
     "    root=root,\n",
     "    overwrite=True,\n",
     "    # use our custom file handler class\n",
-    "    file_handler=ImageFileHandler\n",
+    "    file_handler=SpectrogramWriter\n",
     ") \n",
     "dc.create()\n",
     "\n",
     "s = StaticTorchSigDataset(\n",
     "    root=root,\n",
-    "    impairment_level=impairment_level,\n",
     "    # be sure to use the same class that was written to disk\n",
-    "    file_handler_class=ImageFileHandler\n",
+    "    file_handler_class=SpectrogramReader\n",
     ")\n",
     "\n",
     "data, targets = s[0]\n",
@@ -235,7 +202,7 @@
  ],
  "metadata": {
   "kernelspec": {
-   "display_name": "Python 3",
+   "display_name": "venv",
    "language": "python",
    "name": "python3"
   },
@@ -249,9 +216,9 @@
    "name": "python",
    "nbconvert_exporter": "python",
    "pygments_lexer": "ipython3",
-   "version": "3.10.12"
+   "version": "3.12.3"
   }
  },
  "nbformat": 4,
- "nbformat_minor": 2
+ "nbformat_minor": 4
 }
diff --git a/examples/getting_started.ipynb b/examples/getting_started.ipynb
index dcc6f9740..705851862 100644
--- a/examples/getting_started.ipynb
+++ b/examples/getting_started.ipynb
@@ -5,7 +5,8 @@
    "metadata": {},
    "source": [
     "# TorchSig: Getting Started\n",
-    "This notebook gives an overview of the terms and capabilities of TorchSig.\n",
+    "\n",
+    "This notebook gives an overview of the terms and capabilities of TorchSig. There is no code to run.\n",
     "\n",
     "---"
    ]
@@ -14,22 +15,25 @@
    "cell_type": "markdown",
    "metadata": {},
    "source": [
-    "## Signals\n",
+    "## TorchSig Signals\n",
     "A signal has many definitions in the digital signal processing, radio frequency, and machine learning world. Below we define precisely what we define as certain signals.\n",
     "\n",
+    "```python\n",
+    "from torchsig.signals.signal_types import SignalMetadata, SignalMetadataExternal, Signal\n",
+    "```\n",
+    "\n",
     "* **SignalMetadata**: Object that contains all the metadata for a Signal. There are 7 **core** metadata fields:\n",
     "    * center_freq: Normalized center frequency of signal.\n",
     "    * bandwidth: Normalized bandwidth of signal.\n",
     "    * start_in_samples: Start time of signal in terms of IQ data array idx.\n",
     "    * duration_in_samples: Duration of signal in terms of IQ data array idx.\n",
     "    * snr_db: Signal-to-Noise ratio in dB.\n",
-    "    * class_name: Signal class name/modulation type.\n",
-    "    * class_index: Class index of signal in dataset, which contains a list of all modulations being used.\n",
+    "    * class_name: Signal class name (e.g., modulation) type.\n",
+    "    * class_index: Class index of signal in dataset.\n",
     "    \n",
-    "    Then there are **derived** metadata fields, which are calculate from the 7 core fields. Derived fields for example include lower_freq, upper_freq, start, stop, ect.\n",
-    "* **Signal**: Object that represents a single signal burst. Contains IQ data and SignalMetadata. The **SignalBuilders** are responsible for creating a Signal object.\n",
-    "* **DatasetSignal**: Contains the base noise floor with Signal(s) placed inside it. Also called a **sample**. This represents collecting signals over a set bandwidth.\n",
-    "* **DatasetDict**: Same as DatasetSignal, but metadata is a list of dictionaries (that contain SignalMetadata). This makes performing target transforms much easier. Can also be called a **sample**.\n",
+    "    Then there are **derived** metadata fields, which are calculate from the 7 core fields. Derived fields for example include lower_freq, upper_freq, start, stop, etc.\n",
+    "* **SignalMetadataExternal**: Similar to **SignalMetadata**, but with not required/core metdata fields. This object is used during user imported data.\n",
+    "* **Signal**: Object that represents a single signal burst. Contains IQ data and SignalMetadata/SignalMetdataExternal. The **SignalBuilders** are responsible for creating a Signal object.\n",
     "\n",
     "---"
    ]
@@ -38,26 +42,41 @@
    "cell_type": "markdown",
    "metadata": {},
    "source": [
-    "## Transforms\n",
+    "## TorchSig Transforms\n",
     "\n",
-    "### Functionals\n",
-    "All core compute processes and logic parameters for transforms\n",
-    "* functions perform fundamental operations, but do not define parameters or random distributions/sampling of how the operations are applied or randomized\n",
-    "* Similiar to [Torchvision's transforms framework](https://pytorch.org/vision/0.9/transforms.html#functional-transforms)\n",
+    "```python\n",
+    "from torchsig.transforms.transforms import ...\n",
+    "from torchsig.transforms.functional import ...\n",
+    "from torchsig.transforms.metadata_transforms import ...\n",
+    "```\n",
     "\n",
-    "### Signal Transforms\n",
-    "Applied to Signal objects, which are created from the SignalBuilders. In other words, transforms that are applied to isolated bursts before being placed on noise floor. These can be understood as transmitter effects on the Signal(s).\n",
+    "### Transforms\n",
+    "Provide callable transform operations on TorchSig data.\n",
+    "* Used with Signal object to modify data\n",
+    "* Broad, general application range that include signal processing, communications channel effects, and dataset manipulation\n",
+    "* Often configure and call TorchSig Functionals for lower-level operations by controlling how data is modified and defining parameter distributions\n",
     "\n",
-    "Note that impairments are carefully applied within the SignalBuilder in a strict order to represent actual signal processing effects.\n",
+    "Transforms work at several levels of TorchSig data organization. When applied to Signal objects they transform these isolated signal bursts individually, often to model transmitter effects on signal I/Q data. When applied to Signal objects they transform the aggregate data within these samples, which were constructed with an arbitrary number of Signals. These sample-scale modifications often implement wideband channel or receiver effects, or perform dataset manipulations.\n",
     "\n",
-    "### Dataset Transforms\n",
-    "Applied to DatasetSignal objects, after all the IQ data of all Signal object(s) are placed onto the noise floor. These transforms are applied to the whole IQ data, including the bursts and noise floor. In particular, these transforms correspond to wideband effects, such as channel or receiver effects.\n",
+    "### Functionals\n",
+    "Core computational processes and algorithm implementations for transforming data.\n",
+    "* Functions that perform fundamental data operations, but do not specify how input parameters are distributed or selected\n",
+    "* Similiar to the organization of [Torchvision's transforms framework](https://pytorch.org/vision/0.9/transforms.html#functional-transforms)\n",
     "\n",
     "### Dataset Impairments\n",
-    "Impairments are a collections of SignalTransforms and DatasetTransforms that emulate different environments.\n",
-    "* Level 1: Perfect environment, like inside a computer simulation. Has no transforms.\n",
-    "* Level 2: Cabled environment. Contains some transforms that slightly impair the signals.\n",
-    "* Level 3: Wireless environment. Contains many transforms that impair the signals greatly.\n",
+    "Special collections of Transform sequences that emulate different types of channel environment effects.\n",
+    "* Level 0: Perfect environment, such as inside a computer simulation. Has no transforms.\n",
+    "* Level 1: Cabled environment, such as a benchtop experiment. Contains some transforms that moderately impair the signals.\n",
+    "* Level 2: Wireless environment. Contains many transforms that impair the signals greatly, such as models of radio frequency hardware and wireless channel effects.\n",
+    "\n",
+    "Most of the provided default TorchSig dataset classes allow the user to specify the baseline impairment level, as well as specify any additional desired transforms in sequence. Note that Impairments are carefully applied within the SignalBuilders in a strict order to represent actual signal processing effects.\n",
+    "\n",
+    "### Metadata Transforms\n",
+    "Similar to Transforms define above, but these transforms do not alter signal data, and only alter signal metadata. \n",
+    "* The metadata transforms enable users to calculate custoom labels, targets, or other fields they would like from the dataset. \n",
+    "* Metadata transforms interface with SignalMetadata/SignalMetadataExternal.\n",
+    "\n",
+    "In older versions of TorchSig, this would be target transforms. \n",
     "\n",
     "---"
    ]
@@ -66,40 +85,51 @@
    "cell_type": "markdown",
    "metadata": {},
    "source": [
-    "## Datasets\n",
+    "## TorchSig Datasets\n",
+    "Two broad dataset formats are supported in TorchSig with different workflows: \n",
+    "* I/Q Datasets\n",
+    "* Spectrogram Image Datasets\n",
+    "\n",
+    "### I/Q Datasets\n",
+    "```python\n",
+    "from torchsig.datasets.dataset_metadata import DatasetMetadata ExternalDatasetMetadata\n",
+    "from torchsig.datasets.datasets import TorchSigIterableDataset, StaticTorchSigDataset\n",
+    "from torchsig.utils.writer import DatasetCreator\n",
+    "```\n",
+    "\n",
+    "In I/Q datasets the data is structured in arrays of signal I/Q samples with supporting metadata, as described in the signals section above. These datasets are usually synthetic I/Q data and metadata generated parametrically with a TorchSig workflow, but may also be externally sourced data imported into the TorchSig dataset framework.\n",
+    "\n",
+    "These are some major object types for generating or working with a dataset.\n",
+    "* DatasetMetadata: Metadata information necessary for generating or working with the dataset\n",
+    "  * ExternalDatasetMetadata: Similar to DatasetMetadata, but for user imported data.\n",
+    "* TorchSigIterableDataset: Dataset that can infinitely generate signals in memory or optionally write finite datasets to disk with DatasetCreator. Is an instance of PyTorch's [IterableDataset](https://docs.pytorch.org/docs/stable/data.html#iterable-style-datasets).\n",
+    "* StaticTorchSigDataset: Dataset that reads in a pre-generated TorchSig dataset from disk. This assumes you have created a dataset using DatasetCreator\n",
+    "* ExternalTorchSigDataset: Similar to StaticTorchSigDataset, but users are required to define how their data is loaded. This is done with a file_handler class. See example notebooks for more detail.\n",
+    "* DatasetCreator: Takes in a PyTorch [DataLoader](https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader), and writes the dataset to disk. The DataLoader should contain a TorchSigIterableDataset.\n",
+    "\n",
+    "Refer to the provided example notebooks for illustrative workflows on generating datasets, saving and loading datasets, importing external data, and working with TorchSig I/Q datasets.\n",
+    "\n",
+    "### Spectrogram Image Datasets\n",
+    "```python\n",
+    "from torchsig.image_datasets.datasets.yolo_datasets import YOLOFileDataset\n",
+    "from torchsig.image_datasets.datasets.protocols import CFGSignalProtocolDataset,\n",
+    "```\n",
+    "This dataset employs workflows oriented around the spectrogram domain, and the creation and manipulation of spectrum image data.\n",
+    "* Image datasets, cropping images to create a new dataset.\n",
+    "* CFGSignalProtocolDataset\n",
     "\n",
-    "### Two Types: IQ vs. Spectrogram Image\n",
     "\n",
-    "#### Synthetic IQ Datasets: Narrowband and Wideband\n",
-    "* Narrowband\n",
-    "* Wideband\n",
     "\n",
-    "#### Synthetic Spectrogram Dataset: Image Datasets\n",
-    "* Image datasets, cropping images to create a new dataset.\n",
-    "* CFGSignalProtocolDataset\n",
+    "### Dataset Feature Selection Table\n",
     "\n",
-    "### Dataset Objects\n",
-    "These are the types of object you can instantiate in order to generate, create, or read a dataset.\n",
-    "* DatasetMetadata:\n",
-    "    * NarrowbandMetadata\n",
-    "    * WidebandMetadtata\n",
-    "* NewDataset: Dataset that can infinitely (or finite) generate signals in memory, but you cannot access previously generated samples.\n",
-    "    * NewNarrowband, NewWideband\n",
-    "* DatasetCreator: Takes in a NewDataset, and writes the dataset to disk.\n",
-    "    * When a dataset is written or read from disk, it can either be **raw** or **processed**.\n",
-    "    * **raw**: Raw IQ and signal metadata were written to disk. In other words, no transforms or target transforms were applied to the data. This means when the dataset is read back in, users can define their own transforms or target transforms to apply then. Note that impairment level cannot be changed once written to disk.\n",
-    "    * **processed**: IQ data and/or metadata has transforms/target transforms applied. Thsi means that when the dataset is read back into memory, users cannot apply more transforms or target transforms.\n",
-    "* StaticDataset: Reads in a dataset from disk. This assumes you have created a dataset using a DatasetCreator, and want to read it back in.\n",
-    "    * StaticNarrowband, StaticWideband\n",
-    "\n",
-    "\n",
-    "| I want... | Use |\n",
+    "| I want to ... | Use |\n",
     "| --------- | ----- |\n",
-    "| an infinite dataset | NewDataset |\n",
-    "| to write a dataset to disk | NewDataset, DatasetCreator |\n",
-    "| to load a dataset from disk | StaticDataset |\n",
-    "| to write a dataset to disk, so someone else can use it with their own transforms/target transforms | NewDataset (no transforms or target transforms), DatasetCreator |\n",
-    "| a finite dataset, where I can call previously generated samples | NewDataset, DatasetCreator, StaticDataset |\n",
+    "| generate an infinite dataset | TorchSigIterableDataset |\n",
+    "| write a dataset to disk | TorchSigIterableDataset, DatasetCreator |\n",
+    "| load a dataset from disk | StaticDataset |\n",
+    "| import external data from disk as a static TorchSig dataset | ExternalTorchSigDataset (provide a file handler) |\n",
+    "| generate a finite dataset, where I can call previously generated TorchSig samples | TorchSigIterableDataset, DatasetCreator, StaticDataset |\n",
+    "\n",
     "---"
    ]
   },
@@ -107,33 +137,13 @@
    "cell_type": "markdown",
    "metadata": {},
    "source": [
-    "## Workflow\n",
-    "\n",
-    "### NewDataset\n",
-    "The below diagram shows how a sample is generated from start to finish in a NewDataset's `__getitem__` method.\n",
-    "\n",
-    "![NEWDATASET](diagrams/new_dataset_workflow.png)\n",
-    "\n",
-    "### StaticDataset\n",
-    "The below diagram shows how a sample is read in and optionally transformed in a StaticDataset's `__getitem__` method.\n",
-    "\n",
-    "![STATICDATSET](diagrams/static_dataset_workflow.png)\n",
-    "\n",
-    "---"
+    "This is the end of the notebook. If you are unsure where to start, see `examples/README.md` to view the list of notebooks or check out `create_dataset_example.ipynb`."
    ]
   }
  ],
  "metadata": {
-  "kernelspec": {
-   "display_name": "Julia 1.11.2",
-   "language": "julia",
-   "name": "julia-1.11"
-  },
   "language_info": {
-   "file_extension": ".jl",
-   "mimetype": "application/julia",
-   "name": "julia",
-   "version": "1.11.2"
+   "name": "python"
   }
  },
  "nbformat": 4,
diff --git a/examples/reproducibility_example.ipynb b/examples/reproducibility_example.ipynb
index f98fd45a4..03c1b3038 100644
--- a/examples/reproducibility_example.ipynb
+++ b/examples/reproducibility_example.ipynb
@@ -28,7 +28,6 @@
     "\n",
     "num_iq_samples_dataset = 4096 # 64^2\n",
     "fft_size = 64\n",
-    "impairment_level = 0 # clean\n",
     "num_signals_max = 1"
    ]
   },
@@ -42,9 +41,7 @@
     "\n",
     "dataset_metadata = DatasetMetadata(\n",
     "    num_iq_samples_dataset = num_iq_samples_dataset,\n",
-    "    fft_size = fft_size,\n",
-    "    impairment_level = impairment_level,\n",
-    "    num_signals_max = num_signals_max\n",
+    "    fft_size = fft_size\n",
     ")\n",
     "print(dataset_metadata)"
    ]
@@ -82,9 +79,9 @@
    "outputs": [],
    "source": [
     "dataset = TorchSigIterableDataset(dataset_metadata)\n",
-    "print(next(dataset)[0])\n",
-    "print(next(dataset)[0])\n",
-    "print(next(dataset)[0])"
+    "print(next(dataset).data)\n",
+    "print(next(dataset).data)\n",
+    "print(next(dataset).data)"
    ]
   },
   {
@@ -94,9 +91,9 @@
    "outputs": [],
    "source": [
     "dataset = TorchSigIterableDataset(dataset_metadata)\n",
-    "print(next(dataset)[0])\n",
-    "print(next(dataset)[0])\n",
-    "print(next(dataset)[0])"
+    "print(next(dataset).data)\n",
+    "print(next(dataset).data)\n",
+    "print(next(dataset).data)"
    ]
   },
   {
@@ -133,9 +130,9 @@
    "source": [
     "dataset = TorchSigIterableDataset(dataset_metadata)\n",
     "dataset.seed(42)\n",
-    "print(next(dataset)[0])\n",
-    "print(next(dataset)[0])\n",
-    "print(next(dataset)[0])"
+    "print(next(dataset).data)\n",
+    "print(next(dataset).data)\n",
+    "print(next(dataset).data)"
    ]
   },
   {
@@ -146,9 +143,9 @@
    "source": [
     "dataset = TorchSigIterableDataset(dataset_metadata)\n",
     "dataset.seed(42)\n",
-    "print(next(dataset)[0])\n",
-    "print(next(dataset)[0])\n",
-    "print(next(dataset)[0])"
+    "print(next(dataset).data)\n",
+    "print(next(dataset).data)\n",
+    "print(next(dataset).data)"
    ]
   },
   {
@@ -176,7 +173,7 @@
    "metadata": {},
    "outputs": [],
    "source": [
-    "from torchsig.utils.data_loading import WorkerSeedingDataLoader, metadata_padding_collate_fn\n",
+    "from torchsig.utils.data_loading import WorkerSeedingDataLoader\n",
     "batch_size = 8\n",
     "num_workers = 2"
    ]
@@ -188,10 +185,10 @@
    "outputs": [],
    "source": [
     "dataset = TorchSigIterableDataset(dataset_metadata)\n",
-    "dataloader = WorkerSeedingDataLoader(dataset, batch_size=batch_size, num_workers=num_workers, collate_fn=metadata_padding_collate_fn)\n",
+    "dataloader = WorkerSeedingDataLoader(dataset, batch_size=batch_size, num_workers=num_workers, collate_fn = lambda x: x)\n",
     "dataloader.seed(42)\n",
     "\n",
-    "data, metadata = next(iter(dataloader))\n",
+    "data = [x.data for x in next(iter(dataloader))]\n",
     "print(data)"
    ]
   },
@@ -209,10 +206,10 @@
    "outputs": [],
    "source": [
     "dataset = TorchSigIterableDataset(dataset_metadata)\n",
-    "dataloader = WorkerSeedingDataLoader(dataset, batch_size=batch_size, num_workers=num_workers, collate_fn=metadata_padding_collate_fn)\n",
+    "dataloader = WorkerSeedingDataLoader(dataset, batch_size=batch_size, num_workers=num_workers, collate_fn = lambda x: x)\n",
     "dataloader.seed(42)\n",
     "\n",
-    "data, metadata = next(iter(dataloader))\n",
+    "data = [x.data for x in next(iter(dataloader))]\n",
     "print(data)"
    ]
   },
@@ -222,15 +219,6 @@
    "source": [
     "Tensors expect each array to have the same size. This presents a challenge when there is no signal present, ex: `num_signals_min == 0`, which is the default for `DatasetMetadata()`. All of the IQ time-series within a dataset will always be same, even when there is no signal present, because the underlying noise is created. However, when there is no signal the metadata becomes an empty list. Therefore when viewing the metadata in tensor format there will be zero-padded fields. When processing the output of the data loader the zero-padding will need to be undone."
    ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": null,
-   "metadata": {},
-   "outputs": [],
-   "source": [
-    "print(metadata)"
-   ]
   }
  ],
  "metadata": {
@@ -252,7 +240,7 @@
    "name": "python",
    "nbconvert_exporter": "python",
    "pygments_lexer": "ipython3",
-   "version": "3.10.12"
+   "version": "3.12.3"
   }
  },
  "nbformat": 4,
diff --git a/examples/transforms/carrier_frequency_drift.ipynb b/examples/transforms/carrier_frequency_drift.ipynb
index 457629fe2..26edd1f71 100644
--- a/examples/transforms/carrier_frequency_drift.ipynb
+++ b/examples/transforms/carrier_frequency_drift.ipynb
@@ -233,7 +233,7 @@
  ],
  "metadata": {
   "kernelspec": {
-   "display_name": "Python 3",
+   "display_name": "venv",
    "language": "python",
    "name": "python3"
   },
@@ -247,7 +247,7 @@
    "name": "python",
    "nbconvert_exporter": "python",
    "pygments_lexer": "ipython3",
-   "version": "3.10.12"
+   "version": "3.12.3"
   }
  },
  "nbformat": 4,
diff --git a/examples/transforms/carrier_phase_noise.ipynb b/examples/transforms/carrier_phase_noise.ipynb
index e153c9afb..cdb4aad15 100644
--- a/examples/transforms/carrier_phase_noise.ipynb
+++ b/examples/transforms/carrier_phase_noise.ipynb
@@ -7,7 +7,7 @@
    "source": [
     "# Carrier Phase Noise\n",
     "\n",
-    "This notebook demonstates the functional of the carrier phase noise transform. The transform models the carrier having a phase which is represented by a Gaussian random variable with zero mean and whose standard deviation is parameterizable. It simulates a type of carrier modulation where the phase on average is correct but varies over time. It simulates the error and uncertainty of the real-world parameter due to manufacturing tolerance, temperature variation and other factors."
+    "This notebook demonstrates the functional of the carrier phase noise transform. The transform models the carrier having a phase which is represented by a Gaussian random variable with zero mean and whose standard deviation is parameterizable. It simulates a type of carrier modulation where the phase on average is correct but varies over time. It simulates the error and uncertainty of the real-world parameter due to manufacturing tolerance, temperature variation and other factors."
    ]
   },
   {
@@ -217,7 +217,7 @@
  ],
  "metadata": {
   "kernelspec": {
-   "display_name": "Python 3",
+   "display_name": "Python 3 (ipykernel)",
    "language": "python",
    "name": "python3"
   },
diff --git a/examples/transforms/clock_drift.ipynb b/examples/transforms/clock_drift.ipynb
new file mode 100644
index 000000000..05e2ed094
--- /dev/null
+++ b/examples/transforms/clock_drift.ipynb
@@ -0,0 +1,237 @@
+{
+ "cells": [
+  {
+   "cell_type": "markdown",
+   "id": "71d06404-6c20-40be-a8b7-9788df6ec9d5",
+   "metadata": {},
+   "source": [
+    "# Clock Drift\n",
+    "\n",
+    "This notebook demonstates the functional of the clock drift transform. The transform models the sampling rate having some error, represented by an accumulate Gaussian random variable whose mean is zero and whose variance is according to the PPM error parameter. The effect will increase or decrease the sampling rate randomly over the course of the input signal. Over long sequences this will produce a handful of more or less samples than were input."
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "83bdc715",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "import torchsig.transforms.functional as F\n",
+    "\n",
+    "import numpy as np\n",
+    "import scipy as sp\n",
+    "%matplotlib inline\n",
+    "import matplotlib.pyplot as plt"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "id": "412f7598-c06e-42aa-bc26-1f26abfb4043",
+   "metadata": {},
+   "source": [
+    "A tone signal is generated to test the clock drift transform. The error is defined in parts-per-million (PPM). A larger PPM represents a larger frequency error on average. Using 0 PPM will result in no drift."
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "6afa7e07",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "# test functional\n",
+    "rng = np.random.default_rng(42)\n",
+    "\n",
+    "N = 10000\n",
+    "sample_rate = 10e6\n",
+    "#center_frequency = 0\n",
+    "center_frequency = sample_rate/N\n",
+    "n = np.arange(0,N)\n",
+    "t = n/sample_rate\n",
+    "tone_bb_data = np.exp(2j*np.pi*center_frequency*t)\n",
+    "\n",
+    "drift_ppm=1\n",
+    "\n",
+    "data_out = F.clock_drift(\n",
+    "    data = tone_bb_data,\n",
+    "    drift_ppm = drift_ppm,\n",
+    "    rng = rng\n",
+    ")"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "id": "880ea4dd",
+   "metadata": {},
+   "source": [
+    "Time-domain plots show how the clock drift effects the complex sinusoid input. For small PPM errors the effect will may not be visible in the time domain."
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "e3dc1a42",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "fig = plt.figure(figsize=(10,6))\n",
+    "fig.subplots_adjust(hspace=0.5)\n",
+    "ax = fig.add_subplot(2,1,1)\n",
+    "ax.plot(t,np.real(tone_bb_data),label='Real, Input Tone')\n",
+    "ax.plot(t,np.imag(tone_bb_data),label='Imag, Input Tone')\n",
+    "ylim = np.max(np.abs(tone_bb_data))*1.1\n",
+    "ax.set_ylim([-ylim,ylim])\n",
+    "ax.set_xlim([t[0],t[-1]])\n",
+    "ax.set_xlabel('Time (s)')\n",
+    "ax.set_ylabel('Amplitude')\n",
+    "ax.grid()\n",
+    "ax.legend(loc='upper right')\n",
+    "\n",
+    "ax = fig.add_subplot(2,1,2)\n",
+    "ax.plot(t,np.real(data_out),label='Real, Tone with Clock Drift')\n",
+    "ax.plot(t,np.imag(data_out),label='Imag, Tone with Clock Drift')\n",
+    "ax.set_ylim([-ylim,ylim])\n",
+    "ax.set_xlim([t[0],t[-1]])\n",
+    "ax.set_xlabel('Time (s)')\n",
+    "ax.set_ylabel('Amplitude')\n",
+    "ax.grid()\n",
+    "ax.legend(loc='upper right')"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "65f03cf5",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "from torchsig.signals.signal_types import Signal\n",
+    "from torchsig.datasets.dataset_metadata import DatasetMetadata\n",
+    "from torchsig.signals.builders import ConstellationSignalBuilder\n",
+    "def generate_qpsk_signal(num_iq_samples: int = 128, scale: float = 1.0) -> Signal:\n",
+    "    \"\"\"Generate a scaled, high SNR baseband QPSK Signal.\n",
+    "\n",
+    "        Args:\n",
+    "        num_iq_samples (int, optional): Length of sample. Defaults to 10.\n",
+    "        scale (int, optional): scale normalized signal data. Defaults to 1.0.\n",
+    "\n",
+    "        Returns:\n",
+    "            signal: generated Signal \n",
+    "\n",
+    "    \"\"\"\n",
+    "    sample_rate = 10e6\n",
+    "    md = DatasetMetadata(\n",
+    "        num_iq_samples_dataset = num_iq_samples,\n",
+    "        fft_size = 4,\n",
+    "        impairment_level = 0,\n",
+    "        sample_rate = sample_rate,\n",
+    "        num_signals_max = 1,\n",
+    "        num_signals_min = 1,\n",
+    "        num_signals_distribution = [1.0],\n",
+    "        snr_db_min = 100.0,\n",
+    "        snr_db_max = 100.0,\n",
+    "        signal_duration_min = 1.00*num_iq_samples/sample_rate,\n",
+    "        signal_duration_max = 1.00*num_iq_samples/sample_rate,\n",
+    "        signal_bandwidth_min = sample_rate/4,\n",
+    "        signal_bandwidth_max = sample_rate/4,\n",
+    "        signal_center_freq_min = 0.0,\n",
+    "        signal_center_freq_max = 0.0,         \n",
+    "        class_list = ['qpsk'],\n",
+    "        class_distribution = [1.0],\n",
+    "        seed = 42\n",
+    "    )\n",
+    "\n",
+    "    builder = ConstellationSignalBuilder(\n",
+    "        dataset_metadata = md, \n",
+    "        class_name = 'qpsk',\n",
+    "        seed = 42\n",
+    "    )\n",
+    "    signal = builder.build()\n",
+    "\n",
+    "    # normalize, then scale data   \n",
+    "    signal.data = F.normalize(\n",
+    "        data = signal.data,\n",
+    "        norm_order = 2,\n",
+    "        flatten = False\n",
+    "    )\n",
+    "    signal.data = np.multiply(signal.data, scale)\n",
+    "\n",
+    "    return signal.data"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "id": "d4b79628",
+   "metadata": {},
+   "source": [
+    "A QPSK signal is used to demonstrate the drift. A larger drift PPM value is used to make the effect more obvious."
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "b14b1ec7",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "# test data\n",
+    "N = 128\n",
+    "qpsk_data = generate_qpsk_signal(num_iq_samples = N)\n",
+    "\n",
+    "# phase noise\n",
+    "impaired_qpsk_data = F.clock_drift(\n",
+    "    data = qpsk_data,\n",
+    "    drift_ppm=drift_ppm*100\n",
+    ")\n",
+    "\n",
+    "n = np.arange(0,len(qpsk_data))\n",
+    "t = n/sample_rate\n",
+    "\n",
+    "fig = plt.figure(figsize=(10,6))\n",
+    "fig.subplots_adjust(hspace=0.5)\n",
+    "ax = fig.add_subplot(2,1,1)\n",
+    "ax.plot(t,np.real(qpsk_data),label='Real, Input QPSK')\n",
+    "ax.plot(t,np.real(impaired_qpsk_data),label='Real, QPSK with Drift')\n",
+    "ylim = np.max(np.abs(qpsk_data))*1.1\n",
+    "#ax.set_ylim([-ylim,ylim])\n",
+    "ax.set_xlim([t[0],t[-1]])\n",
+    "ax.set_xlabel('Time (s)')\n",
+    "ax.set_ylabel('Amplitude')\n",
+    "ax.grid()\n",
+    "ax.legend(loc='upper right')\n",
+    "\n",
+    "ax = fig.add_subplot(2,1,2)\n",
+    "ax.plot(t,np.imag(qpsk_data),label='Imag, Input QPSK')\n",
+    "ax.plot(t,np.imag(impaired_qpsk_data),label='Imag, QPSK with Drift')\n",
+    "ax.set_ylim([-ylim,ylim])\n",
+    "ax.set_xlim([t[0],t[-1]])\n",
+    "ax.set_xlabel('Time (s)')\n",
+    "ax.set_ylabel('Amplitude')\n",
+    "ax.grid()\n",
+    "ax.legend(loc='upper right')"
+   ]
+  }
+ ],
+ "metadata": {
+  "kernelspec": {
+   "display_name": "Python 3",
+   "language": "python",
+   "name": "python3"
+  },
+  "language_info": {
+   "codemirror_mode": {
+    "name": "ipython",
+    "version": 3
+   },
+   "file_extension": ".py",
+   "mimetype": "text/x-python",
+   "name": "python",
+   "nbconvert_exporter": "python",
+   "pygments_lexer": "ipython3",
+   "version": "3.10.12"
+  }
+ },
+ "nbformat": 4,
+ "nbformat_minor": 5
+}
diff --git a/examples/transforms/clock_jitter.ipynb b/examples/transforms/clock_jitter.ipynb
new file mode 100644
index 000000000..8c4830222
--- /dev/null
+++ b/examples/transforms/clock_jitter.ipynb
@@ -0,0 +1,237 @@
+{
+ "cells": [
+  {
+   "cell_type": "markdown",
+   "id": "71d06404-6c20-40be-a8b7-9788df6ec9d5",
+   "metadata": {},
+   "source": [
+    "# Clock Jitter\n",
+    "\n",
+    "This notebook demonstates the functional of the clock jitter transform. The transform models the sampling phase having some error, represented by a Gaussian random variable whose mean is zero and whose variance is according to the PPM error parameter. The effect will increase or decrease the sampling phase randomly by a fractional sample. Over long sequences this will produce a handful of more or less samples than were input."
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "83bdc715",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "import torchsig.transforms.functional as F\n",
+    "\n",
+    "import numpy as np\n",
+    "import scipy as sp\n",
+    "%matplotlib inline\n",
+    "import matplotlib.pyplot as plt"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "id": "412f7598-c06e-42aa-bc26-1f26abfb4043",
+   "metadata": {},
+   "source": [
+    "A tone signal is generated to test the clock jitter transform. The error is defined in parts-per-million (PPM). A larger PPM represents a larger frequency error on average. Using 0 PPM will result in no sampling phase error."
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "6afa7e07",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "# test functional\n",
+    "rng = np.random.default_rng(42)\n",
+    "\n",
+    "N = 10000\n",
+    "sample_rate = 10e6\n",
+    "#center_frequency = 0\n",
+    "center_frequency = sample_rate/N\n",
+    "n = np.arange(0,N)\n",
+    "t = n/sample_rate\n",
+    "tone_bb_data = np.exp(2j*np.pi*center_frequency*t)\n",
+    "\n",
+    "jitter_ppm=1\n",
+    "\n",
+    "data_out = F.clock_jitter(\n",
+    "    data = tone_bb_data,\n",
+    "    jitter_ppm = jitter_ppm,\n",
+    "    rng = rng\n",
+    ")"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "id": "880ea4dd",
+   "metadata": {},
+   "source": [
+    "Time-domain plots show how the clock jitter effects the complex sinusoid input. For small PPM errors the effect will may not be visible in the time domain."
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "e3dc1a42",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "fig = plt.figure(figsize=(10,6))\n",
+    "fig.subplots_adjust(hspace=0.5)\n",
+    "ax = fig.add_subplot(2,1,1)\n",
+    "ax.plot(t,np.real(tone_bb_data),label='Real, Input Tone')\n",
+    "ax.plot(t,np.imag(tone_bb_data),label='Imag, Input Tone')\n",
+    "ylim = np.max(np.abs(tone_bb_data))*1.1\n",
+    "ax.set_ylim([-ylim,ylim])\n",
+    "ax.set_xlim([t[0],t[-1]])\n",
+    "ax.set_xlabel('Time (s)')\n",
+    "ax.set_ylabel('Amplitude')\n",
+    "ax.grid()\n",
+    "ax.legend(loc='upper right')\n",
+    "\n",
+    "ax = fig.add_subplot(2,1,2)\n",
+    "ax.plot(t,np.real(data_out),label='Real, Tone with Clock Jitter')\n",
+    "ax.plot(t,np.imag(data_out),label='Imag, Tone with Clock Jitter')\n",
+    "ax.set_ylim([-ylim,ylim])\n",
+    "ax.set_xlim([t[0],t[-1]])\n",
+    "ax.set_xlabel('Time (s)')\n",
+    "ax.set_ylabel('Amplitude')\n",
+    "ax.grid()\n",
+    "ax.legend(loc='upper right')"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "65f03cf5",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "from torchsig.signals.signal_types import Signal\n",
+    "from torchsig.datasets.dataset_metadata import DatasetMetadata\n",
+    "from torchsig.signals.builders import ConstellationSignalBuilder\n",
+    "def generate_qpsk_signal(num_iq_samples: int = 128, scale: float = 1.0) -> Signal:\n",
+    "    \"\"\"Generate a scaled, high SNR baseband QPSK Signal.\n",
+    "\n",
+    "        Args:\n",
+    "        num_iq_samples (int, optional): Length of sample. Defaults to 10.\n",
+    "        scale (int, optional): scale normalized signal data. Defaults to 1.0.\n",
+    "\n",
+    "        Returns:\n",
+    "            signal: generated Signal \n",
+    "\n",
+    "    \"\"\"\n",
+    "    sample_rate = 10e6\n",
+    "    md = DatasetMetadata(\n",
+    "        num_iq_samples_dataset = num_iq_samples,\n",
+    "        fft_size = 4,\n",
+    "        impairment_level = 0,\n",
+    "        sample_rate = sample_rate,\n",
+    "        num_signals_max = 1,\n",
+    "        num_signals_min = 1,\n",
+    "        num_signals_distribution = [1.0],\n",
+    "        snr_db_min = 100.0,\n",
+    "        snr_db_max = 100.0,\n",
+    "        signal_duration_min = 1.00*num_iq_samples/sample_rate,\n",
+    "        signal_duration_max = 1.00*num_iq_samples/sample_rate,\n",
+    "        signal_bandwidth_min = sample_rate/4,\n",
+    "        signal_bandwidth_max = sample_rate/4,\n",
+    "        signal_center_freq_min = 0.0,\n",
+    "        signal_center_freq_max = 0.0,         \n",
+    "        class_list = ['qpsk'],\n",
+    "        class_distribution = [1.0],\n",
+    "        seed = 42\n",
+    "    )\n",
+    "\n",
+    "    builder = ConstellationSignalBuilder(\n",
+    "        dataset_metadata = md, \n",
+    "        class_name = 'qpsk',\n",
+    "        seed = 42\n",
+    "    )\n",
+    "    signal = builder.build()\n",
+    "\n",
+    "    # normalize, then scale data   \n",
+    "    signal.data = F.normalize(\n",
+    "        data = signal.data,\n",
+    "        norm_order = 2,\n",
+    "        flatten = False\n",
+    "    )\n",
+    "    signal.data = np.multiply(signal.data, scale)\n",
+    "\n",
+    "    return signal.data"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "id": "d4b79628",
+   "metadata": {},
+   "source": [
+    "A QPSK signal is used to demonstrate the jitter. A larger jitter PPM value is used to make the effect more obvious."
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "b14b1ec7",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "# test data\n",
+    "N = 128\n",
+    "qpsk_data = generate_qpsk_signal(num_iq_samples = N)\n",
+    "\n",
+    "# phase noise\n",
+    "impaired_qpsk_data = F.clock_jitter(\n",
+    "    data = qpsk_data,\n",
+    "    jitter_ppm=jitter_ppm*100\n",
+    ")\n",
+    "\n",
+    "n = np.arange(0,len(qpsk_data))\n",
+    "t = n/sample_rate\n",
+    "\n",
+    "fig = plt.figure(figsize=(10,6))\n",
+    "fig.subplots_adjust(hspace=0.5)\n",
+    "ax = fig.add_subplot(2,1,1)\n",
+    "ax.plot(t,np.real(qpsk_data),label='Real, Input QPSK')\n",
+    "ax.plot(t,np.real(impaired_qpsk_data),label='Real, QPSK with Jitter')\n",
+    "ylim = np.max(np.abs(qpsk_data))*1.1\n",
+    "#ax.set_ylim([-ylim,ylim])\n",
+    "ax.set_xlim([t[0],t[-1]])\n",
+    "ax.set_xlabel('Time (s)')\n",
+    "ax.set_ylabel('Amplitude')\n",
+    "ax.grid()\n",
+    "ax.legend(loc='upper right')\n",
+    "\n",
+    "ax = fig.add_subplot(2,1,2)\n",
+    "ax.plot(t,np.imag(qpsk_data),label='Imag, Input QPSK')\n",
+    "ax.plot(t,np.imag(impaired_qpsk_data),label='Imag, QPSK with Jitter')\n",
+    "ax.set_ylim([-ylim,ylim])\n",
+    "ax.set_xlim([t[0],t[-1]])\n",
+    "ax.set_xlabel('Time (s)')\n",
+    "ax.set_ylabel('Amplitude')\n",
+    "ax.grid()\n",
+    "ax.legend(loc='upper right')"
+   ]
+  }
+ ],
+ "metadata": {
+  "kernelspec": {
+   "display_name": "Python 3",
+   "language": "python",
+   "name": "python3"
+  },
+  "language_info": {
+   "codemirror_mode": {
+    "name": "ipython",
+    "version": 3
+   },
+   "file_extension": ".py",
+   "mimetype": "text/x-python",
+   "name": "python",
+   "nbconvert_exporter": "python",
+   "pygments_lexer": "ipython3",
+   "version": "3.10.12"
+  }
+ },
+ "nbformat": 4,
+ "nbformat_minor": 5
+}
diff --git a/examples/transforms/co_adj_interference_plots.ipynb b/examples/transforms/co_adj_interference_plots.ipynb
index 8186d6f42..a8d94ae71 100644
--- a/examples/transforms/co_adj_interference_plots.ipynb
+++ b/examples/transforms/co_adj_interference_plots.ipynb
@@ -5,7 +5,8 @@
    "id": "71d06404-6c20-40be-a8b7-9788df6ec9d5",
    "metadata": {},
    "source": [
-    "# Plots of co-channel and adjacent channel interference transforms"
+    "# Co-Channel and Adjacent Channel Interference Transforms\n",
+    "This notebook illustrates the two functional transforms that model co-channel interference and adjacent channel interference. The co-channel interference transform models interference as a configurable noise-like signal. The adjacent channel interference transform adds a similarly structured adjacent channel signal by modifying a copy of the original signal. Using an input high SNR tone signal, this notebook plots the frequency response within the entire sampled bandwidth for both transforms, highlighting the in-band and out-of-band responses. "
    ]
   },
   {
@@ -20,7 +21,7 @@
     "from torchsig.signals.builders.tone import ToneSignalBuilder\n",
     "import torchsig.transforms.functional as F\n",
     "from torchsig.utils.dsp import (\n",
-    "    torchsig_complex_data_type,\n",
+    "    TorchSigComplexDataType,\n",
     "    low_pass\n",
     ")\n",
     "\n",
@@ -31,6 +32,14 @@
     "from scipy.signal import spectrogram"
    ]
   },
+  {
+   "cell_type": "markdown",
+   "id": "2a10a02b-2027-4d4b-8da6-218fb24eedfe",
+   "metadata": {},
+   "source": [
+    "Function for generating input tone signals in the test interference scenarios."
+   ]
+  },
   {
    "cell_type": "code",
    "execution_count": null,
@@ -84,11 +93,19 @@
     "        norm_order = 2,\n",
     "        flatten = False\n",
     "    )\n",
-    "    signal.data = np.multiply(signal.data, scale).astype(torchsig_complex_data_type)\n",
+    "    signal.data = np.multiply(signal.data, scale).astype(TorchSigComplexDataType)\n",
     "\n",
     "    return signal"
    ]
   },
+  {
+   "cell_type": "markdown",
+   "id": "2f233e0a-c3eb-42b3-a204-8a17d093fb72",
+   "metadata": {},
+   "source": [
+    "Visualize the default filter design for the in-band and out-of-band channel frequency response."
+   ]
+  },
   {
    "cell_type": "code",
    "execution_count": null,
@@ -96,7 +113,6 @@
    "metadata": {},
    "outputs": [],
    "source": [
-    "# visualize default filter design\n",
     "cutoff = 0.125\n",
     "transition_bandwidth = 0.125\n",
     "sample_rate = 1.0\n",
@@ -112,55 +128,11 @@
    ]
   },
   {
-   "cell_type": "code",
-   "execution_count": null,
-   "id": "4d9c55bb-ae04-4109-ba63-6b4c4cc00447",
+   "cell_type": "markdown",
+   "id": "bcb61579-4f9f-4f17-ab11-17a836a2d623",
    "metadata": {},
-   "outputs": [],
    "source": [
-    "rng = np.random.default_rng(seed=42)\n",
-    "\n",
-    "N = 8192\n",
-    "sample_rate = 1.0\n",
-    "power = 0.1\n",
-    "tone_freq = 0.1\n",
-    "filter_weights = low_pass(0.125, 0.125, 1.0)\n",
-    "tone_bb_data = generate_tone_signal(num_iq_samples = N, scale = 1.0).data \n",
-    "tone_data = tone_bb_data * np.exp(2j * np.pi * tone_freq * np.arange(N) / sample_rate) * np.sqrt(N) # f0 = 0.2, total power = 1.0 W\n",
-    "est_power = np.sum(np.abs(tone_data)**2)/len(tone_data)\n",
-    "print(\"tone_data power: \", est_power) # verify 1.0 W\n",
-    "\n",
-    "data_co = F.cochannel_interference(\n",
-    "    data = tone_data,\n",
-    "    power = power,\n",
-    "    filter_weights = filter_weights,\n",
-    "    color = 'white',\n",
-    "    continuous = True,\n",
-    ")\n",
-    "est_power = np.sum(np.abs(data_co)**2)/len(data_co)\n",
-    "print(\"data_co power: \", est_power) # verify 1.0 W + 1.0 W = 2.0 W (uncorrelated)\n",
-    "\n",
-    "# verify peaks\n",
-    "D = np.abs(np.fft.fft(data_co, norm='ortho'))\n",
-    "freqs = np.fft.fftfreq(N) * sample_rate\n",
-    "\n",
-    "peaks, _ = sp.find_peaks(D, height=1.0, distance=N/2)\n",
-    "max_peak_ind = np.argmax(D[peaks])\n",
-    "#print(freqs[max_peak_ind])\n",
-    "print(peaks)\n",
-    "print(freqs[peaks])\n",
-    "print(D[peaks])\n",
-    "\n",
-    "\n",
-    "# plots\n",
-    "plt.style.use('dark_background')\n",
-    "fig, ax = plt.subplots()\n",
-    "\n",
-    "spectrum, freqs, _ = ax.magnitude_spectrum(tone_data, Fs=sample_rate, scale='linear', sides='twosided', color='white');\n",
-    "spectrum, freqs, _ = ax.magnitude_spectrum(data_co, Fs=sample_rate, scale='linear', sides='twosided', color='red');\n",
-    "ax.set_yscale('log')\n",
-    "ax.set_xlabel('Frequency');\n",
-    "ax.set_ylabel('Magnitude [log]');"
+    "Generate and frequency shift a new constant tone signal with calibrated power. Apply the co-channel interference transform to produce an output signal, then estimate the power and frequency of the original input component within the total aggregate signal. Verify the tone frequency is undisturbed by the transform."
    ]
   },
   {
@@ -197,7 +169,7 @@
     "freqs = np.fft.fftfreq(N) * sample_rate\n",
     "peaks, _ = sp.find_peaks(D, height=1.0, distance=N/2)\n",
     "max_peak_ind = np.argmax(D[peaks])\n",
-    "print(\"peak freqs:, \", freqs[peaks])\n",
+    "print(\"peak freqs: \", freqs[peaks])\n",
     "\n",
     "# plots\n",
     "plt.style.use('dark_background')\n",
@@ -207,70 +179,15 @@
     "spectrum, freqs, _ = ax.magnitude_spectrum(data_co, Fs=sample_rate, scale='linear', sides='twosided', color='red');\n",
     "ax.set_yscale('log')\n",
     "ax.set_xlabel('Frequency');\n",
-    "ax.set_ylabel('Magnitude [log]');"
+    "ax.set_ylabel('Magnitude');"
    ]
   },
   {
-   "cell_type": "code",
-   "execution_count": null,
-   "id": "67788f83-31f9-4aea-911f-727ae488189a",
+   "cell_type": "markdown",
+   "id": "1b52b827-f5af-4b0b-8bd1-7ad961ae5352",
    "metadata": {},
-   "outputs": [],
    "source": [
-    "rng = np.random.default_rng(seed=42)\n",
-    "\n",
-    "N = 16384\n",
-    "sample_rate = 1.0\n",
-    "power = 0.5\n",
-    "center_frequency = 0.2\n",
-    "tone_freq = 0.042\n",
-    "filter_weights = low_pass(0.125, 0.125, sample_rate)\n",
-    "phase_sigma = 1.0\n",
-    "time_sigma = 0.0\n",
-    "\n",
-    "tone_bb_data = generate_tone_signal(num_iq_samples = N, scale = 1.0).data \n",
-    "tone_data = tone_bb_data * np.exp(2j * np.pi * tone_freq * np.arange(N) / sample_rate) * np.sqrt(N) # f0 = 0.042, total power = 1.0 W\n",
-    "est_power = np.sum(np.abs(tone_data)**2)/len(tone_data)\n",
-    "print(\"tone_data power: \", est_power) # verify 1.0 W\n",
-    "\n",
-    "data_adj0 = F.adjacent_channel_interference(\n",
-    "    data = tone_data,\n",
-    "    sample_rate = sample_rate,\n",
-    "    power = power,\n",
-    "    center_frequency = center_frequency,\n",
-    "    filter_weights = filter_weights,\n",
-    "    phase_sigma = phase_sigma,\n",
-    "    time_sigma = time_sigma,\n",
-    "    rng = rng\n",
-    ")\n",
-    "est_power = np.sum(np.abs(data_adj0)**2)/len(data_adj0)\n",
-    "print(\"total output power: \", est_power) # verify 1.0 W + 1.0 W = 2.0 W (uncorrelated)\n",
-    "\n",
-    "# plots\n",
-    "plt.style.use('dark_background')\n",
-    "fig, ax = plt.subplots()\n",
-    "\n",
-    "spectrum, freqs, _ = ax.magnitude_spectrum(tone_data, Fs=sample_rate, scale='linear', sides='twosided', color='white');\n",
-    "spectrum, freqs, _ = ax.magnitude_spectrum(data_adj0, Fs=sample_rate, scale='linear', sides='twosided', color='red');\n",
-    "ax.set_yscale('log')\n",
-    "ax.set_xlabel('Frequency');\n",
-    "ax.set_ylabel('Magnitude [log]');\n",
-    "\n",
-    "\n",
-    "# verify peaks\n",
-    "D = np.abs(np.fft.fft(data_adj0, norm='ortho'))\n",
-    "freqs = np.fft.fftfreq(N) * sample_rate\n",
-    "peaks, _ = sp.find_peaks(D, height=1.0, distance=N/20)\n",
-    "top_two_indices = np.argsort(D[peaks])[-2:][::-1]\n",
-    "freqs0 = freqs[peaks[top_two_indices[0]]]\n",
-    "freqs1 = freqs[peaks[top_two_indices[1]]]\n",
-    "print(\"freqs[peaks] \", freqs[peaks])\n",
-    "print(\"D[peaks] \", D[peaks])\n",
-    "#print('top_two_indices', top_two_indices)\n",
-    "print('freqs[top_two_indices]', freqs[peaks[top_two_indices]])\n",
-    "print(freqs0, freqs1)\n",
-    "\n",
-    "print(generate_tone_signal(num_iq_samples = N, scale = 1.0))"
+    "Generate and frequency shift a new constant tone signal with calibrated power. Apply the adjacent channel interference transform to produce an output signal, then estimate the power and frequency of the original input component within the total aggregate signal."
    ]
   },
   {
@@ -306,30 +223,21 @@
     "spectrum, freqs, _ = ax.magnitude_spectrum(data_adj1, Fs=sample_rate, scale='linear', sides='twosided', color='red');\n",
     "ax.set_yscale('log')\n",
     "ax.set_xlabel('Frequency');\n",
-    "ax.set_ylabel('Magnitude [log]');"
+    "ax.set_ylabel('Magnitude');"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
-   "id": "32975886-c6be-4320-9e06-441ba6f59d55",
+   "id": "c7a9870a-9e39-4601-8052-c0f9537a7aca",
    "metadata": {},
    "outputs": [],
-   "source": [
-    "# verify peaks\n",
-    "D = np.abs(np.fft.fft(data_adj1, norm='ortho'))\n",
-    "freqs = np.fft.fftfreq(N) * sample_rate\n",
-    "\n",
-    "peaks, _ = sp.find_peaks(D, height=0.5, distance=N/10)\n",
-    "print(freqs[peaks])\n",
-    "plt.plot(freqs, D)\n",
-    "plt.plot(freqs[peaks], D[peaks], \"x\")"
-   ]
+   "source": []
   }
  ],
  "metadata": {
   "kernelspec": {
-   "display_name": "Python 3",
+   "display_name": "venv",
    "language": "python",
    "name": "python3"
   },
@@ -343,7 +251,7 @@
    "name": "python",
    "nbconvert_exporter": "python",
    "pygments_lexer": "ipython3",
-   "version": "3.10.12"
+   "version": "3.12.3"
   }
  },
  "nbformat": 4,
diff --git a/examples/transforms/coarse_gain_change.ipynb b/examples/transforms/coarse_gain_change.ipynb
index 487b3202f..69f888fbc 100644
--- a/examples/transforms/coarse_gain_change.ipynb
+++ b/examples/transforms/coarse_gain_change.ipynb
@@ -136,7 +136,7 @@
  ],
  "metadata": {
   "kernelspec": {
-   "display_name": "Python 3",
+   "display_name": "Python 3 (ipykernel)",
    "language": "python",
    "name": "python3"
   },
diff --git a/examples/transforms/digital_agc.ipynb b/examples/transforms/digital_agc.ipynb
index 3232375be..1a354d834 100644
--- a/examples/transforms/digital_agc.ipynb
+++ b/examples/transforms/digital_agc.ipynb
@@ -20,13 +20,21 @@
     "from torchsig.datasets.dataset_metadata import DatasetMetadata\n",
     "from torchsig.signals.builders.constellation import ConstellationSignalBuilder\n",
     "import torchsig.transforms.functional as F\n",
-    "from torchsig.utils.dsp import torchsig_complex_data_type\n",
+    "from torchsig.utils.dsp import TorchSigComplexDataType\n",
     "\n",
     "import numpy as np\n",
     "%matplotlib inline\n",
     "import matplotlib.pyplot as plt"
    ]
   },
+  {
+   "cell_type": "markdown",
+   "id": "18a765d8-48fa-45ce-9735-81c550fb257c",
+   "metadata": {},
+   "source": [
+    "Function for generating modulated QPSK input signals."
+   ]
+  },
   {
    "cell_type": "code",
    "execution_count": null,
@@ -185,7 +193,7 @@
  ],
  "metadata": {
   "kernelspec": {
-   "display_name": "Python 3",
+   "display_name": "Python 3 (ipykernel)",
    "language": "python",
    "name": "python3"
   },
diff --git a/examples/transforms/doppler_plots.ipynb b/examples/transforms/doppler_plots.ipynb
index 546efbb02..adfa345eb 100644
--- a/examples/transforms/doppler_plots.ipynb
+++ b/examples/transforms/doppler_plots.ipynb
@@ -5,7 +5,8 @@
    "id": "71d06404-6c20-40be-a8b7-9788df6ec9d5",
    "metadata": {},
    "source": [
-    "# Plots of Doppler transform"
+    "# Doppler Transform\n",
+    "This notebook illustrates the Doppler functional transform. This wideband Doppler effect operates over the entire sampled band by rescaling the input time series for a constant relative velocity and propagation speed."
    ]
   },
   {
@@ -21,7 +22,7 @@
     "import torchsig.transforms.functional as F\n",
     "import torchsig.utils.dsp as dsp\n",
     "from torchsig.utils.dsp import (\n",
-    "    torchsig_complex_data_type\n",
+    "    TorchSigComplexDataType\n",
     ")\n",
     "\n",
     "import numpy as np\n",
@@ -31,6 +32,14 @@
     "from scipy.constants import c"
    ]
   },
+  {
+   "cell_type": "markdown",
+   "id": "89d47668-b5d3-488f-aa95-d700929b940a",
+   "metadata": {},
+   "source": [
+    "Function for generating the input constant tone test signal."
+   ]
+  },
   {
    "cell_type": "code",
    "execution_count": null,
@@ -84,11 +93,19 @@
     "        norm_order = 2,\n",
     "        flatten = False\n",
     "    )\n",
-    "    signal.data = np.multiply(signal.data, scale).astype(torchsig_complex_data_type)\n",
+    "    signal.data = np.multiply(signal.data, scale).astype(TorchSigComplexDataType)\n",
     "\n",
     "    return signal"
    ]
   },
+  {
+   "cell_type": "markdown",
+   "id": "a0fe629d-fc9a-46cb-891c-341a41132d30",
+   "metadata": {},
+   "source": [
+    "Place the input tone signal frequency at 0.2, then apply the wideband Doppler effect with a time scaling factor of 1.03. Estimate the frequency shift and compare it with the true shift."
+   ]
+  },
   {
    "cell_type": "code",
    "execution_count": null,
@@ -96,91 +113,67 @@
    "metadata": {},
    "outputs": [],
    "source": [
-    "# Doppler test cases\n",
     "rng = np.random.default_rng(42)\n",
     "\n",
-    "sampling_rate = 1.0\n",
-    "velocity = 1e7\n",
+    "fc = 0.2   # tone center frequency\n",
+    "N = 10000  # tone signal samples\n",
+    "sampling_rate = 4.0\n",
     "\n",
-    "N = 10000\n",
+    "# input tone signal\n",
     "tone_bb_data = generate_tone_signal(num_iq_samples = N, scale = 1.0).data \n",
-    "tone_data = tone_bb_data * np.exp(2j * np.pi * 0.2 * np.arange(N) / sampling_rate) # f0 = 0.2\n",
+    "tone_data = tone_bb_data * np.exp(2j * np.pi * fc * np.arange(N) / sampling_rate) \n",
     "\n",
+    "# Doppler parameters\n",
+    "velocity = -1e7\n",
+    "propagation_speed = 2.9979e8\n",
+    "alpha = propagation_speed / (propagation_speed - velocity)\n",
+    "\n",
+    "# apply Doppler transform\n",
     "data_d = F.doppler(\n",
     "    data = tone_data,\n",
     "    velocity = velocity,\n",
-    "    sampling_rate = sampling_rate\n",
-    ")"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": null,
-   "id": "e85c5c8e-5317-48b2-b50d-b410c0509eeb",
-   "metadata": {},
-   "outputs": [],
-   "source": [
-    "# plots\n",
-    "plt.style.use('dark_background')\n",
-    "fig, ax = plt.subplots()\n",
-    "\n",
-    "spectrum, freqs, _ = ax.magnitude_spectrum(tone_data, Fs=sampling_rate, scale='linear', sides='twosided', color='white');\n",
-    "spectrum, freqs, _ = ax.magnitude_spectrum(data_d, Fs=sampling_rate, scale='linear', sides='twosided', color='red');\n",
-    "\n",
-    "\n",
-    "ax.set_yscale('log')\n",
-    "# ax.set_xscale('log')\n",
-    "# ax.set_xscale('symlog', \n",
-    "#              base=10,          # Logarithm base\n",
-    "#              linthresh=1/N)   # Threshold for linear region near zero\n",
+    "    propagation_speed = propagation_speed,\n",
+    ")\n",
+    "print(f\"Doppler alpha factor: {alpha:.4f}\")\n",
+    "print(f\"True tone frequency pre-Doppler: {fc:.4f}\")\n",
+    "print(f\"True tone frequency post-Doppler: {fc*alpha:.4f}\")\n",
     "\n",
-    "# Configure axis labels and grid\n",
-    "#ax.set_xlabel('Frequency (Hz) [log]');\n",
-    "ax.set_ylabel('Magnitude [log]');\n",
-    "#plt.ylim([1e-5, None]);"
+    "# estimate frequency shift\n",
+    "D = np.abs(np.fft.fft(data_d, norm='ortho'))\n",
+    "freqs = np.fft.fftfreq(len(D)) * sampling_rate\n",
+    "peaks, _ = find_peaks(D, height=0.1, distance=100)\n",
+    "print(f\"Estimated tone frequency post-Doppler: {freqs[peaks[0]]:.4f}\")"
    ]
   },
   {
-   "cell_type": "code",
-   "execution_count": null,
-   "id": "225e9be0-97ca-404d-af7f-45bfce10e348",
+   "cell_type": "markdown",
+   "id": "d3d4938d-3af8-4bd2-a957-2d585fd18fd6",
    "metadata": {},
-   "outputs": [],
    "source": [
-    "# alpha_default =  2.9979e8 / ( 2.9979e8 - 1e2)\n",
-    "# print(alpha_default)\n",
-    "\n",
-    "alpha_test =  c / ( c - 1e7)\n",
-    "print(alpha_test)\n",
-    "print(\"new freq:\",alpha_test*0.2)\n",
-    "\n",
-    "\n",
-    "freqs = np.fft.fftfreq(N) * 4.0\n",
-    "print(freqs[1])\n"
+    "Plot the input and output spectrum magnitudes. Note that the output magnitude frequency response is not ideally clean - it has some residual frequency spurious components from the multiphase polyphase resampler that implements the wideband Doppler shift."
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
-   "id": "a11aedb8-e88c-4f47-920d-f30cda2272e1",
+   "id": "e85c5c8e-5317-48b2-b50d-b410c0509eeb",
    "metadata": {},
    "outputs": [],
    "source": [
-    "D = np.abs(np.fft.fft(data_d, norm='ortho'))\n",
-    "freqs = np.fft.fftfreq(N) * sampling_rate\n",
-    "\n",
-    "peaks, _ = find_peaks(D, height=0.1, distance=N/20)\n",
-    "plt.plot(freqs, D)\n",
-    "plt.plot(freqs[peaks], D[peaks], \"x\")\n",
+    "plt.style.use('dark_background')\n",
+    "fig, ax = plt.subplots()\n",
     "\n",
-    "print(freqs[peaks])\n",
-    "#print(D[peaks])\n"
+    "spectrum, freqs, _ = ax.magnitude_spectrum(tone_data, Fs=sampling_rate, scale='linear', sides='twosided', color='white');\n",
+    "spectrum, freqs, _ = ax.magnitude_spectrum(data_d, Fs=sampling_rate, scale='linear', sides='twosided', color='red');\n",
+    "ax.set_yscale('log')\n",
+    "ax.set_ylabel('Magnitude');\n",
+    "plt.ylim([1e-15, None]);"
    ]
   }
  ],
  "metadata": {
   "kernelspec": {
-   "display_name": "Python 3",
+   "display_name": "venv",
    "language": "python",
    "name": "python3"
   },
@@ -194,7 +187,7 @@
    "name": "python",
    "nbconvert_exporter": "python",
    "pygments_lexer": "ipython3",
-   "version": "3.10.12"
+   "version": "3.12.3"
   }
  },
  "nbformat": 4,
diff --git a/examples/transforms/impairments.ipynb b/examples/transforms/impairments.ipynb
new file mode 100644
index 000000000..d9e2e3ce0
--- /dev/null
+++ b/examples/transforms/impairments.ipynb
@@ -0,0 +1,166 @@
+{
+ "cells": [
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "# TorchSig: Impairments\n",
+    "\n",
+    "This notebook describes TorchSig's concept of **impairments** and the parameterized Transform lists that comprise different TorchSig impairment levels.\n",
+    "\n",
+    "---"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "## TorchSig Impairment Levels\n",
+    "The Impairments class is a special type of Transform that defines prepackaged lists of parameterized Transforms that are applied in a particular order to generate TorchSig datasets.\n",
+    "\n",
+    "```python\n",
+    "from torchsig.transforms.impairments import Impairments\n",
+    "```\n",
+    "\n",
+    "Impairments is usually employed within generation of TorchSig datasets where the specified **level** parameter guides which Transform list is used for data generation. The different levels were created by Radio Frequency engineers familiar with benchtop and over-the-air device testing. Currently, the provided impairments are\\:\n",
+    "- Level 0: Perfect (digital) environment\n",
+    "- Level 1: Cabled (RF benchtop) environment\n",
+    "- Level 2: Wireless (RF over-the-air) environment\n",
+    "\n",
+    "For levels greater than 0, the components of each Impairment capture the in-order TorchSig Transforms that model transmitter, channel, and receiver effects."
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "## Applying Impairments to datasets\n",
+    "Each Impairments instance holds two Transforms, representing the composition of all impairments to be applied to individual bursts within a signal, and the impairments to be applied to the signal as a whole.\n",
+    "\n",
+    "These transforms, like any other transform or callable object, can be passed into Torchsig datasets.\n",
+    "\n",
+    "In the example below, we are applying level 2 impairments (more detail on impairment levels below) to our dataset."
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "from torchsig.datasets.dataset_metadata import DatasetMetadata\n",
+    "from torchsig.datasets.datasets import TorchSigIterableDataset\n",
+    "from torchsig.transforms.impairments import Impairments"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "dataset_metadata = DatasetMetadata(num_iq_samples_dataset=1024, fft_size=64)\n",
+    "impairments = Impairments(level=2)\n",
+    "burst_impairments = impairments.signal_transforms\n",
+    "whole_signal_impairments = impairments.dataset_transforms\n",
+    "\n",
+    "burst_impairments, whole_signal_impairments"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "dataset = TorchSigIterableDataset(dataset_metadata=dataset_metadata, transforms=[whole_signal_impairments], component_transforms=[burst_impairments])"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "## Impairments: Machine Learning Transforms \n",
+    "The Machine Learning (ML) Transforms are a set of data-oriented augmentations and manipulations that TorchSig developers have commonly found to aid with the training of communications signal domain ML models. You might think of these analogously to the randomized augmentations in image rotation, noise, and local region manipulation that often enhance generalization and speed convergence during model training in other domains like computer vision. These are purely data processing transformations that are not meant to represent real world signal effects and conditions. \n",
+    "\n",
+    "As of TorchSig v2.0.0, the current ML Transform definition randomly chooses among a variety of sample dropping, I/Q channel swapping, slope addition and time series reversal augmentations."
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "## Impairments Level 0\n",
+    "Impairments **level 0** comprises a pristine, unimpaired TorchSig signal generation environment that only exists in digital simulations. No additional signal impairments are present, and only the Machine Learning Transforms are applied. This level can usefully serve as a TorchSig baseline useful for data pipeline validation or as a basis for adding your own custom list of Transforms when building your own environments."
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "## Impairments Level 1\n",
+    "Impairments **level 1** models an RF benchtop or 'wired' channel configuration where plausible Commercial Off The Shelf (COTS) transmitter and recevier hardware apply typical signal nonidealities, but the wired channel is a cable that ensures the path from transmitter to receiver is stable and benign.\n",
+    "\n",
+    "Impairment level 1 introduces a list transmitter hardware Transforms applied to signals after modulation, but prior to traversing the wired channel. This order and the default Transform parameters model the sequence those linear and nonlinear effects would apply to each transmitted signal. \n",
+    "\n",
+    "As of TorchSig v2.0.0, the level 1 transmitter Transform list is:\n",
+    "            - RandomApply(Quantize(),0.75),\n",
+    "            - RandomApply(PassbandRipple(),0.75),\n",
+    "            - RandomApply(IQImbalance(),0.25),\n",
+    "            - RandomApply(CarrierPhaseNoise(),0.75),\n",
+    "            - RandomApply(CarrierFrequencyDrift(),0.75),\n",
+    "            - RandomApply(CarrierPhaseOffset(),1.0),\n",
+    "            - RandomApply(IntermodulationProducts(),0.5),\n",
+    "            - RandomApply(NonlinearAmplifier(),0.75),\n",
+    "            - RandomApply(Spurs(),0.75),\n",
+    "            - RandomApply(SpectralInversion(),0.25)\n",
+    "\n",
+    "Similarly, level 1 introduces a list of receiver hardware Transforms applied to signals after the transmitter and propagation channels cause their effects. \n",
+    "\n",
+    "As of TorchSig v2.0.0, the level 1 receiver Transform list is:\n",
+    "            - RandomApply(IntermodulationProducts(),0.5),\n",
+    "            - RandomApply(NonlinearAmplifier(),0.75),\n",
+    "            - RandomApply(CoarseGainChange(),0.25),\n",
+    "            - RandomApply(Spurs(),0.75),\n",
+    "            - RandomApply(IQImbalance(),0.5),\n",
+    "            - RandomApply(CarrierPhaseNoise(),0.75),\n",
+    "            - RandomApply(CarrierFrequencyDrift(),0.75),\n",
+    "            - RandomApply(CarrierPhaseOffset(),1.0),\n",
+    "            - RandomApply(PassbandRipple(),0.75),\n",
+    "            - RandomApply(Quantize(),0.75),\n",
+    "            - RandomApply(DigitalAGC(),0.25),\n",
+    "\n",
+    "The Machine Learning Transforms are applied after the receiver impairments."
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "## Impairments Level 2\n",
+    "Impairments **level 2** models an RF over-the-air environment by introducing a wireless channel model using the TorchSig Fading Transform. Therefore, level 2 has all the effects of level 1 (including ML Transforms), plus the randomized addition of a fading channel. As of TorchSig v2.0.0, by default this wireless channel is a straightfoward Rayleigh fading model."
+   ]
+  }
+ ],
+ "metadata": {
+  "kernelspec": {
+   "display_name": "Python 3 (ipykernel)",
+   "language": "python",
+   "name": "python3"
+  },
+  "language_info": {
+   "codemirror_mode": {
+    "name": "ipython",
+    "version": 3
+   },
+   "file_extension": ".py",
+   "mimetype": "text/x-python",
+   "name": "python",
+   "nbconvert_exporter": "python",
+   "pygments_lexer": "ipython3",
+   "version": "3.12.3"
+  }
+ },
+ "nbformat": 4,
+ "nbformat_minor": 4
+}
diff --git a/examples/transforms/intermodulation_products.ipynb b/examples/transforms/intermodulation_products.ipynb
index 51e3977a1..daf99c5a3 100644
--- a/examples/transforms/intermodulation_products.ipynb
+++ b/examples/transforms/intermodulation_products.ipynb
@@ -1,5 +1,14 @@
 {
  "cells": [
+  {
+   "cell_type": "markdown",
+   "id": "f2dd776e",
+   "metadata": {},
+   "source": [
+    "# Intermodulation Products\n",
+    "Intermodulation products are created by nonlinearities in analog hardware, represented of the form $\\sum_{k} c[k-1] * x[n]^k$. The 3rd and 5th order terms are the most important because they fall in band due to the sums and differences of the frequency terms."
+   ]
+  },
   {
    "cell_type": "code",
    "execution_count": null,
@@ -22,6 +31,14 @@
     "import matplotlib.pyplot as plt"
    ]
   },
+  {
+   "cell_type": "markdown",
+   "id": "7c1eaac0",
+   "metadata": {},
+   "source": [
+    "Two test signals are created: a QPSK signal and an unmodulated carrier (tone)."
+   ]
+  },
   {
    "cell_type": "code",
    "execution_count": null,
@@ -138,6 +155,14 @@
     "    return signal"
    ]
   },
+  {
+   "cell_type": "markdown",
+   "id": "4d60575c",
+   "metadata": {},
+   "source": [
+    "The QPSK and tone signals are created."
+   ]
+  },
   {
    "cell_type": "code",
    "execution_count": null,
@@ -166,6 +191,14 @@
     "freq_vec = np.arange(-1.0/2,1.0/2,1.0/(N*8))"
    ]
   },
+  {
+   "cell_type": "markdown",
+   "id": "42ca5934",
+   "metadata": {},
+   "source": [
+    "The 3rd order intermodulation distortion model (IMD) is applied to the QPSK and tone signals. Notice how the frequency plot demonstrates an increase in the bandwidth of the QPSK signal, and results in two extra tones for the tone signal case."
+   ]
+  },
   {
    "cell_type": "code",
    "execution_count": null,
@@ -207,6 +240,14 @@
     "ax[1].legend(['Nonlinear','Linear'],fontsize='large', loc='upper left');"
    ]
   },
+  {
+   "cell_type": "markdown",
+   "id": "d1c65a0e",
+   "metadata": {},
+   "source": [
+    "The 5th order intermodulation product transform is applied to the QPSK signal. For QPSK, the result is similar to the 3rd order, however there is less visible contribution from the 5th order terms because they are smaller in magnitude. For the tone signal, a two additional tones are created but at reduced magnitudes."
+   ]
+  },
   {
    "cell_type": "code",
    "execution_count": null,
diff --git a/examples/transforms/iq_imbalance.ipynb b/examples/transforms/iq_imbalance.ipynb
index e5f40553d..a7b0a57a3 100644
--- a/examples/transforms/iq_imbalance.ipynb
+++ b/examples/transforms/iq_imbalance.ipynb
@@ -1,5 +1,14 @@
 {
  "cells": [
+  {
+   "cell_type": "markdown",
+   "id": "fb275ef5",
+   "metadata": {},
+   "source": [
+    "# IQ Imbalance Transform\n",
+    "I/Q Imbalance is a predominantly radio hardware effect that comes from direct conversion transmitters and receivers whose I and Q channels are not perfectly $90^o$ aligned with one another. A relative phase error between the I and Q channels will cause deterministic phase and amplitude distortion, alongside a direct-current (DC) offset."
+   ]
+  },
   {
    "cell_type": "code",
    "execution_count": null,
@@ -17,6 +26,14 @@
     "import matplotlib.pyplot as plt"
    ]
   },
+  {
+   "cell_type": "markdown",
+   "id": "7254a50f",
+   "metadata": {},
+   "source": [
+    "The following function creates a test QPSK signal."
+   ]
+  },
   {
    "cell_type": "code",
    "execution_count": null,
@@ -75,6 +92,14 @@
     "    return signal"
    ]
   },
+  {
+   "cell_type": "markdown",
+   "id": "bf0088f2",
+   "metadata": {},
+   "source": [
+    "IQ imbalance is applied to the QPSK signal. The effect manifests itself by distorting the otherwise square constellation shape and marginally increasing the DC offset by moving constellation the direction represented by `dc_offset_phase_rads`."
+   ]
+  },
   {
    "cell_type": "code",
    "execution_count": null,
@@ -89,9 +114,10 @@
     "# IQ imbalance model\n",
     "impaired_qpsk_data = F.iq_imbalance(\n",
     "    data = qpsk_data,\n",
-    "    amplitude_imbalance = 1,\n",
+    "    amplitude_imbalance = 1, # dB\n",
     "    phase_imbalance = np.pi/10,\n",
-    "    dc_offset = (0.01,0.01)\n",
+    "    dc_offset_db = 10,\n",
+    "    dc_offset_phase_rads = -np.pi/20\n",
     ")\n",
     "\n",
     "freq_vec = np.arange(-1.0/2,1.0/2,1.0/(N))\n",
@@ -123,7 +149,7 @@
  ],
  "metadata": {
   "kernelspec": {
-   "display_name": "Python 3",
+   "display_name": "Python 3 (ipykernel)",
    "language": "python",
    "name": "python3"
   },
diff --git a/examples/transforms/noise_plots.ipynb b/examples/transforms/noise_plots.ipynb
index a50fff746..d206ad460 100644
--- a/examples/transforms/noise_plots.ipynb
+++ b/examples/transforms/noise_plots.ipynb
@@ -5,7 +5,8 @@
    "id": "71d06404-6c20-40be-a8b7-9788df6ec9d5",
    "metadata": {},
    "source": [
-    "# Plots of colored noise generation transform"
+    "# Noise Generation and Additive Noise Transform\n",
+    "This notebook illustrates some of the primary options for generating noise of various configurations using both the provided noise_generator utility and the additive noise transform"
    ]
   },
   {
@@ -17,7 +18,7 @@
    "source": [
     "import torchsig.transforms.functional as F\n",
     "from torchsig.utils.dsp import (\n",
-    "    torchsig_complex_data_type,\n",
+    "    TorchSigComplexDataType,\n",
     "    noise_generator\n",
     ")\n",
     "\n",
@@ -27,23 +28,11 @@
    ]
   },
   {
-   "cell_type": "code",
-   "execution_count": null,
-   "id": "e66b1d27-6165-4155-ab95-d3e41925f1af",
+   "cell_type": "markdown",
+   "id": "54e296ac-2aa3-415d-88fc-2914cd3c99dc",
    "metadata": {},
-   "outputs": [],
    "source": [
-    "N = 100000\n",
-    "rng = np.random.default_rng(seed=42)\n",
-    "#noise = (1 + 1j) / np.sqrt(2)\n",
-    "noise = (rng.standard_normal((1,)) + 1j*rng.standard_normal((1,))) / np.sqrt(2)\n",
-    "power = np.abs(noise)**2\n",
-    "print(power)\n",
-    "\n",
-    "noise0 = np.zeros((N,),dtype=torchsig_complex_data_type)\n",
-    "print(noise.dtype)\n",
-    "print(noise0.dtype)\n",
-    "noise0"
+    "Generate continous noise of colors white, pink, and red. Plot the magnitude spectra and compare the frequency roll-offs."
    ]
   },
   {
@@ -82,6 +71,14 @@
     "#plt.ylim([1e-5, None]);"
    ]
   },
+  {
+   "cell_type": "markdown",
+   "id": "1838d926-f237-40df-97cd-e845221b3e5e",
+   "metadata": {},
+   "source": [
+    "Generate impulsive noise of colors white, pink, and red. Plot the magnitude spectra and compare the frequency roll-offs."
+   ]
+  },
   {
    "cell_type": "code",
    "execution_count": null,
@@ -89,7 +86,6 @@
    "metadata": {},
    "outputs": [],
    "source": [
-    "# impulsive noise generator plots\n",
     "N = 100000\n",
     "freqs = np.fft.fftfreq(N)\n",
     "\n",
@@ -118,6 +114,14 @@
     "#plt.ylim([1e-5, None]);"
    ]
   },
+  {
+   "cell_type": "markdown",
+   "id": "fd8bdd8d-800b-4477-8e01-5f1ad4295d93",
+   "metadata": {},
+   "source": [
+    "Demonstrate the additive noise function transform."
+   ]
+  },
   {
    "cell_type": "code",
    "execution_count": null,
@@ -125,11 +129,9 @@
    "metadata": {},
    "outputs": [],
    "source": [
-    "# test functional additive noise\n",
-    "\n",
     "# continous noise generator plots\n",
     "N = 100000\n",
-    "data_z = np.zeros((N,), dtype=torchsig_complex_data_type)\n",
+    "data_z = np.zeros((N,), dtype=TorchSigComplexDataType)\n",
     "freqs = np.fft.fftfreq(N)\n",
     "\n",
     "# plots\n",
@@ -153,13 +155,13 @@
     "# # Configure axis labels and grid\n",
     "ax2.set_xlabel('Frequency (Hz) [log]');\n",
     "ax2.set_ylabel('Magnitude [log]');\n",
-    "plt.ylim([1e-5, None]);\n"
+    "plt.ylim([1e-5, None]);"
    ]
   }
  ],
  "metadata": {
   "kernelspec": {
-   "display_name": "ts_dev",
+   "display_name": "Python 3 (ipykernel)",
    "language": "python",
    "name": "python3"
   },
@@ -173,7 +175,7 @@
    "name": "python",
    "nbconvert_exporter": "python",
    "pygments_lexer": "ipython3",
-   "version": "3.12.9"
+   "version": "3.10.12"
   }
  },
  "nbformat": 4,
diff --git a/examples/transforms/nonlinear_amp_plots.ipynb b/examples/transforms/nonlinear_amp_plots.ipynb
index 167958b07..abc84fedc 100644
--- a/examples/transforms/nonlinear_amp_plots.ipynb
+++ b/examples/transforms/nonlinear_amp_plots.ipynb
@@ -1,5 +1,14 @@
 {
  "cells": [
+  {
+   "cell_type": "markdown",
+   "id": "b917e481",
+   "metadata": {},
+   "source": [
+    "# Nonlinear Amplifier\n",
+    "The following notebook demonstrates the function-baed nonlinear amplifier transform, which models the compressive effects of a nonlinear amplifier."
+   ]
+  },
   {
    "cell_type": "code",
    "execution_count": null,
@@ -20,6 +29,14 @@
     "import matplotlib.pyplot as plt"
    ]
   },
+  {
+   "cell_type": "markdown",
+   "id": "0f3ff07d",
+   "metadata": {},
+   "source": [
+    "This function creates a QPSK signal which is used to test the nonlinear amplifier."
+   ]
+  },
   {
    "cell_type": "code",
    "execution_count": null,
@@ -78,6 +95,14 @@
     "    return signal"
    ]
   },
+  {
+   "cell_type": "markdown",
+   "id": "f4940334",
+   "metadata": {},
+   "source": [
+    "The QPSK signal is created and then resampled."
+   ]
+  },
   {
    "cell_type": "code",
    "execution_count": null,
@@ -96,6 +121,18 @@
     "print(qpsk_mean_power)"
    ]
   },
+  {
+   "cell_type": "markdown",
+   "id": "e6cf6ab9",
+   "metadata": {},
+   "source": [
+    "The nonlinear amplifier is parameterized and then applied to the QPSK signal. The `pin_dBW` variable determines the range for which the amplifier is simulated over. Increasing the input power into an amplifier can reach a nonlinear region in which there are dimensing returns in terms of gain, or no increase in gain at all, which is the nonlinear effect.\n",
+    "\n",
+    "The transform does not model the amplification effect itself (due to how SNR and power values are handled internally), but instead applies the nonlinear compressive effect. Therefore, a nominal gain of 1.0 is used with a saturation level `psat` of 1.0 W input power. The phase response is handled with the maximum phase difference according to the `phi_max` and the rate of change represented by `phi_slope`.\n",
+    "\n",
+    "The result shows that as the input power `pin` increases the nonlinear compression effect is more pronounced. With `pin=-10dB` the effect is not noticable, when `pin=-5dB` some distortion can be seen around the edge of the constellation diagram, and when `pin=0dB` the four constellation points are moved off their originating points."
+   ]
+  },
   {
    "cell_type": "code",
    "execution_count": null,
@@ -168,7 +205,7 @@
  ],
  "metadata": {
   "kernelspec": {
-   "display_name": "Python 3",
+   "display_name": "Python 3 (ipykernel)",
    "language": "python",
    "name": "python3"
   },
diff --git a/examples/transforms/passband_ripple_plots.ipynb b/examples/transforms/passband_ripple_plots.ipynb
index ad3edd916..d00230556 100644
--- a/examples/transforms/passband_ripple_plots.ipynb
+++ b/examples/transforms/passband_ripple_plots.ipynb
@@ -5,7 +5,8 @@
    "id": "71d06404-6c20-40be-a8b7-9788df6ec9d5",
    "metadata": {},
    "source": [
-    "# Passband Ripple"
+    "# Passband Ripple\n",
+    "A slight passband ripple effect is applied to simulate analog filtering in RF front ends."
    ]
   },
   {
@@ -26,6 +27,14 @@
     "import matplotlib.pyplot as plt"
    ]
   },
+  {
+   "cell_type": "markdown",
+   "id": "3a6629fb-5044-4c1d-a6c3-a33fee316344",
+   "metadata": {},
+   "source": [
+    "Function for generating a test modulated QPSK signal."
+   ]
+  },
   {
    "cell_type": "code",
    "execution_count": null,
@@ -84,6 +93,14 @@
     "    return signal"
    ]
   },
+  {
+   "cell_type": "markdown",
+   "id": "f08c8e62",
+   "metadata": {},
+   "source": [
+    "The passband ripple impairment is applied to a QPSK signal. The impairment is parameterized by the number of taps, the maximum amount of ripple, and an exponential decay rate that controls the rate at which the filter weights decrease to zero."
+   ]
+  },
   {
    "cell_type": "code",
    "execution_count": null,
@@ -101,9 +118,24 @@
     "    num_taps = 3,\n",
     "    max_ripple_db=2,\n",
     "    coefficient_decay_rate=2\n",
-    ")\n",
-    "\n",
-    "### Plots\n",
+    ")"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "id": "8179c9a2-467d-428c-9522-280f4dabf79d",
+   "metadata": {},
+   "source": [
+    "Plots of entire spectrum and zoomed to in-band spectrum responses (frequency normalized). Viewing the zoomed in spectral response will demonstrate a ripple effect, with a slight change from the input signal."
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "8970d462-06bf-4c5e-89f1-def97fed5709",
+   "metadata": {},
+   "outputs": [],
+   "source": [
     "fig = plt.figure(figsize=(10,8))\n",
     "ax = fig.add_subplot(2,1,1)\n",
     "fft_size = N\n",
@@ -123,23 +155,13 @@
     "ax.set_ylabel('Magnitude (dB)')\n",
     "ax.legend()\n",
     "ax.grid()\n",
-    "ax.set_ylim([-10,15])\n",
-    "\n",
-    "\n"
-   ]
-  },
-  {
-   "cell_type": "markdown",
-   "id": "f0b83469-ef00-4892-9b85-cfa8f57a1bbf",
-   "metadata": {},
-   "source": [
-    "#### "
+    "ax.set_ylim([-10,15])"
    ]
   }
  ],
  "metadata": {
   "kernelspec": {
-   "display_name": "Python 3",
+   "display_name": "Python 3 (ipykernel)",
    "language": "python",
    "name": "python3"
   },
diff --git a/examples/transforms/phase_offset.ipynb b/examples/transforms/phase_offset.ipynb
index e346906a1..47619286c 100644
--- a/examples/transforms/phase_offset.ipynb
+++ b/examples/transforms/phase_offset.ipynb
@@ -1,5 +1,14 @@
 {
  "cells": [
+  {
+   "cell_type": "markdown",
+   "id": "678d16da",
+   "metadata": {},
+   "source": [
+    "# Carrier Phase Offset\n",
+    "Carrier phase offset is a randomized phase between 0 and $2\\pi$ that is applied to a signal. The transform is usually employed to simulate a fixed carrier phase offset corresponding to a fixed propagation time delay for the signal that may include transmitter hardware, the channel, and the receiver hardware. The effect is applied by multiplying the signal by complex exponential $e^{j\\phi}$ where $\\phi \\sim U(0,2\\pi)$."
+   ]
+  },
   {
    "cell_type": "code",
    "execution_count": null,
@@ -17,6 +26,14 @@
     "import matplotlib.pyplot as plt"
    ]
   },
+  {
+   "cell_type": "markdown",
+   "id": "fc9a89bd-0491-40ac-91e3-cd3178b947f8",
+   "metadata": {},
+   "source": [
+    "Function for generating the test QPSK modulated signal."
+   ]
+  },
   {
    "cell_type": "code",
    "execution_count": null,
@@ -75,6 +92,14 @@
     "    return signal"
    ]
   },
+  {
+   "cell_type": "markdown",
+   "id": "4c4c30f5-3649-49a3-99e6-bf7709197402",
+   "metadata": {},
+   "source": [
+    "Generate modulated input data and apply the transform with a fixed pi/8 phase offset."
+   ]
+  },
   {
    "cell_type": "code",
    "execution_count": null,
@@ -86,12 +111,28 @@
     "N = 1024\n",
     "qpsk_data = generate_qpsk_signal(num_iq_samples = N, scale = 1.0).data\n",
     "\n",
-    "# IQ imbalance model\n",
+    "# apply transform\n",
     "impaired_qpsk_data = F.phase_offset(\n",
     "    data = qpsk_data,\n",
     "    phase = np.pi/8\n",
-    ")\n",
-    "\n",
+    ")"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "id": "9557adff-02e4-43d4-916e-e303314c7d7d",
+   "metadata": {},
+   "source": [
+    "Plot the I/Q constellation result - note the fixed pi/8 rotation for all samples."
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "c4b8063d-748b-4484-9112-9ac0137ca02a",
+   "metadata": {},
+   "outputs": [],
+   "source": [
     "fig = plt.figure(figsize=(6,6))\n",
     "ax = fig.add_subplot(1,1,1)\n",
     "ax.set_box_aspect(1)\n",
@@ -107,7 +148,7 @@
  ],
  "metadata": {
   "kernelspec": {
-   "display_name": "Python 3",
+   "display_name": "Python 3 (ipykernel)",
    "language": "python",
    "name": "python3"
   },
diff --git a/examples/transforms/quantize.ipynb b/examples/transforms/quantize.ipynb
index b2f71253d..218f104f9 100644
--- a/examples/transforms/quantize.ipynb
+++ b/examples/transforms/quantize.ipynb
@@ -1,5 +1,14 @@
 {
  "cells": [
+  {
+   "cell_type": "markdown",
+   "id": "fdd24fdf-3a52-4b72-9c50-395395356b08",
+   "metadata": {},
+   "source": [
+    "# Quantize Transform\n",
+    "This notebook illustrates the effects of quantizing signals. Different quantization methods have particular nonlinear effects on signal properties such as dynamic range."
+   ]
+  },
   {
    "cell_type": "code",
    "execution_count": null,
@@ -17,6 +26,14 @@
     "import matplotlib.pyplot as plt"
    ]
   },
+  {
+   "cell_type": "markdown",
+   "id": "927c85e0-3bf5-4717-b42b-1d45f7e1a031",
+   "metadata": {},
+   "source": [
+    "Generator function for test modulated signal input"
+   ]
+  },
   {
    "cell_type": "code",
    "execution_count": null,
@@ -75,10 +92,18 @@
     "    return signal"
    ]
   },
+  {
+   "cell_type": "markdown",
+   "id": "1c6e5c2c-f51d-4ab0-9403-67202fd5648a",
+   "metadata": {},
+   "source": [
+    "Create input test data at full scale complex64 precision."
+   ]
+  },
   {
    "cell_type": "code",
    "execution_count": null,
-   "id": "50a617f8-356f-4b7d-8f83-fc51f9508b3d",
+   "id": "da3f4d5c-f3d9-4ebc-a531-44d06a293903",
    "metadata": {},
    "outputs": [],
    "source": [
@@ -88,11 +113,29 @@
     "\n",
     "# add in a tiny amount of noise to avoid log10(0)\n",
     "complex_noise = np.sqrt(1e-6)*(np.random.normal(0,1,N) + 1j*np.random.normal(0,1,N))\n",
-    "qpsk_data += complex_noise\n",
-    "\n",
+    "qpsk_data += complex_noise"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "id": "ff2c14c7-14c9-4259-b513-55a9477fc0e7",
+   "metadata": {},
+   "source": [
+    "Illustrate the effects of 8-bit quantization for three different quantizing configurations"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "50a617f8-356f-4b7d-8f83-fc51f9508b3d",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "# quantization: fixed configuration parameters\n",
     "num_bits = 8\n",
     "rounding_mode = 'floor'\n",
     "\n",
+    "\n",
     "# simulate quantization at full scale\n",
     "qpsk_data_full_scale = F.quantize(\n",
     "    data = qpsk_data,\n",
@@ -129,7 +172,24 @@
     "below_full_scale_sfdr = np.mean(np.abs(qpsk_data)**2) / np.mean(np.abs(qpsk_data-qpsk_data_below_full_scale)**2)\n",
     "below_full_scale_sfdr_db = 10*np.log10(below_full_scale_sfdr)\n",
     "enob_below_full_scale = below_full_scale_sfdr_db/6.02\n",
-    "\n",
+    "\n"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "id": "542389d7-fbb3-4459-94c3-b0dd90acbf7d",
+   "metadata": {},
+   "source": [
+    "Plot the Full Scale, Saturated, and below Full Scale effects"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "975e2c4e-27fb-45de-aa0d-395d5cf4610c",
+   "metadata": {},
+   "outputs": [],
+   "source": [
     "fig = plt.figure(figsize=(16,12))\n",
     "fig.subplots_adjust(hspace=0.5)\n",
     "\n",
@@ -156,13 +216,13 @@
     "ax.grid()\n",
     "ax.set_title(f'Quantization when Below Full Scale by {below_level_db:0.1f} dB. SFDR = {below_full_scale_sfdr_db:0.1f}, ENOB = {enob_below_full_scale:0.1f} bits')\n",
     "ax.set_xlabel('Time Index $n$',fontsize='large')\n",
-    "ax.set_ylabel('Amplitude')\n"
+    "ax.set_ylabel('Amplitude')"
    ]
   }
  ],
  "metadata": {
   "kernelspec": {
-   "display_name": "Python 3",
+   "display_name": "Python 3 (ipykernel)",
    "language": "python",
    "name": "python3"
   },
diff --git a/examples/transforms/shadowing_plots.ipynb b/examples/transforms/shadowing_plots.ipynb
index ebb44b455..0103de1b6 100644
--- a/examples/transforms/shadowing_plots.ipynb
+++ b/examples/transforms/shadowing_plots.ipynb
@@ -5,8 +5,8 @@
    "id": "71d06404-6c20-40be-a8b7-9788df6ec9d5",
    "metadata": {},
    "source": [
-    "# Plots of shadowing transform\n",
-    "Refer to: https://www.gaussianwaves.com/2013/09/log-distance-path-loss-or-log-normal-shadowing-model/\n"
+    "# Shadowing Transform\n",
+    "This notebook demonstrates the shadowing transform. Shadowing corresponds to real-world path blockages and channel effects that cause signal path losses to deviate significantly from unobstructed free-space path loss between transmitter and receiver. Though these effects vary greatly, they are commonly modeled as following a log-normal response (Refer to: https://www.gaussianwaves.com/2013/09/log-distance-path-loss-or-log-normal-shadowing-model/), as parameterized by the log-normal distribution mean and standard deviation."
    ]
   },
   {
@@ -21,7 +21,7 @@
     "from torchsig.signals.builders.tone import ToneSignalBuilder\n",
     "import torchsig.transforms.functional as F\n",
     "from torchsig.utils.dsp import (\n",
-    "    torchsig_complex_data_type\n",
+    "    TorchSigComplexDataType\n",
     ")\n",
     "\n",
     "import numpy as np\n",
@@ -32,6 +32,14 @@
     "from scipy.signal import spectrogram"
    ]
   },
+  {
+   "cell_type": "markdown",
+   "id": "fe632b2d-03c2-4bf7-bcf2-d2ba24049b47",
+   "metadata": {},
+   "source": [
+    "Generator function for QPSK test signal."
+   ]
+  },
   {
    "cell_type": "code",
    "execution_count": null,
@@ -89,11 +97,19 @@
     "        norm_order = 2,\n",
     "        flatten = False\n",
     "    )\n",
-    "    signal.data = np.multiply(signal.data, scale).astype(torchsig_complex_data_type)\n",
+    "    signal.data = np.multiply(signal.data, scale).astype(TorchSigComplexDataType)\n",
     "\n",
     "    return signal"
    ]
   },
+  {
+   "cell_type": "markdown",
+   "id": "377ad0e1-0396-409c-a025-a078b771533f",
+   "metadata": {},
+   "source": [
+    "Generate test input data."
+   ]
+  },
   {
    "cell_type": "code",
    "execution_count": null,
@@ -103,25 +119,23 @@
    "source": [
     "rng = np.random.default_rng(42)\n",
     "\n",
+    "# signal parameters\n",
     "N = 10000\n",
     "sampling_rate = 4.0\n",
-    "tone_bb_data = generate_tone_signal(num_iq_samples = N, scale = 1.0).data \n",
-    "tone_data = tone_bb_data * np.exp(2j * np.pi * 0.2 * np.arange(N) / sampling_rate)\n",
-    "tone_power = np.mean(np.abs(tone_data) ** 2)\n",
-    "\n",
-    "# point check\n",
-    "mean_db = 0\n",
-    "sigma_db = 3\n",
-    "power_db = rng.normal(mean_db, sigma_db) # normal distribution in log domain\n",
-    "#power_db = -3.0\n",
-    "\n",
-    "new_tone = tone_data * 10 ** (power_db / 20)\n",
-    "new_power = np.mean(np.abs(new_tone) ** 2)\n",
+    "fc = 0.2 # center frequency\n",
     "\n",
-    "print(\"power_db: \",power_db)\n",
-    "print(tone_power)\n",
-    "print(new_power)\n",
-    "print(\"ratio: \",10*np.log10(new_power) - 10*np.log10(tone_power))"
+    "# generate, frequency shift, and power scale the input tone signal\n",
+    "tone_bb_data = generate_tone_signal(num_iq_samples = N, scale = 1.0).data \n",
+    "tone_data = tone_bb_data * np.exp(2j * np.pi * fc * np.arange(N) / sampling_rate)\n",
+    "tone_power = np.mean(np.abs(tone_data) ** 2)"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "id": "6c1cdeec-ce9b-4d29-bcba-2d1ce175454b",
+   "metadata": {},
+   "source": [
+    "Test log-normal shadowing power distribution with multiple transform calls."
    ]
   },
   {
@@ -131,10 +145,8 @@
    "metadata": {},
    "outputs": [],
    "source": [
-    "rng = np.random.default_rng(42)\n",
-    "\n",
     "# functional check\n",
-    "n_iterations = 30\n",
+    "n_iterations = 1000\n",
     "results = [\n",
     "    10*np.log10(np.mean(np.abs(\n",
     "        F.shadowing(\n",
@@ -155,15 +167,35 @@
     "if p_value > 0.05:\n",
     "    print(\"The distribution is likely normal\")\n",
     "else:\n",
-    "    print(\"The distribution is likely not normal\")\n",
-    "\n",
-    "plt.plot(results_array)"
+    "    print(\"The distribution is likely not normal\")"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "id": "921aabc8-a606-4f67-b614-5e373cea1812",
+   "metadata": {},
+   "source": [
+    "Plot output power distribution histogram."
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "f22b941e-96e1-4d92-96f8-c36132bfd284",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "fig = plt.figure(figsize=(6,6))\n",
+    "plt.hist(results_array);\n",
+    "plt.title('Shadowing: Power Distribution');\n",
+    "plt.xlabel('Mean Signal Power [dB]');\n",
+    "plt.ylabel('Frequency');"
    ]
   }
  ],
  "metadata": {
   "kernelspec": {
-   "display_name": "Python 3",
+   "display_name": "Python 3 (ipykernel)",
    "language": "python",
    "name": "python3"
   },
diff --git a/examples/transforms/spectral_inversion.ipynb b/examples/transforms/spectral_inversion.ipynb
index 30e03ec81..318f6ae6e 100644
--- a/examples/transforms/spectral_inversion.ipynb
+++ b/examples/transforms/spectral_inversion.ipynb
@@ -1,5 +1,14 @@
 {
  "cells": [
+  {
+   "cell_type": "markdown",
+   "id": "badc340d-828f-4bf0-ab87-9018de851536",
+   "metadata": {},
+   "source": [
+    "# Spectral Inversion\n",
+    "Notebook illustrating the spectral inversion transform. Spectral inversion usual occurs during a frequency conversion stage where the frequency scheme mirrors the signal spectrum frequency response."
+   ]
+  },
   {
    "cell_type": "code",
    "execution_count": null,
@@ -18,6 +27,14 @@
     "import matplotlib.pyplot as plt"
    ]
   },
+  {
+   "cell_type": "markdown",
+   "id": "37463846-ef36-4297-8fe0-4c23c87b8d5a",
+   "metadata": {},
+   "source": [
+    "Function for generating modulated test input signal."
+   ]
+  },
   {
    "cell_type": "code",
    "execution_count": null,
@@ -76,14 +93,21 @@
     "    return signal"
    ]
   },
+  {
+   "cell_type": "markdown",
+   "id": "4d09b38f-4658-4da3-a466-f1513f47c9a1",
+   "metadata": {},
+   "source": [
+    "Create test data at some center frequency, then apply spectral inversion."
+   ]
+  },
   {
    "cell_type": "code",
    "execution_count": null,
-   "id": "50a617f8-356f-4b7d-8f83-fc51f9508b3d",
+   "id": "d1c4f0f0-a44b-4bc6-8d81-04aa9fce8ad1",
    "metadata": {},
    "outputs": [],
    "source": [
-    "# test data\n",
     "N = 1024\n",
     "qpsk_data_baseband = generate_qpsk_signal(num_iq_samples = N, scale = 1.0).data\n",
     "sample_rate = 1\n",
@@ -93,8 +117,24 @@
     "# spectral inversion\n",
     "impaired_qpsk_data = F.spectral_inversion(\n",
     "    data = qpsk_data_if\n",
-    ")\n",
-    "\n",
+    ")"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "id": "59017f8f-61ed-47b2-b949-dd00ca78443c",
+   "metadata": {},
+   "source": [
+    "Plot signal with and without spectral inversion - note the frequency mirror around the origin."
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "50a617f8-356f-4b7d-8f83-fc51f9508b3d",
+   "metadata": {},
+   "outputs": [],
+   "source": [
     "freq_vec = np.arange(-1.0/2,1.0/2,1.0/(N))\n",
     "qpsk_fft = np.fft.fftshift(np.fft.fft(qpsk_data_if))/np.sqrt(N)\n",
     "impaired_qpsk_fft = np.fft.fftshift(np.fft.fft(impaired_qpsk_data))/np.sqrt(N)\n",
@@ -102,7 +142,7 @@
     "fig = plt.figure(figsize=(12,8))\n",
     "ax = fig.add_subplot(1,1,1)\n",
     "ax.plot(freq_vec, 20*np.log10(np.abs(qpsk_fft)),label='Input');\n",
-    "ax.plot(freq_vec, 20*np.log10(np.abs(impaired_qpsk_fft)),alpha=0.5,label='Spectral Inversion');\n",
+    "ax.plot(freq_vec, 20*np.log10(np.abs(impaired_qpsk_fft)),alpha=0.5,label='Spectrally Inverted');\n",
     "ax.set_ylim([-70, 0])\n",
     "ax.set_xlim([freq_vec[0],freq_vec[-1]])\n",
     "ax.set_ylabel('Magnitude (log10)',fontsize='large');\n",
@@ -110,11 +150,19 @@
     "ax.legend(fontsize='large', loc='upper left');\n",
     "ax.grid()"
    ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "603c4aec-65f7-4aa6-af67-c9f16119249f",
+   "metadata": {},
+   "outputs": [],
+   "source": []
   }
  ],
  "metadata": {
   "kernelspec": {
-   "display_name": "Python 3",
+   "display_name": "Python 3 (ipykernel)",
    "language": "python",
    "name": "python3"
   },
diff --git a/examples/transforms/spurs.ipynb b/examples/transforms/spurs.ipynb
index 23b749090..f7e4830ac 100644
--- a/examples/transforms/spurs.ipynb
+++ b/examples/transforms/spurs.ipynb
@@ -1,5 +1,14 @@
 {
  "cells": [
+  {
+   "cell_type": "markdown",
+   "id": "93dc34b3-ef15-430e-8598-edab37acab03",
+   "metadata": {},
+   "source": [
+    "# Spurs Transform\n",
+    "Spurs, short for spurious signals, are undesired signal components within the band of interest. They are produced by many real world sources such as power circuitry, clocks and oscillator harmonics, and many other electronics. The TorchSig spur functional transform enables placement of narrowband spurs within the band at any frequency and relative power level. "
+   ]
+  },
   {
    "cell_type": "code",
    "execution_count": null,
@@ -14,6 +23,14 @@
     "import matplotlib.pyplot as plt"
    ]
   },
+  {
+   "cell_type": "markdown",
+   "id": "0ce120cb-478d-4557-9a4b-16d8441dd7a8",
+   "metadata": {},
+   "source": [
+    "Generate white gaussian noise as the input test signal. Add spurs at 1, 2, and 3 MHz with +10, +15, and +20 dB power relative to the noise floor."
+   ]
+  },
   {
    "cell_type": "code",
    "execution_count": null,
@@ -21,20 +38,36 @@
    "metadata": {},
    "outputs": [],
    "source": [
-    "# generate noise\n",
     "N = 1024\n",
-    "noise = np.sqrt(1e-6)*(np.random.normal(0,1,N) + 1j*np.random.normal(0,1,N))\n",
-    "\n",
     "sample_rate = 10e6\n",
     "\n",
+    "# generate white gaussian noise\n",
+    "noise = np.sqrt(1e-6)*(np.random.normal(0,1,N) + 1j*np.random.normal(0,1,N))\n",
+    "\n",
     "# simulate quantization at full scale\n",
     "noise_with_spurs = F.spurs(\n",
     "    data = noise,\n",
     "    center_freqs = [1e6, 2e6, 3e6],\n",
     "    relative_power_db = [10, 15, 20],\n",
     "    sample_rate = sample_rate\n",
-    ")\n",
-    "\n",
+    ")"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "id": "4cc21517-bc5c-45fb-9478-91783352afac",
+   "metadata": {},
+   "source": [
+    "Plot the combined noise and spurs."
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "a1ad7765-f78d-4740-aad8-f9d99a4b9709",
+   "metadata": {},
+   "outputs": [],
+   "source": [
     "fig = plt.figure(figsize=(12,6))\n",
     "fig.subplots_adjust(hspace=0.5)\n",
     "ax = fig.add_subplot(1,1,1)\n",
@@ -44,13 +77,13 @@
     "ax.grid()\n",
     "ax.set_title(f'AWGN with Added Spurs')\n",
     "ax.set_xlabel('Frequency',fontsize='large')\n",
-    "ax.set_ylabel('Magnitude (dB)',fontsize='large')\n"
+    "ax.set_ylabel('Magnitude (dB)',fontsize='large')"
    ]
   }
  ],
  "metadata": {
   "kernelspec": {
-   "display_name": "Python 3",
+   "display_name": "Python 3 (ipykernel)",
    "language": "python",
    "name": "python3"
   },
diff --git a/examples/yaml_dataset_example.ipynb b/examples/yaml_dataset_example.ipynb
new file mode 100644
index 000000000..291593061
--- /dev/null
+++ b/examples/yaml_dataset_example.ipynb
@@ -0,0 +1,131 @@
+{
+ "cells": [
+  {
+   "cell_type": "markdown",
+   "id": "72ac19c9-296e-4631-bca6-f4cd1961b0f8",
+   "metadata": {},
+   "source": [
+    "# Saving and loading Datasets From YAML\n",
+    "This notebook showcases how TorchSig datasets can be saved as YAML files and loaded from YAML later for convenience. \n",
+    "This is useful when trying to share or version control a large dataset so that it can be reproduced exactly across different teams, but without sharing large arrays of data or different dataset creation scripts.\n",
+    "\n",
+    "---"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "id": "f02d5074-ab5f-40a3-9ed6-740aa9efc192",
+   "metadata": {},
+   "source": [
+    "## Saving to YAML\n",
+    "The dataset below is saved to a YAML file for use later. \n",
+    "Since we give a seed to the dataset, the yaml file will store that seed and use it to reproduce the exact data every time we load from the YAML."
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "0cf57051-abbf-4f96-b480-9a1df4f60775",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "from torchsig.utils.defaults import default_dataset\n",
+    "from torchsig.utils.yaml import save_dataset_yaml, load_dataset_yaml"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "c8984a8b-cd7d-44a0-8b02-0a64ad99300a",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "filepath = \"./datasets/yaml_test_dataset\""
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "41f5241e-99c7-4848-b5f4-e0024b9d1d8e",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "dataset = default_dataset(seed=42, target_labels=[\"class_name\",\"snr_db\"], impairment_level=None) # basic default dataset used for testing\n",
+    "save_dataset_yaml(filepath, dataset)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "fe000c3b-d271-4c82-b94b-596d7122e5b8",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "print(next(dataset))\n",
+    "print(next(dataset))\n",
+    "print(next(dataset))"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "id": "5f99dbad-7cee-47e2-b251-ccebe24cd94b",
+   "metadata": {},
+   "source": [
+    "## Loading from YAML\n",
+    "Now we load a copy of the same dataset. Because the copy loads the same random seed from YAML, the values returned below should match the values above."
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "640eed4f-a9aa-4d26-bb2b-76b69751da18",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "dataset_copy = load_dataset_yaml(filepath)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "b258e9e5-749b-4464-bbda-320fedf48fb5",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "print(next(dataset_copy))\n",
+    "print(next(dataset_copy))\n",
+    "print(next(dataset_copy))"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "id": "11840cab-91e1-4ea4-aa23-9500b24389ea",
+   "metadata": {},
+   "source": [
+    "### NOTE:\n",
+    "As of torchsig 2.0.0, saving transforms via YAML is not supported, so to ensure a perfect match either the dataset must not contain transforms, or the same transforms with the same arguments must be added to the loaded dataset after loading"
+   ]
+  }
+ ],
+ "metadata": {
+  "kernelspec": {
+   "display_name": "Python 3",
+   "language": "python",
+   "name": "python3"
+  },
+  "language_info": {
+   "codemirror_mode": {
+    "name": "ipython",
+    "version": 3
+   },
+   "file_extension": ".py",
+   "mimetype": "text/x-python",
+   "name": "python",
+   "nbconvert_exporter": "python",
+   "pygments_lexer": "ipython3",
+   "version": "3.10.12"
+  }
+ },
+ "nbformat": 4,
+ "nbformat_minor": 5
+}
diff --git a/gr-spectrumdetect/Dockerfile b/gr-spectrumdetect/Dockerfile
index 3f02497c6..4094c1f3e 100755
--- a/gr-spectrumdetect/Dockerfile
+++ b/gr-spectrumdetect/Dockerfile
@@ -2,7 +2,9 @@ FROM nvidia/cuda:12.4.1-cudnn-devel-ubuntu22.04
 
 ENV DEBIAN_FRONTEND=noninteractive
 
-RUN apt-get update && apt-get install -y \
+RUN apt-get update -y && apt-get upgrade -y
+
+RUN apt-get install -y \
     less \
     git \
     cmake \
diff --git a/gr-spectrumdetect/docs/doxygen/update_pydoc.py b/gr-spectrumdetect/docs/doxygen/update_pydoc.py
index b65e168ae..63c364951 100755
--- a/gr-spectrumdetect/docs/doxygen/update_pydoc.py
+++ b/gr-spectrumdetect/docs/doxygen/update_pydoc.py
@@ -84,7 +84,6 @@ def utoascii(text):
         return ''
     out = text.encode('ascii', 'replace')
     # swig will require us to replace blackslash with 4 backslashes
-    # TODO: evaluate what this should be for pybind11
     out = out.replace(b'\\', b'\\\\\\\\')
     out = out.replace(b'"', b'\\"').decode('ascii')
     return str(out)
@@ -313,7 +312,7 @@ def sub_docstring_in_pydoc_h(pydoc_files, docstrings_dict, output_dir, filter_st
                         status_file.write("PASS: " + pydoc_file + "\n")
                 except KeyboardInterrupt:
                     raise KeyboardInterrupt
-                except:  # be permissive, TODO log, but just leave the docstring blank
+                except:  # be permissive, but just leave the docstring blank
                     status_file.write("FAIL: " + pydoc_file + "\n")
                     file_in = file_in_tmp
 
diff --git a/pyproject.toml b/pyproject.toml
index 8dc7f417a..4623c16f3 100755
--- a/pyproject.toml
+++ b/pyproject.toml
@@ -1,5 +1,6 @@
 [build-system]
-requires = ["setuptools", "wheel"]
+# Define build dependencies and backend
+requires = ["setuptools>=61", "setuptools-rust>=1.10"]
 build-backend = "setuptools.build_meta"
 
 [project]
@@ -10,44 +11,71 @@ authors = [
 ]
 readme = "README.md"
 requires-python = ">=3.10"
-license = {text = "MIT"}
+license = "MIT"
+license-files = ["LICENSE.md"]
+keywords = ["signal processing", "machine learning"]
+dynamic = ["version"]
+
 classifiers = [
     "Programming Language :: Python",
     "Programming Language :: Python :: 3",
+    "Programming Language :: Rust",
 ]
-keywords = ["signal processing", "machine learning"]
+# Runtime dependencies
 dependencies = [
+    # Core Libraries
     "torch",
     "torchvision",
+    "torchaudio",
     "tqdm",
-    "opencv-python==4.8.0.74",
     "numpy<2",
     "scipy",
     "h5py",
     "matplotlib",
-    "PyWavelets",
     "pandas",
+    "PyWavelets",
     "scikit-learn",
-    "torchaudio",
     "timm",
-    "pytorch_lightning",
-    "jupyter_bbox_widget",
+    "pytorch_lightning>=2.0.0,<3.0.0",
+    "ultralytics==8.3.57",  # Keep the latest version
     "torchinfo",
-    "ultralytics",
     "sigmf",
-    "pytest",
     "zarr==2.18.3",
-    "numcodecs",
+    "numcodecs==0.13.1",
+    "opencv-python==4.8.0.74",
+    "jupyter_bbox_widget",
+
+    # Testing, CI/CD
+    "pytest",
     "pylint",
     "pytest-cov",
+
+    # Satnogs
+    "librosa",
 ]
-dynamic = ["version"]
+
+
+[project.urls]
+Homepage = "https://torchsig.com/"
+Documentation = "https://torchsig.readthedocs.io/en/latest/index.html"
+Repository = "https://github.com/TorchDSP/torchsig.git"
+Issues = "https://github.com/TorchDSP/torchsig/issues"
+
+[tool.setuptools.packages.find]
+# Automatically find all packages starting in root directory
+where = ["."]
 
 [tool.setuptools.dynamic]
+# Dynamically read version from torchsig.__version__
 version = {attr = "torchsig.__version__"}
 
-[tool.setuptools.package-data]
-"torchsig.datasets.default_configs" = ["*.yaml"]
+[[tool.setuptools-rust.ext-modules]]
+# Define the Rust extension module built with PyO3
+target = "torchsig.utils.rust_functions"  # Must match import path and lib.name in Cargo.toml
+path = "rust_functions/Cargo.toml"        # Path to Cargo.toml
+binding = "PyO3"                          # Bindings to use
+debug = false                             # Enable release mode for optimized builds
+optional = false                          # Crash if the extension build fails
 
 [tool.coverage.run]
 branch = true
@@ -62,6 +90,7 @@ omit = [
 ]
 
 [tool.pytest.ini_options]
+# Configure pytest behavior and test discovery
 markers = [
     "slow: marks tests as slow (deselect with '-m \"not slow\"')",
 ]
diff --git a/rust_functions/Cargo.toml b/rust_functions/Cargo.toml
new file mode 100644
index 000000000..161c63d33
--- /dev/null
+++ b/rust_functions/Cargo.toml
@@ -0,0 +1,20 @@
+[package]
+name = "rust_functions"
+version = "2.0.0"
+edition = "2021"
+rust-version = "1.83"
+
+[lib]
+name = "rust_functions"
+crate-type = ["cdylib"]
+
+[dependencies]
+pyo3 = { version = "0.21", features = ["extension-module"] }
+numpy = "0.21.0"
+ndrustfft = "0.4.5"
+futuredsp = "0.0.6"
+fixed = "1.28.0"
+ndarray = "0.15"
+rand_distr = "0.5.1"
+rand = "0.9.1"
+num-complex = "0.4"
\ No newline at end of file
diff --git a/rust_functions/README.md b/rust_functions/README.md
new file mode 100644
index 000000000..f79466c88
--- /dev/null
+++ b/rust_functions/README.md
@@ -0,0 +1,34 @@
+# Rust Functions for TorchSig
+
+Rust implementations for various DSP computations for TorchSig library. Code is automatically compiled and accessible under torchsig using [setuptools-rust](https://pypi.org/project/setuptools-rust/).
+
+## Rust File Structure
+```
+rust_functions/
+├── Cargo.toml
+├── README.md
+├── src
+│   └── lib.rs
+```
+
+
+## For Developers/Advanced Users
+Most users do not need to do anything to this code in order to use TorchSig. However, if you want to see how we have implemented our code or want to override it for a specific purpose, see below.
+
+
+### Build Code for TorchSig
+
+1. Code your changes/functions inside `src/`. Most of our code is in `src/lib.rs`
+
+2. Bind your Rust functions inside `src/lib.rs` in order to use in TorchSig. See [PyO3 user guide](https://pyo3.rs/v0.25.1/rust-from-python.html) to learn more about exposing Rust code to Python.
+
+3. Reinstall TorchSig. `setuptools-rust` will automatically compile and copy the binaries, and make them usable within torchsig.
+```bash
+pip install -e .
+```
+
+4. Now you can call the Rust functions in Python:
+```python
+from torchsig.utils.rust_functions import <insert_rust_function_name>
+```
+
diff --git a/rust_functions/src/lib.rs b/rust_functions/src/lib.rs
new file mode 100644
index 000000000..e26ed3fe2
--- /dev/null
+++ b/rust_functions/src/lib.rs
@@ -0,0 +1,251 @@
+use pyo3::prelude::*;
+use numpy::PyReadonlyArray1;
+use numpy::{Complex32, Complex64, PyArray1, PyArrayMethods, PyArray};
+use rand::SeedableRng;
+use rand::rngs::StdRng;
+use rand_distr::{Normal, Distribution};
+use pyo3::Bound; 
+use pyo3::wrap_pyfunction;
+
+
+
+// implements the jitter & drift transform
+#[pyfunction]
+#[pyo3(signature = (h, x, uprate, drate, jitter_ppm, drift_ppm, seed))]
+fn sampling_clock_impairments<'py>(
+    py: Python<'py>, 
+    h: PyReadonlyArray1<'py,f32>, 
+    x: PyReadonlyArray1<'py,Complex32>, 
+    uprate: i32, 
+    drate: f32, 
+    jitter_ppm: f32, 
+    drift_ppm: f32, 
+    seed: u64
+) -> Bound<'py,PyArray1<Complex32>> {
+
+   // run the transform
+   let output_vec = irrational_rate_resampler(h.to_vec().unwrap(),&x.to_vec().unwrap(),uprate as u32,drate as u32, jitter_ppm, drift_ppm, seed);
+   // return the output
+   PyArray::from_vec_bound(py, output_vec)
+}
+
+// function to emulate SciPy's upfirdn() call
+#[pyfunction]
+#[pyo3(signature = (h, x, uprate, drate))]
+fn upfirdn<'py>(
+    py: Python<'py>, 
+    h: PyReadonlyArray1<'py,f32>, 
+    x: PyReadonlyArray1<'py,Complex32>, 
+    uprate: i32, 
+    drate: f32
+) -> Bound<'py,PyArray1<Complex32>> {
+
+    // // run the resampler
+    // Convert inputs into owned Rust types
+    let h_vec = h.to_vec().unwrap();
+    let x_vec = x.to_vec().unwrap();
+
+    // Call your Rust resampler function
+    // we use nominal seed = 0
+    let output_vec = irrational_rate_resampler(h_vec, &x_vec, uprate as u32, drate as u32, 0.0, 0.0, 0);
+
+    // Convert the output Vec<Complex32> into a NumPy array and return
+    PyArray::from_vec_bound(py, output_vec)
+}
+
+// 
+// implements an irrational rate resampler using pfb
+pub fn irrational_rate_resampler(
+    h: Vec<f32>,
+    input_samples: &Vec<Complex32>,
+    up_rate: u32,
+    down_rate: u32,
+    jitter_ppm: f32,
+    drift_ppm: f32,
+    seed: u64
+) -> Vec<Complex32> {
+
+    // compute the number of taps per phase in PFB
+    let taps_per_phase = (h.len() as f32 / up_rate as f32).ceil() as u32;
+
+    let mut rng = StdRng::seed_from_u64(seed);
+    let normal_jitter = Normal::new(0.0, jitter_ppm*1e-6).unwrap();
+    let normal_drift = Normal::new(0.0, drift_ppm * 1e-6).unwrap();
+
+    // let mut rng = rand::rng();
+    
+    // design and partition the polyphase filter bank
+    let h_pfb = partition_polyphase(h, up_rate, taps_per_phase);
+
+    let padded_len: usize = input_samples.len() + taps_per_phase as usize * 2 - 1;
+    // zero-pad the samples to flush the sample buffer on output
+    let mut input_samples_padded: Vec<Complex32> = vec![Complex32::ZERO; padded_len];  //input_samples.clone();
+    let start = taps_per_phase as usize - 2; // minus 2 is to accurately replicate scipy's upfirdn function
+    let end = start + input_samples.len();
+    input_samples_padded[start..end].copy_from_slice(&input_samples);
+
+    // commutator
+    let mut q_step: f32 = up_rate as f32 / down_rate as f32;
+
+    // calculate number of output samples
+    let num_output_samples_estimated = (input_samples_padded.len() as f32 * up_rate as f32 / down_rate as f32).ceil() as u32 + 1;
+    // pre-allocate memory for the output samples
+    let mut output_samples = vec![Complex32::ZERO;num_output_samples_estimated as usize];
+
+    // initialize indexing for input and output sample streams
+    let mut input_idx = 0;
+    let mut output_idx = 0;
+    let mut clock_drift: f32 = 0.0;
+
+    let idx_stop = input_samples_padded.len() - taps_per_phase as usize;
+
+    // run the resampler. run until all input samples are processed
+    while input_idx < idx_stop  {
+        // run commutator to determine how many input samples correspond to
+        let delay_slice = &input_samples_padded[input_idx..input_idx + taps_per_phase as usize];
+        while q_step >= up_rate as f32  {
+            // push samples "right" to make room for a new input sample
+            // update commutator position
+            q_step -= up_rate as f32;
+            // update index into input time series
+            input_idx += 1;
+        }
+        
+        if q_step >= up_rate as f32 {
+            break;
+        }
+
+        // "phase" or branch selector into filter bank
+        let phase = q_step as i32 as usize;
+        // get filter weights from PFB
+        let h_phase = &h_pfb[phase][..taps_per_phase as usize];
+        // get input samples from sample buffer
+        // let delay_slice = &delay_line[..taps_per_phase as usize];
+        // implement the multiply and add using iterators
+        let (acc_re, acc_im) = h_phase
+            .iter()
+            .zip(delay_slice.iter().rev())
+            .fold((0.0f32, 0.0f32), |(sum_re, sum_im), (&h_coef, &sample)| {
+                (
+                    sum_re + h_coef * sample.re,
+                    sum_im + h_coef * sample.im,
+                )
+            });
+
+        // define output sample
+        let pfb_out = Complex32::new(acc_re, acc_im);
+
+        // place the output sample at the proper index
+        output_samples[output_idx] = pfb_out;
+        // increment output index
+        output_idx += 1;
+
+        // increment commutator based on resampling rate
+        if jitter_ppm != 0.0 || drift_ppm != 0.0 {
+            let clock_jitter: f32 = normal_jitter.sample(&mut rng);
+            clock_drift += normal_drift.sample(&mut rng);
+            q_step += down_rate as f32 + clock_jitter + clock_drift;
+
+        } else {
+            q_step += down_rate as f32;
+        }
+    }
+
+    // slices output to proper length. subtract off 1 from output_idx
+    // because of most recent +1 does not correspond to an output sample
+    // output_samples[0..output_idx-1].to_vec()
+    if output_idx == 0 {
+        vec![]
+    } else {
+        output_samples[0..output_idx - 1].to_vec()
+    }
+}
+
+
+// transforms the prototype filter weights into a polyphase filter bank,
+// which is a two-dimensional vector
+fn partition_polyphase(h: Vec<f32>, up_rate: u32, taps_per_phase: u32) -> Vec<Vec<f32>> {
+    // pre-allocate two-dimensional vector which will hold PFB weights
+    let mut h_pfb: Vec<Vec<f32>> = vec![vec![0.0 as f32; taps_per_phase as usize]; up_rate as usize];
+    // perform the polyphase partition
+    for phase in 0..up_rate {
+        let mut tap_idx = phase;
+        for idx in 0..taps_per_phase {
+            // h_pfb[phase as usize][idx as usize] = h[tap_idx as usize] * up_rate as f32;
+            // tap_idx += up_rate as u32;
+            if (tap_idx as usize) < h.len() {
+                h_pfb[phase as usize][idx as usize] = h[tap_idx as usize] * up_rate as f32;
+            } else {
+                h_pfb[phase as usize][idx as usize] = 0.0;
+            }
+            tap_idx += up_rate;
+        }
+    }
+    h_pfb
+}
+
+#[pyfunction]
+#[pyo3(signature = (data, 
+    alpha_smooth= 1e-4,
+    alpha_track= 1e-3,
+    alpha_overflow =0.1,
+    alpha_acquire = 1e-3,
+    ref_level_db = 0.0,
+    track_range_db = 1.0,
+    low_level_db = -80.0,
+    high_level_db = 10.0,
+
+))]
+fn digital_agctran<'py>(data:PyReadonlyArray1<'py,Complex64>, py: Python<'py>,
+    alpha_smooth:f32, alpha_track:f32, alpha_overflow:f32, alpha_acquire:f32, ref_level_db:f32, 
+    track_range_db:f32, low_level_db:f32,  high_level_db:f32)-> Bound<'py,PyArray1<Complex64>> {
+
+    let input_vec = data.to_vec().unwrap();
+    // let mut output: PyArray1<Complex64> = input_ndarray_view.mapv(|x| x * 0.0);
+    let mut output = vec![Complex64::ZERO;input_vec.len() as usize];
+
+    let mut gain_db:f32 = 0.0;
+    let mut level_db:f32 = 0.0;
+
+    let mut sample_idx:i32 = 0;
+    for sample in input_vec {
+        if sample.re == 0.0f64 && sample.im == 0.0f64 {
+            level_db = -200.0;
+        }else if sample_idx == 0 {
+            level_db = (sample.re + sample.im).abs().ln() as f32;
+        }else{
+            level_db = level_db * alpha_smooth + ((sample.re + sample.im).abs().log2() as f32) * (1.0 - alpha_smooth);
+        }
+        let output_db = level_db + gain_db;
+        let diff_db = ref_level_db - output_db;
+
+        let alpha_adjust;
+        if level_db <= low_level_db {
+            alpha_adjust = 0.0;
+        }else if level_db > high_level_db{
+            alpha_adjust = alpha_overflow;
+        }else if diff_db.abs() > track_range_db {
+            alpha_adjust = alpha_track;
+        } else {
+            alpha_adjust = alpha_acquire;
+        }
+            
+        gain_db += diff_db * alpha_adjust;
+
+        let gain = gain_db.exp();
+
+        output[sample_idx as usize ] = sample * gain as f64;
+        sample_idx += 1; 
+    }
+    // println!("{:?}", output);
+    PyArray::from_vec_bound(py, output)
+}
+
+// bind rust functions such that they are callable from python
+#[pymodule]
+fn rust_functions(_py: Python, m: &Bound<'_, PyModule>) -> PyResult<()> {
+    m.add_function(wrap_pyfunction!(upfirdn, m)?)?;
+    m.add_function(wrap_pyfunction!(sampling_clock_impairments, m)?)?;
+    m.add_function(wrap_pyfunction!(digital_agctran, m)?)?;
+    Ok(())
+}
diff --git a/scripts/test-docker-ui.sh b/scripts/test-docker-ui.sh
new file mode 100644
index 000000000..392eeb9c9
--- /dev/null
+++ b/scripts/test-docker-ui.sh
@@ -0,0 +1,167 @@
+#!/bin/bash
+
+# TorchSig UI Docker Test Script
+# Helps diagnose blank screen and other Docker issues
+
+set -e
+
+echo "🔍 TorchSig UI Docker Diagnostic Test"
+echo "======================================"
+
+# Colors for output
+RED='\033[0;31m'
+GREEN='\033[0;32m'
+YELLOW='\033[1;33m'
+NC='\033[0m' # No Color
+
+# Configuration
+IMAGE_NAME="torchsig-ui"
+CONTAINER_NAME="torchsig-test"
+TEST_PORT=8001
+
+cleanup() {
+    echo -e "\n🧹 Cleaning up..."
+    docker stop $CONTAINER_NAME 2>/dev/null || true
+    docker rm $CONTAINER_NAME 2>/dev/null || true
+}
+
+# Cleanup on exit
+trap cleanup EXIT
+
+echo -e "📋 Test Configuration:"
+echo -e "  Image: $IMAGE_NAME"
+echo -e "  Container: $CONTAINER_NAME"
+echo -e "  Port: $TEST_PORT"
+
+# Step 1: Check if image exists
+echo -e "\n1️⃣  Checking if Docker image exists..."
+if docker image inspect $IMAGE_NAME >/dev/null 2>&1; then
+    echo -e "${GREEN}✅ Image $IMAGE_NAME found${NC}"
+else
+    echo -e "${RED}❌ Image $IMAGE_NAME not found${NC}"
+    echo -e "   Build it with: docker build -t $IMAGE_NAME ."
+    exit 1
+fi
+
+# Step 2: Start container
+echo -e "\n2️⃣  Starting container..."
+docker run -d --name $CONTAINER_NAME -p $TEST_PORT:8000 $IMAGE_NAME
+echo -e "${GREEN}✅ Container started${NC}"
+
+# Step 3: Wait for startup
+echo -e "\n3️⃣  Waiting for service to start..."
+sleep 10
+
+# Step 4: Run diagnostics inside container
+echo -e "\n4️⃣  Running internal diagnostics..."
+docker exec $CONTAINER_NAME debug-torchsig.sh
+
+# Step 5: Test health endpoint
+echo -e "\n5️⃣  Testing health endpoint..."
+if curl -s http://localhost:$TEST_PORT/health >/dev/null; then
+    echo -e "${GREEN}✅ Health endpoint responding${NC}"
+    curl -s http://localhost:$TEST_PORT/health | python -m json.tool
+else
+    echo -e "${RED}❌ Health endpoint not responding${NC}"
+fi
+
+# Step 6: Test API info endpoint
+echo -e "\n6️⃣  Testing API info endpoint..."
+if curl -s http://localhost:$TEST_PORT/api/info >/dev/null; then
+    echo -e "${GREEN}✅ API info endpoint responding${NC}"
+    echo -e "   System info:"
+    curl -s http://localhost:$TEST_PORT/api/info | python -c "import sys, json; data=json.load(sys.stdin); print(f'   TorchSig: {data.get(\"torchsig_version\", \"unknown\")}'); print(f'   PyTorch: {data.get(\"pytorch_version\", \"unknown\")}'); print(f'   CUDA: {data.get(\"cuda_available\", \"unknown\")}')"
+else
+    echo -e "${RED}❌ API info endpoint not responding${NC}"
+fi
+
+# Step 7: Test root endpoint (frontend)
+echo -e "\n7️⃣  Testing frontend serving..."
+RESPONSE=$(curl -s -w "%{http_code}" http://localhost:$TEST_PORT/ -o /tmp/frontend_response.html)
+if [ "$RESPONSE" = "200" ]; then
+    echo -e "${GREEN}✅ Frontend endpoint responding (HTTP 200)${NC}"
+    
+    # Check if it looks like HTML
+    if grep -q "<html" /tmp/frontend_response.html; then
+        echo -e "${GREEN}✅ Response contains HTML${NC}"
+        
+        # Check for React root div
+        if grep -q 'id="root"' /tmp/frontend_response.html; then
+            echo -e "${GREEN}✅ React root div found${NC}"
+        else
+            echo -e "${YELLOW}⚠️  React root div not found${NC}"
+        fi
+        
+        # Check for JavaScript assets
+        if grep -q "\.js" /tmp/frontend_response.html; then
+            echo -e "${GREEN}✅ JavaScript assets referenced${NC}"
+        else
+            echo -e "${YELLOW}⚠️  No JavaScript assets found${NC}"
+        fi
+        
+    else
+        echo -e "${RED}❌ Response is not HTML${NC}"
+        echo -e "   First 200 characters:"
+        head -c 200 /tmp/frontend_response.html
+    fi
+else
+    echo -e "${RED}❌ Frontend endpoint returned HTTP $RESPONSE${NC}"
+fi
+
+# Step 8: Test static assets
+echo -e "\n8️⃣  Testing static assets..."
+# Try to get a CSS file
+CSS_FILE=$(grep -o '/assets/[^"]*\.css' /tmp/frontend_response.html | head -1)
+if [ -n "$CSS_FILE" ]; then
+    echo -e "   Testing CSS file: $CSS_FILE"
+    CSS_RESPONSE=$(curl -s -w "%{http_code}" http://localhost:$TEST_PORT$CSS_FILE -o /dev/null)
+    if [ "$CSS_RESPONSE" = "200" ]; then
+        echo -e "${GREEN}✅ CSS file accessible${NC}"
+    else
+        echo -e "${RED}❌ CSS file returned HTTP $CSS_RESPONSE${NC}"
+    fi
+fi
+
+# Try to get a JS file
+JS_FILE=$(grep -o '/assets/[^"]*\.js' /tmp/frontend_response.html | head -1)
+if [ -n "$JS_FILE" ]; then
+    echo -e "   Testing JS file: $JS_FILE"
+    JS_RESPONSE=$(curl -s -w "%{http_code}" http://localhost:$TEST_PORT$JS_FILE -o /dev/null)
+    if [ "$JS_RESPONSE" = "200" ]; then
+        echo -e "${GREEN}✅ JS file accessible${NC}"
+    else
+        echo -e "${RED}❌ JS file returned HTTP $JS_RESPONSE${NC}"
+    fi
+fi
+
+# Step 9: Show container logs
+echo -e "\n9️⃣  Container logs (last 20 lines):"
+echo -e "${YELLOW}$(docker logs --tail 20 $CONTAINER_NAME)${NC}"
+
+# Final recommendations
+echo -e "\n📋 Next Steps:"
+echo -e "1. Open browser to http://localhost:$TEST_PORT"
+echo -e "2. Check browser console (F12) for JavaScript errors"
+echo -e "3. If blank screen, likely causes:"
+echo -e "   - JavaScript runtime errors (check browser console)"
+echo -e "   - Static assets not loading (check Network tab)"
+echo -e "   - React app failing to mount"
+echo -e "4. To debug further:"
+echo -e "   docker exec -it $CONTAINER_NAME bash"
+echo -e "   docker logs -f $CONTAINER_NAME"
+
+echo -e "\n✅ Test completed! Container is running on port $TEST_PORT"
+echo -e "   Container will be cleaned up automatically when script exits."
+echo -e "   Press Ctrl+C to stop and cleanup."
+
+# Keep running until user interrupts
+echo -e "\n⏳ Keeping container running for manual testing..."
+echo -e "   Access UI at: http://localhost:$TEST_PORT"
+while true; do
+    sleep 30
+    if ! docker ps | grep -q $CONTAINER_NAME; then
+        echo -e "\n${RED}❌ Container stopped unexpectedly${NC}"
+        break
+    fi
+    echo -e "   Container still running... (Ctrl+C to stop)"
+done
\ No newline at end of file
diff --git a/scripts/test-docker.sh b/scripts/test-docker.sh
new file mode 100755
index 000000000..9c54f2127
--- /dev/null
+++ b/scripts/test-docker.sh
@@ -0,0 +1,154 @@
+#!/bin/bash
+
+# TorchSig Docker Build and Test Script
+
+set -e  # Exit on any error
+
+echo "🐳 Testing TorchSig Docker Build and Deployment"
+echo "================================================"
+
+# Colors for output
+RED='\033[0;31m'
+GREEN='\033[0;32m'
+YELLOW='\033[1;33m'
+NC='\033[0m' # No Color
+
+# Function to print colored output
+print_status() {
+    echo -e "${GREEN}✅ $1${NC}"
+}
+
+print_warning() {
+    echo -e "${YELLOW}⚠️  $1${NC}"
+}
+
+print_error() {
+    echo -e "${RED}❌ $1${NC}"
+}
+
+# Check if Docker is available
+if ! command -v docker &> /dev/null; then
+    print_error "Docker is not installed or not in PATH"
+    exit 1
+fi
+
+print_status "Docker is available"
+
+# Check if required files exist
+if [[ ! -f "Dockerfile" ]]; then
+    print_error "Dockerfile not found in current directory"
+    exit 1
+fi
+
+if [[ ! -f "pyproject.toml" ]]; then
+    print_error "pyproject.toml not found in current directory"
+    exit 1
+fi
+
+print_status "Required files found"
+
+# Build the Docker image
+echo
+echo "🔨 Building TorchSig Docker image..."
+echo "This may take several minutes..."
+
+if docker build -t torchsig-ui-test . --progress=plain; then
+    print_status "Docker image built successfully"
+else
+    print_error "Docker build failed"
+    exit 1
+fi
+
+# Test if the image can start
+echo
+echo "🚀 Testing container startup..."
+
+# Start container in background
+CONTAINER_ID=$(docker run -d -p 8001:8000 --name torchsig-test torchsig-ui-test)
+
+if [[ -z "$CONTAINER_ID" ]]; then
+    print_error "Failed to start container"
+    exit 1
+fi
+
+print_status "Container started with ID: ${CONTAINER_ID:0:12}"
+
+# Wait for container to be ready
+echo "⏳ Waiting for container to be ready..."
+sleep 10
+
+# Test health endpoint
+MAX_RETRIES=30
+RETRY_COUNT=0
+
+while [[ $RETRY_COUNT -lt $MAX_RETRIES ]]; do
+    if curl -f -s http://localhost:8001/health > /dev/null 2>&1; then
+        print_status "Health endpoint is responding"
+        break
+    fi
+    
+    echo "Waiting for health endpoint... ($((RETRY_COUNT + 1))/$MAX_RETRIES)"
+    sleep 2
+    RETRY_COUNT=$((RETRY_COUNT + 1))
+done
+
+if [[ $RETRY_COUNT -eq $MAX_RETRIES ]]; then
+    print_error "Health endpoint did not respond within timeout"
+    echo "Container logs:"
+    docker logs torchsig-test
+    docker stop torchsig-test
+    docker rm torchsig-test
+    exit 1
+fi
+
+# Test API info endpoint
+if curl -f -s http://localhost:8001/api/info > /dev/null 2>&1; then
+    print_status "API info endpoint is responding"
+else
+    print_warning "API info endpoint is not responding (this may be expected)"
+fi
+
+# Test if frontend is being served
+if curl -f -s http://localhost:8001/ > /dev/null 2>&1; then
+    print_status "Frontend is being served"
+else
+    print_warning "Frontend is not being served"
+fi
+
+# Show some container info
+echo
+echo "📊 Container Information:"
+echo "========================"
+docker exec torchsig-test torchsig --version 2>/dev/null || echo "Version check failed"
+docker exec torchsig-test python -c "import torch; print(f'PyTorch: {torch.__version__}')" 2>/dev/null || echo "PyTorch check failed"
+docker exec torchsig-test python -c "import torchsig; print(f'TorchSig: {torchsig.__version__}')" 2>/dev/null || echo "TorchSig check failed"
+
+# Check if frontend is built
+if docker exec torchsig-test ls /build/ui/frontend/dist/ > /dev/null 2>&1; then
+    print_status "Frontend is built in container"
+else
+    print_warning "Frontend dist directory not found"
+fi
+
+# Cleanup
+echo
+echo "🧹 Cleaning up..."
+docker stop torchsig-test > /dev/null
+docker rm torchsig-test > /dev/null
+print_status "Container cleaned up"
+
+# Optional: Remove the test image
+read -p "Do you want to remove the test image? (y/N): " -n 1 -r
+echo
+if [[ $REPLY =~ ^[Yy]$ ]]; then
+    docker rmi torchsig-ui-test > /dev/null
+    print_status "Test image removed"
+fi
+
+echo
+echo "🎉 Docker test completed successfully!"
+echo
+echo "Next steps:"
+echo "- Run: docker compose up --build"
+echo "- Access UI at: http://localhost:8000"
+echo "- Check logs: docker compose logs -f"
\ No newline at end of file
diff --git a/tests/datasets/profile_datasets.py b/tests/datasets/profile_datasets.py
index d6a4b77f3..dece5ab08 100644
--- a/tests/datasets/profile_datasets.py
+++ b/tests/datasets/profile_datasets.py
@@ -32,7 +32,7 @@ impairment_level = 2
 num_signals_max = 10
 num_signals_min = 0
 
-num_samples = 100
+dataset_length = 100
 
 enable_tqdm = True
 
@@ -51,7 +51,7 @@ target_transform = [
 
 def dataset_infinite_generation(transforms = []):
 
-    print(f"\nProfiling infinite dataset for {num_samples} samples..................")
+    print(f"\nProfiling infinite dataset for {dataset_length} samples..................")
 
     print(f"IQ Array Size: {num_iq_samples_dataset}")
     print(f"Impairment Level: {impairment_level}")
@@ -73,7 +73,7 @@ def dataset_infinite_generation(transforms = []):
     dataset = NewTorchSigDataset(dataset_metadata=md)
     
     profiler.enable()
-    for i in tqdm(range(num_samples), disable = not enable_tqdm):
+    for i in tqdm(range(dataset_length), disable = not enable_tqdm):
         data, targets = dataset[i]
     profiler.disable()
     print("Profile done.")
@@ -84,11 +84,11 @@ def dataset_infinite_generation(transforms = []):
     stats.print_stats(20)
 
     total_time = stats.total_tt
-    print(f"Average rate: {num_samples / total_time} samples/sec")
+    print(f"Average rate: {dataset_length / total_time} samples/sec")
 
 def dataset_finite_writing(transforms = []):
 
-    print(f"\nProfiling dataset writing finite dataset for {num_samples} samples..................")
+    print(f"\nProfiling dataset writing finite dataset for {dataset_length} samples..................")
 
     print(f"IQ Array Size: {num_iq_samples_dataset}")
     print(f"Impairment Level: {impairment_level}")
@@ -104,7 +104,7 @@ def dataset_finite_writing(transforms = []):
         impairment_level=impairment_level,
         num_signals_max=num_signals_max,
         num_signals_min=num_signals_min,
-        num_samples=num_samples,
+        dataset_length=dataset_length,
         transforms = transforms,
     )
 
@@ -132,12 +132,12 @@ def dataset_finite_writing(transforms = []):
     stats.print_stats(20)
 
     total_time = stats.total_tt
-    print(f"Average rate: {num_samples / total_time} samples/sec")
+    print(f"Average rate: {dataset_length / total_time} samples/sec")
 
 
 def dataset_finite_reading(transforms = []):
 
-    print(f"\nProfiling dataset reading finite dataset for {num_samples} samples..................")
+    print(f"\nProfiling dataset reading finite dataset for {dataset_length} samples..................")
 
     print(f"IQ Array Size: {num_iq_samples_dataset}")
     print(f"Impairment Level: {impairment_level}")
@@ -156,7 +156,7 @@ def dataset_finite_reading(transforms = []):
 
     profiler.enable()
 
-    for i in tqdm(range(num_samples), disable = not enable_tqdm):
+    for i in tqdm(range(dataset_length), disable = not enable_tqdm):
         data, targets = static_dataset[i]
 
     profiler.disable()
@@ -169,7 +169,7 @@ def dataset_finite_reading(transforms = []):
     stats.print_stats(20)
 
     total_time = stats.total_tt
-    print(f"Average rate: {num_samples / total_time} samples/sec")
+    print(f"Average rate: {dataset_length / total_time} samples/sec")
 
 
 def main():
diff --git a/tests/datasets/randomize_dataset_test.py b/tests/datasets/randomize_dataset_test.py
deleted file mode 100644
index b336e57b0..000000000
--- a/tests/datasets/randomize_dataset_test.py
+++ /dev/null
@@ -1,160 +0,0 @@
-#!/usr/bin/env python3
-
-# testing dataset with randomized parameters
-
-from torchsig.datasets.dataset_metadata import DatasetMetadata
-from torchsig.datasets.datasets import TorchSigIterableDataset, StaticTorchSigDataset
-from torchsig.utils.writer import DatasetCreator
-from torchsig.signals.signal_lists import TorchSigSignalLists
-from torchsig.transforms.target_transforms import (
-    ClassName,
-    Start,
-    Stop,
-    LowerFreq,
-    UpperFreq,
-    SNR,
-    YOLOLabel
-)
-from torchsig.transforms.transforms import Spectrogram
-
-import numpy as np
-import matplotlib.pyplot as plt
-from tqdm import tqdm
-from pathlib import Path
-import os
-import shutil
-
-# number of samples to test generation
-num_samples = 10
-save_num_signals = 5
-
-# signals to simulate
-class_list = TorchSigSignalLists.all_signals
-
-# distribution of classes
-class_dist = np.ones(len(class_list))/len(class_list)
-
-# FFT/spectrogram params
-fft_size = np.random.randint(128,1024)
-# num_iq_samples_dataset = fft_size*np.random.randint(128,1024)
-num_iq_samples_dataset = fft_size**2
-
-# testing to handle cases in which number of samples is not an integer multiple of FFT size
-num_iq_samples_dataset += np.random.randint(0,fft_size) # test cases in which data length is not integer multiple of FFT size
-
-# works for variable sample rates
-sample_rate = 100e6
-
-# minimum and maximum SNR for signals
-snr_db_max = 50
-snr_db_min = 0
-
-# define impairment level
-impairment_level = 2
-
-# define maximum number of signals to generate
-num_signals_min = 1
-num_signals_max = 10
-
-# probability for each sample to contain N signals where N is the index,
-# for example, num_signals_dist = [0.15, 0.5, 0.35] is 25% probability to 
-# generate 0 signals, 50% probability to generate 1 signal, 35% 
-# probability to generate 2 signals
-num_signals_dist = np.ones(num_signals_max - num_signals_min+1)/(num_signals_max-num_signals_min+1)
-
-# define transforms
-transforms = Spectrogram(fft_size=fft_size)
-target_transform = [
-    ClassName(),
-    Start(),
-    Stop(),
-    LowerFreq(),
-    UpperFreq(),
-    SNR(),
-    YOLOLabel()
-]
-
-# set up path to cache directory
-root = Path.joinpath(Path(__file__).parent,'wideband_test')
-image_path = f"{root}/images_impaired_{impairment_level}"
-
-if os.path.exists(root):
-    shutil.rmtree(f"{root}")
-os.makedirs(root, exist_ok=True)
-os.makedirs(image_path, exist_ok=True)
-
-# build the wideband metadata
-md = DatasetMetadata(
-    num_iq_samples_dataset=num_iq_samples_dataset,
-    sample_rate=sample_rate,
-    fft_size=fft_size,
-    num_samples=num_samples,
-    num_signals_max=num_signals_max,
-    num_signals_min=num_signals_min,
-    num_signals_distribution=num_signals_dist,
-    snr_db_max=snr_db_max,
-    snr_db_min=snr_db_min,
-    transforms=transforms,
-    target_transforms=target_transform,
-    impairment_level=impairment_level,
-    class_list=class_list,
-    class_distribution=class_dist,
-)
-
-# create the wideband object, derived from the metadata object
-WB = TorchSigIterableDataset(dataset_metadata=md)
-
-
-# write dataset to disk
-dc = DatasetCreator(
-    dataset=WB,
-    root=root,
-    overwrite=True,
-    batch_size=3,
-    num_workers=4
-)
-dc.create()
-
-# load dataset back in from disk
-WBS = StaticTorchSigDataset(
-    root=root,
-    impairment_level=impairment_level,
-)
-
-# save as images
-for i in tqdm(range(save_num_signals), desc = "Saving as Images"):
-    data, targets = WBS[i] # (data, List[dict])
-
-    fig = plt.figure(figsize=(18,12))
-    ax = fig.add_subplot(1,1,1)
-    xmin = 0
-    xmax = 1
-    ymin = -sample_rate / 2
-    ymax = sample_rate / 2
-    pos = ax.imshow(data,extent=[xmin,xmax,ymin,ymax],aspect='auto',cmap='Wistia',vmin=md.noise_power_db)
-
-    fig.colorbar(pos, ax=ax)
-
-    title = "labels: "
-
-    for t in targets:
-        classname, start, stop, lower, upper, snr, yololabel = t
-
-        ax.plot([start,start],[lower,upper],'b',alpha=0.5)
-        ax.plot([stop, stop],[lower,upper],'b',alpha=0.5)
-        ax.plot([start,stop],[lower,lower],'b',alpha=0.5)
-        ax.plot([start,stop],[upper,upper],'b',alpha=0.5)
-        textDisplay = str(classname) + ', SNR = ' + str(snr) + ' dB'
-        ax.text(start,lower,textDisplay, bbox=dict(facecolor='w', alpha=0.5, linewidth=0))
-        ax.set_xlim([0,1])
-        ax.set_ylim([-sample_rate/2,sample_rate/2])
-        title = f"{title}{classname} "
-    
-    fig.suptitle(title, fontsize=16)
-    plt.ylabel("Frequency (Hz)")
-    plt.xlabel("Time")
-    plt.savefig(f"{image_path}/{i}")
-    plt.close()
-
-    
-
diff --git a/tests/datasets/seedable_tree.py b/tests/datasets/seedable_tree.py
new file mode 100644
index 000000000..eefca82fb
--- /dev/null
+++ b/tests/datasets/seedable_tree.py
@@ -0,0 +1,58 @@
+"""Prints out Seedable Dependency Tree
+
+Helps debugging for developers. Outputs tree to `seedable_tree.txt`.
+"""
+
+from torchsig.datasets.dataset_metadata import DatasetMetadata
+from torchsig.datasets.datasets import TorchSigIterableDataset
+from torchsig.transforms.impairments import Impairments
+from torchsig.utils.random import Seedable
+from pathlib import Path
+
+num_iq_samples_dataset = 4096 # 64^2
+fft_size = 64
+num_signals_max = 5
+num_signals_min = 1
+seed = 10
+impairment_level = 2
+
+THIS_DIR = Path(__file__).resolve().parent
+
+def print_seedable_tree(seedable_obj: Seedable, file, prefix="", is_last=True):
+    connector = "└── " if is_last else "├── "
+    # write to terminal and file
+    print(prefix + connector + seedable_obj.__class__.__name__)
+    file.write(prefix + connector + seedable_obj.__class__.__name__ + "\n")
+
+    new_prefix = prefix + ("    " if is_last else "│   ")
+    child_count = len(seedable_obj.children)
+    for i, child in enumerate(seedable_obj.children):
+        is_last_child = (i == child_count - 1)
+        print_seedable_tree(child, file, new_prefix, is_last_child)
+
+def main():
+    md = DatasetMetadata(
+        num_iq_samples_dataset = num_iq_samples_dataset,
+        fft_size = fft_size,
+        num_signals_max = num_signals_max,
+        num_signals_min = num_signals_min
+    )
+
+    impairments = Impairments(level=impairment_level)
+
+    ds = TorchSigIterableDataset(
+        dataset_metadata = md,
+        transforms=[impairments.dataset_transforms],
+        component_transforms=[impairments.signal_transforms],
+        target_labels=["class_index"],
+        seed=seed
+    )
+    print(ds)
+
+    with open(THIS_DIR / "seedable_tree.txt", "w", encoding="utf-8") as f:
+        print_seedable_tree(ds, f)
+
+    print(f"Tree output written: {THIS_DIR / "seedable_tree.txt"}")
+
+if __name__ == "__main__":
+    main()
\ No newline at end of file
diff --git a/tests/datasets/test_datamodules.py b/tests/datasets/test_datamodules.py
index 8775416fa..52f3d358e 100644
--- a/tests/datasets/test_datamodules.py
+++ b/tests/datasets/test_datamodules.py
@@ -1,59 +1,45 @@
-"""Unit Tests for datasets/datamodules.py
-
-Classes:
-- TorchSigDataModule
-- OfficialTorchSigDataModule
+"""Unit Tests for datamodules
 """
 
-from torchsig.datasets.datamodules import (
-    TorchSigDataModule,  
-    OfficialTorchSigDataModule,
-)
+from torchsig.datasets.datamodules import TorchSigDataModule
 from torchsig.datasets.dataset_metadata import DatasetMetadata
+from torchsig.utils.writer import default_collate_fn
 
 import pytest
+import copy
+from pathlib import Path
 
-def test_datamodule(tmpdir):
-
-    root = tmpdir
-
-    train_metadata = DatasetMetadata(
-        num_iq_samples_dataset = 64 ** 2,
-        fft_size = 64,
-        impairment_level = 2,
-        num_signals_max=3,
-        num_samples = 10
-    )
-
-    val_metadata = DatasetMetadata(
-        num_iq_samples_dataset = 64 ** 2,
-        fft_size = 64,
-        impairment_level = 2,
-        num_signals_max=3,
-        num_samples = 10
-    )
-
-    dm = TorchSigDataModule(
-        root = root,
-        train_metadata = train_metadata,
-        val_metadata = val_metadata
-    )
-    dm.prepare_data()
-    dm.setup()
+filename = "data_module_test"
+data_dir =  Path(__file__).parent
 
+fft_size = 64
+num_iq_samples_dataset = fft_size ** 2
 
-@pytest.mark.slow
-@pytest.mark.skip(reason = "Tests too slow")
-def test_official_datamodule(tmpdir):
-    root = tmpdir
+md = DatasetMetadata(
+    num_iq_samples_dataset=num_iq_samples_dataset,
+    fft_size=fft_size,
+    num_signals_max=1
+)
 
-    dm = OfficialTorchSigDataModule(
-        root=root,
-        impairment_level=2,
-        create_batch_size=32,
-        create_num_workers=16
+@pytest.mark.filterwarnings(r"ignore:.*fork\(\) may lead to deadlocks in the child:DeprecationWarning")
+def test_TorchSigDataModule():
+    datamodule = TorchSigDataModule(
+        root = Path.joinpath(data_dir, filename),
+        dataset_metadata=copy.deepcopy(md),
+        dataset_size=50,
+        overwrite=True,
+        collate_fn=lambda x: x
     )
-    dm.prepare_data()
-    dm.setup()
-
-
+    datamodule.prepare_data()
+    datamodule.setup()
+
+    dataloaders = [
+        datamodule.train_dataloader(),
+        datamodule.val_dataloader(),
+        datamodule.test_dataloader()
+    ]
+
+    for d in dataloaders:
+        for batch in d:
+            print(batch)
+            break
diff --git a/tests/datasets/test_datasets.py b/tests/datasets/test_datasets.py
index 49643af9e..9c2a43c57 100644
--- a/tests/datasets/test_datasets.py
+++ b/tests/datasets/test_datasets.py
@@ -1,46 +1,44 @@
 """Unit Tests for datasets
 """
-from torchsig.datasets.dataset_metadata import DatasetMetadata
-from torchsig.datasets.datasets import TorchSigIterableDataset, StaticTorchSigDataset
-from torchsig.utils.writer import DatasetCreator
+from torchsig.datasets.dataset_metadata import DatasetMetadata, ExternalDatasetMetadata
+from torchsig.datasets.datasets import TorchSigIterableDataset, StaticTorchSigDataset, ExternalTorchSigDataset
+from torchsig.utils.writer import DatasetCreator, default_collate_fn
 from torchsig.signals.signal_lists import TorchSigSignalLists
-from torchsig.transforms.target_transforms import (
-    TargetTransform,
-    ClassName,
-    Start,
-    Stop,
-    LowerFreq,
-    UpperFreq,
-    SNR,
-    YOLOLabel,
-    FamilyName,
-)
-from torchsig.transforms.transforms import Spectrogram
-from torchsig.utils.dsp import (
-    torchsig_complex_data_type,
-    torchsig_real_data_type
-)
+from torchsig.transforms.metadata_transforms import YOLOLabel
+from torchsig.utils.data_loading import WorkerSeedingDataLoader
+from torchsig.transforms.transforms import Spectrogram, ComplexTo2D
+from torchsig.signals.signal_types import Signal
+from torchsig.utils.file_handlers import ExternalFileHandler
+from torchsig.utils.dsp import TorchSigRealDataType
 
 # Third Party
 import numpy as np
 import matplotlib.pyplot as plt
 from tqdm import tqdm
-from copy import deepcopy
-from pathlib import Path
-import os
+import zarr
 import shutil
 import pytest
 
-from typing import List, Any
+
+from typing import List, Any, Tuple, Dict
 from collections.abc import Iterable
 import itertools
+import csv
+import math
+import json
+import pprint
+from copy import deepcopy
+from pathlib import Path
+import os
+import random
 
 
 RTOL = 1E-6
 
-wb_data_dir =  Path.joinpath(Path(__file__).parent,'data/dataset_data')
-wb_image_dir = Path.joinpath(Path(__file__).parent,'data/dataset_images')
-getitem_dir = Path.joinpath(Path(__file__).parent,'data/getitem_data')
+wb_data_dir =  Path.joinpath(Path(__file__).parent,'datasets/dataset_data')
+wb_image_dir = Path.joinpath(Path(__file__).parent,'datasets/dataset_images')
+getitem_dir = Path.joinpath(Path(__file__).parent,'datasets/getitem_data')
+external_dir = Path.joinpath(Path(__file__).parent,'datasets/external_data')
 
 # directory for test data
 def setup_module(module):
@@ -58,152 +56,104 @@ test_dataset_getitem_params = list(itertools.product(
     [1, 2, 3],
     # target transforms to test
     [
-        [],
-        [ClassName()],
-        [YOLOLabel()],
-        [ClassName(), SNR()],
-        [ClassName(), YOLOLabel()],
-        [ClassName(), FamilyName(), Start(), Stop(), SNR()]
+#        None,
+#        [],
+        ["class_name"],
+        ["yolo_label"],
+        ["class_name", "snr_db"],
+        ["class_name", "yolo_label"],
+        ["class_name", "class_index", "start", "stop", "snr_db"]
     ],
-    # impairement level
-    [0, 2]
 ))
 num_check = 5
+    
 
+def verify_getitem_targets(num_signals_max: int, target_labels: List[str], sample: Any) -> None:
+    """ Verfies target labels applied correctly
+
+    Target Labels Table
+    
+    | Case      | target_labels                  | num_signals_max = 1          | num_signals_max > 1                                               |
+    |-----------|--------------------------------|------------------------------|-------------------------------------------------------------------|
+    | Case 1    | None                           | nothing, just Signal object  | nothing, just Signal object                                       |
+    | Case 2    | []                             | nothing, just returns data   | nothing, just returns data                                        |
+    | Case 3    | ["class_name"]                 | '8msk'                       | ['8msk', 'ofdm-600']                                              |
+    | Case 4    | ["class_name", "class_index"]  | ('8msk', 0)                  | [('8msk', 0), ('ofdm-600', 1)]                                    |
+    | Case 5    | ["class_name", "yolo_label"]   | ('8msk', (idx, x, y, w, h))  | [('8msk', (idx, x, y, w, h)), ('ofdm-600', (idx, x, y, w, h))]    |
+    | Case 6    | ["yolo_label"]                 | (idx, x, y, w, h)            | [(idx, x, y, w, h), (idx, x, y, w, h)]                            |
+
+    
+    """
+    # target_labels are None or []
+    # just return data
+    if target_labels is None:
+        # Case 1
+        assert isinstance(sample, Signal)
+    elif len(target_labels) == 0:
+        # Case 2
+        assert isinstance(sample, np.ndarray)
+    else:
+        # Case 3-6
+        # target_labels has at least 1 item
+        data, targets = sample
+        print(targets)
 
-def verify_getitem_targets(num_signals_max: int, target_transforms: List[TargetTransform], targets: Any) -> None:
-    # no TT -> list of dicts
-    if len(target_transforms) == 0:
-        required_keys = [
-            "center_freq",
-            "bandwidth",
-            "start_in_samples",
-            "duration_in_samples",
-            "snr_db",
-            "class_name",
-            "class_index",
-            "sample_rate",
-            "num_samples",
-            "start",
-            "stop",
-            "duration",
-            "stop_in_samples",
-            "upper_freq",
-            "lower_freq",
-            "oversampling_rate"
-        ]
-        assert isinstance(targets, list)
-        for t in targets:
-            assert isinstance(t, dict)
-            assert set(required_keys) == set(t.keys())
-
-    # 1 TT
-    # num_signals_max == 1: single item
-    #   signal 1 output
-    # num_signals_max > 1: list of single items 
-    # [
-    #   signal 1 output, 
-    #   signal 2 output
-    # ]
-    if len(target_transforms) == 1:
-        if num_signals_max == 1:
-            assert not isinstance(targets, dict)
-            if isinstance(targets, tuple):
-                for item in targets:
-                    assert isinstance(item, str) or not isinstance(item, Iterable)
-        else:
-            assert isinstance(targets, list)
-            for t in targets:
-                # can be a signle tuple
-                if isinstance(t, tuple):
-                    for item in t:
-                        # should not be nested tuple
-                        assert isinstance(t, str) or not isinstance(item, Iterable)
-                else:
-                    # primitive or some other datatype
-                    # should not be iterable/nested lists
-                    assert isinstance(t, str) or not isinstance(t, Iterable)
-
-    # 2+ TT
-    # num_signals_max == 1: a (sorta) single tuple
-    #   (signal 1 output)
-    #   (class name, (x, y, w, h))
-    # num_signals_max > 1: list of tuples 
-    # [
-    #   (signal 1 output),
-    #   (signal 2 output), 
-    #   ...
-    # ]
-    # [ 
-    #   (class name 1, (x1, y1, w1, h1)),
-    #   (class name 2, (x2, y2, w2, h2)),
-    #   ...
-    # ]
-    if len(target_transforms) > 1:
         if num_signals_max == 1:
-            assert isinstance(targets, tuple) or isinstance(targets,list)
-            for item in targets:
-                if isinstance(item, tuple):
-                    for i in item:
-                        # should not be nested tuple
-                        assert isinstance(i, str) or not isinstance(i, Iterable)
-                else:
-                    # primitive or some other datatype
-                    # should not be iterable/nested lists
-                    assert isinstance(item, str) or not isinstance(item, Iterable)
+            # one signal
+            assert isinstance(targets, tuple) or isinstance(targets, list) or isinstance(targets, float) or isinstance(targets, int) or isinstance(targets, str)
         else:
+            # sample has more than one signal
+            # targets should be a list
             assert isinstance(targets, list)
             for t in targets:
-                assert isinstance(t, tuple)
-                for item in t:
-                    if isinstance(item, tuple):
-                        for i in item:
-                            # should not be nested tuple
-                            assert isinstance(i, str) or not isinstance(i, Iterable)
-                    else:
-                        # primitive or some other datatype
-                        # should not be iterable/nested lists
-                        assert isinstance(item, str) or not isinstance(item, Iterable)
-
-@pytest.mark.parametrize("num_signals_max, target_transforms, impairment_level", test_dataset_getitem_params)
-def test_NewDataset_getitem(num_signals_max: int, target_transforms: List[TargetTransform], impairment_level: int):
+                assert isinstance(targets, tuple) or isinstance(targets, list) or isinstance(targets, float) or isinstance(targets, int) or isinstance(targets, str)
+    
+
+@pytest.mark.parametrize("num_signals_max, target_labels", test_dataset_getitem_params)
+def test_IterableDataset_getitem(num_signals_max: int, target_labels: List[str],):
     """ Tests targets from target transform are properly returned from dataset's getitem
 
     >>> pytest test_datasets.py -s
 
     Args:
         num_signals_max (str): Maximum number of signals.
-        target_transforms (List[TargetTransform]): target transforms to test.
+        target_labels: List[str] (List[TargetTransform]): target labels to test.
     """    
-    print(f"\n{num_signals_max}, {target_transforms}, level {impairment_level}")
+    print(f"\nnum_signals_max={num_signals_max}, target_labels={target_labels}")
     dataset = None
     fft_size = 64
 
     dm = DatasetMetadata(
         num_iq_samples_dataset=fft_size**2,
         fft_size=fft_size,
-        impairment_level=impairment_level,
         num_signals_max=num_signals_max,
-        target_transforms=target_transforms
     )
-    dataset = TorchSigIterableDataset(dataset_metadata=dm)
+    dataset = TorchSigIterableDataset(
+        dataset_metadata=dm,
+        transforms = [YOLOLabel()],
+        target_labels=target_labels
+    )
 
     for i in range(num_check):
-        data, targets = next(dataset)
+        sample = next(dataset)
+        # data, targets = sample.data, [x.to_dict() for x in sample.get_full_metadata()]
 
-        verify_getitem_targets(num_signals_max, target_transforms, targets)
+        verify_getitem_targets(num_signals_max, target_labels, sample)
 
-@pytest.mark.parametrize("num_signals_max, target_transforms, impairment_level", test_dataset_getitem_params)
-def test_StaticDataset_getitem(num_signals_max: int, target_transforms: List[TargetTransform], impairment_level: int):
+@pytest.mark.parametrize("num_signals_max, target_labels", test_dataset_getitem_params)
+def test_StaticDataset_getitem(num_signals_max: int, target_labels):
     """ Tests targets from target transform are properly returned from dataset's getitem
 
     >>> pytest test_datasets.py -s
 
     Args:
         num_signals_max (int): Maximum number of signals.
-        target_transforms (List[TargetTransform]): target transforms to test.
+        target_labels (List[TargetTransform]): target labels to test.
     """    
-    print(f"\n{num_signals_max}, {target_transforms}, level {impairment_level}")
+    print(f"\nnum_signals_max={num_signals_max}, target_labels={target_labels}")
+    if target_labels is None or len(target_labels) == 0:
+        # skip
+        return
     new_dataset = None
     fft_size = 64
     root = getitem_dir
@@ -212,40 +162,247 @@ def test_StaticDataset_getitem(num_signals_max: int, target_transforms: List[Tar
     dm = DatasetMetadata(
         num_iq_samples_dataset=fft_size**2,
         fft_size=fft_size,
-        impairment_level=impairment_level,
         num_signals_max=num_signals_max,
         num_signals_min = 1,
-        num_samples=num_generate
     )
-    new_dataset = TorchSigIterableDataset(dataset_metadata=dm)
-
+    new_dataset = TorchSigIterableDataset(
+        dataset_metadata=dm, 
+        transforms = [YOLOLabel()],
+        target_labels=target_labels
+    )
+    new_dataloader = WorkerSeedingDataLoader(new_dataset, collate_fn=default_collate_fn)
     dc = DatasetCreator(
-        new_dataset,
+        dataloader=new_dataloader,
         root = root,
-        overwrite = True
+        overwrite = True,
+        dataset_length=num_generate
     )
     
     dc.create()
 
-    static_dataset = None
-
     static_dataset = StaticTorchSigDataset(
         root = root,
-        impairment_level = impairment_level,
-        target_transforms=target_transforms,
     )
 
     for i in range(num_check):
         idx = np.random.randint(len(static_dataset))
-        data, targets = static_dataset[idx]
+        sample = static_dataset[idx]
+
+        # verify_getitem_targets(num_signals_max, target_labels, sample)
 
-        verify_getitem_targets(num_signals_max, target_transforms, targets)
+
+class BYODExampleFileHandler(ExternalFileHandler):
+
+    def __init__(
+        self,
+        root: str
+    ):
+        super().__init__(root=root)
+
+        self.class_list = ['BPSK', 'QPSK', 'Noise']  
+
+    def size(self) -> int:
+        try:
+            with open(f"{self.root}/info.json", "r") as f:
+                dataset_info = json.load(f)
+
+            return dataset_info["size"]
+        except:
+            raise ValueError(f"Error loading {root}/info.json")
     
+    def load_dataset_metadata(self) -> ExternalDatasetMetadata:
+        try:
+            with open(f"{self.root}/info.json", "r") as f:
+                dataset_info = json.load(f)
+
+            return ExternalDatasetMetadata(
+                # minimum fields required for ExternalDatasetMetadata
+                num_iq_samples_dataset = dataset_info["dataset_length"],
+                sample_rate = dataset_info["sample_rate"],
+                class_list = dataset_info["class_labels"],
+                dataset_length = dataset_info["size"]
+            )
+        except:
+            raise ValueError(f"Error loading {self.root}/info.json")
+
+    def load(self, idx: int) -> Tuple[np.ndarray, List[Dict]]:
+        try:
+            # load data
+            data = np.load(f"{self.root}/data.npy")[idx]
+
+            with open(f"{self.root}/metadata.csv", "r") as f:
+                reader = csv.DictReader(f, fieldnames=["index", "label", "modcod", "sample_rate"])
+                # get to idx row
+                row = next(itertools.islice(reader, idx, idx+1), None)
+                if row is None:
+                    raise IndexError(f"Metadata idx {idx} is out of bounds")
+
+                row["index"] = int(row["index"])
+                row["sample_rate"] = float(row["sample_rate"])
+                # add class_name
+                row["class_name"] = row["label"].lower()
+                # add class index
+                row["class_index"] = self.class_list.index(row["label"])
+
+                metadata = row
+
+            return data, [metadata]
+        except:
+            raise ValueError(f"Error loading {root}/info.json")
+
+
+class BYODExampleFileHandler(ExternalFileHandler):
+
+    def __init__(
+        self,
+        root: str
+    ):
+        super().__init__(root=root)
+
+        self.class_list = ['BPSK', 'QPSK', 'Noise']  
+
+    def size(self) -> int:
+        try:
+            with open(f"{self.root}/info.json", "r") as f:
+                dataset_info = json.load(f)
+
+            return dataset_info["dataset_length"]
+        except:
+            raise ValueError(f"Error loading {root}/info.json")
+    
+    def load_dataset_metadata(self) -> ExternalDatasetMetadata:
+        try:
+            with open(f"{self.root}/info.json", "r") as f:
+                dataset_info = json.load(f)
+
+            return ExternalDatasetMetadata(
+                # minimum fields required for ExternalDatasetMetadata
+                num_iq_samples_dataset = dataset_info["dataset_length"],
+                sample_rate = dataset_info["sample_rate"],
+                class_list = dataset_info["class_labels"],
+            )
+        except:
+            raise ValueError(f"Error loading {self.root}/info.json")
+
+    def load(self, idx: int) -> Tuple[np.ndarray, List[Dict]]:
+        try:
+            # load data
+            data = np.load(f"{self.root}/data.npy")[idx]
+
+            with open(f"{self.root}/metadata.csv", "r") as f:
+                reader = csv.DictReader(f, fieldnames=["index", "label", "modcod", "sample_rate"])
+                # get to idx row
+                row = next(itertools.islice(reader, idx, idx+1), None)
+                if row is None:
+                    raise IndexError(f"Metadata idx {idx} is out of bounds")
+
+                row["index"] = int(row["index"])
+                row["sample_rate"] = float(row["sample_rate"])
+                # add class_name
+                row["class_name"] = row["label"].lower()
+                # add class index
+                row["class_index"] = self.class_list.index(row["label"])
+
+                metadata = row
+
+            return data, [metadata]
+        except:
+            raise ValueError(f"Error loading {root}/info.json")
+
+def test_ExternalTorchSigDataset() -> None:
+    root = external_dir               # data file top-level folder 
+    seed = 1234567890                         # rng seed
+
+    # directories
+    os.makedirs(root, exist_ok=True)
+
+    # Parameters
+    fs = 1_000_000                              # 1 MHz sample-rate (fixed rate)
+    dataset_length = 1024                          # samples per data (fixed size)
+    dataset_size = 8                            # dataset size
+    labels = ['BPSK', 'QPSK', 'Noise']          # three arbitrary metadata class labels (strings)
+    modcod = [0, 1, 2]                          # three arbitrary metadata integers
+    rng = np.random.default_rng(seed)           # random number generator
+
+    # Create user's external data: non-TorchSig synthetic data along with metadata
+    signals_array = np.empty((dataset_size, dataset_length), dtype=np.complex64)  # store all data in memory
+    meta_rows = []                                           # store all metadata in memory
+
+    t = np.arange(dataset_length) / fs  # timesteps
+
+    # create dataset
+    for idx in range(dataset_size):
+        label = rng.choice(labels)
+        mc = rng.choice(modcod)
+        
+        if label == "BPSK":
+            bits   = rng.integers(0, 2, dataset_length)
+            sig    = (2*bits-1) + 0j
+        elif label == "QPSK":
+            bits   = rng.integers(0, 4, dataset_length)
+            table  = {0:1+1j, 1:1-1j, 2:-1+1j, 3:-1-1j}
+            sig    = np.vectorize(table.get)(bits)
+        else:  # white noise
+            sig = (rng.normal(size=dataset_length) + 1j*rng.normal(size=dataset_length)) * 0.1
+        
+        sig /= np.sqrt((np.abs(sig)**2).mean()) # normalize power for consistency
+        signals_array[idx] = sig.astype(np.complex64)
+        
+        # add to metadata
+        meta_rows.append(
+            dict(
+                index=idx, 
+                label=label, 
+                modcod=mc, 
+                sample_rate=fs
+            )
+        )
+
+    # write information about dataset
+    global_metadata = {
+        "size": dataset_size,
+        "dataset_length": dataset_length,
+        "class_labels": labels,
+        "sample_rate": fs
+    }
+    with open(f"{root}/info.json", 'w') as f:
+        json.dump(global_metadata, f, indent=4)
+
+    # write data as npy
+    np.save(f"{root}/data.npy", signals_array)
+
+    # write metadata
+    with open(f"{root}/metadata.csv", 'w', newline='') as f:
+        csv.DictWriter(f, fieldnames=meta_rows[0].keys()).writerows(meta_rows)
+
+    print(f"Synthetic signals + metadata staged in {root}")
+
+    custom_dataset = ExternalTorchSigDataset(
+        file_handler = BYODExampleFileHandler(root),
+        target_labels = None
+    )
+    print(f"Dataset size: {len(custom_dataset)}")
+
+    sample = custom_dataset[4]
+    print(f"data: {sample.data}")
+    print(f"metadata: {[meta.to_dict() for meta in sample.get_full_metadata()]}")
+
+    custom_dataset_2 = ExternalTorchSigDataset(
+        file_handler = BYODExampleFileHandler(root),
+        transforms = [ComplexTo2D()],
+        target_labels = ["modcod"]
+    )
+    print(f"Dataset size: {len(custom_dataset_2)}")
+
+    data, metadata = custom_dataset_2[4]
+    print(f"data: {data.shape}")
+    print(f"metadata: {metadata}")
+
 
 
 @pytest.mark.parametrize("params, is_error", [
     (
-        {'num_samples': 10, 'impairment_level': 2},
+        {'dataset_length': 10},
         False
     )
 ])
@@ -269,13 +426,10 @@ def test_datasets(params: dict, is_error: bool) -> None:
     class_dist = np.ones(len(class_list))/len(class_list)    
     
     # number of samples to test generation
-    num_samples = params["num_samples"]
+    dataset_length = params["dataset_length"]
     save_num_signals = 5
     num_signals_min = 1 # always generate a signal
     num_signals_max = 1
-    
-    # define impairment level
-    impairment_level = params["impairment_level"]
 
     # FFT/spectrogram params
     fft_size = rng.integers(128,1024, dtype=int)
@@ -300,55 +454,49 @@ def test_datasets(params: dict, is_error: bool) -> None:
 
     # define transforms
     transforms = [Spectrogram(fft_size=fft_size)]
-    target_transform = [
-        ClassName(),
-        Start(),
-        Stop(),
-        LowerFreq(),
-        UpperFreq(),
-        SNR()
-    ]
     
     # build the dataset metadata
     md = DatasetMetadata(
         num_iq_samples_dataset=num_iq_samples_dataset,
         sample_rate=sample_rate,
         fft_size=fft_size,
-        num_samples=num_samples,
+        dataset_length=dataset_length,
         num_signals_max=num_signals_max,
         num_signals_min=num_signals_min,
         num_signals_distribution=num_signals_dist,
         snr_db_max=snr_db_max,
         snr_db_min=snr_db_min,
-        transforms=transforms,
-        target_transforms=target_transform,
-        impairment_level=impairment_level,
         class_list=class_list,
         class_distribution=class_dist,
     )
 
     if is_error:
         with pytest.raises(Exception, match=r".*"):
-            DS = TorchSigIterableDataset(dataset_metadata=md)
+            DS = TorchSigIterableDataset(dataset_metadata=md, target_labels=["class_index"], transforms=transforms)
+            DL = WorkerSeedingDataLoader(DS, collate_fn=default_collate_fn)
+            DL.seed(seed)
             dc = DatasetCreator(
-                DS,
+                dataloader=DL,
                 root = wb_data_dir,
+                dataset_length=dataset_length,
                 overwrite = True
             )
             dc.create()
             SDS = StaticTorchSigDataset(
                 root = wb_data_dir,
-                impairment_level = impairment_level,
             )
     else:
         # create the dataset object, derived from the metadata object
-        DS0 = TorchSigIterableDataset(dataset_metadata=deepcopy(md), seed=seed)
-        DS1 = TorchSigIterableDataset(dataset_metadata=deepcopy(md), seed=seed) # reproducible copy
+        DS0 = TorchSigIterableDataset(dataset_metadata=deepcopy(md), target_labels=None, seed=seed, transforms=transforms)
+        DS1 = TorchSigIterableDataset(dataset_metadata=deepcopy(md), target_labels=None, seed=seed, transforms=transforms) # reproducible copy
 
         # save dataset to disk
+        DL0 = WorkerSeedingDataLoader(DS0, collate_fn=lambda x: x)
+        DL0.seed(seed)
         dc = DatasetCreator(
-            DS0,
+            dataloader=DL0,
             root = wb_data_dir,
+            dataset_length=dataset_length,
             overwrite = True
         )
         dc.create()
@@ -356,41 +504,25 @@ def test_datasets(params: dict, is_error: bool) -> None:
         # load dataset from disk
         SDS0 = StaticTorchSigDataset(
             root = wb_data_dir,
-            impairment_level = impairment_level,
+            target_labels=["class_index"]
         )
         SDS1 = StaticTorchSigDataset(
             root = wb_data_dir,
-            impairment_level = impairment_level,
+            target_labels=["class_index"]
         )
             
         # dataset
         assert isinstance(DS0, TorchSigIterableDataset)
-        for i in range(num_samples):
-            data0, meta0 = next(DS0)
-            data1, meta1 = next(DS1) # reproducible copy
-
-            assert type(data0) == np.ndarray
-            assert data0.dtype == torchsig_real_data_type
-            if (num_signals_max == 1):
-                assert type(meta0) == tuple
-            else:
-                assert type(meta0) == list
-            assert meta0 == meta1
-            assert np.allclose(data0, data1, RTOL)
 
         # static dataset
         assert isinstance(SDS0, StaticTorchSigDataset)
-        assert len(SDS0) == num_samples
-        for i in range(num_samples):
+        assert len(SDS0) == dataset_length
+        for i in range(dataset_length):
             data0, meta0 = SDS0[i]
             data1, meta1 = SDS1[i] # reproducible copy
             
             assert type(data0) == np.ndarray
-            assert data0.dtype == torchsig_real_data_type
-            if (num_signals_max == 1):
-                assert type(meta0) == tuple
-            else:
-                assert type(meta0) == list
+            assert data0.dtype == TorchSigRealDataType
             assert meta0 == meta1
             assert np.allclose(data0, data1, RTOL)
         
diff --git a/tests/datasets/test_default_configs.py b/tests/datasets/test_default_configs.py
new file mode 100644
index 000000000..3a0de6287
--- /dev/null
+++ b/tests/datasets/test_default_configs.py
@@ -0,0 +1,43 @@
+""" Tests Default DatasetMetadata configs at torchsig.datasets.default_configs
+"""
+from torchsig.datasets.datasets import TorchSigIterableDataset
+from torchsig.datasets.default_configs.loader import get_yaml_filename, default_config_dir
+
+import pytest
+from pathlib import Path
+import itertools
+import pprint
+
+
+all_configs = [file.name for file in default_config_dir.glob('*.yaml')]
+
+@pytest.mark.parametrize("config_name", itertools.chain(all_configs))
+def test_config(config_name: str):
+    print(f"Testing config: {config_name}...")
+    md_dict = get_yaml_filename(config_name)
+    pprint.pprint(md_dict)
+
+
+    ds = TorchSigIterableDataset(
+        dataset_metadata = md_dict,
+        target_labels=["class_index"]
+    )
+
+    data, targets = next(ds)
+    print(f"data shape: {data.shape}")
+    print(f"targets: {targets}")
+
+def test_narrowband():
+    md_dict = get_yaml_filename("narrowband_defaults.yaml")
+    pprint.pprint(md_dict)
+
+
+    ds = TorchSigIterableDataset(
+        dataset_metadata = md_dict,
+        target_labels=["class_index"]
+    )
+
+    data, metadata = next(ds)
+
+if __name__ == "__main__":
+    test_narrowband()
\ No newline at end of file
diff --git a/tests/datasets/yaml_test.py b/tests/datasets/yaml_test.py
deleted file mode 100644
index 352ee8838..000000000
--- a/tests/datasets/yaml_test.py
+++ /dev/null
@@ -1,53 +0,0 @@
-
-from torchsig.datasets.datasets import TorchSigIterableDataset, StaticTorchSigDataset
-import yaml
-import numpy as np
-from torchsig.utils.writer import DatasetCreator
-import pathlib
-
-
-def compare(s1, s2):
-    d1, t1 = s1
-    d2, t2 = s2
-
-    data_matches = np.all(d1 == d2)
-    targets_match = t1 == t2
-
-    return data_matches and targets_match
-
-dataset_name = f"yaml_test_dataset"
-directory_path = pathlib.Path(__file__).parent.resolve()
-yaml_path = str(directory_path.joinpath(f"{dataset_name}.yaml"))
-dataset_path = str(directory_path.joinpath(f"{dataset_name}"))
-
-DS = TorchSigIterableDataset(yaml_path)
-
-test_idx = np.random.randint(DS.dataset_metadata.num_samples)
-
-dc = DatasetCreator(
-    DS,
-    dataset_path,
-    overwrite=True
-)
-
-dc.create()
-
-SDS = StaticTorchSigDataset(
-    root = dataset_path,
-    impairment_level = 0
-)
-
-SDS2 = StaticTorchSigDataset(
-    root = dataset_path,
-    impairment_level = 0
-)
-
-match = compare(SDS[test_idx], SDS2[test_idx])
-if not match:
-    print("Does not match.")
-    breakpoint()
-print("Success.")
-
-
-    
-
diff --git a/tests/datasets/yaml_test_dataset.yaml b/tests/datasets/yaml_test_dataset.yaml
deleted file mode 100644
index b1385ec20..000000000
--- a/tests/datasets/yaml_test_dataset.yaml
+++ /dev/null
@@ -1,17 +0,0 @@
-required:
-  num_iq_samples_dataset: 4096
-  fft_size: 64
-  num_signals_max: 2
-  impairment_level: 1
-
-overrides:
-  num_samples: 10
-  sample_rate: 1000000 # 1e6
-  num_signals_min: 1
-  num_signals_distribution: null
-  snr_db_min: 0.0
-  snr_db_max: 50.0
-  impairment_level: 0
-  class_list: ['tone', 'qpsk', 'fm', 'am-dsb', 'lfm_data', '4fsk', '2gmsk']
-  class_distribution: uniform
-  seed: 123456789
diff --git a/tests/signals/test_signal_builder.py b/tests/signals/test_signal_builder.py
index d3466c568..24b496437 100644
--- a/tests/signals/test_signal_builder.py
+++ b/tests/signals/test_signal_builder.py
@@ -5,11 +5,11 @@ Classes:
 - SignalBuilder
 """
 
-from torchsig.signals.signal_types import Signal, DatasetSignal, DatasetDict
+from torchsig.signals.signal_types import Signal
 from torchsig.datasets.dataset_metadata import DatasetMetadata
 from torchsig.signals.builders.constellation import ConstellationSignalBuilder
 import torchsig.transforms.functional as F
-from torchsig.utils.dsp import torchsig_complex_data_type
+from torchsig.utils.dsp import TorchSigComplexDataType
 
 # Third Party
 import numpy as np
@@ -22,18 +22,14 @@ for i in range(3):
     md_qpsk = DatasetMetadata(
         num_iq_samples_dataset = 1024,
         fft_size = 128,
-        impairment_level = 0,
         sample_rate = 10e6,
         num_signals_min = 1,
         num_signals_max = 1,
         num_signals_distribution = [1.0],
         snr_db_min = 100.0,
-        snr_db_max = 100.0,       
-        transforms = [],
-        target_transforms = [],
+        snr_db_max = 100.0,
         class_list = ['qpsk'],
         class_distribution = [1.0],
-        num_samples = 1,
         seed = 1234
     )
     
diff --git a/tests/signals/test_signal_types.py b/tests/signals/test_signal_types.py
index f1ce7817d..58ede6f2f 100644
--- a/tests/signals/test_signal_types.py
+++ b/tests/signals/test_signal_types.py
@@ -3,8 +3,6 @@
 Classes:
 - SignalMetadata
 - Signal
-- DatasetSignal
-- DatasetDict
 """
 
 from __future__ import annotations
@@ -13,10 +11,8 @@ from __future__ import annotations
 from torchsig.signals.signal_types import (
     SignalMetadata,
     Signal,
-    DatasetSignal,
-    DatasetDict
 )
-from torchsig.utils.dsp import torchsig_complex_data_type
+from torchsig.utils.dsp import TorchSigComplexDataType
 # from torchsig.signals.signal_lists import TorchSigSignalLists
 
 # Third Party
@@ -38,13 +34,12 @@ sample_rate = 10e6
 snr_db_min = 0.0
 snr_db_max = 50.0
 
-def wideband_metadata():
+def get_metadata():
     from torchsig.datasets.dataset_metadata import DatasetMetadata
 
     return DatasetMetadata(
         num_iq_samples_dataset=num_iq_samples_dataset,
         fft_size=fft_size,
-        impairment_level=0,
         num_signals_max=3,
         sample_rate=sample_rate,
         snr_db_max=snr_db_max,
@@ -165,7 +160,7 @@ def test_valid_SignalMetadata(
 
     )
 
-    dataset_metadata = wideband_metadata()
+    dataset_metadata = get_metadata()
 
     edge_cases = dict(
         # center_freq
@@ -204,7 +199,7 @@ def test_valid_SignalMetadata(
 
 
 def test_invalid_SignalMetadata():
-    dataset_metadata = wideband_metadata()
+    dataset_metadata = get_metadata()
 
     bad_params = dict(
         # dataset_metadata
@@ -266,23 +261,23 @@ def test_invalid_SignalMetadata():
 # Signal Tests
 
 @pytest.mark.parametrize("data, is_error", [
-    (np.ones((good_signal_metadata['duration_in_samples']), dtype=torchsig_complex_data_type), False),
-    (np.zeros((good_signal_metadata['duration_in_samples']), dtype=torchsig_complex_data_type), False),
-    (np.random.random((good_signal_metadata['duration_in_samples'])).astype(torchsig_complex_data_type), False),
+    (np.ones((good_signal_metadata['duration_in_samples']), dtype=TorchSigComplexDataType), False),
+    (np.zeros((good_signal_metadata['duration_in_samples']), dtype=TorchSigComplexDataType), False),
+    (np.random.random((good_signal_metadata['duration_in_samples'])).astype(TorchSigComplexDataType), False),
 
     (np.ones((good_signal_metadata['duration_in_samples']), dtype=int), True),
     (np.zeros((good_signal_metadata['duration_in_samples']), dtype=float), True),
     (np.random.random((good_signal_metadata['duration_in_samples'])).astype(float), True),
 
-    (np.ones((good_signal_metadata['duration_in_samples'] + 1), dtype=torchsig_complex_data_type), True),
-    (np.zeros((good_signal_metadata['duration_in_samples'] - 1), dtype=torchsig_complex_data_type), True),
+    (np.ones((good_signal_metadata['duration_in_samples'] + 1), dtype=TorchSigComplexDataType), True),
+    (np.zeros((good_signal_metadata['duration_in_samples'] - 1), dtype=TorchSigComplexDataType), True),
 
     (np.random.random((good_signal_metadata['duration_in_samples'] + 2)).astype(float), True),
 ])
 def test_Signal(data: np.ndarray, is_error: bool):
 
     signal_metadata = deepcopy(good_signal_metadata)
-    signal_metadata['dataset_metadata'] = wideband_metadata()
+    signal_metadata['dataset_metadata'] = get_metadata()
     if is_error:
         with pytest.raises(Exception):
             
@@ -298,7 +293,7 @@ def test_Signal(data: np.ndarray, is_error: bool):
         )
         s.verify()
 
-# DatasetSignal Tests
+# Signal Tests
 good_signal_metadata = dict(
     center_freq = 0.0,
     bandwidth = 0.5,
@@ -309,75 +304,4 @@ good_signal_metadata = dict(
     class_index = 0
 )
 
-@pytest.mark.parametrize("data, is_error", [
-    (np.ones((num_iq_samples_dataset), dtype=torchsig_complex_data_type), False),
-    (np.zeros((num_iq_samples_dataset), dtype=torchsig_complex_data_type), False),
-    (np.random.random((num_iq_samples_dataset)).astype(torchsig_complex_data_type), False),
-
-    (np.ones((num_iq_samples_dataset + 1), dtype=torchsig_complex_data_type), True),
-    (np.zeros((num_iq_samples_dataset - 1), dtype=torchsig_complex_data_type), True),
-
-    (np.random.random((num_iq_samples_dataset + 2)).astype(float), True),
-])
-def test_DatasetSignal(data: np.ndarray, is_error: bool):
-    signal_metadata = deepcopy(good_signal_metadata)
-    signal_metadata['dataset_metadata'] = wideband_metadata()
-    s1 = Signal(
-        data = np.ones((good_signal_metadata['duration_in_samples']), dtype=torchsig_complex_data_type),
-        metadata = SignalMetadata(**signal_metadata)
-    )
-    s2 = Signal(
-        data = np.ones((good_signal_metadata['duration_in_samples']), dtype=torchsig_complex_data_type),
-        metadata = SignalMetadata(**signal_metadata)
-    )
-    signals = [s1, s2]
-
-    all_signals = [
-        [s1, s2],
-        s1,
-        [SignalMetadata(**signal_metadata), SignalMetadata(**signal_metadata)],
-        SignalMetadata(**signal_metadata),
-        [signal_metadata],
-        [signal_metadata, deepcopy(signal_metadata)]
-    ]
-
-    for signals in all_signals:
-        if is_error:
-            with pytest.raises(Exception):
-                
-                ds = DatasetSignal(
-                    data = data,
-                    signals = signals,
-                    dataset_metadata = signal_metadata['dataset_metadata']
-                )
-                ds.verify()
-        else:
-            ds = DatasetSignal(
-                    data = data,
-                    signals = signals,
-                    dataset_metadata = signal_metadata['dataset_metadata']
-                )
-            ds.verify()
-
-# DatasetDict
-
-def test_DatasetDict():
-    signal_metadata = deepcopy(good_signal_metadata)
-    signal_metadata['dataset_metadata'] = wideband_metadata()
-    s1 = Signal(
-        data = np.ones((good_signal_metadata['duration_in_samples']), dtype=torchsig_complex_data_type),
-        metadata = SignalMetadata(**signal_metadata)
-    )
-    s2 = Signal(
-        data = np.ones((good_signal_metadata['duration_in_samples']), dtype=torchsig_complex_data_type),
-        metadata = SignalMetadata(**signal_metadata)
-    )
-    signals = [s1, s2]
-    data = np.ones((num_iq_samples_dataset), dtype=torchsig_complex_data_type)
-    ds = DatasetSignal(
-        data = data,
-        signals = signals
-    )
 
-    dd = DatasetDict(signal = ds)
-    dd.verify()
diff --git a/tests/test_utils.py b/tests/test_utils.py
index 441fd1e0f..d3bfe76c2 100644
--- a/tests/test_utils.py
+++ b/tests/test_utils.py
@@ -2,7 +2,9 @@
 import numpy as np
 import matplotlib.pyplot as plt
 
-from typing import List
+from typing import List, Tuple, Any
+
+from torchsig.datasets.dataset_metadata import ExternalDatasetMetadata
 
 # Signal Metadata type checking
 
@@ -22,7 +24,7 @@ signal_metadata_ints = [
     'start_in_samples',
     'duration_in_samples',
     'class_index',
-    'num_samples',
+    'dataset_length',
     'stop_in_samples'
 ]
 signal_metadata_strs = [
diff --git a/tests/transforms/test_base_transforms.py b/tests/transforms/test_base_transforms.py
index 5f33c5641..c3f0f349c 100644
--- a/tests/transforms/test_base_transforms.py
+++ b/tests/transforms/test_base_transforms.py
@@ -9,11 +9,10 @@ from torchsig.transforms.base_transforms import (
     RandomApply,
     RandAugment
 )
-from torchsig.signals.signal_types import Signal, DatasetSignal
-from torchsig.utils.dsp import torchsig_complex_data_type
+from torchsig.signals.signal_types import Signal
+from torchsig.utils.dsp import TorchSigComplexDataType
 from test_transforms_utils import (
     generate_test_signal,
-    generate_test_dataset_signal
 )
 
 # Third Party
@@ -23,10 +22,9 @@ from copy import deepcopy
 import pytest
 
 
-AnySignal = Signal | DatasetSignal
+AnySignal = Signal
 RTOL = 1E-6
 TEST_SIGNAL = generate_test_signal(num_iq_samples = 64, scale = 1.0)
-TEST_DS_SIGNAL = generate_test_dataset_signal(num_iq_samples = 64, scale = 1.0)
 
 
 @pytest.mark.parametrize("is_error", [False])
@@ -49,7 +47,6 @@ def test_Transform(is_error: bool) -> None:
 @pytest.mark.parametrize("signal, params, expected, is_error", [
     (deepcopy(TEST_SIGNAL), {'transforms' :  ['invalid_transform']}, AttributeError, True),
     (deepcopy(TEST_SIGNAL), {'transforms' :  [lambda x: x]}, True, False),
-    (deepcopy(TEST_DS_SIGNAL), {'transforms' :  []}, True, False)
 ])
 def test_Compose(
     signal: AnySignal,
@@ -87,7 +84,7 @@ def test_Compose(
         assert isinstance(signal, AnySignal)
         assert type(signal) == type(signal_test)
         assert type(signal.data) == type(signal_test.data)
-        assert signal.data.dtype == torchsig_complex_data_type
+        assert signal.data.dtype == TorchSigComplexDataType
         assert np.allclose(signal.data, signal_test.data, RTOL) == expected
 
 
@@ -104,12 +101,6 @@ def test_Compose(
         generate_test_signal(num_iq_samples=64, scale=42.0),
         False
     ),
-    (
-        deepcopy(TEST_DS_SIGNAL),
-        lambda x: x*0.42,
-        generate_test_dataset_signal(num_iq_samples=64, scale=0.42),
-        False
-    ),
 
 ])
 def test_Lambda(
@@ -145,7 +136,7 @@ def test_Lambda(
         assert isinstance(signal, AnySignal)
         assert type(signal) == type(signal_test)
         assert type(signal.data) == type(signal_test.data)
-        assert signal.data.dtype == torchsig_complex_data_type
+        assert signal.data.dtype == TorchSigComplexDataType
         assert np.allclose(signal.data, expected.data, RTOL)
 
 
@@ -162,12 +153,6 @@ def test_Lambda(
         TEST_SIGNAL,
         False
     ),
-    (
-        generate_test_dataset_signal(num_iq_samples=64, scale=0.42),
-        {'norm': 2, 'flatten': False},
-        TEST_DS_SIGNAL,
-        False
-    ),
 ])
 def test_Normalize(
     signal: AnySignal, 
@@ -209,7 +194,7 @@ def test_Normalize(
         assert isinstance(signal, AnySignal)
         assert type(signal) == type(signal_test)
         assert type(signal.data) == type(signal_test.data)
-        assert signal.data.dtype == torchsig_complex_data_type
+        assert signal.data.dtype == TorchSigComplexDataType
         assert np.allclose(signal.data, expected.data, RTOL) 
 
 
@@ -226,12 +211,6 @@ def test_Normalize(
         generate_test_signal(num_iq_samples=64, scale=42.0),
         False
     ),
-    (
-        generate_test_dataset_signal(num_iq_samples=64, scale=0.42),
-        {'transform': Normalize(), 'probability': 1.0},
-        TEST_DS_SIGNAL,
-        False
-    ),
 ])
 def test_RandomApply(
     signal: AnySignal, 
@@ -273,7 +252,7 @@ def test_RandomApply(
         assert isinstance(signal, AnySignal)
         assert type(signal) == type(signal_test)
         assert type(signal.data) == type(signal_test.data)
-        assert signal.data.dtype == torchsig_complex_data_type
+        assert signal.data.dtype == TorchSigComplexDataType
 
 
 @pytest.mark.parametrize("signal, params, expected, is_error", [
@@ -297,16 +276,6 @@ def test_RandomApply(
         TEST_SIGNAL,
         False
     ),
-    (
-        generate_test_dataset_signal(num_iq_samples=64, scale=0.42),
-        {
-            'transforms': [Normalize()],
-            'choose': 1,
-            'replace': True,
-        }, 
-        TEST_DS_SIGNAL,
-        False
-    ),    
 ])
 def test_RandAugment(
     signal: AnySignal, 
@@ -353,6 +322,6 @@ def test_RandAugment(
         assert isinstance(signal, AnySignal)
         assert type(signal) == type(signal_test)
         assert type(signal.data) == type(signal_test.data)
-        assert signal.data.dtype == torchsig_complex_data_type
+        assert signal.data.dtype == TorchSigComplexDataType
         assert np.allclose(signal.data, expected.data, RTOL)
 
diff --git a/tests/transforms/test_functional.py b/tests/transforms/test_functional.py
index 8d986082d..cbe939d8f 100644
--- a/tests/transforms/test_functional.py
+++ b/tests/transforms/test_functional.py
@@ -40,8 +40,8 @@ from test_transforms_utils import (
 )
 import torchsig.utils.dsp as dsp
 from torchsig.utils.dsp import (
-    torchsig_complex_data_type,
-    torchsig_real_data_type,
+    TorchSigComplexDataType,
+    TorchSigRealDataType,
     compute_spectrogram,
 )
 
@@ -90,7 +90,7 @@ def test_add_slope(
 
         assert np.allclose(data, data_test, RTOL) == expected
         assert (type(data) == type(data_test)) == expected
-        assert (data.dtype == torchsig_complex_data_type) == expected
+        assert (data.dtype == TorchSigComplexDataType) == expected
 
 
 @pytest.mark.parametrize("data, params, expected, is_error", [
@@ -150,7 +150,7 @@ def test_additive_noise(
 
         assert (len(data) == len(data_test)) == expected
         assert (np.abs(power_delta - power) < 10**(0.1/10)) == expected
-        assert (data.dtype == torchsig_complex_data_type) == expected
+        assert (data.dtype == TorchSigComplexDataType) == expected
 
 
 @pytest.mark.parametrize("params, expected, is_error", [
@@ -224,12 +224,12 @@ def test_adjacent_channel_interference(
         assert (np.abs(freqs1 - (tone_freq + center_frequency)) < 0.01) == expected
         assert (len(data) == len(data_test)) == expected
         assert (type(data) == type(data_test)) == expected
-        assert (data.dtype == torchsig_complex_data_type) == expected
+        assert (data.dtype == TorchSigComplexDataType) == expected
 
 
 @pytest.mark.parametrize("data, params, expected, is_error", [
     (0, {'noise_power_db' : 0.0}, AttributeError, True),
-    (np.zeros(1024, dtype=torchsig_complex_data_type), {'noise_power_db' : 3.0}, True, False)
+    (np.zeros(1024, dtype=TorchSigComplexDataType), {'noise_power_db' : 3.0}, True, False)
 ])
 def test_awgn(
     data: Any, 
@@ -272,7 +272,7 @@ def test_awgn(
         
         assert (abs(power_est - noise_power_linear) < 1E-1) == expected
         assert (type(data) == type(data_test)) == expected
-        assert (data.dtype == torchsig_complex_data_type) == expected
+        assert (data.dtype == TorchSigComplexDataType) == expected
 
 
 @pytest.mark.parametrize("data, params, expected, is_error", [
@@ -318,7 +318,7 @@ def test_carrier_frequency_drift(
 
         assert (len(data) == len(data_test)) == expected
         assert (type(data) == type(data_test)) == expected
-        assert (data.dtype == torchsig_complex_data_type) == expected
+        assert (data.dtype == TorchSigComplexDataType) == expected
 
 
 @pytest.mark.parametrize("data, params, expected, is_error", [
@@ -363,7 +363,7 @@ def test_carrier_phase_noise(
 
         assert (len(data) == len(data_test)) == expected
         assert (type(data) == type(data_test)) == expected
-        assert (data.dtype == torchsig_complex_data_type) == expected
+        assert (data.dtype == TorchSigComplexDataType) == expected
 
 
 @pytest.mark.parametrize("data, expected, is_error", [
@@ -400,7 +400,7 @@ def test_channel_swap(
         assert np.allclose(data.real, test_imag, RTOL) == expected
         assert np.allclose(data.imag, test_real, RTOL) == expected
         assert (type(data) == type(data_test)) == expected
-        assert (data.dtype == torchsig_complex_data_type) == expected
+        assert (data.dtype == TorchSigComplexDataType) == expected
 
 
 @pytest.mark.parametrize("data, params, expected, is_error", [
@@ -457,7 +457,7 @@ def test_coarse_gain_change(
         gain_change_linear = 10**(gain_change_db/10)
         assert (np.allclose(data[start_idx:], gain_change_linear * data_test[start_idx:], RTOL)) == expected
         assert (type(data) == type(data_test)) == expected
-        assert (data.dtype == torchsig_complex_data_type) == expected
+        assert (data.dtype == TorchSigComplexDataType) == expected
 
 
 @pytest.mark.parametrize("params, expected, is_error", [
@@ -524,7 +524,7 @@ def test_cochannel_interference(
         assert (np.abs(est_freq - tone_freq) < (3/N)) == expected
         assert (len(data) == len(data_test)) == expected
         assert (type(data) == type(data_test)) == expected
-        assert (data.dtype == torchsig_complex_data_type) == expected
+        assert (data.dtype == TorchSigComplexDataType) == expected
 
 
 @pytest.mark.parametrize("data, params, expected, is_error", [
@@ -608,7 +608,7 @@ def test_cut_out(
             assert duration_samples == cut_inds[-1] - cut_inds[0] + 1
 
         assert (type(data) == type(data_test)) == expected
-        assert (data.dtype == torchsig_complex_data_type) == expected
+        assert (data.dtype == TorchSigComplexDataType) == expected
 
 
 @pytest.mark.parametrize("data, params, expected, is_error", [
@@ -699,12 +699,12 @@ def test_digital_agc(
 
         assert (abs(mean_level_est - reference_level) < 1E-1) == expected
         assert (type(data) == data_type) == expected
-        assert (data.dtype == torchsig_complex_data_type) == expected
+        assert (data.dtype == TorchSigComplexDataType) == expected
 
 
 @pytest.mark.parametrize("params, expected, is_error", [
-    ({'N': 10000, 'sampling_rate': 4.0,'tone_freq': 0.2, 'velocity': 1e7}, True, False),
-    ({'N': 1000, 'sampling_rate': 2.0,'tone_freq': 0.42, 'velocity': 1e6}, True, False),
+    ({'N': 10000, 'tone_freq': 0.2, 'velocity': 1e7}, True, False),
+    ({'N': 10000, 'tone_freq': 0.2, 'velocity': 1e6}, True, False),
 ])
 def test_doppler(
     params: dict,
@@ -725,40 +725,37 @@ def test_doppler(
     rng = np.random.default_rng(42)
 
     N = params['N']
-    sampling_rate = params['sampling_rate']
     tone_freq = params['tone_freq']
     velocity = params['velocity']
 
     tone_baseband = generate_tone_signal(num_iq_samples = N, scale = 1.0).data
-    data = tone_baseband * np.exp(2j * np.pi * tone_freq * np.arange(N) / sampling_rate)
+    data = tone_baseband * np.exp(2j * np.pi * tone_freq * np.arange(N))
 
     if is_error:
         with pytest.raises(expected):
             data = doppler(
                 data = data,
                 velocity = velocity,
-                propagation_speed = 2.9979e8,
-                sampling_rate = sampling_rate
+                propagation_speed = 2.9979e8
             )
     else:
         data_test = deepcopy(data)
         data = doppler(
             data = data,
             velocity = velocity,
-            propagation_speed = 2.9979e8,
-            sampling_rate = sampling_rate
+            propagation_speed = 2.9979e8
         )
 
         alpha = 2.9979e8 / (2.9979e8 - velocity) # scaling factor
         D = np.abs(np.fft.fft(data, norm='ortho'))
-        freqs = np.fft.fftfreq(N) * sampling_rate
+        freqs = np.fft.fftfreq(N)
         peaks, _ = sp.signal.find_peaks(D, height=0.5, distance=N/10)
         est_freq = freqs[peaks[0]]
         
-        assert (np.abs(est_freq - alpha*tone_freq) < (3/N)) == expected
+        assert (np.abs(est_freq - tone_freq*alpha) < 0.01) == expected
         assert (len(data) == len(data_test)) == expected
         assert (type(data) == type(data_test)) == expected
-        assert (data.dtype == torchsig_complex_data_type) == expected
+        assert (data.dtype == TorchSigComplexDataType) == expected
 
 
 @pytest.mark.parametrize("data, params, expected, is_error", [
@@ -842,7 +839,7 @@ def test_drop_samples(
             assert np.allclose(drop_inds, fill_inds, RTOL) == expected
 
         assert (type(data) == type(data_test)) == expected
-        assert (data.dtype == torchsig_complex_data_type) == expected
+        assert (data.dtype == TorchSigComplexDataType) == expected
 
 
 @pytest.mark.parametrize("data, params, expected, is_error", [
@@ -904,7 +901,7 @@ def test_fading(
         data_test_mean_power = np.mean(np.abs(data_test)**2)
         assert (abs(data_mean_power - data_test_mean_power) < 1E-1) == expected
         assert (type(data) == type(data_test)) == expected
-        assert (data.dtype == torchsig_complex_data_type) == expected
+        assert (data.dtype == TorchSigComplexDataType) == expected
 
 
 @pytest.mark.parametrize("data, params, expected, is_error", [
@@ -940,7 +937,7 @@ def test_intermodulation_products(
         data = intermodulation_products(data = data, coeffs = coeffs)
 
         assert (type(data) == type(data_test)) == expected
-        assert (data.dtype == torchsig_complex_data_type) == expected        
+        assert (data.dtype == TorchSigComplexDataType) == expected        
 
         
 @pytest.mark.parametrize("data, params, expected, is_error", [
@@ -1012,7 +1009,7 @@ def test_iq_imbalance(
         )
 
         assert (type(data) == type(data_test)) == expected
-        assert (data.dtype == torchsig_complex_data_type) == expected
+        assert (data.dtype == TorchSigComplexDataType) == expected
 
 
 @pytest.mark.parametrize("data, params, expected, is_error", [
@@ -1050,7 +1047,7 @@ def test_interleave_complex(
 
         data = interleave_complex(data_test)
 
-        assert (data.dtype == torchsig_real_data_type) == expected
+        assert (data.dtype == TorchSigRealDataType) == expected
         assert (len(data) == len(data_test)*2) == expected
 
 
@@ -1139,16 +1136,16 @@ def test_nonlinear_amplifier(
             assert (np.all(output_power <= psat)) == expected
         assert (phase_diff <= (abs(phi_max) + RTOL)) == expected
         assert (type(data) == type(data_test)) == expected
-        assert (data.dtype == torchsig_complex_data_type) == expected
+        assert (data.dtype == TorchSigComplexDataType) == expected
 
 
 @pytest.mark.parametrize("data, params, expected, is_error", [
     (
         np.zeros((2,)), 
         {
-            'Pin': np.zeros((3,)), 
-            'Pout': np.zeros((4,)), 
-            'Phi': np.zeros((5,)),
+            'p_in': np.zeros((3,)), 
+            'p_out': np.zeros((4,)), 
+            'phi': np.zeros((5,)),
             'p_ratio': 0.,
             'phase_shift': 0.
         }, 
@@ -1158,9 +1155,9 @@ def test_nonlinear_amplifier(
     (
         deepcopy(TEST_DATA),
         {
-            'Pin':     10**((np.array([-100., -50.,  0., 50.])) / 10), 
-            'Pout':    10**((np.array([ -97., -47.,  3., 53.])) / 10), 
-            'Phi': np.deg2rad(np.array([ 0.1,  0.1, 0.1, 0.1])),
+            'p_in':     10**((np.array([-100., -50.,  0., 50.])) / 10), 
+            'p_out':    10**((np.array([ -97., -47.,  3., 53.])) / 10), 
+            'phi': np.deg2rad(np.array([ 0.1,  0.1, 0.1, 0.1])),
             'p_ratio': 10**(3./10),
             'phase_shift': np.deg2rad(0.1)
         }, 
@@ -1186,9 +1183,9 @@ def test_nonlinear_amplifier_table(
         AssertionError: If unexpected test outcome.
 
     """
-    Pin = params['Pin']
-    Pout = params['Pout']
-    Phi = params['Phi']
+    p_in = params['p_in']
+    p_out = params['p_out']
+    phi = params['phi']
     p_ratio = params['p_ratio']
     phase_shift = params['phase_shift']
     
@@ -1196,9 +1193,9 @@ def test_nonlinear_amplifier_table(
         with pytest.raises(expected): 
             data = nonlinear_amplifier_table(
                 data = data,
-                Pin  = Pin,
-                Pout = Pout,
-                Phi  = Phi,
+                p_in  = p_in,
+                p_out = p_out,
+                phi  = phi,
                 auto_scale = False
             )
     else:
@@ -1206,9 +1203,9 @@ def test_nonlinear_amplifier_table(
 
         data = nonlinear_amplifier_table(
             data = data,
-            Pin  = Pin,
-            Pout = Pout,
-            Phi  = Phi,
+            p_in  = p_in,
+            p_out = p_out,
+            phi  = phi,
             auto_scale = False
         )
 
@@ -1220,7 +1217,7 @@ def test_nonlinear_amplifier_table(
         assert (abs(output_power/input_power - p_ratio) < RTOL) == expected
         assert (abs(np.mean(np.unwrap(output_phase_rad - input_phase_rad)) - phase_shift) < RTOL) == expected
         assert (type(data) == type(data_test)) == expected
-        assert (data.dtype == torchsig_complex_data_type) == expected
+        assert (data.dtype == TorchSigComplexDataType) == expected
 
 
 @pytest.mark.parametrize("data, params, expected, is_error", [
@@ -1274,7 +1271,7 @@ def test_normalize(
 
         assert np.allclose(data, expected, RTOL)
         assert type(data) == type(data_test) 
-        assert data.dtype == torchsig_complex_data_type
+        assert data.dtype == TorchSigComplexDataType
 
 
 @pytest.mark.parametrize("params, expected, is_error", [
@@ -1307,7 +1304,7 @@ def test_passband_ripple(
 
     # create impulse response
     data = dsp.noise_generator(
-        N       = 128,
+        num_samples  = 128,
         power   = 1.0, 
         color   = 'white',
         continuous = False,
@@ -1336,7 +1333,7 @@ def test_passband_ripple(
         M = len(D)
         
         assert (type(data) == type(data_test)) == expected
-        assert (data.dtype == torchsig_complex_data_type) == expected
+        assert (data.dtype == TorchSigComplexDataType) == expected
 
 @pytest.mark.parametrize("data, params, expected, is_error", [
     (
@@ -1385,7 +1382,7 @@ def test_patch_shuffle(
         patch_inds = np.where(data != data_test)[0]
         assert ((patch_inds[0] + patch_size - 1) in patch_inds) == expected
         assert (type(data) == type(data_test)) == expected
-        assert (data.dtype == torchsig_complex_data_type) == expected
+        assert (data.dtype == TorchSigComplexDataType) == expected
 
 
 @pytest.mark.parametrize("data, params, expected, is_error", [
@@ -1433,7 +1430,7 @@ def test_phase_offset(
         data_restored = data * np.exp(-1j * phase)
         assert (np.allclose(data_restored, data_test, rtol=RTOL)) == expected
         assert (type(data) == type(data_test)) == expected
-        assert (data.dtype == torchsig_complex_data_type) == expected
+        assert (data.dtype == TorchSigComplexDataType) == expected
 
 
 @pytest.mark.parametrize("data, params, expected, is_error", [
@@ -1483,7 +1480,7 @@ def test_quantize(
         )
 
         assert type(data) == type(expected)
-        assert data.dtype == torchsig_complex_data_type
+        assert data.dtype == TorchSigComplexDataType
 
 
 @pytest.mark.parametrize("data, params, expected, is_error", [
@@ -1543,7 +1540,7 @@ def test_shadowing(
         assert (p_value > 0.05) == expected
         assert (len(data) == len(data_test)) == expected
         assert (type(data) == type(data_test)) == expected
-        assert (data.dtype == torchsig_complex_data_type) == expected
+        assert (data.dtype == TorchSigComplexDataType) == expected
 
 
 @pytest.mark.parametrize("data, expected, is_error", [
@@ -1578,7 +1575,7 @@ def test_spectral_inversion(
         assert np.allclose(data.real, test_real, RTOL) == expected
         assert np.allclose(data.imag, -test_imag, RTOL) == expected
         assert (type(data) == type(data_test)) == expected
-        assert (data.dtype == torchsig_complex_data_type) == expected
+        assert (data.dtype == TorchSigComplexDataType) == expected
 
 
 @pytest.mark.parametrize("data, params, expected, is_error", [
@@ -1800,7 +1797,7 @@ def test_spurs(
             relative_power_db = relative_power_db
         )
 
-        assert data.dtype == torchsig_complex_data_type
+        assert data.dtype == TorchSigComplexDataType
 
 
 @pytest.mark.parametrize("data, expected, is_error", [
@@ -1833,7 +1830,7 @@ def test_time_reversal(
 
         assert np.allclose(data, np.flip(data_test, axis=0), RTOL) == expected
         assert (type(data) == type(data_test)) == expected
-        assert (data.dtype == torchsig_complex_data_type) == expected
+        assert (data.dtype == TorchSigComplexDataType) == expected
 
 
 @pytest.mark.parametrize("data, params, expected, is_error", [
@@ -1849,7 +1846,7 @@ def test_time_reversal(
         True
     ),
     (
-        np.zeros(1024, dtype=torchsig_complex_data_type),
+        np.zeros(1024, dtype=TorchSigComplexDataType),
         {
             'noise_power_low' : 3.0, 
             'noise_power_high': 3.0,
@@ -1910,6 +1907,6 @@ def test_time_varying_noise(
         power_est = np.mean(np.abs(data)**2)
         assert (abs(power_est - noise_power_high_linear) < 1E-1) == expected
         assert (type(data) == type(data_test)) == expected
-        assert (data.dtype == torchsig_complex_data_type) == expected
+        assert (data.dtype == TorchSigComplexDataType) == expected
 
 
diff --git a/tests/transforms/test_impairments.py b/tests/transforms/test_impairments.py
index d109ca82a..625d465cd 100644
--- a/tests/transforms/test_impairments.py
+++ b/tests/transforms/test_impairments.py
@@ -1,4 +1,4 @@
-"""Unit Tests for transforms/impairments_narrowband and impairments_wideband.py
+"""Unit Tests for transforms impairments
 """
 from torchsig.transforms.impairments import Impairments
 from torchsig.transforms.base_transforms import Transform
diff --git a/tests/transforms/test_target_transforms.py b/tests/transforms/test_target_transforms.py
deleted file mode 100644
index 1e493ad95..000000000
--- a/tests/transforms/test_target_transforms.py
+++ /dev/null
@@ -1,382 +0,0 @@
-"""Unit Tests: transforms/taregt_transforms.py
-"""
-
-from torchsig.transforms.target_transforms import (
-    TargetTransform,
-    CustomLabel,
-    PassThrough,
-    CenterFreq,
-    Bandwidth,
-    StartInSamples,
-    DurationInSamples,
-    SNR,
-    ClassName,
-    SampleRate,
-    NumSamples,
-    Start,
-    Stop,
-    Duration,
-    StopInSamples,
-    UpperFreq,
-    LowerFreq,
-    OversamplingRate,
-    FamilyName,
-    FamilyIndex,
-    YOLOLabel
-)
-from test_transforms_utils import (
-    generate_test_dataset_dict
-)
-from torchsig.signals.signal_types import DatasetDict
-from torchsig.signals.signal_lists import TorchSigSignalLists
-
-import pytest
-from copy import deepcopy
-from typing import Any
-
-
-TEST_SIGNAL = generate_test_dataset_dict(num_iq_samples = 64, scale = 1.0)
-
-
-def is_valid(target_transform: TargetTransform, call_output: Any = None) -> bool:
-    if not isinstance(target_transform, TargetTransform):
-        return False
-    if not isinstance(target_transform.required_metadata, list):
-        return False
-    if not isinstance(target_transform.targets_metadata, list):
-        return False
-    if not call_output is None:
-        if not isinstance(call_output, list):
-            return False
-        for new_field in target_transform.targets_metadata:
-            for m in call_output:
-                if new_field not in m.keys():
-                    return False
-
-    return True
-
-
-@pytest.mark.parametrize("is_error", [False])
-def test_TargetTransform(is_error: bool) -> None:
-
-    TT = TargetTransform()
-
-    assert is_valid(TT)
-    assert len(TT.required_metadata) == 0
-    assert len(TT.targets_metadata) == 0
-
-    with pytest.raises(ValueError, match=r".*"):
-        signal = TT("error")
-
-    with pytest.raises(NotImplementedError):
-        signal = generate_test_dataset_dict(
-            num_iq_samples = 64,
-            scale = 1.0
-        )
-        signal.metadata = TT(signal.metadata)
-
-
-@pytest.mark.parametrize("signal, params, is_error", [
-    (
-        deepcopy(TEST_SIGNAL), 
-        {
-            'label_fields': "error",
-            'label_name': "error"
-        },
-        True
-    ),
-    (
-        deepcopy(TEST_SIGNAL), 
-        {
-            'label_fields': ["class_index"],
-            'label_name': "label"
-        },
-        False
-    ),
-    (
-        deepcopy(TEST_SIGNAL), 
-        {
-            'label_fields': ["class_index", "snr_db"],
-            'label_name': "label"
-        },
-        False
-    ),
-])
-def test_CustomLabel(
-    signal: DatasetDict,
-    params: dict,
-    is_error: bool
-):
-
-    label_fields = params['label_fields']
-    label_name = params['label_name']
-    if is_error:
-        with pytest.raises(Exception, match=r".*"):
-            TT = CustomLabel(label_fields=label_fields, label_name=label_name)
-            signal.metadata = TT(signal.metadata)
-
-            assert is_valid(TT, signal.metadata)
-    else:
-        TT = CustomLabel(label_fields=label_fields, label_name=label_name)
-        signal.metadata = TT(signal.metadata)
-
-        assert isinstance(TT, CustomLabel)
-        assert TT.required_metadata == label_fields
-        assert TT.targets_metadata == [label_name]
-        assert is_valid(TT, signal.metadata)
-
-@pytest.mark.parametrize("signal, params, is_error", [
-    (
-        deepcopy(TEST_SIGNAL), 
-        {
-            'field': "error"
-        },
-        True
-    ),
-    (
-        deepcopy(TEST_SIGNAL), 
-        {
-            'field': "class_index"
-        },
-        True
-    ),
-    (
-        deepcopy(TEST_SIGNAL), 
-        {
-            'field': ["class_index"]
-        },
-        False
-    )
-])
-def test_PassThrough(
-    signal: DatasetDict,
-    params: dict,
-    is_error: bool
-):
-    field = params['field']
-
-    if is_error:
-        with pytest.raises(Exception, match=r".*"):
-            TT = PassThrough(field = field)
-            signal.metadata = TT(signal.metadata)
-
-            assert is_valid(TT, signal.metadata)
-    else:
-        TT = PassThrough(field = field)
-        signal.metadata = TT(signal.metadata)
-
-        assert isinstance(TT, PassThrough)
-        assert TT.required_metadata == field
-        assert TT.targets_metadata == field
-        assert is_valid(TT, signal.metadata)
-
-@pytest.mark.parametrize("signal, target_transform, is_error", [
-    (
-        deepcopy(TEST_SIGNAL), 
-        CenterFreq,
-        False
-    ),
-    (
-        deepcopy(TEST_SIGNAL), 
-        Bandwidth,
-        False
-    ),
-    (
-        deepcopy(TEST_SIGNAL), 
-        StartInSamples,
-        False
-    ),
-    (
-        deepcopy(TEST_SIGNAL), 
-        DurationInSamples,
-        False
-    ),
-    (
-        deepcopy(TEST_SIGNAL), 
-        SNR,
-        False
-    ),
-    (
-        deepcopy(TEST_SIGNAL), 
-        ClassName,
-        False
-    ),
-    (
-        deepcopy(TEST_SIGNAL), 
-        SampleRate,
-        False
-    ),
-    (
-        deepcopy(TEST_SIGNAL), 
-        NumSamples,
-        False
-    ),
-    (
-        deepcopy(TEST_SIGNAL), 
-        Start,
-        False
-    ),
-    (
-        deepcopy(TEST_SIGNAL), 
-        Stop,
-        False
-    ),
-    (
-        deepcopy(TEST_SIGNAL), 
-        Duration,
-        False
-    ),
-    (
-        deepcopy(TEST_SIGNAL), 
-        StopInSamples,
-        False
-    ),
-    (
-        deepcopy(TEST_SIGNAL), 
-        UpperFreq,
-        False
-    ),
-    (
-        deepcopy(TEST_SIGNAL), 
-        LowerFreq,
-        False
-    ),
-    (
-        deepcopy(TEST_SIGNAL), 
-        OversamplingRate,
-        False
-    ),
-])
-def test_BuiltInTargetTransforms(
-    signal: DatasetDict,
-    target_transform: PassThrough,
-    is_error: bool
-):
-    if is_error:
-        with pytest.raises(Exception, match=r".*"):
-            TT = target_transform()
-            signal.metadata = TT(signal.metadata)
-
-            assert is_valid(TT, signal.metadata)
-    else:
-        TT = target_transform()
-        signal.metadata = TT(signal.metadata)
-
-        assert isinstance(TT, target_transform)
-        assert is_valid(TT, signal.metadata)
-
-@pytest.mark.parametrize("signal, params, is_error", [
-    (
-        deepcopy(TEST_SIGNAL), 
-        {
-            'class_family_dict': TorchSigSignalLists.family_dict
-        },
-        False
-    ),
-    (
-        deepcopy(TEST_SIGNAL), 
-        {
-            'class_family_dict': "error"
-        },
-        True
-    ),
-])
-def test_FamilyName(
-    signal: DatasetDict,
-    params: dict,
-    is_error: bool
-):
-    class_family_dict = params['class_family_dict']
-
-    if is_error:
-        with pytest.raises(Exception, match=r".*"):
-            TT = FamilyName(class_family_dict=class_family_dict)
-            signal.metadata = TT(signal.metadata)
-
-            assert is_valid(TT, signal.metadata)
-    else:
-        TT = FamilyName(class_family_dict=class_family_dict)
-        signal.metadata = TT(signal.metadata)
-
-        assert isinstance(TT, FamilyName)
-        assert TT.class_family_dict == class_family_dict
-        assert is_valid(TT, signal.metadata)
-
-@pytest.mark.parametrize("signal, params, is_error", [
-    (
-        deepcopy(TEST_SIGNAL), 
-        {
-            'class_family_dict': TorchSigSignalLists.family_dict,
-            'family_list': TorchSigSignalLists.family_list
-        },
-        False
-    ),
-    (
-        deepcopy(TEST_SIGNAL), 
-        {
-            'class_family_dict': "error",
-            'family_list': "error"
-        },
-        True
-    ),
-])
-def test_FamilyIndex(
-    signal: DatasetDict,
-    params: dict,
-    is_error: bool
-):
-    class_family_dict = params['class_family_dict']
-    family_list = params['family_list']
-
-    if is_error:
-        with pytest.raises(Exception, match=r".*"):
-            TT = FamilyIndex(
-                class_family_dict=class_family_dict,
-                family_list=family_list
-            )
-            signal.metadata = TT(signal.metadata)
-
-            assert is_valid(TT, signal.metadata)
-    else:
-        TT = FamilyIndex(
-            class_family_dict=class_family_dict,
-            family_list=family_list
-        )        
-        signal.metadata = TT(signal.metadata)
-
-        assert isinstance(TT, FamilyIndex)
-        assert TT.class_family_dict == class_family_dict
-        assert TT.family_list == family_list
-        assert is_valid(TT, signal.metadata)
-
-
-@pytest.mark.parametrize("signal, params, is_error", [
-    (
-        deepcopy(TEST_SIGNAL), 
-        {
-        },
-        False
-    ),
-])
-def test_YOLOLabel(
-    signal: DatasetDict,
-    params: dict,
-    is_error: bool
-):
-
-    if is_error:
-        with pytest.raises(Exception, match=r".*"):
-            TT = YOLOLabel()
-            signal.metadata = TT(signal.metadata)
-
-            assert is_valid(TT, signal.metadata)
-    else:
-        TT = YOLOLabel()       
-        signal.metadata = TT(signal.metadata)
-
-        assert isinstance(TT, YOLOLabel)
-        assert is_valid(TT, signal.metadata)
-        for m in signal.metadata:
-            label = m['yolo_label']
-            assert isinstance(label, tuple)
-            assert len(label) == 5
diff --git a/tests/transforms/test_transforms.py b/tests/transforms/test_transforms.py
index c2165095f..0eb5cc308 100644
--- a/tests/transforms/test_transforms.py
+++ b/tests/transforms/test_transforms.py
@@ -10,6 +10,8 @@ from torchsig.transforms.transforms import (
     CarrierPhaseNoise,
     CarrierPhaseOffset,
     ChannelSwap,
+    ClockDrift,
+    ClockJitter,
     CoarseGainChange,
     CochannelInterference,
     ComplexTo2D,
@@ -33,16 +35,15 @@ from torchsig.transforms.transforms import (
     TimeReversal,
     TimeVaryingNoise,
 )
-from torchsig.signals.signal_types import Signal, DatasetSignal
+from torchsig.signals.signal_types import Signal
 from torchsig.utils.dsp import (
     compute_spectrogram,
     low_pass,
-    torchsig_complex_data_type,
-    torchsig_real_data_type
+    TorchSigComplexDataType,
+    TorchSigRealDataType
 )
 from test_transforms_utils import (
-    generate_test_signal,
-    generate_test_dataset_signal
+    generate_test_signal
 )
 
 # Third Party
@@ -57,16 +58,12 @@ from copy import deepcopy
 
 RTOL = 1E-6
 TEST_SIGNAL = generate_test_signal(num_iq_samples = 64, scale = 1.0)
-TEST_DS_SIGNAL = generate_test_dataset_signal(num_iq_samples = 64, scale = 1.0)
 
 
 # test fixtures
 def new_test_signal() -> Signal:
     return deepcopy(TEST_SIGNAL)
 
-def new_test_ds_signal() -> DatasetSignal:
-    return deepcopy(TEST_DS_SIGNAL)
-
 
 # pytests
 @pytest.mark.parametrize("is_error", [False])
@@ -91,22 +88,19 @@ def test_SignalTransform(is_error: bool) -> None:
 
 
 @pytest.mark.parametrize("signal, params, is_error", [
-    (generate_test_signal(num_iq_samples = 1024, scale = 1.0), {'noise_power_db': 3.0, 'measure': False}, False),
-    (generate_test_signal(num_iq_samples = 1024, scale = 1.0), {'noise_power_db': 0.1, 'measure': False}, False),
-    (generate_test_signal(num_iq_samples = 1024, scale = 1.0), {'noise_power_db': 0.5, 'measure': True}, False),
-    (generate_test_dataset_signal(num_iq_samples = 1024, scale = 1.0), {'noise_power_db': 3.0, 'measure': False}, False),
-    (generate_test_dataset_signal(num_iq_samples = 1024, scale = 1.0), {'noise_power_db': 0.1, 'measure': False}, False),
-    (generate_test_dataset_signal(num_iq_samples = 1024, scale = 1.0), {'noise_power_db': 0.5, 'measure': True}, False)
+    (generate_test_signal(num_iq_samples = 1024, scale = 1.0), {'noise_power_db': 3.0, 'precise': False}, False),
+    (generate_test_signal(num_iq_samples = 1024, scale = 1.0), {'noise_power_db': 0.1, 'precise': False}, False),
+    (generate_test_signal(num_iq_samples = 1024, scale = 1.0), {'noise_power_db': 0.5, 'precise': True}, False),
 ])
 def test_AWGN(
-    signal: Union[Signal, DatasetSignal], 
+    signal: Signal, 
     params: dict, 
     is_error: bool
 ) -> None:
     """Test the AWGN transform with pytest.
 
     Args:
-        signal (Union[Signal, DatasetSignal]): input signal.
+        signal: input signal.
         params (dict): AWGN parameters (see functional AWGN description).
         is_error (bool): Is a test error expected. 
 
@@ -116,13 +110,13 @@ def test_AWGN(
     """
     noise_power_db = params['noise_power_db']
     add_noise_power_linear = 10**(noise_power_db / 10)
-    measure = params['measure']
+    precise = params['precise']
     
     if is_error:
         with pytest.raises(Exception, match=r".*"):
             T = AWGN(
                 noise_power_db = noise_power_db,
-                measure = measure,
+                precise = precise,
                 seed = 42
             )
             signal = T(signal)
@@ -130,14 +124,14 @@ def test_AWGN(
         signal_test = deepcopy(signal)
         T = AWGN(
             noise_power_db = noise_power_db,
-            measure = measure,
+            precise = precise,
             seed = 42
         )
         signal = T(signal)
 
-        if isinstance(signal, DatasetSignal):
+        if False:
             for i, m in enumerate(signal.metadata):
-                if measure:
+                if precise:
                     start = m.start_in_samples
                     duration = m.duration_in_samples
                     stop = start + duration
@@ -151,15 +145,14 @@ def test_AWGN(
                 else:
                     assert signal.metadata[i].snr_db == signal_test.metadata[i].snr_db
         else: #Signal
-            if measure:
+            if precise:
                 orig_power = np.sum(np.abs(signal_test.data)**2)/len(signal_test.data)
-                orig_snr_linear = 10 ** (signal_test.metadata.snr_db / 10)
-                out_power = np.sum(np.abs(signal.data)**2)/len(signal.data)
+                orig_snr_linear = 10 ** (signal_test.metadata.snr_db / 10)                 
+                out_power = np.sum(np.abs(signal.data)**2)/len(signal.data)                
                 add_noise_power = out_power - orig_power
                 sig_power = orig_power / (1 + 1/orig_snr_linear)
                 noise_power = sig_power / orig_snr_linear
                 new_snr_db = 10*np.log10(sig_power / (noise_power + add_noise_power))
-
                 assert np.abs(signal.metadata.snr_db - new_snr_db) < 10**(1.0/10)
             else:
                 assert signal.metadata.snr_db == signal_test.metadata.snr_db
@@ -167,7 +160,7 @@ def test_AWGN(
         assert isinstance(T, AWGN)
         assert isinstance(T.random_generator, np.random.Generator)   
         assert isinstance(T.noise_power_db, float) 
-        assert isinstance(signal, (Signal, DatasetSignal))
+        
         assert type(signal.data) == type(signal_test.data)
         assert signal.data.dtype == signal_test.data.dtype
         assert np.not_equal(signal.data, signal_test.data).any()
@@ -176,17 +169,15 @@ def test_AWGN(
 @pytest.mark.parametrize("signal, is_error", [
     (generate_test_signal(num_iq_samples=64, scale=1.0), False),
     (generate_test_signal(num_iq_samples=256, scale=1.0), False),
-    (generate_test_dataset_signal(num_iq_samples=64, scale=1.0), False),
-    (generate_test_dataset_signal(num_iq_samples=256, scale=1.0), False)
 ])
 def test_AddSlope(
-    signal: Union[Signal, DatasetSignal], 
+    signal: Signal, 
     is_error: bool
 ) -> None:
     """Test AddSlope transform with pytest.
 
     Args:
-        signal (Union[Signal, DatasetSignal]): Input signal to transform.
+        signal (Signal): Input signal to transform.
         is_error (bool): Is a test error expected.
 
     Raises:
@@ -203,28 +194,25 @@ def test_AddSlope(
         
         assert isinstance(T, AddSlope)
         assert isinstance(T.random_generator, np.random.Generator)
-        assert isinstance(signal, (Signal, DatasetSignal))
+        
         assert len(signal.data) == len(signal_test.data)
-        assert (signal.data.dtype == torchsig_complex_data_type) 
+        assert (signal.data.dtype == TorchSigComplexDataType) 
 
 
 @pytest.mark.parametrize("signal, params, is_error", [
-    (generate_test_signal(num_iq_samples = 1024, scale = 1.0),{'power_range': (0.01, 10.0),'color': 'white','continuous': True, 'measure': False}, False),
-    (generate_test_signal(num_iq_samples = 1024, scale = 1.0),{'power_range': (0.5, 2.0),'color': 'pink','continuous': False, 'measure': False}, False),
-    (generate_test_signal(num_iq_samples = 1024, scale = 1.0),{'power_range': (2.0, 2.0),'color': 'white','continuous': True, 'measure': True}, False),
-    (generate_test_dataset_signal(num_iq_samples = 1024, scale = 1.0), {'power_range': (0.01, 10.0), 'color': 'white', 'continuous': True, 'measure': False}, False),
-    (generate_test_dataset_signal(num_iq_samples = 1024, scale = 1.0), {'power_range': (0.5, 2.0), 'color': 'pink', 'continuous': False, 'measure': False}, False),
-    (generate_test_dataset_signal(num_iq_samples = 1024, scale = 1.0), {'power_range': (2.0, 2.0), 'color': 'white', 'continuous': True, 'measure': True}, False)
+    (generate_test_signal(num_iq_samples = 1024, scale = 1.0),{'power_range': (0.01, 10.0),'color': 'white','continuous': True, 'precise': False}, False),
+    (generate_test_signal(num_iq_samples = 1024, scale = 1.0),{'power_range': (0.5, 2.0),'color': 'pink','continuous': False, 'precise': False}, False),
+    (generate_test_signal(num_iq_samples = 1024, scale = 1.0),{'power_range': (2.0, 2.0),'color': 'white','continuous': True, 'precise': True}, False),
 ])
 def test_AdditiveNoise(
-    signal: Union[Signal, DatasetSignal], 
+    signal: Signal, 
     params: dict, 
     is_error: bool
 ) -> None:
     """Test AdditiveNoise transform with pytest.
 
     Args:
-        signal (Union[Signal, DatasetSignal]): Input signal to transform.
+        signal (Signal): Input signal to transform.
         params (dict): Transform call parameters (see description).
         is_error (bool): Is a test error expected.
 
@@ -235,7 +223,7 @@ def test_AdditiveNoise(
     power_range = params['power_range']
     color = params['color']
     continuous = params['continuous']
-    measure = params['measure']
+    precise = params['precise']
     
     if is_error:
         with pytest.raises(Exception, match=r".*"):
@@ -243,7 +231,7 @@ def test_AdditiveNoise(
                     power_range = power_range,
                     color = color,
                     continuous = continuous,
-                    measure = measure,
+                    precise = precise,
                     seed = 42
                 )
                 signal = T(signal)
@@ -254,14 +242,14 @@ def test_AdditiveNoise(
             power_range = power_range,
             color = color,
             continuous = continuous,
-            measure = measure,
+            precise = precise,
             seed = 42
         )
         signal = T(signal)
         
-        if isinstance(signal, DatasetSignal):
+        if False:
             for i, m in enumerate(signal.metadata):
-                if measure:
+                if precise:
                     start = m.start_in_samples
                     duration = m.duration_in_samples
                     stop = start + duration
@@ -277,7 +265,7 @@ def test_AdditiveNoise(
                 else:
                     assert signal.metadata[i].snr_db == signal_test.metadata[i].snr_db
         else: #Signal
-            if measure:
+            if precise:
                 orig_power = np.sum(np.abs(signal_test.data)**2)/len(signal_test.data)
                 orig_snr_linear = 10 ** (signal_test.metadata.snr_db / 10)
                 out_power = np.sum(np.abs(signal.data)**2)/len(signal.data)
@@ -294,10 +282,10 @@ def test_AdditiveNoise(
         assert isinstance(T.power_distribution(), float)
         assert isinstance(T.color, str)
         assert isinstance(T.continuous, bool)
-        assert isinstance(T.measure, bool)
-        assert isinstance(signal, (Signal, DatasetSignal))
+        assert isinstance(T.precise, bool)
+        
         assert len(signal.data) == len(signal_test.data)
-        assert (signal.data.dtype == torchsig_complex_data_type)
+        assert (signal.data.dtype == TorchSigComplexDataType)
     
 
 @pytest.mark.parametrize("signal, params, expected, is_error", [
@@ -329,7 +317,7 @@ def test_AdditiveNoise(
     ),
 ])
 def test_AdjacentChannelInterference(
-    signal: Union[Signal, DatasetSignal],
+    signal: Signal,
     params: dict, 
     expected: Union[bool, ValueError], 
     is_error: bool
@@ -337,7 +325,7 @@ def test_AdjacentChannelInterference(
     """Test AdjacentChannelInterference transform with pytest.
 
     Args:
-        signal (Union[Signal, DatasetSignal]): Input signal to transform.
+        signal (Signal): Input signal to transform.
         params (dict): Transform call parameters (see description).
         expected (bool | ValueError): Expected test result.
         is_error (bool): Is a test error expected.
@@ -384,8 +372,8 @@ def test_AdjacentChannelInterference(
         assert isinstance(T.phase_sigma_distribution(), float) == expected
         assert isinstance(T.time_sigma_distribution(), float) == expected
         assert isinstance(T.filter_weights, np.ndarray) == expected
-        assert isinstance(signal, (Signal, DatasetSignal)) == expected
-        assert (signal.data.dtype == torchsig_complex_data_type) == expected
+
+        assert (signal.data.dtype == TorchSigComplexDataType) == expected
 
 
 @pytest.mark.parametrize("signal, params, is_error", [
@@ -403,30 +391,16 @@ def test_AdjacentChannelInterference(
         },
         False
     ),
-    (
-        new_test_ds_signal(), 
-        {
-            'drift_ppm': (0.1, 1)
-        },
-        False
-    ),
-    (
-        new_test_ds_signal(), 
-        {
-            'drift_ppm': (0.1, 1)
-        },
-        False
-    )
 ])
 def test_CarrierFrequencyDrift(
-    signal: Union[Signal, DatasetSignal],
+    signal: Signal,
     params: dict, 
     is_error: bool
 ) -> None:
     """Test CarrierFrequencyDrift transform with pytest.
 
     Args:
-        signal (Union[Signal, DatasetSignal]): Input signal to transform.
+        signal (Signal): Input signal to transform.
         params (dict): Transform call parameters (see description).
         is_error (bool): Is a test error expected.
 
@@ -453,10 +427,10 @@ def test_CarrierFrequencyDrift(
 
         assert isinstance(T, CarrierFrequencyDrift)
         assert isinstance(T.drift_ppm_distribution(), float)
-        assert isinstance(signal, (Signal, DatasetSignal))
+        
         assert len(signal.data) == len(signal_test.data)
         assert type(signal.data) == type(signal_test.data)
-        assert signal.data.dtype == torchsig_complex_data_type
+        assert signal.data.dtype == TorchSigComplexDataType
 
 
 @pytest.mark.parametrize("signal, params, is_error", [
@@ -466,24 +440,17 @@ def test_CarrierFrequencyDrift(
             'phase_noise_degrees': (0.25, 1), 
         },
         False
-    ),
-    (
-        new_test_ds_signal(), 
-        {
-            'phase_noise_degrees': (0.42, 1), 
-        },
-        False
-    ),    
+    ),  
 ])
 def test_CarrierPhaseNoise(
-    signal: Union[Signal, DatasetSignal],
+    signal: Signal,
     params: dict, 
     is_error: bool
 ) -> None:
     """Test CarrierPhaseNoise transform with pytest.
 
     Args:
-        signal (Union[Signal, DatasetSignal]): Input signal to transform.
+        signal (Signal): Input signal to transform.
         params (dict): Transform call parameters (see description).
         is_error (bool): Is a test error expected.
 
@@ -511,10 +478,10 @@ def test_CarrierPhaseNoise(
         assert isinstance(T, CarrierPhaseNoise)
         assert isinstance(T.phase_noise_degrees, tuple)
         assert isinstance(T.phase_noise_degrees_distribution(), float)
-        assert isinstance(signal, (Signal, DatasetSignal))
+        
         assert len(signal.data) == len(signal_test.data)
         assert type(signal.data) == type(signal_test.data)
-        assert signal.data.dtype == torchsig_complex_data_type
+        assert signal.data.dtype == TorchSigComplexDataType
 
 
 @pytest.mark.parametrize("signal, is_error", [
@@ -522,13 +489,13 @@ def test_CarrierPhaseNoise(
     (generate_test_signal(num_iq_samples = 256, scale = 1.0), False)
 ])
 def test_CarrierPhaseOffset(
-    signal: Union[Signal, DatasetSignal], 
+    signal: Signal, 
     is_error: bool
 ) -> None:
     """Test CarrierPhaseOffset transform with pytest.
 
     Args:
-        signal (Union[Signal, DatasetSignal]): Input signal to transform.
+        signal (Signal): Input signal to transform.
         is_error (bool): Is a test error expected.
 
     Raises:
@@ -551,25 +518,23 @@ def test_CarrierPhaseOffset(
 
         assert isinstance(T, CarrierPhaseOffset)
         assert isinstance(T.phase_offset_distribution(), float)
-        assert isinstance(signal, (Signal, DatasetSignal))
+        
         assert type(signal.data) == type(signal_test.data)
-        assert signal.data.dtype == torchsig_complex_data_type
+        assert signal.data.dtype == TorchSigComplexDataType
 
 
 @pytest.mark.parametrize("signal, is_error", [
     (generate_test_signal(num_iq_samples=64, scale=1.0), False),
     (generate_test_signal(num_iq_samples=256, scale=1.0), False),
-    (generate_test_dataset_signal(num_iq_samples=64, scale=1.0), False),
-    (generate_test_dataset_signal(num_iq_samples=256, scale=1.0), False)
 ])
 def test_ChannelSwap(
-    signal: Union[Signal, DatasetSignal],
+    signal: Signal,
     is_error: bool
 ) -> None:
     """Test ChannelSwap transform with pytest.
 
     Args:
-        signal (Union[Signal, DatasetSignal]): Input signal to transform.
+        signal (Signal): Input signal to transform.
         is_error (bool): Is a test error expected.
 
     Raises:
@@ -585,27 +550,117 @@ def test_ChannelSwap(
         signal = T(signal)
         
         assert isinstance(T, ChannelSwap)
-        assert isinstance(signal, (Signal, DatasetSignal))
+        
         assert len(signal.data) == len(signal_test.data)
         assert np.not_equal(signal.data, signal_test.data).any()
-        assert (signal.data.dtype == torchsig_complex_data_type)
+        assert (signal.data.dtype == TorchSigComplexDataType)
+
+
+@pytest.mark.parametrize("signal, params, is_error", [
+    (new_test_signal(), {'drift_ppm': (0.1, 1.0)}, False),
+    (new_test_signal(), {'drift_ppm': (1.0, 10.0)}, False),
+])
+def test_ClockDrift(
+    signal: Signal,
+    params: dict, 
+    is_error: bool
+) -> None:
+    """Test ClockDrift transform with pytest.
+
+    Args:
+        signal (Signal): Input signal to transform.
+        params (dict): Transform call parameters.
+        is_error (bool): Is a test error expected.
+
+    Raises:
+        AssertionError: If unexpected test outcome.
+    """
+    drift_ppm = params['drift_ppm']
+    
+    if is_error:
+        with pytest.raises(Exception, match=r".*"):
+            T = ClockDrift(
+                drift_ppm = drift_ppm,
+                seed = 42
+            )
+            signal = T(signal)
+    else:
+        signal_test = deepcopy(signal)
+
+        T = ClockDrift(
+            drift_ppm = drift_ppm,
+            seed = 42
+        )
+        signal = T(signal)
+        
+        assert isinstance(T, ClockDrift)
+        assert isinstance(T.random_generator, np.random.Generator)
+        assert isinstance(T.drift_ppm_distribution(), float)
+        
+        assert len(signal.data) == len(signal_test.data)
+        assert (signal.data.dtype == TorchSigComplexDataType)
+
+
+
+@pytest.mark.parametrize("signal, params, is_error", [
+    (new_test_signal(), {'jitter_ppm': (0.1, 1.0)}, False),
+    (new_test_signal(), {'jitter_ppm': (1.0, 10.0)}, False),
+])
+def test_ClockJitter(
+    signal: Signal,
+    params: dict, 
+    is_error: bool
+) -> None:
+    """Test ClockJitter transform with pytest.
+
+    Args:
+        signal (Signal): Input signal to transform.
+        params (dict): Transform call parameters.
+        is_error (bool): Is a test error expected.
+
+    Raises:
+        AssertionError: If unexpected test outcome.
+    """
+    jitter_ppm = params['jitter_ppm']
+    
+    if is_error:
+        with pytest.raises(Exception, match=r".*"):
+            T = ClockJitter(
+                jitter_ppm = jitter_ppm,
+                seed = 42
+            )
+            signal = T(signal)
+    else:
+        signal_test = deepcopy(signal)
+
+        T = ClockJitter(
+            jitter_ppm = jitter_ppm,
+            seed = 42
+        )
+        signal = T(signal)
+        
+        assert isinstance(T, ClockJitter)
+        assert isinstance(T.random_generator, np.random.Generator)
+        assert isinstance(T.jitter_ppm_distribution(), float)
+        
+        assert len(signal.data) == len(signal_test.data)
+        assert (signal.data.dtype == TorchSigComplexDataType)
+
 
 
 @pytest.mark.parametrize("signal, params, is_error", [
     (new_test_signal(), {'gain_change_db': (-3.0, 3.0)}, False),
     (new_test_signal(), {'gain_change_db': (-10.0, 10.0)}, False),
-    (new_test_ds_signal(), {'gain_change_db': (-3.0, 3.0)}, False),
-    (new_test_ds_signal(), {'gain_change_db': (-10.0, 10.0)}, False)
 ])
 def test_CoarseGainChange(
-    signal: Union[Signal, DatasetSignal],
+    signal: Signal,
     params: dict, 
     is_error: bool
 ) -> None:
     """Test CoarseGainChange transform with pytest.
 
     Args:
-        signal (Union[Signal, DatasetSignal]): Input signal to transform.
+        signal (Signal): Input signal to transform.
         params (dict): Transform call parameters.
         is_error (bool): Is a test error expected.
 
@@ -633,9 +688,9 @@ def test_CoarseGainChange(
         assert isinstance(T, CoarseGainChange)
         assert isinstance(T.random_generator, np.random.Generator)
         assert isinstance(T.gain_change_db_distribution(), float)
-        assert isinstance(signal, (Signal, DatasetSignal))
+        
         assert len(signal.data) == len(signal_test.data)
-        assert (signal.data.dtype == torchsig_complex_data_type)
+        assert (signal.data.dtype == TorchSigComplexDataType)
 
 
 @pytest.mark.parametrize("signal, params, expected, is_error", [
@@ -646,7 +701,7 @@ def test_CoarseGainChange(
             'filter_weights': low_pass(0.125, 0.125, 1.0),
             'color': 'white',
             'continuous': True,
-            'measure': False,
+            'precise': False,
         },
         True,
         False
@@ -658,26 +713,14 @@ def test_CoarseGainChange(
             'filter_weights': low_pass(0.04, 0.16, 2.4),
             'color': 'pink',
             'continuous': False,
-            'measure': False,
+            'precise': False,
         },
         True,
         False
-    ),
-    (
-        new_test_ds_signal(), 
-        {
-            'power_range': (0.1, 0.1),
-            'filter_weights': low_pass(0.125, 0.125, 1.0),
-            'color': 'white',
-            'continuous': True,
-            'measure': True,
-        },
-        True,
-        False
-    ),    
+    ), 
 ])
 def test_CochannelInterference(
-    signal: Union[Signal, DatasetSignal],
+    signal: Signal,
     params: dict, 
     expected: bool, 
     is_error: bool
@@ -685,7 +728,7 @@ def test_CochannelInterference(
     """Test CochannelInterference with pytest.
 
     Args:
-        signal (Union[Signal, DatasetSignal]): Input signal to transform.
+        signal (Signal): Input signal to transform.
         params (dict): Transform call parameters (see description).
         expected (bool): Expected test result.
         is_error (bool): Is a test error expected.
@@ -698,7 +741,7 @@ def test_CochannelInterference(
     filter_weights = params['filter_weights']
     color = params['color']
     continuous = params['continuous']
-    measure = params['measure']
+    precise = params['precise']
     
     if is_error:
         with pytest.raises(Exception, match=r".*"):
@@ -707,7 +750,7 @@ def test_CochannelInterference(
                 filter_weights = filter_weights,
                 color = color,
                 continuous = continuous,
-                measure = measure,
+                precise = precise,
                 seed = 42
             )
             signal = T(signal)
@@ -719,7 +762,7 @@ def test_CochannelInterference(
             filter_weights = filter_weights,
             color = color,
             continuous = continuous,
-            measure = measure,
+            precise = precise,
             seed = 42
         )
         signal = T(signal)
@@ -730,23 +773,22 @@ def test_CochannelInterference(
         assert isinstance(T.filter_weights, np.ndarray) == expected
         assert isinstance(T.color, str) == expected
         assert isinstance(T.continuous, bool) == expected
-        assert isinstance(T.measure, bool) == expected
-        assert isinstance(signal, (Signal, DatasetSignal)) == expected
-        assert (signal.data.dtype == torchsig_complex_data_type) == expected
+        assert isinstance(T.precise, bool) == expected
+
+        assert (signal.data.dtype == TorchSigComplexDataType) == expected
 
 
 @pytest.mark.parametrize("signal, is_error", [
     (new_test_signal(), False),
-    (new_test_ds_signal(), False)
 ])
 def test_ComplexTo2D(
-    signal: Union[Signal, DatasetSignal],
+    signal: Signal,
     is_error: bool
 ) -> None:
     """Test ComplexTo2D transform with pytest.
 
     Args:
-        signal (Union[Signal, DatasetSignal]): Input signal to transform.
+        signal (Signal): Input signal to transform.
         is_error (bool): Is a test error expected.
 
     Raises:
@@ -762,22 +804,21 @@ def test_ComplexTo2D(
         signal = T(signal)
         
         assert isinstance(T, ComplexTo2D)
-        assert isinstance(signal, (Signal, DatasetSignal))
-        assert (signal.data.dtype == torchsig_real_data_type) 
+        
+        assert (signal.data.dtype == TorchSigRealDataType) 
 
 
 @pytest.mark.parametrize("signal, is_error", [
     (new_test_signal(), False),
-    (new_test_ds_signal(), False)
 ])
 def test_CutOut(
-    signal: Union[Signal, DatasetSignal],
+    signal: Signal,
     is_error: bool
 ) -> None:
     """Test CutOut transform with pytest.
 
     Args:
-        signal (Union[Signal, DatasetSignal]): Input signal to transform.
+        signal (Signal): Input signal to transform.
         is_error (bool): Is a test error expected.
 
     Raises:
@@ -796,9 +837,9 @@ def test_CutOut(
         assert isinstance(T, CutOut)
         assert isinstance(T.duration_distribution(), float)
         assert isinstance(T.cut_type_distribution(), str)
-        assert isinstance(signal, (Signal, DatasetSignal))
+        
         assert len(signal.data) == len(signal_test.data)
-        assert (signal.data.dtype == torchsig_complex_data_type) 
+        assert (signal.data.dtype == TorchSigComplexDataType) 
 
 @pytest.mark.parametrize("signal, params, is_error", [
     (
@@ -813,28 +854,16 @@ def test_CutOut(
         },
         False
     ),
-    (
-        new_test_ds_signal(),
-        { 
-            'initial_gain_db' : (-3,3),
-            'alpha_smooth'    : (1e-5,1e-3),
-            'alpha_track'     : (1e-4,1e-2),
-            'alpha_overflow'  : (1e-1,3e-1),
-            'alpha_acquire'   : (1e-4,1e-3),
-            'track_range_db'  : (0.5,2),
-        },
-        False
-    )
 ])
 def test_DigitalAGC(
-    signal: Union[Signal, DatasetSignal], 
+    signal: Signal, 
     params: dict, 
     is_error: bool
 ) -> None:
     """Test the DigitalAGC transform with pytest.
 
     Args:
-        signal (Union[Signal, DatasetSignal]): input dataset.
+        signal (Signal): input dataset.
         params (dict): AGC parameters (see DigitalAGC description).
         is_error (bool): Is a test error expected. 
 
@@ -868,9 +897,9 @@ def test_DigitalAGC(
         signal = T(signal)
 
         assert isinstance(T, DigitalAGC)
-        assert isinstance(signal, (Signal, DatasetSignal))
+        
         assert type(signal.data) == type(signal_test.data)
-        assert signal.data.dtype == torchsig_complex_data_type
+        assert signal.data.dtype == TorchSigComplexDataType
         assert np.not_equal(signal.data, signal_test.data).any()
 
 
@@ -879,30 +908,20 @@ def test_DigitalAGC(
         new_test_signal(), 
         {
             'velocity_range': (0.0, 10.0), 
-            'propagation_speed': 2.9979e8,
-            'sampling_rate': 1.0
+            'propagation_speed': 2.9979e8
         },
         False
-    ),
-    (
-        new_test_ds_signal(), 
-        {
-            'velocity_range': (-12.0, 12.0), 
-            'propagation_speed': 343.0,
-            'sampling_rate': 10e3
-        },
-        False
-    ),    
+    ),  
 ])
 def test_Doppler(
-    signal: Union[Signal, DatasetSignal],
+    signal: Signal,
     params: dict, 
     is_error: bool
 ) -> None:
     """Test Doppler with pytest.
 
     Args:
-        signal (Union[Signal, DatasetSignal]): Input signal to transform.
+        signal (Signal): Input signal to transform.
         params (dict): Transform call parameters (see description).
         is_error (bool): Is a test error expected.
 
@@ -912,14 +931,12 @@ def test_Doppler(
     """      
     velocity_range = params['velocity_range']
     propagation_speed = params['propagation_speed']
-    sampling_rate = params['sampling_rate']
 
     if is_error:
         with pytest.raises(Exception, match=r".*"):   
             T = Doppler(
                 velocity_range = velocity_range,
                 propagation_speed = propagation_speed,
-                sampling_rate = sampling_rate,
                 seed = 42
             )
             signal = T(signal)
@@ -928,7 +945,6 @@ def test_Doppler(
         T = Doppler(
             velocity_range = velocity_range,
             propagation_speed = propagation_speed,
-            sampling_rate = sampling_rate,
             seed = 42
         )
         signal = T(signal)
@@ -936,10 +952,9 @@ def test_Doppler(
         assert isinstance(T, Doppler)
         assert isinstance(T.velocity_distribution(), float)
         assert isinstance(T.propagation_speed, float)
-        assert isinstance(T.sampling_rate, float)
-        assert isinstance(signal, (Signal, DatasetSignal))
+        
         assert type(signal.data) == type(signal_test.data)
-        assert signal.data.dtype == torchsig_complex_data_type
+        assert signal.data.dtype == TorchSigComplexDataType
 
 
 @pytest.mark.parametrize("signal, params, is_error", [
@@ -951,24 +966,16 @@ def test_Doppler(
         },
         False
     ),
-    (
-        new_test_ds_signal(), 
-        {
-            'coherence_bandwidth': (0.05, 0.2), 
-            'power_delay_profile': (0.1, 0.4)
-        },
-        False
-    )
 ])
 def test_Fading(
-    signal: Union[Signal, DatasetSignal],
+    signal: Signal,
     params: dict, 
     is_error: bool
 ) -> None:
     """Test Fading transform with pytest.
 
     Args:
-        signal (Union[Signal, DatasetSignal]): Input signal to transform.
+        signal (Signal): Input signal to transform.
         params (dict): Transform call parameters (see description).
         is_error (bool): Is a test error expected.
 
@@ -1000,9 +1007,9 @@ def test_Fading(
         assert isinstance(T, Fading)
         assert isinstance(T.coherence_bandwidth_distribution(), float)
         assert np.allclose(T.power_delay_profile, power_delay_profile)
-        assert isinstance(signal, (Signal, DatasetSignal))
+        
         assert type(signal.data) == type(signal_test.data)
-        assert signal.data.dtype == torchsig_complex_data_type
+        assert signal.data.dtype == TorchSigComplexDataType
 
 
 
@@ -1014,25 +1021,17 @@ def test_Fading(
             'coeffs_range': (1e-3, 1e-1),
         },
         False
-    ),
-    (
-        new_test_ds_signal(), 
-        {
-            'model_order': [2,10], 
-            'coeffs_range': (1e-6, 1e-3),
-        },
-        False
-    )     
+    ),   
 ])
 def test_IntermodulationProducts(
-    signal: Union[Signal, DatasetSignal],
+    signal: Signal,
     params: dict, 
     is_error: bool
 ) -> None:
     """Test IntermodulationProducts transform with pytest.
 
     Args:
-        signal (Union[Signal, DatasetSignal]): Input signal to transform.
+        signal (Signal): Input signal to transform.
         params (dict): Transform call parameters (see description).
         is_error (bool): Is a test error expected.
 
@@ -1064,9 +1063,9 @@ def test_IntermodulationProducts(
         assert isinstance(T, IntermodulationProducts)
         assert isinstance(T.model_order_distribution(), np.int64)
         assert isinstance(T.coeffs_distribution(), float)
-        assert isinstance(signal, (Signal, DatasetSignal))
+        
         assert type(signal.data) == type(signal_test.data)
-        assert signal.data.dtype == torchsig_complex_data_type
+        assert signal.data.dtype == TorchSigComplexDataType
 
 
 @pytest.mark.parametrize("signal, params, is_error", [
@@ -1075,29 +1074,27 @@ def test_IntermodulationProducts(
         {
             'amplitude_imbalance': (0.0, 6.0), 
             'phase_imbalance': (-np.pi, np.pi),
-            'dc_offset': ((-0.2, 0.2),(-0.2, 0.2))
+            'dc_offset': ((-0.2, 0.2))
         },
         False
-    ),
-    (
-        new_test_ds_signal(), 
-        {
-            'amplitude_imbalance': [0.2, 2.2], 
-            'phase_imbalance': [-np.pi/8, np.pi/8],
-            'dc_offset': ([-0.03, 0.03],[-0.03, 0.03])
-        },
-        False
-    )    
+        # new_test_signal(), 
+        # {
+        #     'amplitude_imbalance': (0.0, 6.0), 
+        #     'phase_imbalance': (-np.pi, np.pi),
+        #     'dc_offset': ((-0.2, 0.2),(-0.2, 0.2))
+        # },
+        # False
+    ),  
 ])
 def test_IQImbalance(
-    signal: Union[Signal, DatasetSignal],
+    signal: Signal,
     params: dict, 
     is_error: bool
 ) -> None:
     """Test IQImbalance with pytest.
 
     Args:
-        signal (Union[Signal, DatasetSignal]): Input signal to transform.
+        signal (Signal): Input signal to transform.
         params (dict): Transform call parameters (see description).
         is_error (bool): Is a test error expected.
 
@@ -1114,7 +1111,7 @@ def test_IQImbalance(
                 T = IQImbalance(
                     amplitude_imbalance = amplitude_imbalance,
                     phase_imbalance = phase_imbalance,
-                    dc_offset = dc_offset,
+                    dc_offset_db = dc_offset,
                     seed = 42
                 )
                 signal = T(signal)
@@ -1124,7 +1121,7 @@ def test_IQImbalance(
         T = IQImbalance(
             amplitude_imbalance = amplitude_imbalance,
             phase_imbalance = phase_imbalance,
-            dc_offset = dc_offset,
+            dc_offset_db = dc_offset,
             seed = 42
         )
         signal = T(signal)
@@ -1134,9 +1131,9 @@ def test_IQImbalance(
         assert isinstance(T.phase_imbalance_distribution(), float)
         assert isinstance(T.dc_offset_db_distribution(), float)
         assert isinstance(T.dc_offset_phase_rads_distribution(), float)
-        assert isinstance(signal, (Signal, DatasetSignal))
+        
         assert type(signal.data) == type(signal_test.data)
-        assert signal.data.dtype == torchsig_complex_data_type
+        assert signal.data.dtype == TorchSigComplexDataType
 
 
 @pytest.mark.parametrize("signal, params, is_error", [
@@ -1151,27 +1148,16 @@ def test_IQImbalance(
         },
         False
     ),
-    (
-        new_test_ds_signal(), 
-        {
-            'gain_range': (0.5, 17.2),
-            'psat_backoff_range': (1.0, 7.0),
-            'phi_max_range': (-np.deg2rad(10.0), np.deg2rad(17.0)),
-            'phi_slope_range': (-0.1, 0.1),
-            'auto_scale': True
-        },
-        False
-    )  
 ])
 def test_NonlinearAmplifier(
-    signal: Union[Signal, DatasetSignal],
+    signal: Signal,
     params: dict, 
     is_error: bool
 ) -> None:
     """Test NonlinearAmplifier with pytest.
 
     Args:
-        signal (Union[Signal, DatasetSignal]): Input signal to transform.
+        signal (Signal): Input signal to transform.
         params (dict): Transform call parameters (see description).
         is_error (bool): Is a test error expected.
 
@@ -1212,8 +1198,8 @@ def test_NonlinearAmplifier(
         assert isinstance(T.psat_backoff_distribution(), float)
         assert isinstance(T.phi_max_distribution(), float)
         assert isinstance(T.phi_slope_distribution(), float)
-        assert isinstance(signal, (Signal, DatasetSignal))
-        assert (signal.data.dtype == torchsig_complex_data_type)
+        
+        assert (signal.data.dtype == TorchSigComplexDataType)
 
 
 @pytest.mark.parametrize("signal, params, is_error", [
@@ -1226,26 +1212,17 @@ def test_NonlinearAmplifier(
         },
         False
     ),
-    (
-        new_test_ds_signal(), 
-        {
-            'max_ripple_db': (1,2),
-            'num_taps': [2,3],
-            'coefficient_decay_rate': (1,5),
-        },
-        False
-    ),    
 ])
 
 def test_PassbandRipple(
-    signal: Union[Signal, DatasetSignal],
+    signal: Signal,
     params: dict, 
     is_error: bool
 ) -> None:
     """Test PassbandRipple transform with pytest.
 
     Args:
-        signal (Union[Signal, DatasetSignal]): Input signal to transform.
+        signal (Signal): Input signal to transform.
         is_error (bool): Is a test error expected.
 
     Raises:
@@ -1274,9 +1251,9 @@ def test_PassbandRipple(
         signal = T(signal)
 
         assert isinstance(T, PassbandRipple)
-        assert isinstance(signal, (Signal, DatasetSignal))
+        
         assert type(signal.data) == type(signal_test.data)
-        assert signal.data.dtype == torchsig_complex_data_type
+        assert signal.data.dtype == TorchSigComplexDataType
 
 
 @pytest.mark.parametrize("signal, params, is_error", [
@@ -1285,20 +1262,15 @@ def test_PassbandRipple(
         {'patch_size': [2, 2], 'shuffle_ratio': 0.5},
         False
     ),
-    (
-        new_test_ds_signal(), 
-        {'patch_size': [2, 2], 'shuffle_ratio': [0.5, 0.5]},
-        False
-    )
 ])
 def test_PatchShuffle(
-    signal: Union[Signal, DatasetSignal], 
+    signal: Signal, 
     params: dict, is_error: bool
     ) -> None:
     """Test the PatchShuffle transform with pytest.
 
     Args:
-        signal (Union[Signal, DatasetSignal]): input dataset.
+        signal (Signal): input dataset.
         params (dict): PatchShuffle parameters (see functional PatchShuffle description).
         is_error (bool): Is a test error expected. 
 
@@ -1330,7 +1302,7 @@ def test_PatchShuffle(
         assert isinstance(T.random_generator, np.random.Generator)
         assert isinstance(T.patch_size_distribution(), np.int_)
         assert isinstance(T.shuffle_ratio_distribution(), float)
-        assert isinstance(signal, (Signal, DatasetSignal))
+        
         assert type(signal) == type(signal_test)
         assert signal.data.dtype == signal_test.data.dtype
         assert np.not_equal(signal.data, signal_test.data).any()
@@ -1344,23 +1316,16 @@ def test_PatchShuffle(
         },
         False
     ),
-    (
-        new_test_ds_signal(), 
-        {
-            'num_bits': [16]
-        },
-        False
-    )
 ])
 def test_Quantize(
-    signal: Union[Signal, DatasetSignal], 
+    signal: Signal, 
     params: dict, 
     is_error: bool
     ) -> None:
     """Test the Quantize transform with pytest.
 
     Args:
-        signal (Union[Signal, DatasetSignal]): input dataset.
+        signal (Signal): input dataset.
         params (dict): Quantize parameters (see functional description).
         is_error (bool): Is a test error expected. 
 
@@ -1387,7 +1352,7 @@ def test_Quantize(
         assert isinstance(T, Quantize)
         assert isinstance(T.random_generator, np.random.Generator)
         assert isinstance(T.num_bits_distribution(), np.int_)
-        assert isinstance(signal, (Signal, DatasetSignal))
+        
         assert type(signal.data) == type(signal_test.data)
         assert signal.data.dtype == signal_test.data.dtype
         assert np.not_equal(signal.data, signal_test.data).any()
@@ -1399,21 +1364,16 @@ def test_Quantize(
         {'drop_rate': (0.01, 0.02), 'size': (5, 7), 'fill': ['zero']},
         False
     ),
-    (
-        new_test_ds_signal(), 
-        {'drop_rate': (0.01, 0.02), 'size': (5, 7), 'fill': ['mean', 'bfill', 'ffill']},
-        False
-    )
 ])
 def test_RandomDropSamples(
-    signal: Union[Signal, DatasetSignal], 
+    signal: Signal, 
     params: dict, 
     is_error: bool
     ) -> None:
     """Test the RandomDropSamples transform with pytest.
 
     Args:
-        signal (Union[Signal, DatasetSignal]): input dataset.
+        signal (Signal): input dataset.
         params (dict): RandomDropSamples parameters (see functional description).
         is_error (bool): Is a test error expected. 
 
@@ -1449,7 +1409,6 @@ def test_RandomDropSamples(
         assert isinstance(T.drop_rate_distribution(), float)
         assert isinstance(T.size_distribution(), float)
         assert isinstance(T.fill_distribution(), str)
-        assert isinstance(signal, (Signal,DatasetSignal))
         assert type(signal) == type(signal_test)
         assert signal.data.dtype == signal_test.data.dtype
         assert np.not_equal(signal.data, signal_test.data).any()
@@ -1465,17 +1424,16 @@ def test_RandomDropSamples(
 
 @pytest.mark.parametrize("signal, params, is_error", [
     (new_test_signal(), {'mean_db_range': (0.0, 4.0), 'sigma_db_range': (2.0, 6.0)},False),
-    (new_test_ds_signal(), {'mean_db_range': (0.0, 0.0), 'sigma_db_range': (3.0, 9.0)},False),    
 ])
 def test_Shadowing(
-    signal: Union[Signal, DatasetSignal],
+    signal: Signal,
     params: dict, 
     is_error: bool
 ) -> None:
     """Test Shadowing transform with pytest.
 
     Args:
-        signal (Union[Signal, DatasetSignal]): Input signal to transform.
+        signal (Signal): Input signal to transform.
         is_error (bool): Is a test error expected.
 
     Raises:
@@ -1504,9 +1462,9 @@ def test_Shadowing(
         assert isinstance(T, Shadowing)
         assert isinstance(T.mean_db_distribution(), float)
         assert isinstance(T.sigma_db_distribution(), float)
-        assert isinstance(signal, (Signal, DatasetSignal))
+        
         assert type(signal.data) == type(signal_test.data)
-        assert signal.data.dtype == torchsig_complex_data_type
+        assert signal.data.dtype == TorchSigComplexDataType
 
 
 @pytest.mark.parametrize("signal, is_error", [
@@ -1514,13 +1472,13 @@ def test_Shadowing(
     (generate_test_signal(num_iq_samples = 256, scale = 1.0), False)
 ])
 def test_SpectralInversion(
-    signal: Union[Signal, DatasetSignal],
+    signal: Signal,
     is_error: bool
 ) -> None:
     """Test SpectralInversion transform with pytest.
 
     Args:
-        signal (Union[Signal, DatasetSignal]): Input signal to transform.
+        signal (Signal): Input signal to transform.
         is_error (bool): Is a test error expected.
 
     Raises:
@@ -1538,16 +1496,16 @@ def test_SpectralInversion(
         signal = T(signal)
 
         # metadata
-        if isinstance(signal, DatasetSignal):
+        if False:
             for m in signal.metadata:
                 assert m.center_freq == -1 * m.center_freq
         else: #Signal
             assert signal.metadata.center_freq == -1 * signal_test.metadata.center_freq
 
         assert isinstance(T, SpectralInversion)
-        assert isinstance(signal, (Signal, DatasetSignal))
+        
         assert type(signal.data) == type(signal_test.data)
-        assert signal.data.dtype == torchsig_complex_data_type
+        assert signal.data.dtype == TorchSigComplexDataType
 
 
 @pytest.mark.parametrize("signal, params, is_error", [
@@ -1556,21 +1514,16 @@ def test_SpectralInversion(
         {'fft_size': 16, 'fft_stride': 4},
         False
     ),
-    (
-        new_test_ds_signal(), 
-        {'fft_size': 32, 'fft_stride': 8},
-        False
-    )    
 ])
 def test_Spectrogram(
-    signal: Union[Signal, DatasetSignal],
+    signal: Signal,
     params: dict, 
     is_error: bool
 ) -> None:
     """Test the Spectrogram transform with pytest.
 
     Args:
-        signal (Union[Signal, DatasetSignal]): input dataset.
+        signal (Signal): input dataset.
         params (dict): Spectrogram parameters (see functional description).
         is_error (bool): Is a test error expected. 
 
@@ -1597,7 +1550,7 @@ def test_Spectrogram(
     
         assert isinstance(T, Spectrogram)       
         assert isinstance(T.fft_size, int)
-        assert isinstance(signal, (Signal, DatasetSignal))
+        
 
         
 @pytest.mark.parametrize("signal, params, is_error", [
@@ -1606,21 +1559,16 @@ def test_Spectrogram(
         {'drop_rate': [0.1], 'size': [5], 'fill': ['zero']},
         False
     ),
-    (
-        new_test_ds_signal(), 
-        {'drop_rate': [0.11], 'size': [7, 7], 'fill': ['mean', 'bfill', 'ffill']},
-        False
-    )
 ])
 def test_SpectrogramDropSamples(
-    signal: Union[Signal, DatasetSignal], 
+    signal: Signal, 
     params: dict, 
     is_error: bool
 ) -> None:
     """Test the SpectrogramDropSamples transform with pytest.
 
     Args:
-        signal (Union[Signal, DatasetSignal]): input dataset.
+        signal (Signal): input dataset.
         params (dict): SpectrogramDropSamples parameters (see functional description).
         is_error (bool): Is a test error expected. 
 
@@ -1669,7 +1617,7 @@ def test_SpectrogramDropSamples(
         assert isinstance(T.drop_rate_distribution(), float)
         assert isinstance(T.size_distribution(), np.int_) 
         assert isinstance(T.fill_distribution(), str)
-        assert isinstance(signal, (Signal, DatasetSignal))
+        
         assert type(signal) == type(signal_test)
         assert signal.data.dtype == signal_test.data.dtype
         assert np.not_equal(signal.data, signal_test.data).any()
@@ -1685,17 +1633,16 @@ def test_SpectrogramDropSamples(
 
 @pytest.mark.parametrize("signal, params, is_error", [
     (new_test_signal(), {'fft_size': 16}, False),
-    (new_test_ds_signal(), {'fft_size': 8}, False)
 ])
 def test_SpectrogramImage(
-    signal: Union[Signal, DatasetSignal],
+    signal: Signal,
     params: dict,
     is_error: bool
 ) -> None:
     """Test SpectrogramImage transform with pytest.
 
     Args:
-        signal (Union[Signal, DatasetSignal]): Input signal to transform.
+        signal (Signal): Input signal to transform.
 
         is_error (bool): Is a test error expected.
 
@@ -1717,8 +1664,8 @@ def test_SpectrogramImage(
         signal = T(signal)
         
         assert isinstance(T, SpectrogramImage)
-        assert isinstance(signal, (Signal, DatasetSignal))
-        assert (signal.data.dtype == 'uint8') 
+        
+        # assert (signal.data.dtype == 'uint8') 
 
 @pytest.mark.parametrize("signal, params, is_error", [
     (
@@ -1729,24 +1676,16 @@ def test_SpectrogramImage(
         },
         False
     ),
-    (
-        new_test_ds_signal(), 
-        {
-            'num_spurs': [3,10],
-            'relative_power_db': [0,20]
-        },
-        False
-    )
 ])
 def test_Spurs(
-    signal: DatasetSignal, 
+    signal: Signal, 
     params: dict, 
     is_error: bool
     ) -> None:
     """Test the Spurs transform with pytest.
 
     Args:
-        signal (DatasetSignal): input dataset.
+        signal (Signal): input dataset.
         params (dict): Spurs parameters (see functional description).
         is_error (bool): Is a test error expected. 
 
@@ -1776,7 +1715,7 @@ def test_Spurs(
         assert isinstance(T, Spurs)
         assert isinstance(T.random_generator, np.random.Generator)
         assert isinstance(T.num_spurs_distribution(), np.int_)
-        assert isinstance(signal, (Signal, DatasetSignal))
+        
         assert type(signal.data) == type(signal_test.data)
         assert signal.data.dtype == signal_test.data.dtype
         assert np.not_equal(signal.data, signal_test.data).any()
@@ -1785,17 +1724,16 @@ def test_Spurs(
 
 @pytest.mark.parametrize("signal, params, is_error", [
     (new_test_signal(), {'allow_spectral_inversion': False}, False ),
-    (new_test_ds_signal(), {'allow_spectral_inversion': True}, False )
 ])
 def test_TimeReversal(
-    signal: Union[Signal, DatasetSignal], 
+    signal: Signal, 
     params: dict, 
     is_error: bool
 ) -> None:
     """Test the TimeReversal transform with pytest.
 
     Args:
-        signal (Union[Signal, DatasetSignal]): input dataset.
+        signal (Signal): input dataset.
         params (dict): TimeReversal parameters (see functional description).
         is_error (bool): Is a test error expected. 
 
@@ -1819,7 +1757,7 @@ def test_TimeReversal(
         signal = T(signal)
 
         assert isinstance(T, TimeReversal)
-        assert isinstance(signal, (Signal, DatasetSignal))
+        
         assert type(signal) == type(signal_test)
         assert signal.data.dtype == signal_test.data.dtype
         assert np.not_equal(signal.data, signal_test.data).any()
@@ -1835,27 +1773,17 @@ def test_TimeReversal(
             'random_regions' : False
         },
         False
-    ),
-    (
-        new_test_ds_signal(),
-        {
-            'noise_power_low' : (0.0, 0.0), 
-            'noise_power_high': (6.0, 12.0),
-            'inflections' : [int(4), int(17)],
-            'random_regions' : True
-        },
-        False
-    )       
+    ),    
 ])
 def test_TimeVaryingNoise(
-    signal: Union[Signal, DatasetSignal], 
+    signal: Signal, 
     params: dict, 
     is_error: bool
 ) -> None:
     """Test the TimeVaryingNoise transform with pytest.
 
     Args:
-        signal (Union[Signal, DatasetSignal]): input dataset.
+        signal (Signal): input dataset.
         params (dict): TimeVaryingNoise parameters (see functional description).
         is_error (bool): Is a test error expected. 
 
@@ -1897,7 +1825,7 @@ def test_TimeVaryingNoise(
         assert isinstance(T.noise_power_high_distribution(), float)
         assert isinstance(T.inflections_distribution(), np.int_)
         assert isinstance(T.random_regions_distribution(), float)
-        assert isinstance(signal, (Signal, DatasetSignal))
+        
         assert type(signal.data) == type(signal_test.data)
         assert signal.data.dtype == signal_test.data.dtype
         assert np.not_equal(signal.data, signal_test.data).any()
diff --git a/tests/transforms/test_transforms_utils.py b/tests/transforms/test_transforms_utils.py
index a3d9bf2c1..dcd4e4f66 100644
--- a/tests/transforms/test_transforms_utils.py
+++ b/tests/transforms/test_transforms_utils.py
@@ -1,129 +1,16 @@
 """Utility functions for transforms testing.
 """
-from torchsig.signals.signal_types import Signal, DatasetSignal, DatasetDict
+from torchsig.signals.signal_types import Signal
 from torchsig.datasets.dataset_metadata import DatasetMetadata
 from torchsig.signals.builders.constellation import ConstellationSignalBuilder
 from torchsig.signals.builders.tone import ToneSignalBuilder
 import torchsig.transforms.functional as F
-from torchsig.utils.dsp import torchsig_complex_data_type
+from torchsig.utils.dsp import TorchSigComplexDataType
 
 # Third Party
 import numpy as np
 
 
-def generate_test_dataset_dict(num_iq_samples: int = 64, scale: float = 1.0) -> DatasetDict:
-    dataset_signal = generate_test_dataset_signal(
-        num_iq_samples=num_iq_samples,
-        scale=scale
-    )
-    return DatasetDict(signal = dataset_signal)
-
-
-def generate_test_dataset_signal(num_iq_samples: int = 64, scale: float = 1.0) -> DatasetSignal:
-    """Generate a DatasetSignal with two signals: high SNR baseband BPSK and QPSK Signals.
-
-        Args:
-            num_iq_samples (int, optional): Length of sample. Defaults to 64.
-            scale (int, optional): scale normalized signal data. Defaults to 1.0.            
-
-        Returns:
-            nb_signal: generated DatatsetSignal.
-
-    """
-    rng = np.random.default_rng(42)
-
-    # build a test scaled QPSK Signal component
-    sample_rate = 10e6
-    md_qpsk = DatasetMetadata(
-        num_iq_samples_dataset = num_iq_samples,
-        fft_size = 4,
-        impairment_level = 0,
-        sample_rate = 10e6,
-        num_signals_min = 1,
-        num_signals_max = 1,
-        num_signals_distribution = [1.0],
-        snr_db_min = 100.0,
-        snr_db_max = 100.0,
-        signal_duration_min = 1.00*num_iq_samples/sample_rate,
-        signal_duration_max = 1.00*num_iq_samples/sample_rate,
-        signal_bandwidth_min = sample_rate/4,
-        signal_bandwidth_max = sample_rate/4,
-        signal_center_freq_min = 0.0,
-        signal_center_freq_max = 0.0,                
-        transforms = [],
-        target_transforms = [],
-        class_list = ['qpsk'],
-        class_distribution = [1.0],
-        num_samples = 1,
-        seed = 1234
-    )
-    qpsk_builder = ConstellationSignalBuilder(
-        dataset_metadata = md_qpsk, 
-        class_name = 'qpsk',
-        seed = 1234
-    )
-    qpsk_signal = qpsk_builder.build()
-
-    # build a test scaled BPSK Signal component
-    md_bpsk = DatasetMetadata(
-        num_iq_samples_dataset = num_iq_samples,
-        fft_size = 4,
-        impairment_level = 0,
-        sample_rate = 10e6,
-        num_signals_min = 1,
-        num_signals_max = 1,
-        num_signals_distribution = [1.0],
-        snr_db_min = 100.0,
-        snr_db_max = 100.0,
-        signal_duration_min = 1.00*num_iq_samples/sample_rate,
-        signal_duration_max = 1.00*num_iq_samples/sample_rate,
-        signal_bandwidth_min = sample_rate/4,
-        signal_bandwidth_max = sample_rate/4,
-        signal_center_freq_min = 0.0,
-        signal_center_freq_max = 0.0,            
-        class_list = ['bpsk'],
-        class_distribution = [1.0],
-        seed = 5678
-    )
-
-    bpsk_builder = ConstellationSignalBuilder(
-        dataset_metadata = md_bpsk,
-        class_name = 'bpsk',
-        seed = 5678
-    )
-    bpsk_signal = bpsk_builder.build()
-
-    # create test DatasetSignal
-    
-    # noise floor
-    noise_power_lin = 10**(md_bpsk.noise_power_db / 10)
-    noise_real_samples = rng.normal(0,np.sqrt(noise_power_lin/2),4*num_iq_samples)
-    noise_imag_samples = rng.normal(0,np.sqrt(noise_power_lin/2),4*num_iq_samples)
-    iq_samples = noise_real_samples + 1j*noise_imag_samples
-
-    # place baseband QPSK signal at start and BPSK signal at midpoint
-    qpsk_signal.metadata.start_in_samples = 0
-    bpsk_signal.metadata.start_in_samples = int(2*num_iq_samples)
-        
-    iq_samples[qpsk_signal.metadata.start_in_samples: qpsk_signal.metadata.start_in_samples 
-               + qpsk_signal.metadata.duration_in_samples] += qpsk_signal.data
-    
-    iq_samples[bpsk_signal.metadata.start_in_samples: bpsk_signal.metadata.start_in_samples 
-               + bpsk_signal.metadata.duration_in_samples] += bpsk_signal.data   
-    
-    signals = [qpsk_signal, bpsk_signal] 
-    ds_signal = DatasetSignal(data=iq_samples, signals=signals)
-    
-    # normalize, then scale data   
-    ds_signal.data = F.normalize(
-        data = ds_signal.data,
-        norm_order = 2,
-        flatten = False
-    )
-    ds_signal.data = np.multiply(ds_signal.data, scale).astype(torchsig_complex_data_type)    
-    return ds_signal
-
-
 def generate_test_signal(num_iq_samples: int = 10, scale: float = 1.0) -> Signal:
     """Generate a scaled, high SNR baseband QPSK Signal.
 
@@ -170,7 +57,7 @@ def generate_test_signal(num_iq_samples: int = 10, scale: float = 1.0) -> Signal
         norm_order = 2,
         flatten = False
     )
-    signal.data = np.multiply(signal.data, scale).astype(torchsig_complex_data_type)
+    signal.data = np.multiply(signal.data, scale).astype(TorchSigComplexDataType)
 
     return signal
 
@@ -220,6 +107,6 @@ def generate_tone_signal(num_iq_samples: int = 10, scale: float = 1.0) -> Signal
         norm_order = 2,
         flatten = False
     )
-    signal.data = np.multiply(signal.data, scale).astype(torchsig_complex_data_type)
+    signal.data = np.multiply(signal.data, scale).astype(TorchSigComplexDataType)
 
     return signal
diff --git a/tests/utils/profile_rust.py b/tests/utils/profile_rust.py
new file mode 100644
index 000000000..600034265
--- /dev/null
+++ b/tests/utils/profile_rust.py
@@ -0,0 +1,96 @@
+"""Profile Rust Functions
+"""
+from torchsig.utils.rust_functions import upfirdn as upfirdn_RUST
+
+import numpy as np
+from scipy.signal import firwin
+from scipy.signal import upfirdn as upfirdn_SCIPY
+
+import cProfile
+import pstats
+import os
+import sys
+import datetime
+
+THIS_DIR = os.path.dirname(os.path.abspath(__file__))
+
+def profile_upfirdn():
+    print(f"\nProfiling upfirdn (resampler)...........")
+
+    # initialize profiler
+    profiler = cProfile.Profile()
+
+    up_rate = 10000
+    down_rate = 9700
+    input_len = 5310
+
+    print(f"up = {up_rate}, down = {down_rate}")
+    print(f"num input samples = {input_len}")
+
+    # build input signal
+    cfo = 1/input_len
+    in_array = np.array(np.exp(1j*2*np.pi*cfo*np.arange(input_len)),dtype=np.complex64)
+
+    # number of iterations to test speed
+    num_iter = 100
+
+    # filter design params
+    num_taps = 10*up_rate
+    # num_taps = 197000 # ** test case breaks resampler **
+    fs = 1
+    cutoff = 0.5/up_rate
+    weights = firwin(num_taps,cutoff,fs=fs)
+    weights = weights.astype(np.float32)
+
+    # profile resampler
+    profiler.enable()
+    for this_iter in range(num_iter):
+        out_array_rust = upfirdn_RUST(weights,in_array,up_rate,down_rate)
+    profiler.disable()
+    print("Profile done.")
+
+    stats = pstats.Stats(profiler)
+    stats.strip_dirs()
+
+    stats.sort_stats('cumtime')
+    stats.print_stats(20)
+
+    total_time_rust = stats.total_tt
+    
+
+    # profile scipy's resampler
+    profiler_2 = cProfile.Profile()
+    profiler_2.enable()
+    for this_iter in range(num_iter):
+        out_array_scipy = upfirdn_SCIPY(weights,in_array,up_rate,down_rate)
+    profiler_2.disable()
+    print("Profile done.")
+
+    stats = pstats.Stats(profiler_2)
+    stats.strip_dirs()
+
+    stats.sort_stats('cumtime')
+    stats.print_stats(20)
+
+    total_time_scipy = stats.total_tt
+
+    print(f"Rust Resampler Timer: {total_time_rust}s")
+    print(f"Scipy Resampler Timer: {total_time_scipy}s")
+
+    print(f"\nRust resampler is {total_time_scipy/total_time_rust}x faster than scipy.")
+
+def main():
+    print(f"\nOutput will be saved to {THIS_DIR}/profile_rust.out")
+
+    with open(f"{THIS_DIR}/profile_rust.out", 'w') as terminal_output:
+        sys.stdout = terminal_output
+
+        # Timestamp output file
+        now = datetime.datetime.now()
+        print("Profile Run at: ", now.strftime("%Y-%m-%d %H:%M:%S"))
+
+        profile_upfirdn()
+
+
+if __name__ == "__main__":
+    main()
\ No newline at end of file
diff --git a/tests/utils/test_hdf5.py b/tests/utils/test_hdf5.py
new file mode 100644
index 000000000..654b02831
--- /dev/null
+++ b/tests/utils/test_hdf5.py
@@ -0,0 +1,68 @@
+import pytest
+from typing import Any, Sequence, Optional, List, Tuple, Dict
+import numpy as np
+import h5py
+
+# --- Test Data Setup ---
+# Define complex tuple-based targets for reusability
+YOLO_1 = (41, 0.2279052734375, 0.25370860860317335, 0.199951171875, 0.078125)
+YOLO_2 = (0, 0.6279296875, 0.3705115805038923, 0.13525390625, 0.390625)
+YOLO_3 = (25, 0.7984619140625, 0.05374288372813274, 0.181396484375, 0.10748576735626561)
+YOLO_4 = (49, 0.2596435546875, 0.9226088171111424, 0.120361328125, 0.140625)
+YOLO_5 = (40, 0.4500732421875, 0.8010194135042737, 0.199951171875, 0.140625)
+YOLO_6 = (26, 0.3477783203125, 0.5554004366512442, 0.162353515625, 0.265625)
+YOLO_7 = (51, 0.3206787109375, 0.644611440615514, 0.170654296875, 0.328125)
+YOLO_8 = (20, 0.8094482421875, 0.18160910573387345, 0.154541015625, 0.36321821136774707)
+
+# --- Test Cases based on the provided table ---
+TEST_CASES_test_find_first_target = [
+    # id, targets, expected_output
+    ("single_str", ('ofdm-300', [], [], []), 'ofdm-300'),
+    ("multi_str", (['ofdm-300', 'ook', '16psk'], ['am-dsb-sc', 'ofdm-256', '32psk'], ['am-lsb', '16msk'], []), 'ofdm-300'),
+    ("single_int", (41, [], [], []), 41),
+    ("multi_int", ([41, 0, 25], [49, 40, 26], [51, 20], []), 41),
+    ("multi_int_with_zero", ([0, 41, 25], [49, 40, 26]), 0),
+    ("single_composite_tuple_name_index", (('ofdm-300', 41), [], [], []), ('ofdm-300', 41)),
+    ("multi_composite_tuple_name_index", ([('ofdm-300', 41), ('ook', 0), ('16psk', 25)], [('am-dsb-sc', 49)], [],), ('ofdm-300', 41)),
+    ("single_yolo", (YOLO_1, [], [], []), YOLO_1),
+    ("multi_yolo", ([YOLO_1, YOLO_2, YOLO_3], [YOLO_4, YOLO_5, YOLO_6], [YOLO_7, YOLO_8], []), YOLO_1),
+    ("single_composite_tuple_name_yolo", (('ofdm-300', YOLO_1), [], [], []), ('ofdm-300', YOLO_1)),
+    ("multi_composite_tuple_name_yolo", ([('ofdm-300', YOLO_1), ('ook', YOLO_2)], [('am-dsb-sc', YOLO_4)],), ('ofdm-300', YOLO_1)),
+    ("empty_first_then_valid_str", ([], 'ofdm-300', []), 'ofdm-300'),
+    ("empty_first_then_valid_list", ([], ['ofdm-300', 'ook'], []), 'ofdm-300'),
+    ("all_empty", ([], [], (), []), None),
+    ("empty_tuple_then_valid", ((), 'ofdm-300'), 'ofdm-300'),
+    ("empty_batch", (), None),
+]
+
+
+YOLO_TUPLE = (41, 0.227, 0.253, 0.199, 0.078)
+YOLO_DTYPE = np.dtype([('f0', np.int32), ('f1', np.float32), ('f2', np.float32), ('f3', np.float32), ('f4', np.float32)])
+YOLO_PADDING = (-1, -1.0, -1.0, -1.0, -1.0)
+
+COMPLEX_TUPLE = ("ofdm", YOLO_TUPLE)
+COMPLEX_DTYPE = np.dtype([('f0', '<S32'), ('f1', YOLO_DTYPE)])
+COMPLEX_PADDING = (b'-1', YOLO_PADDING)
+
+
+# --- Test Cases ---
+TEST_CASES_test_get_target_properties = [
+    # id, target, expected_dtype, expected_shape, expected_padding
+    ("base_string", "a_string", '<S32', (), b'-1'),
+    ("base_int", 42, np.int32, (), -1),
+    ("base_float", 3.14, np.float32, (), -1.0),
+
+    ("uniform_list_int", [1, 2, 3], np.int32, (3,), (-1, -1, -1)),
+    ("uniform_list_str", ["a", "b"], '<S32', (2,), (b'-1', b'-1')),
+    ("uniform_nested_list", [[1.0, 2.0], [3.0, 4.0]], np.float32, (2, 2), ((-1.0, -1.0), (-1.0, -1.0))),
+
+    ("struct_yolo_tuple", YOLO_TUPLE, YOLO_DTYPE, (), YOLO_PADDING),
+    ("struct_complex_tuple", COMPLEX_TUPLE, COMPLEX_DTYPE, (), COMPLEX_PADDING),
+    ("struct_list_of_yolos", [YOLO_TUPLE, YOLO_TUPLE], YOLO_DTYPE, (2,), (YOLO_PADDING, YOLO_PADDING)),
+
+    # --- Error Cases ---
+    ("error_empty_list", [], None, None, pytest.raises(ValueError)),
+    ("error_empty_tuple", (), None, None, pytest.raises(ValueError)),
+    ("error_unsupported_type", {"a": 1}, None, None, pytest.raises(TypeError)),
+    # ("error_non_uniform_struct", [("a",), ("b", "c")], None, None, pytest.raises(TypeError)),
+]
diff --git a/tests/utils/test_rust_functions.py b/tests/utils/test_rust_functions.py
new file mode 100644
index 000000000..9d49c128e
--- /dev/null
+++ b/tests/utils/test_rust_functions.py
@@ -0,0 +1,45 @@
+""" Test DSP Rust Code
+"""
+
+from torchsig.utils.rust_functions import upfirdn as upfirdn_RUST
+
+from scipy.signal import firwin
+import pytest
+import numpy as np
+
+
+def test_rust_upfirdn():
+    up_rate = 10000
+    down_rate = 9700
+    input_len = 5310
+
+    print('up = ' + str(up_rate) + ', down = ' + str(down_rate))
+    print('num input samples = ' + str(input_len))
+
+    # build input signal
+    cfo = 1/input_len
+    in_array = np.array(np.exp(1j*2*np.pi*cfo*np.arange(input_len)),dtype=np.complex64)
+
+    # number of iterations to test speed
+    num_iter = 100
+
+    # filter design params
+    num_taps = 10*up_rate
+    fs = 1
+    cutoff = 0.5/up_rate
+    weights = firwin(num_taps,cutoff,fs=fs)
+    weights = weights.astype(np.float32)
+
+    # rust resampler
+    for this_iter in range(num_iter):
+        out_array_rust = upfirdn_RUST(weights,in_array,up_rate,down_rate)
+
+    # check for reproducibility
+    for this_iter in range(num_iter):
+        out_array_rust_2 = upfirdn_RUST(weights,in_array,up_rate,down_rate)
+
+    assert out_array_rust.dtype == np.complex64
+    assert all(out_array_rust == out_array_rust_2)
+
+def test_sampling_clock_impairments():
+    pass
\ No newline at end of file
diff --git a/tests/utils/test_seeding_dataloader.py b/tests/utils/test_seeding_dataloader.py
index 1cec1ece6..9c25daa0d 100644
--- a/tests/utils/test_seeding_dataloader.py
+++ b/tests/utils/test_seeding_dataloader.py
@@ -8,34 +8,35 @@ from torchsig.datasets.datasets import TorchSigIterableDataset
 from torchsig.utils.data_loading import WorkerSeedingDataLoader
 
 def test_dataset_seeds_correctly():
-    num_iq_samples_dataset = 4096 # 64^2
     fft_size = 64
+    num_iq_samples_dataset = fft_size ** 2 # 64^2
     impairment_level = 0 # clean
     metadata = DatasetMetadata(
         num_iq_samples_dataset = num_iq_samples_dataset, # 64^2
         fft_size = fft_size,
-        impairment_level = impairment_level, # clean
         num_signals_max = 1,
     )
 
-    narrowband_dataset = TorchSigIterableDataset(metadata)
-    narrowband_dataset.seed(42)
-    test_value11 = next(narrowband_dataset)[0][0]
-    test_value12 = next(narrowband_dataset)[0][0]
-    narrowband_dataset = TorchSigIterableDataset(metadata)
-    narrowband_dataset.seed(42)
-    test_value21 = next(narrowband_dataset)[0][0]
-    test_value22 = next(narrowband_dataset)[0][0]
-    narrowband_dataset = TorchSigIterableDataset(metadata)
-    narrowband_dataset.seed(7)
-    test_value31 = next(narrowband_dataset)[0][0]
-    test_value32 = next(narrowband_dataset)[0][0]
+    ts_ds = TorchSigIterableDataset(metadata, target_labels=["class_name"])
+    ts_ds.seed(42)
+    test_value11 = next(ts_ds)[0][0]
+    test_value12 = next(ts_ds)[0][0]
+    ts_ds = TorchSigIterableDataset(metadata, target_labels=["class_name"])
+    ts_ds.seed(42)
+    test_value21 = next(ts_ds)[0][0]
+    test_value22 = next(ts_ds)[0][0]
+    ts_ds = TorchSigIterableDataset(metadata, target_labels=["class_name"])
+    ts_ds.seed(7)
+    test_value31 = next(ts_ds)[0][0]
+    test_value32 = next(ts_ds)[0][0]
 
     assert test_value11 == test_value21
     assert test_value12 == test_value22
     assert test_value31 != test_value21
     assert test_value31 != test_value21
 
+
+@pytest.mark.filterwarnings(r"ignore:.*fork\(\) may lead to deadlocks in the child:DeprecationWarning")
 def test_dataloader_seeds_correctly():
     num_iq_samples_dataset = 4096 # 64^2
     fft_size = 64
@@ -47,14 +48,14 @@ def test_dataloader_seeds_correctly():
         num_signals_max = 1,
     )
 
-    narrowband_dataset = TorchSigIterableDataset(metadata)
-    dataloader = WorkerSeedingDataLoader(narrowband_dataset, batch_size=8, num_workers=2)
+    ts_ds = TorchSigIterableDataset(metadata, target_labels=["class_name"])
+    dataloader = WorkerSeedingDataLoader(ts_ds, batch_size=4, num_workers=2)
     dataloader.seed(42)
     test_value1 = next(iter(dataloader))[0][-1][0]
-    dataloader = WorkerSeedingDataLoader(narrowband_dataset, batch_size=8, num_workers=2)
+    dataloader = WorkerSeedingDataLoader(ts_ds, batch_size=4, num_workers=2)
     dataloader.seed(42)
     test_value2 = next(iter(dataloader))[0][-1][0]
-    dataloader = WorkerSeedingDataLoader(narrowband_dataset, batch_size=8, num_workers=2)
+    dataloader = WorkerSeedingDataLoader(ts_ds, batch_size=4, num_workers=2)
     dataloader.seed(7)
     test_value3 = next(iter(dataloader))[0][-1][0]
 
diff --git a/tests/utils/test_writer.py b/tests/utils/test_writer.py
new file mode 100644
index 000000000..38fcc3063
--- /dev/null
+++ b/tests/utils/test_writer.py
@@ -0,0 +1,215 @@
+"""Unit Tests for writer utilies.
+"""
+from torchsig.datasets.dataset_metadata import DatasetMetadata
+from torchsig.datasets.datasets import TorchSigIterableDataset, StaticTorchSigDataset
+from torchsig.utils.writer import (
+    DatasetCreator, 
+    default_collate_fn, 
+)
+from torchsig.utils.data_loading import WorkerSeedingDataLoader
+from torchsig.transforms.metadata_transforms import YOLOLabel
+from torchsig.transforms.transforms import Spectrogram
+
+# Third Party
+import numpy as np
+import matplotlib.pyplot as plt
+from tqdm import tqdm
+from copy import deepcopy
+from pathlib import Path
+import os
+import shutil
+import pytest
+
+from typing import List, Any, Tuple
+from collections.abc import Iterable
+import itertools
+
+
+RTOL = 1E-6
+wb_data_dir =  Path.joinpath(Path(__file__).parent,'data/dataset_data/')
+wb_image_dir = Path.joinpath(Path(__file__).parent,'data/dataset_images/')
+getitem_dir = Path.joinpath(Path(__file__).parent,'data/getitem_data/')
+
+# directory for test data
+def setup_module(module):
+    if os.path.exists(wb_data_dir):
+        shutil.rmtree(wb_data_dir)
+    if os.path.exists(wb_image_dir):
+        shutil.rmtree(wb_image_dir) 
+
+    os.makedirs(wb_data_dir)
+    os.makedirs(wb_image_dir)
+
+
+@pytest.mark.parametrize("params, is_error", [
+    ({'dataset_length': None,}, True),
+    ({'dataset_length': 10,}, False)
+])
+def test_DatasetCreator(params: dict, is_error: bool) -> None:
+    """Test DatasetCreator with pytest.
+
+    Args:
+        is_error (bool): Is a test error expected.
+
+    Raises:
+        AssertionError: If unexpected test outcome.
+
+    """
+    seed = 1234567890
+    dataset_length = params["dataset_length"]
+    batch_size = 4
+
+    md = DatasetMetadata(
+        num_iq_samples_dataset = 4096,
+        fft_size = 64,
+        sample_rate = 10e6,
+        num_signals_max = 3,
+        num_signals_min = 0,
+    )
+
+    ds = TorchSigIterableDataset(
+        dataset_metadata = md,
+        seed = seed,
+        transforms=[YOLOLabel()],
+        # target_labels=None,
+        # target_labels=[],
+        target_labels=["class_name"]
+        # target_labels=["class_index", "class_name"]
+        # target_labels=["yolo_label"],
+        # target_labels=["class_name", "yolo_label"]
+    )
+    dl = WorkerSeedingDataLoader(
+        ds, 
+        batch_size = batch_size, 
+        collate_fn=default_collate_fn
+    )
+    if is_error:
+        with pytest.raises(Exception, match=r".*"):
+            dc = DatasetCreator(
+                dataloader=dl,
+                dataset_length = dataset_length,
+                root = wb_data_dir,
+                overwrite = True,
+                multithreading=False   
+            )
+            dc.create()
+    else:
+        # save dataset to disk
+        dc = DatasetCreator(
+            dataloader=dl,
+            dataset_length = dataset_length,
+            root = wb_data_dir,
+            overwrite = True,
+            multithreading=False   
+        )
+        dc.create()
+
+
+test_DatasetCreator_targets_params = list(itertools.product(
+    # transforms
+    [[YOLOLabel()], [YOLOLabel(), Spectrogram(fft_size=64)]],
+    # target_labels
+    [["class_name"], ["class_index"], ["class_name", "class_index"], ["yolo_label"], ["class_name", "yolo_label"]],
+    # num_signals_min
+    [0, 1],
+    # num_signals_max
+    [1, 2, 3]
+))
+
+@pytest.mark.parametrize(
+    "transforms, target_labels, num_signals_min, num_signals_max", 
+    test_DatasetCreator_targets_params
+)
+def test_DatasetCreator_targets(
+    transforms,
+    target_labels,
+    num_signals_min,
+    num_signals_max,
+) -> None:
+    """Test DatasetCreator with pytest.
+
+    Args:
+        is_error (bool): Is a test error expected.
+
+    Raises:
+        AssertionError: If unexpected test outcome.
+
+    """
+    
+    seed = 1234567890
+    dataset_length = 6
+    batch_size = 4
+
+    md = DatasetMetadata(
+        num_iq_samples_dataset = 4096,
+        fft_size = 64,
+        sample_rate = 10e6,
+        num_signals_max = num_signals_max,
+        num_signals_min = num_signals_min,
+    )
+
+    ds = TorchSigIterableDataset(
+        dataset_metadata = md,
+        seed = seed,
+        transforms=transforms,
+        target_labels=None
+    )
+    dl = WorkerSeedingDataLoader(
+        ds, 
+        batch_size = batch_size, 
+        collate_fn=lambda x: x
+    )
+    
+    # save dataset to disk
+    dc = DatasetCreator(
+        dataloader=dl,
+        dataset_length = dataset_length,
+        root = wb_data_dir,
+        overwrite = True,
+        multithreading=False   
+    )
+    dc.create()
+
+    # breakpoint()
+
+    # load dataset from disk
+    sds = StaticTorchSigDataset(
+        root = wb_data_dir,
+        target_labels=target_labels
+    )
+
+    assert isinstance(dc, DatasetCreator)
+    assert isinstance(dc.root, Path)
+    assert isinstance(dc.overwrite, bool)
+    assert isinstance(dc.multithreading, bool)
+    assert dc.overwrite
+    assert isinstance(dc.get_writing_info_dict(), dict)
+
+
+if __name__ == "__main__":
+    # test_DatasetCreator(params={'dataset_length': 10}, is_error=False)
+    transforms = [[YOLOLabel()]]
+    target_labels = [
+        ["class_name"], # ofdm-300
+        ["class_index"], # 41
+        ["class_name", "class_index"], # ('ofdm-300', 41)
+        ["yolo_label"], # (41, 0.2279052734375, 0.25370860860317335, 0.199951171875, 0.078125)
+        ["class_name", "yolo_label"] #('ofdm-300', (41, 0.2279052734375, 0.25370860860317335, 0.199951171875, 0.078125))
+    ]
+    num_signals_min = [0]
+    num_signals_max = [1, 3]
+    params = itertools.product(
+        transforms,
+        target_labels,
+        num_signals_min,
+        num_signals_max
+    )
+    # breakpoint()
+    for p in params:
+        print(f"{p} -------")
+        try:
+            test_DatasetCreator_targets(*p)
+        except ImportError:
+            pass
+        # breakpoint()
+    # test_padding()
diff --git a/tools/examples/satnogs_processer.ipynb b/tools/examples/satnogs_processer.ipynb
new file mode 100644
index 000000000..b1c6dca6b
--- /dev/null
+++ b/tools/examples/satnogs_processer.ipynb
@@ -0,0 +1,954 @@
+{
+ "cells": [
+  {
+   "cell_type": "markdown",
+   "id": "6eceef8d",
+   "metadata": {},
+   "source": [
+    "# SatNOGS Processor\n",
+    "\n",
+    "This notebook showcases how to use SatNOGS (Satellite Networked Open Ground Station) with TorchSig. This downloads 1 observations from satnogs and creates a spectrogram and PNGs file. Then allows the user to draw bounding boxes on the spectrogram, the spectrogram is processed into Torchsig to make predictions. The torchsig predictions are given back to the user for further refinement via sigmf.\n",
+    "\n",
+    "Note:  This notebook must be ran in Jupyter notebook due to Yolo annotation tool and may not work properly in VS code \n",
+    "---"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "b45fbc94-6c9f-4874-a8e9-ea33757dd123",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "\"\"\" This notebook grabs signals from Satnogs and then converts it to sigmf and then runs it through Torchsig\"\"\"\n",
+    "import os\n",
+    "import tempfile\n",
+    "import subprocess\n",
+    "import math\n",
+    "from datetime import datetime, timedelta\n",
+    "import requests\n",
+    "from bs4 import BeautifulSoup\n",
+    "import numpy as np\n",
+    "from ultralytics import YOLO\n",
+    "import librosa\n",
+    "import cv2\n",
+    "from scipy import signal\n",
+    "import torchaudio\n",
+    "import torch\n",
+    "import matplotlib.pyplot as plt\n",
+    "from jupyter_bbox_widget import BBoxWidget\n",
+    "from sigmf import SigMFFile, sigmffile\n",
+    "from torchsig.image_datasets.datasets.yolo_datasets import YOLOFileDataset\n",
+    "from torchsig.image_datasets.annotation_tools.yolo_annotation_tool import yolo_annotator"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "7f05162f-c885-4f65-a750-58036220fbb2",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "# Get the current date\n",
+    "now = datetime.today()\n",
+    "yesterday = now - timedelta(days=1)\n",
+    "date =  yesterday.strftime(\"%Y-%m-%d\")\n",
+    "PAGENUM = 1\n",
+    "NEXTPAGE = 1\n",
+    "waterfall_links = []\n",
+    "BASE_SATNOGS_URL = 'https://network.satnogs.org/observations/'\n",
+    "x = 1"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "47c8701c-3b7c-41b1-9fa5-3ea4fe3f393b",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "while NEXTPAGE == 1 and x == 1:\n",
+    "    URELDATE = f'https://network.satnogs.org/observations/?norad=&start={date}'\n",
+    "    URLRES = '+18%3A55&end=&observer=&station=&results=w1&results=a1&results=d1&rated=rw1&'\n",
+    "    MAINURL = URELDATE + URLRES + f'transmitter_mode=&transmitter_uuid=&page={PAGENUM}'\n",
+    "\n",
+    "    print(f\"\\nCurrently on page: {PAGENUM}\")\n",
+    "    print(f\"Current item count: {x}\")\n",
+    "\n",
+    "    try:\n",
+    "        mainresponse = requests.get(MAINURL, timeout=10)\n",
+    "\n",
+    "        if mainresponse.status_code == 200:\n",
+    "            # Parse the HTML content of the main page\n",
+    "            mainsoup = BeautifulSoup(mainresponse.text, 'html.parser')\n",
+    "            disable_next = mainsoup.select_one('#page-selector > ul > li.page-item.disabled')\n",
+    "            if disable_next and PAGENUM > 1:\n",
+    "                NEXTPAGE = 0\n",
+    "                print(\"On the last page, setting NEXTPAGE to 0.\")\n",
+    "\n",
+    "            # Find all elements with the class \"badge badge-good\" (these contain observation IDs)\n",
+    "            GoodStatus = mainsoup.find_all(class_='badge badge-good')\n",
+    "            for item in GoodStatus:\n",
+    "                if x != 1:\n",
+    "                    print(f\"Reached item limit of {x}. Stopping inner loop.\")\n",
+    "                    break\n",
+    "                observation_id = item.text.strip()\n",
+    "                ITEMURL = f'https://network.satnogs.org/observations/{observation_id}'\n",
+    "\n",
+    "                print(f\"  Processing observation ID: {observation_id}\")\n",
+    "                try:\n",
+    "                    itemresponse = requests.get(ITEMURL, timeout=10)\n",
+    "                    if itemresponse.status_code == 200:\n",
+    "                        itemsoup = BeautifulSoup(itemresponse.text, 'html.parser')\n",
+    "                        title = itemsoup.title\n",
+    "                        if title:\n",
+    "                            print(f\"    Page Title: {title.text.strip()}\")\n",
+    "                        else:\n",
+    "                            print(f\"    Warning: Could not find page title for {observation_id}.\")\n",
+    "                        data_element = itemsoup.find('a', href=lambda x_href: x_href and\n",
+    "                                                                    'satnogs' in x_href and\n",
+    "                                                                    x_href.endswith('.ogg'))\n",
+    "                        if data_element:\n",
+    "                            waterfall_link = data_element['href']\n",
+    "                            waterfall_links.append(waterfall_link)\n",
+    "                            x += 1\n",
+    "                            print(f\"    Successfully found and saved audio link. Total items: {x}\")\n",
+    "                        else:\n",
+    "                            print(f\"    Audio link ('.ogg') not found for observation {observation_id}.\")\n",
+    "                    else:\n",
+    "                        print(f\"    Failed to retrieve data for observation {observation_id}. \"\n",
+    "                                f\"Status code: {itemresponse.status_code}\")\n",
+    "                except requests.exceptions.RequestException as e:\n",
+    "                    print(f\"    An error occurred while requesting {ITEMURL}: {e}\")\n",
+    "                except Exception as e:\n",
+    "                    print(f\"    An unexpected error occurred for observation {observation_id}: {e}\")\n",
+    "            if x != 1:\n",
+    "                print(f\"Overall item limit of {x} reached. Setting NEXTPAGE to 0 to stop main loop.\")\n",
+    "                NEXTPAGE = 0 #\n",
+    "\n",
+    "        else:\n",
+    "            # If the main page request failed\n",
+    "            print(f\"Failed to retrieve main page. Status code: {mainresponse.status_code}\")\n",
+    "            NEXTPAGE = 0 # Stop the loop if main page fails\n",
+    "    except requests.exceptions.RequestException as e:\n",
+    "        # Catch network errors for the main page request\n",
+    "        print(f\"Network error occurred while fetching main page {MAINURL}: {e}\")\n",
+    "        NEXTPAGE = 0 # Stop the loop on network error\n",
+    "    # Increment to the next page number for the next iteration of the while loop\n",
+    "    PAGENUM += 1\n",
+    "print(waterfall_links)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "f8f7de26-5570-4546-8c56-13b026bbcc43",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "def torchaudioused(torchchunk):\n",
+    "    \"\"\"\n",
+    "    Determines the normalized spectrogram\n",
+    "    \"\"\"\n",
+    "\n",
+    "    torchnfft = 1024\n",
+    "    specgram = torchaudio.transforms.Spectrogram(\n",
+    "        n_fft=torchnfft*2,\n",
+    "        win_length=torchnfft*2,\n",
+    "        hop_length=torchnfft*2,\n",
+    "        window_fn=torch.blackman_window,\n",
+    "        normalized=False,\n",
+    "        center=False,\n",
+    "        onesided=True,\n",
+    "        power=True,\n",
+    "    )\n",
+    "    norm = lambda x: torch.linalg.norm(\n",
+    "        x,\n",
+    "        ord=float(\"inf\"),\n",
+    "            keepdim=True,\n",
+    "    )\n",
+    "    torchx = specgram(torch.from_numpy(torchchunk))\n",
+    "    torchx = torchx[:-1]\n",
+    "    torchx = torchx * (1 / norm(torchx.flatten()))\n",
+    "    torchx = torchx.flipud()\n",
+    "    torchx = 10*np.log10(torchx.numpy()+1e-12)\n",
+    "    return torchx"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "d8e362e0-12de-428d-a186-25d011dc67fd",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "def baseband_downsample_real_to_real(input_data,r_cfreq,signal_freq,israte,osrate):\n",
+    "    \"\"\"\n",
+    "    reduces the data and sample rate due to a constraint\n",
+    "    \"\"\"\n",
+    "    if torch.cuda.is_available() is True:\n",
+    "        with torch.cuda.device('cuda:0'):\n",
+    "            input_data.to('cuda:0')\n",
+    "            inx = torch.linspace(0,len(input_data)-1,len(input_data),\n",
+    "                               dtype=torch.complex64,device='cuda:0')\n",
+    "            fshift = (r_cfreq-signal_freq)/(israte*1.0)\n",
+    "            fv = math.e ** (1j*2* math.pi *fshift*inx)\n",
+    "            fv.to('cuda:0')\n",
+    "            input_data = input_data * fv\n",
+    "            num_samples_in = len(input_data)\n",
+    "            # print(len(input_data))\n",
+    "            num_samples = int(np.ceil(num_samples_in/(israte/osrate)))\n",
+    "            # print (int((num_samples*israte)))\n",
+    "            osrate_new = int((num_samples*israte)/num_samples_in)\n",
+    "            down_factor = int(israte/osrate_new)\n",
+    "            transform = torchaudio.transforms.Resample(int(israte/osrate_new),\n",
+    "                                                       1,dtype=torch.float32).to('cuda:0')\n",
+    "            #test = transform(input_data.real) + 1j*transform(input_data.imag)\n",
+    "            test = transform(input_data.real)\n",
+    "            return test,(israte/down_factor)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "f93b6c74-91e9-4451-91ae-142ab7a8eb61",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "def Save_PNG(directory,sample_rate,pngname,NFFT,x):\n",
+    "    \"\"\"\n",
+    "    Saves an image\n",
+    "    \"\"\"\n",
+    "    if sample_rate > 0:\n",
+    "        sampleRate.update({pngname: sample_rate})\n",
+    "        x = cv2.resize(x, (NFFT, NFFT), interpolation=cv2.INTER_LINEAR)\n",
+    "    #convert to 3 channel grayscale black hot image using opencv\n",
+    "    pngimg_new = np.zeros((NFFT, NFFT, 3),dtype=np.float32)\n",
+    "    pngimg_new = cv2.normalize(x, pngimg_new, 0, 255, cv2.NORM_MINMAX)\n",
+    "    pngimg_new = cv2.cvtColor(pngimg_new.astype(np.uint8), cv2.COLOR_GRAY2BGR)\n",
+    "    pngimg_new = cv2.bitwise_not(pngimg_new)\n",
+    "    # Create the full path for the new file\n",
+    "    imgtext = \"image.png\"\n",
+    "    pngimgname =  pngname + imgtext\n",
+    "    pngoutput_path = os.path.join(directory,pngimgname)  # Change extension as needed\n",
+    "    print(pngoutput_path)\n",
+    "    if cv2.imwrite(pngoutput_path, pngimg_new):\n",
+    "        print(f\"Image saved successfully: {pngoutput_path}\")\n",
+    "    else:\n",
+    "        print(\"Failed to save image.\")"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "8073167f-8a62-4a6c-bb89-cfb7c50f7c01",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "#sets constants nfft, Id (current ogg in audio_links, starts at 1)\n",
+    "NFFT = 1024\n",
+    "NFFTNFFT = NFFT * NFFT * 2\n",
+    "ID = 0\n",
+    "#determines if the user wants to refine the data,\n",
+    "#if they do, It will require further user input.\n",
+    "    #Otherwise will run through the entire file automatically\n",
+    "edit = input(\"Would you like to manually refine the data Y/N\").upper()\n",
+    "# Defines the directory in which final images will be saved in\n",
+    "DIRECTORY = 'signals/dataset'\n",
+    "if not os.path.exists(DIRECTORY):\n",
+    "    os.makedirs(DIRECTORY)\n",
+    "\n",
+    "refdir = os.path.join(DIRECTORY, 'refined')\n",
+    "if not os.path.exists(refdir):\n",
+    "    os.makedirs(refdir)\n",
+    "\n",
+    "undir = os.path.join(DIRECTORY, 'unrefined')\n",
+    "if not os.path.exists(undir):\n",
+    "    os.makedirs(undir)\n",
+    "\n",
+    "#iterates through the entire audio_link file\n",
+    "#2\n",
+    "sampleRate = {}\n",
+    "for link in waterfall_links:\n",
+    "    response = requests.get(link)\n",
+    "\n",
+    "    if response.status_code == 200:\n",
+    "        # Create a temporary ogg file in the system's temp directory\n",
+    "        with tempfile.NamedTemporaryFile(delete=False, suffix='.ogg') as temp_file:\n",
+    "            temp_file.write(response.content)\n",
+    "            fileName = temp_file.name\n",
+    "            #converts the ogg data into a numpy array (data) and\n",
+    "                #determines the sample_rate for later use.\n",
+    "            try:\n",
+    "                data, sample_rate = librosa.load(temp_file.name,sr=None)\n",
+    "            except:\n",
+    "                break\n",
+    "        # #Increments id for each new data and creates chunks from the data\n",
+    "        print(data)\n",
+    "        ID = ID +1\n",
+    "        # print(type(data))\n",
+    "        print(data[:NFFT*NFFT])\n",
+    "        # chunk = data[:NFFT*NFFT]\n",
+    "        # print(chunk)\n",
+    "        lenSamples = len(data)\n",
+    "        chunk_count_rounded = int(lenSamples/NFFTNFFT)\n",
+    "        print(int(lenSamples))\n",
+    "        data = data[:(chunk_count_rounded*NFFTNFFT)]\n",
+    "        data = data.reshape(chunk_count_rounded,NFFTNFFT)\n",
+    "        print(data.shape)\n",
+    "        # Goes through the chunks of the data file and converts them into usable pngs for yolo.\n",
+    "        for i in range(chunk_count_rounded):\n",
+    "            IDNAME = str(ID)+\",\"+str(i)\n",
+    "            # print(data[i].shape)\n",
+    "            chunk = data[i]\n",
+    "            #print(chunk.shape)\n",
+    "            #print(i)\n",
+    "            chunkx = torchaudioused(chunk)\n",
+    "            #3\n",
+    "            #If the user has requested to refine the data,\n",
+    "                #it will pass them to the refine function.\n",
+    "            sampleRate.update({IDNAME: sample_rate})\n",
+    "            if edit in ('Y', 'YES'):\n",
+    "                Save_PNG(undir,0,IDNAME,NFFT,chunkx)\n",
+    "            else:\n",
+    "                Save_PNG(refdir,0,IDNAME,NFFT,chunkx)\n",
+    "                print(\"no refinement\")"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "24c08949-12b5-41ff-839d-0e284195b314",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "def tosigmf (signame,sigidname, manual,sigedit):\n",
+    "    \"\"\"\n",
+    "      converts to SIGMF file\n",
+    "    \"\"\"\n",
+    "    sigauthor = \"jane.doe@domain.org\"\n",
+    "    sigdes = \"ogg real file.\"\n",
+    "    sigver = \"1.0.0\"\n",
+    "    sigpngname = signame.replace(\".txt\", \"\")\n",
+    "    sigpng_path = os.path.join(refdir, sigpngname)\n",
+    "    # Define basic metadata\n",
+    "    if signame !='.ipynb_checkpoints':\n",
+    "        while sigedit in ('Y', 'YES'):\n",
+    "            sigfield = input(\"What field would you like to edit? author, description, or version\")\n",
+    "            match sigfield:\n",
+    "                case \"author\":\n",
+    "                    sigauthor = input(\"What would you like to set as the author of this file?\")\n",
+    "                case \"description\":\n",
+    "                    sigdes = input(\"What would you like to set as the description of this file?\")\n",
+    "                case \"version\":\n",
+    "                    sigver = input(\"What would you like to set as the version of this file?\")\n",
+    "            sigedit = input(\"Would you like to edit another field? Y/N\")\n",
+    "        sigsample_rate = sampleRate[sigidname]\n",
+    "        sigmeta = SigMFFile(\n",
+    "            global_info = {\n",
+    "                SigMFFile.DATATYPE_KEY: 'cf64_le',\n",
+    "                SigMFFile.SAMPLE_RATE_KEY: sigsample_rate,\n",
+    "                SigMFFile.AUTHOR_KEY: sigauthor,\n",
+    "                SigMFFile.DESCRIPTION_KEY: sigdes,\n",
+    "                SigMFFile.VERSION_KEY: sigver,\n",
+    "            }\n",
+    "        )\n",
+    "        if not manual:\n",
+    "            for siglabel in labels:\n",
+    "                i = 0\n",
+    "                sx, sigcx, sigcy, sigw, _ = siglabel\n",
+    "                sigcx = sigcx * width\n",
+    "                sigsx = sigcx - ((sigw * width) // 2)\n",
+    "                sigex = sigcx + ((sigw * width) // 2)\n",
+    "                sigcy = (sigcy * 2) * int(sigsample_rate /2)\n",
+    "\n",
+    "                if len(labels) == 1:\n",
+    "                    #crops image to only where the signal has been identified, which will prevent the sigmf file from being created\n",
+    "                    refdata, refsample_rate = baseband_downsample_real_to_real(torch.from_numpy(chunk[(int(sigsx)*2048):(int(sigex)*2048)]).to('cuda:0'),\n",
+    "                                                                               int(int(sample_rate)/4),int(sigcy),48000,1600)\n",
+    "                    #overwrites data in annotation dataset\n",
+    "                    refdata = refdata[:(chunk_count_rounded*NFFTNFFT)]\n",
+    "                    refdata = refdata.cpu().numpy()\n",
+    "                    x = torchaudioused(refdata)\n",
+    "                    print(\"x\", x)\n",
+    "                    Save_PNG(refdir,refsample_rate,sigidname,NFFT,x)\n",
+    "\n",
+    "                sigmeta.add_capture(sx, metadata={\n",
+    "                    \"core:sample_start\":sigsx,\n",
+    "                    \"core:sample_count\":1,\n",
+    "                    \"core:frequency\": sigcy,\n",
+    "                    \"core:comment\": i,\n",
+    "                })\n",
+    "                sigmeta.validate()\n",
+    "                output_path = os.path.join(refdir, metaname)\n",
+    "                sigmeta.tofile(output_path)\n",
+    "                i = i + 1\n",
+    "\n",
+    "        else:\n",
+    "            sigsx = labels[0]\n",
+    "            sigex = labels[1]\n",
+    "            sigcy = labels[2]\n",
+    "            try:\n",
+    "                #crops image to only where the signal has been identified, which will prevent the sigmf file from being created\n",
+    "                refdata, refsample_rate = baseband_downsample_real_to_real(torch.from_numpy(chunk[(int(sigsx)*2048):(int(sigex)*2048)]).to('cuda:0'),\n",
+    "                                                                           int(int(sample_rate)/4),int(sigcy),48000,1600)\n",
+    "                # #overwrites data in annotation dataset\n",
+    "                data = refdata[:(chunk_count_rounded*NFFTNFFT)]\n",
+    "                x = torchaudioused(data)\n",
+    "\n",
+    "                Save_PNG(refdir,refsample_rate,sigidname,NFFT,x)\n",
+    "                #6\n",
+    "                sigmeta.add_capture(sx, metadata={\n",
+    "                    \"core:sample_start\":sigsx,\n",
+    "                    \"core:sample_count\":1,\n",
+    "                    \"core:frequency\": sigcy,\n",
+    "                    \"core:comment\": 1,\n",
+    "                })\n",
+    "                sigmeta.validate()\n",
+    "                output_path = os.path.join(refdir, metaname + \".sigmf-meta\")\n",
+    "                # print(output_path)\n",
+    "                sigmeta.tofile(output_path)\n",
+    "            except:\n",
+    "                print(\"no meta saved\")"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "7b244048-8e97-4190-8e88-c98174c3e5fc",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "#data that needs refrainment via manual input\n",
+    "if edit == \"Y\":\n",
+    "    for file in os.listdir(undir):\n",
+    "        filename = os.fsdecode(file)\n",
+    "        if filename.endswith(\".png\"):\n",
+    "            name = filename.replace(\".png\",\"\")\n",
+    "            idname = name.replace(\"image_name\", \"\")\n",
+    "            metaname = name + \"sigmf-meta\"\n",
+    "            imagepath = os.path.join(undir,filename)\n",
+    "            # print(imagepath)\n",
+    "            # Load the image\n",
+    "            image = cv2.imread(imagepath)\n",
+    "            # Adjust the brightness and contrast\n",
+    "            # Adjusts the brightness by adding 10 to each pixel value\n",
+    "            BRIGHTNESS = 10\n",
+    "            # Adjusts the contrast by scaling the pixel values by 2.3\n",
+    "            CONTRAST = 2.3\n",
+    "            image2 = cv2.addWeighted(image, CONTRAST, np.zeros(image.shape, image.dtype), 0, BRIGHTNESS)\n",
+    "\n",
+    "            figure = plt.figure(figsize=(30,30))\n",
+    "            ax = plt.subplot()\n",
+    "            figure.suptitle(\"with axis 48K real\")\n",
+    "            ax.imshow(image)\n",
+    "            ax.set_xlabel(\"Duration:\")\n",
+    "            ax.set_ylabel(\"Bandwidth:\")\n",
+    "            ax.set_yticks(list(np.linspace(1023,0,100)),list(np.linspace(0,int(sample_rate/2),100)))\n",
+    "            plt.show()\n",
+    "            mansx = input(\"Enter start duration\")\n",
+    "            manex = input(\"Enter end duration\")\n",
+    "            mancy = input(\"Enter frequency\")\n",
+    "            manlabels = [mansx,manex,mancy]\n",
+    "            tosigmf (name,idname, True)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "8997f17f-b414-41d5-940e-4bf6d3b8b78b",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "#data that needs refrainment via drawling\n",
+    "from torchsig.image_datasets.annotation_tools.yolo_annotation_tool import yolo_annotator\n",
+    "if edit == \"Y\":\n",
+    "    UNLAB_DIR = \"signals/dataset/unrefined/\" # directory of images to be annotated\n",
+    "else:\n",
+    "    UNLAB_DIR = \"signals/dataset/refined/\"\n",
+    "NEWYOLODT = \"signals/annotated_dataset/\" # directory to save annotated yolo data\n",
+    "yolo_annotator(UNLAB_DIR,NEWYOLODT)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "fd1c74f8-8134-4516-9d5a-4ecbf87bffec",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "#data that needs refrainment via drawling\n",
+    "from torchsig.image_datasets.datasets.yolo_datasets import YOLOFileDataset\n",
+    "plt.rcParams[\"figure.figsize\"] = (50,50)\n",
+    "yds1 = YOLOFileDataset(NEWYOLODT)\n",
+    "yds1.root_filepath, os.listdir(yds1.root_filepath + \"labels\")"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "5967abbb-98b7-4406-a9c9-11c1e082d252",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "print(\"current defaults for all files: Author: jane.doe@domain.org Description: ogg real file. Version Key: 1.0.0\") \n",
+    "sigedit = input(\"would you like to edit the default fields for all files? Y/N\").upper()\n",
+    "\n",
+    "for x in range (len(yds1)):\n",
+    "    image= yds1[x].img\n",
+    "    height, width = image.shape[:2]\n",
+    "    labels = yds1[x].labels\n",
+    "    name = os.listdir(yds1.root_filepath + \"labels\")[x]\n",
+    "    name = name.replace(\".png\",\"\")\n",
+    "    idname = name.replace(\"image\", \"\")\n",
+    "    idname = idname.replace(\".txt\", \"\")\n",
+    "    metaname = name.replace(\".txt\", \".sigmf-meta\")\n",
+    "    meta_path = os.path.join(refdir, metaname)\n",
+    "    # print(name + \"-\" + idname + \"-\" + metaname)\n",
+    "    #metadata\n",
+    "    tosigmf(name,idname, False,sigedit)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "77fa343b-03c4-4bb9-8ec8-908c6ad8f3eb",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "class UniqueListOfLists:\n",
+    "    \"\"\"\n",
+    "    Make sure that the list only contains unique values\n",
+    "    \"\"\"\n",
+    "    def __init__(self):\n",
+    "        self._lists = []\n",
+    "\n",
+    "    def add(self, new_list):\n",
+    "        \"\"\"\n",
+    "        Adds unique values to the list\n",
+    "        \"\"\"\n",
+    "        if new_list not in self._lists:\n",
+    "            self._lists.append(new_list)\n",
+    "\n",
+    "    def __iter__(self):\n",
+    "        return iter(self._lists)\n",
+    "\n",
+    "    def __repr__(self):\n",
+    "        return f\"UniqueListOfLists({self._lists})\""
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "2b4bcc5e-fe78-4bcc-82c1-207bc4bed308",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "#downloads detect model\n",
+    "if not os.path.exists(\"detect.pt\"):\n",
+    "    print(os.getcwd())\n",
+    "    path = os.getcwd()\n",
+    "    parent_dir = os.path.dirname(path)\n",
+    "    parent_dir = os.path.dirname(parent_dir)\n",
+    "    print(parent_dir)\n",
+    "    script_path = os.path.join(parent_dir, \"gr-spectrumdetect\", \"examples\", \"trained_model_download.sh\")\n",
+    "    try:\n",
+    "        result = subprocess.run([script_path], capture_output=True, text=True, check=True)\n",
+    "        # Print any errors from the shell script\n",
+    "        if result.stderr:\n",
+    "            print(\"Shell script errors:\")\n",
+    "            print(result.stderr)\n",
+    "\n",
+    "    except subprocess.CalledProcessError as e:\n",
+    "        # Handle errors if the script returns a non-zero exit code\n",
+    "        print(f\"Error executing shell script: {e}\")\n",
+    "        print(f\"Stderr: {e.stderr}\")\n",
+    "    except FileNotFoundError:\n",
+    "        print(f\"Error: Script not found at {script_path}\")\n"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "a6a3419d-64fe-40cc-9ea3-26e5ae4fe2df",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "#passing sigmf files to model for predictions\n",
+    "model = YOLO('detect.pt')\n",
+    "result = model.named_parameters\n",
+    "# Load a dataset\n",
+    "for file in os.listdir(refdir):\n",
+    "    filename = os.fsdecode(file)\n",
+    "    if filename.endswith(\"-meta\"):\n",
+    "        output_path = os.path.join(refdir,filename)\n",
+    "        # print(output_path)\n",
+    "\n",
+    "        signal = sigmffile.fromfile(output_path)\n",
+    "        samples = 1\n",
+    "\n",
+    "        #removes any current annotations from file\n",
+    "        filetxt = filename.replace(\".sigmf-meta\", \".txt\")\n",
+    "        file_path = os.path.join(\"signals/annotated_dataset/labels/\",filetxt)\n",
+    "        # print(file_path)\n",
+    "\n",
+    "        fileNamepng = filename.replace(\".sigmf-meta\", \".png\")\n",
+    "        fileNamepng = fileNamepng.replace(\".png.png\", \".png\")\n",
+    "        file_png_path = os.path.join(\"signals/dataset/refined/\",fileNamepng)\n",
+    "        # print(file_png_path)\n",
+    "        labels = UniqueListOfLists()\n",
+    "        for x in range(len(signal.get_captures())):\n",
+    "            # Get some metadata and all annotations\n",
+    "            fc = signal.get_captures()[x]['core:frequency']\n",
+    "            sample_rate = signal.get_global_field(SigMFFile.SAMPLE_RATE_KEY)\n",
+    "            sample_count = signal.get_captures()[x][ \"core:sample_count\"]\n",
+    "            signal_duration = sample_count / sample_rate\n",
+    "            fs = sample_rate\n",
+    "            file_png_path = os.path.join(\"signals/dataset/refined/\",fileNamepng)\n",
+    "            if cv2.haveImageReader(file_png_path):\n",
+    "                img_new = cv2.imread(file_png_path)\n",
+    "            else:\n",
+    "                continue\n",
+    "            result = model(img_new , imgsz=NFFT, save=False, augment=False,iou=0.1, max_det=300)\n",
+    "            plot_img = result[0].orig_img\n",
+    "            height, width = plot_img.shape[:2]\n",
+    "            print(height,width)\n",
+    "            Z = 0\n",
+    "            # print(result[0].boxes.xyxy)\n",
+    "            if result[0].boxes.xyxy != []:\n",
+    "                for Z, boxes_xyxy in enumerate(result[0].boxes.xyxy):\n",
+    "                    y = 0\n",
+    "                    box_xyxy = boxes_xyxy.cpu().numpy()\n",
+    "                    box_xywh = result[0].boxes.xywh[Z].cpu().numpy()\n",
+    "                    center_freq = (float(fs)/2.0)-(float(box_xywh[1]/NFFT)*float(fs))+fc\n",
+    "                    top_freq = (float(fs)/2.0)-((box_xyxy[1]/NFFT)*float(fs))+fc\n",
+    "                    bottom_freq = (float(fs)/2.0)-((box_xyxy[3]/NFFT)*float(fs))+fc\n",
+    "                    bandwidth = top_freq - bottom_freq\n",
+    "                    start_sample = int(box_xyxy[0])*int(NFFT)\n",
+    "                    end_sample = int(box_xyxy[2])*int(NFFT)\n",
+    "                    duration = end_sample - start_sample\n",
+    "                    signal.add_annotation(start_sample,duration, metadata = {\n",
+    "                        SigMFFile.FLO_KEY: bottom_freq,\n",
+    "                        SigMFFile.FHI_KEY: top_freq,\n",
+    "                        SigMFFile.COMMENT_KEY:str(y),\n",
+    "                    })\n",
+    "                    # print(box_xyxy[0])\n",
+    "                    cx = (box_xyxy[0] + box_xywh[2]//2)/width\n",
+    "                    cy = (box_xyxy[1] + box_xywh[3]//2)/height\n",
+    "                    # print(cx)\n",
+    "                    new_width = box_xywh[2]/width\n",
+    "                    # print(new_width)\n",
+    "                    new_height = box_xywh[3]/height\n",
+    "                    # print(new_height)\n",
+    "                    # print(\"end:\" + str(cx))\n",
+    "                    print(y)\n",
+    "                    labels.add([cx,cy,new_width,new_height])\n",
+    "                    y = y + 1\n",
+    "                signal.tofile(output_path)\n",
+    "            with open(file_path, \"w\") as file:\n",
+    "                y = 0\n",
+    "                for line in labels:\n",
+    "                    file.write(str(y) + \" \"+ str(line[0]) + \" \"+ str(line[1]) + \" \"+str(line[2])+ \" \"+ str(line[3]) + \"\\n\")\n",
+    "                    y = y + 1"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "224e52ee-7904-4c1d-a177-080fe3ca64bc",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "#creates dataset of all annotations images\n",
+    "plt.rcParams[\"figure.figsize\"] = (50,50)\n",
+    "YOLODIR = \"signals/annotated_dataset/\" # directory to save annotated yolo data\n",
+    "yds1 = YOLOFileDataset(YOLODIR )\n",
+    "# type(yds1)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "cb16c8fc-0ba8-4974-ae27-736a9b83af63",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "try:\n",
+    "    yds1.root_filepath, os.listdir(yds1.root_filepath + \"labels\")\n",
+    "    yds1[0]\n",
+    "    # print(yds1[1].labels)\n",
+    "except:\n",
+    "    raise ValueError('No annotated images in directory, please either 1) re-run and annotate images or 2) if the tool is unavailable please run in jupyter lab')"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "398b6491-7770-4610-8d97-bf69eb588970",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "for x in range (len(yds1)):\n",
+    "    imagename = os.listdir(yds1.root_filepath + \"images\")[x]\n",
+    "    imagename =imagename[:-3] + \"png\"\n",
+    "    print(imagename)\n",
+    "    image= yds1[x].img\n",
+    "    boxclass = []\n",
+    "    labels = yds1[x].labels\n",
+    "    image = 1 - image.numpy()\n",
+    "    if labels != [[]]:\n",
+    "        # font\n",
+    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
+    "        # fontScale\n",
+    "        FONTSCALE = 1\n",
+    "        # Blue color in BGR\n",
+    "        color = (0, 255, 0)\n",
+    "        image = (np.stack([image[0,:,:]]*3).transpose(1,2,0)*255).astype(np.uint8)\n",
+    "        for label in labels:\n",
+    "            cid, cx, cy, w, h = label\n",
+    "            print(label)\n",
+    "            img_h, img_w = image.shape[:2]\n",
+    "            x1 = int((cx - w/2)*img_w)\n",
+    "            x2 = int((cx + w/2)*img_w)\n",
+    "            y1 = int((cy - h/2)*img_h)\n",
+    "            y2 = int((cy + h/2)*img_h)\n",
+    "            image = cv2.rectangle(image.copy(), (x1, y1), (x2, y2), color=(255,0,0), thickness=1)\n",
+    "            # org\n",
+    "            org = (x1, y1)\n",
+    "            # Using cv2.putText() method\n",
+    "            image = cv2.putText(image.copy(), str(cid) , org, font, FONTSCALE, color)\n",
+    "            print(cid)\n",
+    "\n",
+    "        plt.imshow(image)\n",
+    "        outimg_path = os.path.join(\"signals/dataset/refined\", imagename)  # Change extension as needed\n",
+    "        if cv2.imwrite(outimg_path, image):\n",
+    "            print(f\"Image saved successfully: {outimg_path}\")\n",
+    "        else:\n",
+    "            print(\"Failed to save image.\")\n"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "40536107-2590-4652-a80c-36982dbce305",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "#gets the users input on what labels they would like to change\n",
+    "changeimagename = input(\"What image would you like to update EX:1,14\")\n",
+    "edit = input(\"What labels would you like to edit\")\n"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "id": "e7bf17a7",
+   "metadata": {},
+   "source": []
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "541826db-e898-4936-870a-770363d88b03",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "#creates output path for img for widget\n",
+    "changeimagename = changeimagename.replace(\".\", \",\")\n",
+    "output_path = os.path.join(\"signals/dataset/refined/\", (changeimagename  + \"image.png\"))\n",
+    "print(output_path)\n"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "68d626e7-71a5-47cf-b663-64e747015d44",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "#creates widget information\n",
+    "widget = BBoxWidget(\n",
+    "    image= output_path,\n",
+    "    classes= ['signal'],\n",
+    ")\n"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "06e8e203-847c-4aef-8e28-7396764897b7",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "@widget.on_submit\n",
+    "def submit():\n",
+    "    \"\"\"\n",
+    "    sets up widget\n",
+    "    \"\"\"\n",
+    "    widget.close()\n"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "6046ce70-9441-4dea-92e3-c6f5fb6584b3",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "widget"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "0208a887-bee0-485b-ba6a-2a5e1c42023f",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "widget.bboxes"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "23c9b33a-818f-43da-95c8-72165aef6ea6",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "# Load a sigmf dataset\n",
+    "filesigmf = output_path[:-4]\n",
+    "\n",
+    "print(\"sigmf\", filesigmf)\n",
+    "signal = sigmffile.fromfile(filesigmf)\n",
+    "print(signal)\n",
+    "#initialize other global variables\n",
+    "img = plt.imread(output_path)\n",
+    "height, width = img.shape[:2]\n",
+    "edits = edit.split(\",\")\n",
+    "nlabels = []\n",
+    "labels = []\n",
+    "annotations = []\n",
+    "ydsimage= yds1[0].img\n",
+    "\n",
+    "output_path = output_path.replace(\"image_name\", \"\")\n",
+    "filemeta =  output_path.replace(\".png\", \".sigmf-meta\")\n",
+    "filetxt = output_path.replace(\".png\", \"image.txt\")\n",
+    "filetxt = filetxt.replace(\"signals/dataset/refined/\", \"\")\n",
+    "filetxt = filetxt.replace(\"imageimage\", \"image\")\n",
+    "filename = os.path.join(\"signals/annotated_dataset/labels/\" , changeimagename + \"image.txt\" )\n",
+    "#iterates through the new annotations\n",
+    "for box in widget.bboxes:\n",
+    "    # print(box)\n",
+    "    cx = (box['x'] + box['width']//2)/width\n",
+    "    cy = (box['y'] + box['height']//2)/height\n",
+    "    sx = cx - box['width']// 2\n",
+    "    ex = cx + box['width'] // 2\n",
+    "    new_width = box['width']/width\n",
+    "    new_height = box['height']/height\n",
+    "    duration = ex - sx\n",
+    "    fs = sample_rate\n",
+    "    top_freq = (float(fs)/2.0)-((box['y']/NFFT)*float(fs))+cy\n",
+    "    bottom_freq = (float(fs)/2.0)-((box['height']/NFFT)*float(fs))+cy\n",
+    "    # Retrieve annotations at index z\n",
+    "    annotations += [[cy, bottom_freq,top_freq,duration]]\n",
+    "    labels += [[cx, cy, new_width, new_height]]\n",
+    "# print(labels)\n",
+    "\n",
+    "\n",
+    "#updates meta and yds files\n",
+    "print(filetxt)\n",
+    "for y in range(len(edits)):\n",
+    "    print(y)\n",
+    "    an = signal.get_annotations()\n",
+    "    # print(an)\n",
+    "    if an[y]['core:comment'] == edits[y]:\n",
+    "        an[y]['core:sample_start'] == annotations[y][0]\n",
+    "        an[y]['core:freq_lower_edge'] = annotations[y][1]\n",
+    "        an[y]['core:freq_upper_edge'] = annotations[y][2]\n",
+    "        an[y]['core:sample_count'] =  annotations[y][3]\n",
+    "        signal.validate()\n",
+    "        # print(filemeta)\n",
+    "        signal.tofile(filemeta)\n",
+    "    # print(filename)\n",
+    "    with open(filename, \"r\") as file:\n",
+    "        for line in file:\n",
+    "            item = line.split()  # Automatically splits on whitespace\n",
+    "            if item[0] == edit[y]:  # Check if the first element matches edit[y]\n",
+    "                # Create the new label list\n",
+    "                nlabel = [item[0], labels[y][0], labels[y][1],labels[y][2], labels[y][3]]\n",
+    "                if nlabel not in nlabels:\n",
+    "                    nlabels.append(nlabel)\n",
+    "            else:\n",
+    "                nlabels.append(item)  # Append the original item if no match\n",
+    "print(nlabels)\n",
+    "\n",
+    "\n",
+    "#updates annotates_dataset txt labels\n",
+    "with open(filename, \"w\") as file:\n",
+    "    for line in nlabels:\n",
+    "        file.write(str(line[0]) + \" \"+ str(line[1]) + \" \"+ str(line[2]) + \" \"+str(line[3])+ \" \"+ str(line[4]) + \"\\n\")\n",
+    "\n",
+    "# saves and displays updated photo\n",
+    "INDEX = 0\n",
+    "for x in range (len(yds1)):\n",
+    "    imgname = os.listdir(yds1.root_filepath + \"images\")[x]\n",
+    "    imgname =imgname[:-3] + \"png\"\n",
+    "    print(imagename)\n",
+    "    if imgname == imagename:\n",
+    "        INDEX = x\n",
+    "print(INDEX)\n",
+    "\n",
+    "image= yds1[INDEX].img\n",
+    "boxclass = []\n",
+    "labels = nlabels\n",
+    "image = 1 - image.numpy()\n",
+    "\n",
+    "# font\n",
+    "FONT = cv2.FONT_HERSHEY_SIMPLEX\n",
+    "# fontScale\n",
+    "FONTSCALE = 1\n",
+    "# Blue color in BGR\n",
+    "color = (0, 255, 0)\n",
+    "image = (np.stack([image[0,:,:]]*3).transpose(1,2,0)*255).astype(np.uint8)\n",
+    "for label in labels:\n",
+    "    cid, cx, cy, w, h = label\n",
+    "    img_h, img_w = image.shape[:2]\n",
+    "    x1 = int((float(cx) - float(w)/2)*img_w)\n",
+    "    x2 = int((float(cx) + float(w)/2)*img_w)\n",
+    "    y1 = int((float(cy) - float(h)/2)*img_h)\n",
+    "    y2 = int((float(cy) + float(h)/2)*img_h)\n",
+    "    image = cv2.rectangle(image.copy(), (x1, y1), (x2, y2), color=(255,0,0), thickness=1)\n",
+    "    # org\n",
+    "    org = (x1, y1)\n",
+    "    # Using cv2.putText() method\n",
+    "    image = cv2.putText(image.copy(), str(cid) , org, FONT, FONTSCALE, color)\n",
+    "\n",
+    "plt.imshow(image)\n",
+    "if cv2.imwrite(output_path, image):\n",
+    "    print(f\"Image saved successfully: {output_path}\")\n",
+    "else:\n",
+    "    print(\"Failed to save image.\")"
+   ]
+  }
+ ],
+ "metadata": {
+  "kernelspec": {
+   "display_name": "Python 3",
+   "language": "python",
+   "name": "python3"
+  },
+  "language_info": {
+   "codemirror_mode": {
+    "name": "ipython",
+    "version": 3
+   },
+   "file_extension": ".py",
+   "mimetype": "text/x-python",
+   "name": "python",
+   "nbconvert_exporter": "python",
+   "pygments_lexer": "ipython3",
+   "version": "3.10.12"
+  }
+ },
+ "nbformat": 4,
+ "nbformat_minor": 5
+}
diff --git a/torchsig/__init__.py b/torchsig/__init__.py
index 8c0d5d5bb..e64732020 100755
--- a/torchsig/__init__.py
+++ b/torchsig/__init__.py
@@ -1 +1,2 @@
+# pylint: disable=missing-module-docstring
 __version__ = "2.0.0"
diff --git a/torchsig/datasets/__init__.py b/torchsig/datasets/__init__.py
index e69de29bb..206c74e55 100755
--- a/torchsig/datasets/__init__.py
+++ b/torchsig/datasets/__init__.py
@@ -0,0 +1,12 @@
+"""TorchSig datasets
+"""
+from .dataset_metadata import DatasetMetadata, ExternalDatasetMetadata
+from .datasets import TorchSigIterableDataset, StaticTorchSigDataset, ExternalTorchSigDataset
+
+__all__ = [
+    "DatasetMetadata",
+    "ExternalDatasetMetadata",
+    "TorchSigIterableDataset",
+    "StaticTorchSigDataset",
+    "ExternalTorchSigDataset"
+]
\ No newline at end of file
diff --git a/torchsig/datasets/datamodules.py b/torchsig/datasets/datamodules.py
index 7911f5b50..5a8d24510 100644
--- a/torchsig/datasets/datamodules.py
+++ b/torchsig/datasets/datamodules.py
@@ -1,100 +1,125 @@
 """PyTorch Lightning DataModules
-
 Learn More: https://lightning.ai/docs/pytorch/stable/data/datamodule.html
-
 If dataset does not exist at root, creates new dataset and writes to disk
-If dataset does exsit, simply loaded it back in
+If dataset does exist, simply loaded it back in
 """
 
 from __future__ import annotations
 
 # TorchSig
-from torch.utils.data import DataLoader
 from torchsig.datasets.dataset_metadata import DatasetMetadata
 from torchsig.datasets.datasets import TorchSigIterableDataset, StaticTorchSigDataset
 from torchsig.datasets.dataset_utils import to_dataset_metadata
 from torchsig.utils.writer import DatasetCreator
-from torchsig.utils.file_handlers.base_handler import TorchSigFileHandler
-from torchsig.utils.file_handlers.zarr import ZarrFileHandler
+from torchsig.utils.file_handlers import BaseFileHandler
+from torchsig.utils.file_handlers.hdf5 import HDF5Writer as DEFAULT_WRITER, HDF5Reader as DEFAULT_READER
 from torchsig.transforms.base_transforms import Transform
-from torchsig.transforms.target_transforms import TargetTransform
+from torchsig.transforms.metadata_transforms import MetadataTransform
+from torchsig.transforms.impairments import Impairments
 from torchsig.datasets.default_configs.loader import get_default_yaml_config
 
 # Third Party
 import pytorch_lightning as pl
+from torch.utils.data import DataLoader, random_split
+import numpy as np
 
 # Built-In
 from typing import Callable, List
 from pathlib import Path
 
-
 class TorchSigDataModule(pl.LightningDataModule):
-    """
-    PyTorch Lightning DataModule for managing TorchSig datasets.
-
-    Args:
-        root (str): The root directory where datasets are stored or created.
-        train_metadata (DatasetMetadata | str | dict): Metadata for the training dataset.
-        val_metadata (DatasetMetadata | str | dict): Metadata for the validation dataset.
-        batch_size (int, optional): The batch size for data loading. Defaults to 1.
-        num_workers (int, optional): The number of worker processes for data loading. Defaults to 1.
-        collate_fn (Callable, optional): A function to collate data into batches.
-        create_batch_size (int, optional): The batch size used during dataset creation. Defaults to 8.
-        create_num_workers (int, optional): The number of workers used during dataset creation. Defaults to 4.
-        file_handler (TorchSigFileHandler, optional): The file handler for managing data storage. Defaults to ZarrFileHandler.
-        overwrite (bool, optional): Overwrites data on disk. Defaults to False.
-        transforms (list, optional): A list of transformations to apply to the input data. Defaults to an empty list.
-        target_transforms (list, optional): A list of transformations to apply to the target labels. Defaults to an empty list.
+    """PyTorch Lightning DataModule for creating and loading TorchSig datasets.
+
+    This DataModule handles:
+      - Dataset creation or loading from disk via a file handler.
+      - Splitting into train/val/test subsets.
+      - Batching, collation, and worker seeding for training.
+
+    Attributes:
+        root (Path): Directory where datasets are stored or created.
+        dataset_size (int): Total number of samples in the dataset.
+        dataset_splits (List[float] | List[int]): Fractions or counts for train/val/test splits.
+        dataset_metadata (DatasetMetadata): Metadata describing the dataset.
+        impairment_level (int | None): Optional interference level for synthetic impairments.
+        transforms (List[Transform]): Transforms applied to the input data.
+        component_transforms (List[Transform]): Transforms applied to individual signal components.
+        target_labels (List[str] | None): Names of target metadata fields to include.
+        batch_size (int): Batch size for the training/validation/testing DataLoaders.
+        num_workers (int): Number of worker processes for data loading.
+        collate_fn (Callable | None): Custom collate function for batching.
+        create_batch_size (int): Batch size used during on-disk dataset creation.
+        create_num_workers (int): Number of workers used during dataset creation.
+        file_writer (Type[BaseFileHandler]): FileHandler class for disk I/O.
+        file_reader (Type[BaseFileHandler]): FileReader class for disk I/O.
+        overwrite (bool): If True, existing on-disk data will be overwritten.
+        seed (int | None): Optional random seed for reproducibility.
+        train (StaticTorchSigDataset): Initialized training dataset (set in `setup()`).
+        val (StaticTorchSigDataset): Initialized validation dataset (set in `setup()`).
+        test (StaticTorchSigDataset): Initialized test dataset (set in `setup()`).
     """
     def __init__(
         self,
         root: str,
-        train_metadata: DatasetMetadata | str | dict,
-        val_metadata: DatasetMetadata | str | dict,
+        dataset_metadata: DatasetMetadata | str | dict,
+        dataset_size: int,
+        dataset_splits: List[float] | List[int] = [0.70, 0.20, 0.10],
         # dataloader params
         batch_size: int = 1,
         num_workers: int = 1,
         collate_fn: Callable = None,
+
         # dataset creator params
         create_batch_size: int = 8,
         create_num_workers: int = 4,
-        file_handler: TorchSigFileHandler = ZarrFileHandler,
+        file_writer: BaseFileHandler = DEFAULT_WRITER,
+        file_reader: BaseFileHandler = DEFAULT_READER,
         overwrite: bool = False,
-        # applied after dataset written to disk
-        transforms: list = [],
-        target_transforms: list = [],
+        # tranforms
+        impairment_level: int = None,
+        transforms: List[Transform] = [],
+        component_transforms: List[Transform] = [],
+        target_labels: List[str] = None,
+        seed: int = None,
     ):
-        """
-        Initializes the TorchSigDataModule with the provided parameters.
+        """Initialize the TorchSigDataModule.
 
         Args:
-            root (str): The root directory where datasets are stored or created.
-            train_metadata (DatasetMetadata | str | dict): Metadata for the training dataset.
-            val_metadata (DatasetMetadata | str | dict): Metadata for the validation dataset.
-            batch_size (int, optional): The batch size for data loading. Defaults to 1.
-            num_workers (int, optional): The number of worker processes for data loading. Defaults to 1.
-            collate_fn (Callable, optional): A function to collate data into batches.
-            create_batch_size (int, optional): The batch size used during dataset creation. Defaults to 8.
-            create_num_workers (int, optional): The number of workers used during dataset creation. Defaults to 4.
-            file_handler (TorchSigFileHandler, optional): The file handler for managing data storage. Defaults to ZarrFileHandler.
-            transforms (list, optional): A list of transformations to apply to the input data. Defaults to an empty list.
-            target_transforms (list, optional): A list of transformations to apply to the target labels. Defaults to an empty list.
+            root (str): Path to store or load the dataset.
+            dataset_metadata (DatasetMetadata | str | dict): Metadata object, YAML file path, or dict describing classes and settings.
+            dataset_size (int): Total number of samples to generate or load.
+            dataset_splits (List[float] | List[int], optional): Fractions or counts for train/val/test splits. Defaults to [0.70, 0.20, 0.10].
+            batch_size (int, optional): Batch size for data loaders. Defaults to 1.
+            num_workers (int, optional): Number of worker processes for data loading. Defaults to 1.
+            collate_fn (Callable, optional): Custom function to collate batch samples. Defaults to None.
+            create_batch_size (int, optional): Batch size when writing data to disk. Defaults to 8.
+            create_num_workers (int, optional): Workers used when creating the on-disk dataset. Defaults to 4.
+            file_writer (Type[BaseFileHandler]): FileWriter class for disk I/O.
+            file_reader (Type[BaseFileHandler]): FileReader class for disk I/O.
+            overwrite (bool, optional): If True, existing data at `root` will be overwritten. Defaults to False.
+            impairment_level (int, optional): Level of synthetic impairment to apply. Defaults to None (no impairment).
+            transforms (List[Transform], optional): List of transforms applied to each sample’s input. Defaults to [].
+            component_transforms (List[Transform], optional): Transforms applied to individual signal components. Defaults to [].
+            target_labels (List[str], optional): Names of metadata fields to include. Defaults to None.
+            seed (int, optional): Seed for randomness and reproducibility. Defaults to None.
         """
         # read from yaml or dataset metadata or code inputs
         super().__init__()
-
+        # filepaths
         self.root = Path(root)
-        self.train_metadata = to_dataset_metadata(train_metadata)
-        self.val_metadata = to_dataset_metadata(val_metadata)
-        self.impairment_level = self.train_metadata.impairment_level
-
-        self.new_dataset_class = TorchSigIterableDataset
-        self.static_dataset_class = StaticTorchSigDataset
-
+        self.dataset_size = dataset_size
+        self.dataset_splits = dataset_splits
+        # metadatas
+        self.dataset_metadata = to_dataset_metadata(dataset_metadata)
+        # transforms
+        self.impairment_level = impairment_level
         self.transforms = transforms
-        self.target_transforms = target_transforms
-
-
+        self.component_transforms = component_transforms
+        if self.impairment_level is not None:
+            # add impairment transforms
+            impairment_transforms = Impairments(level=self.impairment_level)
+            self.transforms = impairment_transforms.dataset_transforms + self.transforms
+            self.component_transforms = impairment_transforms.signal_transforms + self.component_transforms
+        self.target_labels = target_labels
         # initialize dataloader params
         self.batch_size = batch_size
         self.num_workers = num_workers
@@ -103,80 +128,61 @@ class TorchSigDataModule(pl.LightningDataModule):
         # dataset creator params
         self.create_batch_size = create_batch_size
         self.create_num_workers = create_num_workers
-        self.file_handler = file_handler
+        self.file_writer = file_writer
+        self.file_reader = file_reader
         self.overwrite = overwrite
-
+        
         # to be initialized in setup()
-        self.train: Optional[self.static_dataset_class] = None
-        self.val: Optional[self.static_dataset_class] = None
-        self.test: Optional[self.static_dataset_class] = None
-
-
+        self.train: StaticTorchSigDataset = None
+        self.val: StaticTorchSigDataset = None
+        self.test: StaticTorchSigDataset = None
+        self.seed = seed
+        
 
     def prepare_data(self) -> None:
         """
         Prepares the dataset by creating new datasets if they do not exist on disk.
         The datasets are created using the `DatasetCreator` class.
-
         If the dataset already exists on disk, it is loaded back into memory.
         """
-        # Creates dataset if does not exist on disk or overwrite
-        train_dataset = self.new_dataset_class(
-            dataset_metadata = self.train_metadata,
+        dataset = TorchSigIterableDataset(
+            dataset_metadata = self.dataset_metadata,
+            transforms = self.transforms,
+            seed=self.seed
         )
-        train_creator = DatasetCreator(
-            dataset = train_dataset,
-            root = self.root,
-            overwrite = self.overwrite,
-            file_handler = self.file_handler,
+        loader = DataLoader(
+            dataset = dataset,
             batch_size = self.create_batch_size,
             num_workers = self.create_num_workers,
-            train = True,
-        )
-        print(f"Train Dataset: Impairment Level {self.train_metadata.impairment_level}, {self.train_metadata.num_samples} samples")
-        train_creator.create()
-
-        val_dataset = self.new_dataset_class(
-            dataset_metadata = self.val_metadata
+            collate_fn = self.collate_fn
         )
-        val_creator = DatasetCreator(
-            dataset = val_dataset,
+        creator = DatasetCreator(
+            dataloader = loader,
+            dataset_length = self.dataset_size,
             root = self.root,
             overwrite = self.overwrite,
-            file_handler = self.file_handler,
-            batch_size = self.create_batch_size,
-            num_workers = self.create_num_workers,
-            train = False,
+            file_writer = self.file_writer,
         )
-        print(f"Val Dataset: Impairment Level {self.val_metadata.impairment_level}, {self.val_metadata.num_samples} samples")
-        val_creator.create()
+        # breakpoint()
+        print(f"Full Dataset: Impairment Level {self.impairment_level}, {self.dataset_size} dataset size")
+        creator.create()
 
     def setup(self, stage: str = 'train') -> None:
         """
         Sets up the train and validation datasets for the given stage.
-
         Args:
             stage (str, optional): The stage of the DataModule, typically 'train' or 'test'. Defaults to 'train'.
         """
-        self.train = self.static_dataset_class(
+        full_dataset = StaticTorchSigDataset(
             root = self.root,
-            impairment_level = self.impairment_level,
-            transforms = self.transforms,
-            target_transforms = self.target_transforms,
-            train = True,
-        )
-        self.val = self.static_dataset_class(
-            root = self.root,
-            impairment_level = self.impairment_level,
-            transforms = self.transforms,
-            target_transforms = self.target_transforms,
-            train = False
+            file_handler_class=self.file_reader,
+            target_labels=self.target_labels
         )
+        self.train, self.val, self.test = random_split(full_dataset, self.dataset_splits)
 
     def train_dataloader(self) -> DataLoader:
         """
         Returns the DataLoader for the training dataset.
-
         Returns:
             DataLoader: A PyTorch DataLoader for the training dataset.
         """
@@ -187,11 +193,9 @@ class TorchSigDataModule(pl.LightningDataModule):
             num_workers = self.num_workers,
             collate_fn = self.collate_fn
         )
-
     def val_dataloader(self) -> DataLoader:
         """
         Returns the DataLoader for the validation dataset.
-
         Returns:
             DataLoader: A PyTorch DataLoader for the validation dataset.
         """
@@ -202,13 +206,22 @@ class TorchSigDataModule(pl.LightningDataModule):
             num_workers = self.num_workers,
             collate_fn = self.collate_fn
         )
-
-
-
-
+    
+    def test_dataloader(self) -> DataLoader:
+        """
+        Returns the DataLoader for the test dataset.
+        Returns:
+            DataLoader: A PyTorch DataLoader for the test dataset.
+        """
+        return DataLoader(
+            dataset = self.test,
+            batch_size = self.batch_size,
+            shuffle = False,
+            num_workers = self.num_workers,
+            collate_fn = self.collate_fn
+        )
 ### DataModules for Official Dataset
 ### uses default YAML configs in torchsig/datasets/default_configs
-
 class OfficialTorchSigDataModule(TorchSigDataModule):
     """
     A PyTorch Lightning DataModule for official TorchSignal datasets.
@@ -217,7 +230,6 @@ class OfficialTorchSigDataModule(TorchSigDataModule):
     for datasets with official configurations instead of using custom metadata. 
     It initializes the train and validation metadata based on the dataset type and 
     impairment level.
-
     Args:
         root (str): Root directory where the dataset is stored.
         impairment_level (int): Defines the impairment level of the dataset.
@@ -226,39 +238,40 @@ class OfficialTorchSigDataModule(TorchSigDataModule):
         collate_fn (Callable, optional): Function to merge a list of samples into a batch. Default is None.
         create_batch_size (int, optional): Batch size used during dataset creation. Default is 8.
         create_num_workers (int, optional): Number of workers used during dataset creation. Default is 4.
-        file_handler (TorchSigFileHandler, optional): File handler used to read/write dataset. Default is ZarrFileHandler.
+        file_handler (BaseFileHandler, optional): File handler used to read/write dataset. Default is HDF5FileHandler.
         transforms (Transform | List[Callable | Transform], optional): List of transforms applied to dataset. Default is empty list.
-        target_transforms (TargetTransform | List[Callable | TargetTransform], optional): List of transforms applied to targets. Default is empty list.
+        target_transforms (MetadataTransform | List[Callable | MetadataTransform], optional): List of transforms applied to targets. Default is empty list.
     """
-
     def __init__(
         self,
         root: str,
         impairment_level: int,
+
         # dataloader params
         batch_size: int = 1,
         num_workers: int = 1,
         collate_fn: Callable = None,
+
         # dataset creator params
         create_batch_size: int = 8,
         create_num_workers: int = 4,
-        file_handler: TorchSigFileHandler = ZarrFileHandler,
+        file_writer: BaseFileHandler = DEFAULT_WRITER,
+        file_reader: BaseFileHandler = DEFAULT_READER,
+
         # applied after dataset written to disk
         transforms: Transform | List[Callable | Transform]  = [],
-        target_transforms: TargetTransform | List[Callable | TargetTransform] = [],
+        target_transforms: MetadataTransform | List[Callable | MetadataTransform] = [],
+        seed = None,
     ):
         # sets train and val metadata
-
         train_metadata = get_default_yaml_config(
             impairment_level = impairment_level,
             train = True
         )
-
         val_metadata = get_default_yaml_config(
             impairment_level = impairment_level,
             train = False
         )
-
         super().__init__(
             root = root,
             train_metadata = train_metadata,
@@ -268,9 +281,9 @@ class OfficialTorchSigDataModule(TorchSigDataModule):
             collate_fn = collate_fn,
             create_batch_size = create_batch_size,
             create_num_workers = create_num_workers,
-            file_handler = file_handler,
+            file_writer = file_writer,
+            file_reader = file_reader,
             transforms = transforms,
             target_transforms = target_transforms,
-        )
-
-
+            seed = seed,
+        )
\ No newline at end of file
diff --git a/torchsig/datasets/dataset_metadata.py b/torchsig/datasets/dataset_metadata.py
index c363a90dd..463628f5e 100644
--- a/torchsig/datasets/dataset_metadata.py
+++ b/torchsig/datasets/dataset_metadata.py
@@ -5,35 +5,32 @@ from __future__ import annotations
 
 # TorchSig
 from torchsig.signals.signal_lists import TorchSigSignalLists
-from torchsig.utils.random import Seedable
 from torchsig.utils.verify import (
     verify_int,
     verify_float,
-    verify_str,
     verify_distribution_list,
-    verify_list,
-    verify_transforms,
-    verify_target_transforms
+    verify_list
 )
 from torchsig.utils.printing import (
     dataset_metadata_str,
-    dataset_metadata_repr,
 )
-from torchsig.transforms.impairments import Impairments
 
 # Third Party
 import numpy as np
 from typing import Dict, List, Any
+import yaml
 
 # Built-In
-from copy import (
-    deepcopy,
-    copy
-)
+from copy import deepcopy, copy
 
+def load_dataset_metadata(filepath):
+    """loads and returns the metadata object stores at filepath"""
+    with open(filepath, 'r') as f:
+        loaded_yaml = yaml.safe_load(f)
+    return DatasetMetadata(**loaded_yaml['required']).update_from(loaded_yaml['overrides'])
 
-class DatasetMetadata(Seedable):
-    """Dataset Metdata. Contains useful information about the dataset.
+class DatasetMetadata():
+    """Dataset Metadata base class. Contains useful information about the dataset.
 
     Maintains the metadata for the parameters of the datasets, such as
     sample rate. The class holds all of the high level information
@@ -62,10 +59,9 @@ class DatasetMetadata(Seedable):
         self, 
         num_iq_samples_dataset: int, 
         fft_size: int,
-        impairment_level: int,
-        num_signals_max: int, 
-        sample_rate: float = 10e6, 
-        num_signals_min: int = 0,
+        num_signals_min: int = 1,
+        num_signals_max: int = 1,
+        sample_rate: float = 10e6,
         num_signals_distribution: np.ndarray | List[float]= None,
         snr_db_min: float = 0.0,
         snr_db_max: float = 50.0,
@@ -76,11 +72,8 @@ class DatasetMetadata(Seedable):
         signal_center_freq_min: float = None,
         signal_center_freq_max: float = None,
         cochannel_overlap_probability: float = 0.1,
-        transforms: list = [],
-        target_transforms: list = [],
         class_list: List[str] = None,
         class_distribution: np.ndarray | List[float]= None,
-        num_samples: int = None,
         **kwargs
     ):
         """Initializes Dataset Metadata
@@ -88,7 +81,6 @@ class DatasetMetadata(Seedable):
         Args:
             num_iq_samples_dataset (int): Length of I/Q array in dataset.
             fft_size (int): Size of FFT (number of bins) to be used in spectrogram.
-            impairment_level (int): Signal impairment level.
             sample_rate (float, optional): Sample rate for dataset. Defaults to 10e6.
             num_signals_min (int, optional): Minimum number of signals per sample. Defaults to 0.
             num_signals_max (int): Maximum number of signals per sample in dataset.
@@ -107,53 +99,54 @@ class DatasetMetadata(Seedable):
             target_transforms (list): List of Target Transforms to apply. Defaults to [].
             class_list (List[str], optional): Signal class name list. Defaults to TorchSigSignalLists.all_signals.
             class_distribution (np.ndarray | List[float], optional): Probabilities for each class in `class_list`. Defaults to None (uniform).
-            num_samples (int, optional): Set dataset size. For infinite dataset, set to None, Defaults to None.
 
         Raises:
             ValueError: If any of the provided parameters are invalid or incompatible.
         """    
-        super().__init__(**kwargs)
-        self._num_iq_samples_dataset = num_iq_samples_dataset
-        self._sample_rate = sample_rate
-        self._fft_size = fft_size
-        self._fft_stride = copy(self._fft_size)
-        self._num_signals_max = num_signals_max
-        self._num_signals_min = self._num_signals_max if num_signals_min is None else num_signals_min
-        self._num_signals_range = np.arange(start=self._num_signals_min, stop=num_signals_max + 1, dtype=int)
-        self._num_signals_distribution = num_signals_distribution
-        self._transforms = transforms
-        self._target_transforms = target_transforms
-        self._impairment_level = impairment_level
-        self._impairments = self._initialize_impairments() # will be updated in subclasses
-        self._impairments.add_parent(self)
-
-        self._class_list = TorchSigSignalLists.all_signals if class_list is None else class_list
-        self._class_distribution = class_distribution
-
-        self._num_samples = num_samples
+        #super().__init__(**kwargs)
+        self._kwargs = kwargs
+        
+        self.num_iq_samples_dataset = num_iq_samples_dataset
+        self.sample_rate = sample_rate
+        self.fft_size = fft_size
+        self.fft_stride = copy(self.fft_size)
+        self.num_signals_max = num_signals_max
+        self.num_signals_min = self.num_signals_max if num_signals_min is None else num_signals_min
+        self.num_signals_range = np.arange(start=self.num_signals_min, stop=num_signals_max + 1, dtype=int)
+        self.num_signals_distribution = num_signals_distribution
 
+        self.class_list = TorchSigSignalLists.all_signals if class_list is None else class_list
+        self.class_distribution = class_distribution
 
-        self._snr_db_max = snr_db_max
-        self._snr_db_min = snr_db_min
+        self.snr_db_max = snr_db_max
+        self.snr_db_min = snr_db_min
 
-        self._signal_duration_min = signal_duration_min if signal_duration_min != None else 0.10*self._num_iq_samples_dataset/sample_rate
-        self._signal_duration_max = signal_duration_max if signal_duration_max != None else 0.20*self._num_iq_samples_dataset/sample_rate
+        self.signal_duration_min = signal_duration_min if signal_duration_min is not None else 0.10*self.num_iq_samples_dataset/sample_rate
+        self.signal_duration_max = signal_duration_max if signal_duration_max is not None else 0.20*self.num_iq_samples_dataset/sample_rate
 
-        self._signal_bandwidth_min = signal_bandwidth_min if signal_bandwidth_min != None else self._sample_rate/20
-        self._signal_bandwidth_max = signal_bandwidth_max if signal_bandwidth_max != None else self._sample_rate/10
+        self.signal_bandwidth_min = signal_bandwidth_min if signal_bandwidth_min is not None else self.sample_rate/20
+        self.signal_bandwidth_max = signal_bandwidth_max if signal_bandwidth_max is not None else self.sample_rate/10
 
-        self._signal_center_freq_min = signal_center_freq_min if signal_center_freq_min != None else self.frequency_min
-        self._signal_center_freq_max = signal_center_freq_max if signal_center_freq_max != None else self.frequency_max
+        self.signal_center_freq_min = signal_center_freq_min if signal_center_freq_min is not None else self.frequency_min
+        self.signal_center_freq_max = signal_center_freq_max if signal_center_freq_max is not None else self.frequency_max
 
-        self._cochannel_overlap_probability = cochannel_overlap_probability
+        self.cochannel_overlap_probability = cochannel_overlap_probability
 
         # provide a noise power reference in dB
-        self._noise_power_db = 0
+        self.noise_power_db = 0
 
         # run _verify() to ensure metadata is valid
-        self._verify()
+        self.verify()
 
-    def _verify(self) -> None:
+    def update_from(self, attr_dict):
+        """updates the fields of this metadata object with the values in attr_dict; good for joining metadata together
+            modifies existing object, and return without copying
+        """
+        for key in attr_dict.keys():
+            setattr(self, key, attr_dict[key])
+        return self
+
+    def verify(self) -> None:
         """Verify that metadata is valid.
 
         This method checks the configuration of the metadata, ensuring all parameters
@@ -164,153 +157,127 @@ class DatasetMetadata(Seedable):
             ValueError: If any dataset configuration is invalid.
         """
 
-        # Transforms
-        self._transforms = verify_transforms(self._transforms)
-        for transform in self._transforms:
-            if isinstance(transform, Seedable):
-                transform.add_parent(self)
-
-        # Target Transforms
-        self._target_transforms = verify_target_transforms(self._target_transforms)
-        for transform in self._target_transforms:
-            if isinstance(transform, Seedable):
-                transform.add_parent(self)
-
-        self._class_distribution = verify_distribution_list(
-            self._class_distribution, 
+        self.class_distribution = verify_distribution_list(
+            self.class_distribution, 
             len(self.class_list), 
             "class_distribution", 
             "class_list"
         )
-        self._num_signals_distribution = verify_distribution_list(
-            self._num_signals_distribution, 
-            len(self._num_signals_range), 
+        self.num_signals_distribution = verify_distribution_list(
+            self.num_signals_distribution, 
+            len(self.num_signals_range), 
             "num_signals_distribution", 
             "[num_signals_min, num_signals_max]"
         )
 
-        self._class_list = verify_list(self._class_list, "class_list")
+        self.class_list = verify_list(self.class_list, "class_list")
 
         # check all of the input parameters
-        self._sample_rate = verify_float(
-            self._sample_rate,
+        self.sample_rate = verify_float(
+            self.sample_rate,
             name = "sample_rate",
             low = 0.0,
             exclude_low = True
         )
-        
-        self._impairment_level = verify_int(
-            self._impairment_level,
-            name = "impairment_level",
-            low = 0,
-            high = 2
-        )
-
-        self._num_iq_samples_dataset = verify_int(
-            self._num_iq_samples_dataset,
-            name = "num_iq_samples_dataset",
-            low = 0,
-            exclude_low = True
-        )
 
-        self._fft_size = verify_int(
-            self._fft_size,
+        self.fft_size = verify_int(
+            self.fft_size,
             name = "fft_size",
             low = 0,
             exclude_low = True
         )
 
-        self._fft_stride = verify_int(
-            self._fft_stride,
+        self.fft_stride = verify_int(
+            self.fft_stride,
             name = "fft_stride",
             low = 0,
-            high = self._fft_size,
+            high = self.fft_size,
             exclude_low = True,
         )
 
-        self._num_signals_max = verify_int(
-            self._num_signals_max,
+        
+        self.num_iq_samples_dataset = verify_int(
+            self.num_iq_samples_dataset,
+            name = "num_iq_samples_dataset",
+            low = 0,
+            exclude_low = True
+        )
+
+        self.num_signals_max = verify_int(
+            self.num_signals_max,
             name = "num_signals_max",
             low = 0
         )
 
-        self._num_signals_min = verify_int(
-            self._num_signals_min,
+        self.num_signals_min = verify_int(
+            self.num_signals_min,
             name = "num_signals_min",
             low = 0,
-            high = self._num_signals_max
+            high = self.num_signals_max
         )
 
-        self._snr_db_max = verify_float(
-            self._snr_db_max,
+        self.snr_db_max = verify_float(
+            self.snr_db_max,
             name = "snr_db_max",
             low = None,
         )
 
-        self._snr_db_min = verify_float(
-            self._snr_db_min,
+        self.snr_db_min = verify_float(
+            self.snr_db_min,
             name = "snr_db_min",
             low = None,
-            high = self._snr_db_max
+            high = self.snr_db_max
         )
 
-        self._signal_duration_max = verify_float(
-            self._signal_duration_max,
+        self.signal_duration_max = verify_float(
+            self.signal_duration_max,
             name = "signal_duration_max",
             low = self.dataset_duration_min,
             high = self.dataset_duration_max
         )
 
-        self._signal_duration_min = verify_float(
-            self._signal_duration_min,
+        self.signal_duration_min = verify_float(
+            self.signal_duration_min,
             name = "signal_duration_min",
             low = self.dataset_duration_min,
             high = self.dataset_duration_max
         )
 
-        self._signal_bandwidth_min = verify_float(
-            self._signal_bandwidth_min,
+        self.signal_bandwidth_min = verify_float(
+            self.signal_bandwidth_min,
             name = "signal_bandwidth_min",
             low = self.dataset_bandwidth_min,
             high = self.dataset_bandwidth_max
         )
 
-        self._signal_bandwidth_max = verify_float(
-            self._signal_bandwidth_max,
+        self.signal_bandwidth_max = verify_float(
+            self.signal_bandwidth_max,
             name = "signal_bandwidth_max",
             low = self.dataset_bandwidth_min,
             high = self.dataset_bandwidth_max
         )
 
-        self._signal_center_freq_min = verify_float(
-            self._signal_center_freq_min,
+        self.signal_center_freq_min = verify_float(
+            self.signal_center_freq_min,
             name = "signal_center_freq_min",
             low = self.dataset_center_freq_min,
             high = self.dataset_center_freq_max
         )
 
-        self._signal_center_freq_max = verify_float(
-            self._signal_center_freq_max,
+        self.signal_center_freq_max = verify_float(
+            self.signal_center_freq_max,
             name = "signal_center_freq_max",
             low = self.dataset_center_freq_min,
             high = self.dataset_center_freq_max
         )
 
-        self._cochannel_overlap_probability = verify_float(
-            self._cochannel_overlap_probability,
+        self.cochannel_overlap_probability = verify_float(
+            self.cochannel_overlap_probability,
             name = "cochannel_overlap_probability",
             low = 0,
             high = 1
         )
 
-        if self._num_samples is not None:
-            self._num_samples = verify_int(
-                self._num_samples,
-                name = "num_samples",
-                low = 0,
-                exclude_low = True
-            )
-
         # check derived values
         
         verify_float(
@@ -351,18 +318,6 @@ class DatasetMetadata(Seedable):
             exclude_low = True
         )
 
-    def _initialize_impairments(self) -> Impairments:
-        """Initializes and returns an instance of the Impairments class.
-        
-        This method creates and returns an instance of the `Impairments` class 
-        initialized with the current `impairment_level` of the dataset. It models 
-        the impairments applied to the wideband signals.
-        
-        Returns:
-            Impairments: A new instance of the `Impairments` class.
-        """
-        return Impairments(self.impairment_level)
-
     def __str__(self) -> str:
         return dataset_metadata_str(self)
 
@@ -389,63 +344,55 @@ class DatasetMetadata(Seedable):
         # organize fields by area
 
         required = {
-            'num_iq_samples_dataset': self._num_iq_samples_dataset,
-            'impairment_level': self._impairment_level,
-            'fft_size': self._fft_size,
-            'num_signals_max': self._num_signals_max
+            'num_iq_samples_dataset': self.num_iq_samples_dataset,
+            'fft_size': self.fft_size,
         }
 
         overrides = {
-            'num_samples': self._num_samples,
-            'sample_rate': self._sample_rate,
-            'num_signals_min': self._num_signals_min,
-            'num_signals_distribution': "uniform" if self._num_signals_distribution is None else self._num_signals_distribution.tolist(),
-            'snr_db_min': self._snr_db_min,
+            'sample_rate': self.sample_rate,
+            'num_signals_min': self.num_signals_min,
+            'num_signals_max': self.num_signals_max,
+            'num_signals_distribution': "uniform" if self.num_signals_distribution is None else self.num_signals_distribution.tolist(),
+            'snr_db_min': self.snr_db_min,
             'snr_db_max': self.snr_db_max,
-            'signal_duration_min': self._signal_duration_min,
-            'signal_duration_max': self._signal_duration_max,
-            'signal_bandwidth_min': self._signal_bandwidth_min,
-            'signal_bandwidth_max': self._signal_bandwidth_max,
-            'signal_center_freq_min': self._signal_center_freq_min,
-            'signal_center_freq_max': self._signal_center_freq_max,
-            'cochannel_overlap_probability': self._cochannel_overlap_probability,
-            'class_list': deepcopy(self._class_list),
-            'class_distribution': "uniform" if self._class_distribution is None else self._class_distribution.tolist(),
-            'seed': self.rng_seed
+            'signal_duration_min': self.signal_duration_min,
+            'signal_duration_max': self.signal_duration_max,
+            'signal_bandwidth_min': self.signal_bandwidth_min,
+            'signal_bandwidth_max': self.signal_bandwidth_max,
+            'signal_center_freq_min': self.signal_center_freq_min,
+            'signal_center_freq_max': self.signal_center_freq_max,
+            'cochannel_overlap_probability': self.cochannel_overlap_probability,
+            'class_list': deepcopy(self.class_list),
+            'class_distribution': "uniform" if self.class_distribution is None else self.class_distribution.tolist(),
         }
 
         # dataset information
         dataset_info = {
-            'num_samples': "infinite" if self._num_samples is None else self._num_samples,
-            'num_iq_samples_dataset': self._num_iq_samples_dataset,
-            'fft_size': self._fft_size,
-            'sample_rate': self._sample_rate,
-            'impairment_level': self._impairment_level,
-            'seed': self.rng_seed,
-            'transforms': [str(tranform) for tranform in self._transforms],
-            'target_transforms': [str(target_transform) for target_transform in self._target_transforms],
+            'num_iq_samples_dataset': self.num_iq_samples_dataset,
+            'fft_size': self.fft_size,
+            'sample_rate': self.sample_rate,
         }
         # signal generation
         signal_gen = {
-            'num_signals_min': self._num_signals_min,
-            'num_signals_max': self._num_signals_max,
-            'num_signals_range': self._num_signals_range.tolist(),
-            'num_signals_distribution': "uniform" if self._num_signals_distribution is None else self._num_signals_distribution.tolist(),
-            'snr_db_min': self._snr_db_min,
-            'snr_db_max': self._snr_db_max,
-            'signal_duration_min': self._signal_duration_min,
-            'signal_duration_max': self._signal_duration_max,
-            'signal_bandwidth_min': self._signal_bandwidth_min,
-            'signal_bandwidth_max': self._signal_bandwidth_max,
-            'signal_center_freq_min': self._signal_center_freq_min,
-            'signal_center_freq_max': self._signal_center_freq_max,
-            'cochannel_overlap_probability': self._cochannel_overlap_probability,
-            'fft_size': self._fft_size,
+            'num_signals_min': self.num_signals_min,
+            'num_signals_max': self.num_signals_max,
+            'num_signals_range': self.num_signals_range.tolist(),
+            'num_signals_distribution': "uniform" if self.num_signals_distribution is None else self.num_signals_distribution.tolist(),
+            'snr_db_min': self.snr_db_min,
+            'snr_db_max': self.snr_db_max,
+            'signal_duration_min': self.signal_duration_min,
+            'signal_duration_max': self.signal_duration_max,
+            'signal_bandwidth_min': self.signal_bandwidth_min,
+            'signal_bandwidth_max': self.signal_bandwidth_max,
+            'signal_center_freq_min': self.signal_center_freq_min,
+            'signal_center_freq_max': self.signal_center_freq_max,
+            'cochannel_overlap_probability': self.cochannel_overlap_probability,
+            'fft_size': self.fft_size,
             'fft_frequency_resolution': self.fft_frequency_resolution,
             'fft_frequency_min': self.fft_frequency_min,
             'fft_frequency_max': self.fft_frequency_max,
-            'class_list': deepcopy(self._class_list),
-            'class_distribution': "uniform" if self._class_distribution is None else self._class_distribution.tolist(),
+            'class_list': deepcopy(self.class_list),
+            'class_distribution': "uniform" if self.class_distribution is None else self.class_distribution.tolist(),
             'signal_duration_in_samples_min': self.signal_duration_in_samples_min,
             'signal_duration_in_samples_max': self.signal_duration_in_samples_max,
         }
@@ -542,18 +489,6 @@ class DatasetMetadata(Seedable):
         """
         return int(self.dataset_duration_min*self.sample_rate)
 
-    @property
-    def dataset_center_freq_min(self) -> float:
-        """The minimum center frequency for a signal
-
-        The minimum is a boundary condition such that the center frequency
-        will not alias across the lower sampling rate boundary.
-
-        Returns:
-            float: minimum center frequency boundary for signal
-        """
-        return -self.sample_rate/2
-
     @property
     def dataset_bandwidth_min(self) -> float:
         """The minimum possible bandwidth for a signal
@@ -578,58 +513,6 @@ class DatasetMetadata(Seedable):
         """
         return self.sample_rate
 
-    @property
-    def signal_center_freq_min(self) -> None:
-        """Defines the minimum center frequency boundary for a signal.
-        Must be within the boundary provided by dataset_center_freq_min().
-
-        Returns:
-            float: minimum center frequency for signal
-        """        
-        return self._signal_center_freq_min
-
-    @property
-    def signal_center_freq_max(self) -> None:
-        """Defines the maximum center frequency boundary for a signal.
-        Must be within the boundary provided by dataset_center_freq_max().
-
-        Returns:
-            float: maximum center frequency for signal
-        """        
-        return self._signal_center_freq_max
-
-    @property
-    def cochannel_overlap_probability(self) -> None:
-        """Probability that two signals are allowed to be
-        co-channel (ex: overlap) when being placed into the
-        spectrogram.
-
-        Returns:
-            float: cochannel (overlap) probability
-        """        
-        return self._cochannel_overlap_probability
-
-    @property
-    def signal_bandwidth_min(self) -> float:
-        """Defines the minimum bandwidth for a signal in the dataset
-        Must be within the boundary provided by dataset_bandwidth_min().
-
-        Returns:
-            float: minimum bandwidth for a signal
-        """
-        return self._signal_bandwidth_min
-
-    @property
-    def signal_bandwidth_max(self) -> float:
-        """Defines the maximum bandwidth for a signal in the dataset
-        Must be within the boundary provided by dataset_bandwidth_max().
-
-        Returns:
-            float: maximumum bandwidth for a signal
-        """
-        return self._signal_bandwidth_max
-
-
     @property
     def signal_duration_in_samples_max(self) -> int:
         """The maximum duration in samples for a signal
@@ -639,7 +522,7 @@ class DatasetMetadata(Seedable):
         Returns:
             float: the maximum duration in samples for a signal
         """
-        return int(self._signal_duration_max*self.sample_rate)
+        return int(self.signal_duration_max*self.sample_rate)
 
     @property
     def signal_duration_in_samples_min(self) -> int:
@@ -650,223 +533,8 @@ class DatasetMetadata(Seedable):
         Returns:
             float: the minimum duration in samples for a signal
         """
-        return int(self._signal_duration_min*self.sample_rate)
-
-    ## Read-Only Dataset Metadata fields
-    @property
-    def num_iq_samples_dataset(self) -> int:
-        """Length of I/Q array per sample in dataset.
-
-        Returns the number of IQ samples of the dataset, this is
-        the length of the array that contains the IQ samples
-
-        Returns:
-            int: number of IQ samples
-        """
-        return self._num_iq_samples_dataset
-
-    @property
-    def sample_rate(self) -> float:
-        """Sample rate for the dataset.
-
-        Returns the sampling rate associated with the IQ samples of the dataset
-
-        Returns:
-            float: sample rate
-        """
-        return self._sample_rate
-    
-    @property
-    def num_signals_max(self) -> int:
-        """Max number of signals in each sample in the dataset
-
-        Returns the number of distinct signals dataset
-
-        Returns:
-            int: max number of signals
-        """
-        return self._num_signals_max
+        return int(self.signal_duration_min*self.sample_rate)
 
-    @property
-    def num_signals_min(self) -> int:
-        """Minimum number of signals in each sample in the dataset.
-
-        Returns:
-            int: min number of signals
-        """        
-        return self._num_signals_min
-
-    @property
-    def num_signals_range(self) -> List[int]:
-        """Range of num_signals can be generated by a sample.
-
-        Returns:
-            List[int]: List of num_signals possibilities.
-        """        
-        return self._num_signals_range
-
-    @property
-    def num_signals_distribution(self) -> List[float]:
-        """Probabilities for each value in `num_signals_range`.
-
-        Returns:
-            List[float]: Probabilties sample generates N signals per sample.
-        """        
-        return self._num_signals_distribution
-
-    @property
-    def transforms(self) -> list:
-        """Transforms to perform on signal data (after signal impairments).
-
-        Returns:
-            Transform: Transform to apply to data.
-        """        
-        return self._transforms
-
-    @property
-    def target_transforms(self) -> list:
-        """Target Transform to apply.
-
-        Returns:
-            TargetTransform: _description_
-        """        
-        return self._target_transforms
-
-    @property
-    def impairment_level(self) -> int:
-        """Level of signal impairments to apply to signals (0-2)
-
-        Returns:
-            int: Impairment level.
-        """        
-        return self._impairment_level
-
-    @property
-    def impairments(self) -> Impairments:
-        """Impairment signal and dataset transforms
-
-        Returns:
-            Impairments: Transforms or impairments
-        """        
-        return self._impairments
-
-    @property
-    def class_list(self) -> List[str]:
-        """Signal modulation class list for dataset.
-
-        Returns:
-            List[str]: List of signal modulation class names
-        """        
-        return self._class_list
-
-    @property
-    def class_distribution(self) -> np.ndarray | List[str]:
-        """Signal modulation class distribution for dataset generation.
-
-        Returns:
-            np.ndarray | List[str]: List of class probabilites.
-        """        
-        return self._class_distribution
-    
-
-    @property
-    def num_samples(self) -> int:
-        """Getter for the number of samples in the dataset.
-
-        This property returns the number of samples that the dataset is configured to have. If the value is set 
-        to `None`, it indicates that the number of samples is considered infinite.
-
-        Returns:
-            int: The number of samples in the dataset, or a representation of infinite samples if set to `None`.
-        """
-        return self._num_samples
-
-    @property
-    def noise_power_db(self) -> float:
-        """Reference noise power (dB) for the dataset
-
-        The noise power is a common reference to be used for all signal
-        generation in order to establish accurate SNR calculations.
-        The noise power dB is given in decibels. The PSD estimate of the
-        AWGN is calculated such that the averaging across all frequency
-        bins average to noise_power_db.
-
-        Returns:
-            float: noise power in dB
-        """
-        return self._noise_power_db
-
-    @property
-    def snr_db_min(self) -> float:
-        """Minimum SNR in dB for signals in dataset
-
-        Signals within the dataset will be assigned a signal to noise
-        ratio (SNR), across a range defined by a minimum and maximum
-        value. snr_db_min is the low end of the SNR range.
-
-        Returns:
-            float: minimum SNR in dB
-        """
-        return self._snr_db_min
-
-
-    @property
-    def snr_db_max(self) -> float:
-        """Minimum SNR in dB for signals in dataset
-
-        Signals within the dataset will be assigned a signal to noise
-        ratio (SNR), across a range defined by a minimum and maximum
-        value. snr_db_max is the high end of the SNR range.
-
-        Returns:
-            float: maximum SNR in dB
-        """
-        return self._snr_db_max
-
-    @property
-    def signal_duration_max(self) -> float:
-        """Getter for the maximum signal duration.
-
-        Returns:
-            float: The maximum of the signal duration.
-        """
-        return self._signal_duration_max
-    
-    @property
-    def signal_duration_min(self) -> float:
-        """Getter for the minimum signal duration.
-
-        Returns:
-            float: The minimum of the signal duration.
-        """
-        return self._signal_duration_min
-
-    @property
-    def fft_size(self) -> int:
-        """The size of FFT (number of bins) to be used in spectrogram.
-
-        The FFT size used to compute the spectrogram for the dataset.
-
-        Returns:
-            int: FFT size
-        """
-        return self._fft_size
-
-    @property
-    def fft_stride(self) -> int:
-        """The stride of input samples in FFT (number of samples)
-
-        The FFT stride controls the distance in samples between successive
-        FFTs. A smaller FFT stride means more averaging between FFTs, a
-        larger stride means less averaging between FFTs. fft_stride = fft_size
-        means there is no overlap of samples between the current and next
-        FFT. fft_stride = fft_size/2 means there is 50% overlap between the
-        input samples of the the current and next fft.
-
-        Returns:
-            int: FFT stride
-        """
-        return self._fft_stride
 
     ## Derived Read-Only Dataset Metadata
 
@@ -939,5 +607,103 @@ class DatasetMetadata(Seedable):
         return (self.sample_rate/2)*(1-epsilon)
 
 
+class ExternalDatasetMetadata():
+    """Dataset Metadata class for external data, with less required infrastructure
+    and fields than the internal metadata class that generates TorchSig datasets.
+    """
+
+    minimum_params: List[str] = [
+        'num_iq_samples_dataset',
+        'class_list',
+        'sample_rate'
+    ]
 
+    def __init__(
+        self, 
+        num_iq_samples_dataset: int,
+        class_list: List[str] = [],
+        sample_rate: float = 10e6,
+        **kwargs
+    ):
+        """Initializes ExternalDatasetMetadata.
 
+        Args:
+            num_iq_samples_dataset (int): Length of I/Q array in dataset.
+            class_list (List[str], optional): Signal class name list. Defaults to []].
+            sample_rate (float, optional): Sample rate for dataset. Defaults to 10e6.
+        Raises:
+            ValueError: If any of the provided parameters are invalid or incompatible.
+        """            
+        self.num_iq_samples_dataset = num_iq_samples_dataset
+        self.sample_rate = sample_rate
+        self.class_list = class_list
+        self.kwargs = kwargs
+
+        # run _verify() to ensure metadata is valid
+        self.verify()
+
+    def verify(self) -> None:
+        """Verify that metadata is valid.
+
+        Raises:
+            ValueError: If any dataset configuration is invalid.
+        """
+
+        # check all of the input parameters
+        self.num_iq_samples_dataset = verify_int(
+            self.num_iq_samples_dataset,
+            name = "num_iq_samples_dataset",
+            low = 0,
+            exclude_low = True
+        )
+
+    def __str__(self) -> str:
+        return f"{self.__class__.__name__}"
+
+    def __repr__(self) -> str:
+        """Returns a string representation of the DatasetMetadata instance.
+        
+        This provides a concise summary of the key parameters such as `num_iq_samples_dataset`, 
+        `sample_rate`, `num_signals_max`, and `fft_size`.
+        
+        Returns:
+            str: String representation of the DatasetMetadata instance.
+        """
+        return f"{self.__class__.__name__}(num_iq_samples_dataset={self.num_iq_samples_dataset}, sample_rate={self.sample_rate})"
+    
+    def to_dict(self) -> Dict[str, Any]:
+        """Converts the dataset metadata into a dictionary format.
+
+        This method organizes various metadata fields related to the dataset into categories such as 
+        general dataset information, signal generation parameters, and dataset writing information.
+
+        Returns:
+            Dict[str, Any]: A dictionary representation of the dataset metadata.
+        """
+        # organize fields by area
+
+        required = {
+            'num_iq_samples_dataset': self.num_iq_samples_dataset,
+
+        }
+
+        overrides = {
+            'sample_rate': self.sample_rate,
+            'class_list': deepcopy(self.class_list),
+        }
+
+        # dataset information
+        dataset_info = {
+            'num_iq_samples_dataset': self.num_iq_samples_dataset,
+            'sample_rate': self.sample_rate,
+        }
+
+        read_only = {
+            'info': dataset_info
+        }
+
+        return {
+            'required': required,
+            'overrides': overrides,
+            'read_only': read_only
+        }
diff --git a/torchsig/datasets/dataset_utils.py b/torchsig/datasets/dataset_utils.py
index 54f90705e..f805bbcfe 100644
--- a/torchsig/datasets/dataset_utils.py
+++ b/torchsig/datasets/dataset_utils.py
@@ -19,52 +19,6 @@ writer_yaml_name = "writer_info.yaml"
 
 
 
-def dataset_full_path(impairment_level: int, train: bool = None) -> str:
-    """Generates the full path for a dataset based on its type, impairment level, and whether it is for training.
-
-    Args:
-        impairment_level (int): The impairment level for the dataset (0 = clean, 1 = level 1, 2 = impaired).
-        train (bool, optional): Whether the dataset is for training (True) or validation (False). Defaults to None.
-
-    Returns:
-        str: The full path to the dataset, e.g., 'torchsig_narrowband_clean/train'.
-
-    Example:
-        full_path = dataset_full_path('narrowband', 0, True)
-        print(full_path)  # Output: 'torchsig_narrowband_clean/train'
-    """
-    impaired_names = [
-        "clean",
-        "impaired_level_1",
-        "impaired"
-    ]
-    impaired = impaired_names[impairment_level]
-    
-    # e.g., torchsig_narrowband_clean
-    full_root = f"torchsig_{impaired}"
-
-
-    if train is not None:
-        # e.g., torchsig_narrowband_clean/train
-        subpath = "train" if train else "val"
-        full_root = f"{full_root}/{subpath}"
-
-    return full_root
-
-    
-
-
-def collate_fn(batch):
-    """Collates a batch by zipping its elements together.
-
-    Args:
-        batch (tuple): A batch from the dataloader.
-
-    Returns:
-        tuple: A tuple of zipped elements, where each element corresponds to a single batch item.
-    """
-    return tuple(zip(*batch))
-
 
 def frequency_shift_signal(
     signal: Signal,
diff --git a/torchsig/datasets/datasets.py b/torchsig/datasets/datasets.py
index 9e4f39253..3996a0c80 100644
--- a/torchsig/datasets/datasets.py
+++ b/torchsig/datasets/datasets.py
@@ -5,20 +5,19 @@ from __future__ import annotations
 
 # TorchSig
 from torchsig.datasets.dataset_metadata import DatasetMetadata
-from torchsig.signals.signal_types import DatasetSignal, DatasetDict
+from torchsig.datasets.dataset_utils import (
+    to_dataset_metadata, 
+    frequency_shift_signal
+)
+from torchsig.signals.signal_types import Signal, SignalMetadataExternal
 from torchsig.signals.builder import SignalBuilder
 import torchsig.signals.builders as signal_builders
+from torchsig.transforms.base_transforms import Transform
 from torchsig.utils.random import Seedable
 from torchsig.utils.dsp import compute_spectrogram
-from torchsig.datasets.dataset_utils import (
-    to_dataset_metadata, 
-    frequency_shift_signal,
-    dataset_full_path
-)
 from torchsig.utils.printing import generate_repr_str
-from torchsig.utils.verify import verify_transforms, verify_target_transforms
-from torchsig.utils.file_handlers.zarr import ZarrFileHandler
-from torchsig.datasets.dataset_utils import dataset_yaml_name, writer_yaml_name
+from torchsig.utils.verify import verify_transforms
+from torchsig.utils.file_handlers.hdf5 import HDF5Reader as DEFAULT_READER
 from torchsig.utils.coordinate_system import (
     Coordinate,
     Rectangle,
@@ -30,25 +29,68 @@ from torch.utils.data import Dataset, IterableDataset
 import numpy as np
 
 # Built-In
-from typing import Tuple, Dict, TYPE_CHECKING
-from pathlib import Path
-import yaml
+from typing import TYPE_CHECKING, Any, Dict, List, Tuple
 import warnings
+from pathlib import Path
+
 
 if TYPE_CHECKING:
-    from torchsig.utils.file_handlers.zarr import TorchSigFileHandler
+    from torchsig.utils.file_handlers import BaseFileHandler, ExternalFileHandler
+
+def apply_transforms_and_labels_to_signal(sample, transforms, target_labels, num_signals_max = None):
+    # apply user transforms
+    for transform in transforms:
+        sample = transform(sample)
+
+    # apply metadata transforms
+    # just return data if target_labels is None or empty list
+    if target_labels is None:
+        # return Signal object
+        return sample
+    if len(target_labels) < 1:
+        # just return np.ndarray data
+        return sample.data
+    metadatas = sample.get_full_metadata()
+    targets = []
+    if len(target_labels) == 1:
+        # just 1 target label
+        # set targets to single item
+        # verify metadatas have target_label
+        #for metadata in metadatas:
+        #    if not hasattr(metadata, target_labels[0]):
+        #        raise AttributeError(f"Metadata does not have target label {target_labels[0]}: {metadata}")
+        # apply target label
+        targets = [getattr(metadata, target_labels[0]) for metadata in metadatas]
+    else:
+        # multiple target labels
+        for metadata in metadatas:
+            # for each signal metadata
+            # apply all target labels
+            #for target_label in target_labels:
+            #    # make sure metadata has target label
+            #    if not hasattr(metadata, target_label):
+            #        raise AttributeError(f"Metadata does not have target label {target_label}: {metadata}")
+            # apply target_label
+            targets += [[getattr(metadata, target_label) for target_label in target_labels]]
+
+    if num_signals_max == 1 and isinstance(targets, list) and len(targets) > 0:
+        targets = targets[0]
+
+    return sample.data, targets
 
 class TorchSigIterableDataset(IterableDataset, Seedable):
-    """Creates a new TorchSig dataset that generates data infinitely unless `num_samples` inside `dataset_metadata` is defined.
-    
+    """
     This base class provides the functionality to generate signals and write them to disk if necessary. The dataset will continue 
-    to generate samples infinitely unless a `num_samples` value is defined in the `dataset_metadata`.
-
+    to generate samples infinitely.
     """ 
+    # pylint: disable=abstract-method
     
     def __init__(
         self, 
         dataset_metadata: DatasetMetadata | str | dict,
+        component_transforms: list = [],
+        transforms: list = [],
+        target_labels: list = None,
         **kwargs
     ):
         """
@@ -60,11 +102,17 @@ class TorchSigIterableDataset(IterableDataset, Seedable):
 
         """
         Seedable.__init__(self, **kwargs)
-
-        self._dataset_metadata: DatasetMetadata = to_dataset_metadata(dataset_metadata)
-        self._dataset_metadata.add_parent(self)
-        self.num_samples_generated = 0
+        self.transforms = transforms
+        for transform in self.transforms:
+            if isinstance(transform, Seedable):
+                transform.add_parent(self)
+        self.component_transforms = component_transforms
+        for component_transform in self.component_transforms:
+            if isinstance(component_transform, Seedable):
+                component_transform.add_parent(self)
+        self.dataset_metadata: DatasetMetadata = to_dataset_metadata(dataset_metadata)
         self.builders: Dict[str, SignalBuilder] = self._initialize_builders() # initialize builders
+        self.target_labels = target_labels
 
 
     def __iter__(self):
@@ -83,65 +131,7 @@ class TorchSigIterableDataset(IterableDataset, Seedable):
         # user requesting another sample at index +1 larger than current list of generates samples
         # generate new sample
         sample = self.__generate_new_signal__()
-        
-        # apply dataset transforms
-        sample = self.dataset_metadata.impairments.dataset_transforms(sample)
-
-        # apply user transforms
-        for transform in self.dataset_metadata.transforms:
-            sample = transform(sample)
-
-        # convert to DatasetDict
-        sample = DatasetDict(signal=sample)
-
-        targets = []
-        # apply target transforms
-        for target_transform in self.dataset_metadata.target_transforms:
-            # apply transform to all metadatas
-            sample.metadata = target_transform(sample.metadata)
-            # get target outputs
-            target_transform_output = []
-            for signal_metadata in sample.metadata:
-                # extract output from metadata
-                # as required by TT target output field name
-                signal_output = []
-                for field in target_transform.targets_metadata:
-                    signal_output.append(signal_metadata[field])
-                
-                signal_output = tuple(signal_output)
-                target_transform_output.append(signal_output)
-
-            targets.append(target_transform_output)
-
-        # convert targets as a list of target transform output ordered by transform
-        # to ordered by signal
-        # e.g., [(transform 1 output for all signals), (transform 2 output for all signals), ... ] ->
-        # [signal 1 outputs, signal 2 outputs, ... ]
-        targets = list(zip(*targets))
-               
-        if len(self.dataset_metadata.target_transforms) == 0:
-            # no target transform applied
-            targets = sample.metadata
-        elif self.dataset_metadata.num_signals_max == 1 and len(targets) == 1:
-            # only one signal and only one target
-            # unwrap targets
-            targets = [item[0] if len(item) == 1 else item for row in targets for item in row]
-            # unwrap any target transform output that produced a tuple
-            targets = targets[0] if len(targets) == 1 else tuple(targets)
-        else:
-            # multiple signals and/or multiple targets
-            targets = [tuple([item[0] if len(item) == 1 else item for item in row]) for row in targets]
-            # unwrap any target transform output that produced a tuple
-            targets = [row[0] if len(row) == 1 else row for row in targets]
-
-
-        self.num_samples_generated += 1
-
-        return sample.data, targets
-
-    def reset(self):
-        """Resets the dataset to its initial state."""
-        self._dataset_metadata.num_samples_generated = 0
+        return apply_transforms_and_labels_to_signal(sample, self.transforms, self.target_labels, num_signals_max=self.dataset_metadata.num_signals_max)
     
     def _initialize_builders(self) -> Dict[str, SignalBuilder]:
         """
@@ -156,11 +146,11 @@ class TorchSigIterableDataset(IterableDataset, Seedable):
         for builder_name in signal_builders.__all__:
             builder = getattr(signal_builders, builder_name) # get builder class
             # check if class list has any of the builder's supported classes
-            matching_classes = set(self._dataset_metadata.class_list) & set(builder.supported_classes)
+            matching_classes = set(self.dataset_metadata.class_list) & set(builder.supported_classes)
             if len(matching_classes) > 0: # yes
                 for c in matching_classes:
                     # add builder
-                    builders[c] = builder(self._dataset_metadata, c,)
+                    builders[c] = builder(self.dataset_metadata, c,)
                     builders[c].add_parent(self)
         return builders
 
@@ -179,8 +169,14 @@ class TorchSigIterableDataset(IterableDataset, Seedable):
         class_str = f"{self.__class__.__name__}"
         center_width = (max_width - len(class_str)) // 2
 
+        transforms_str = [f"{t}" for t in self.transforms]
+
         return (
             f"\n{'-' * center_width} {self.__class__.__name__} {'-' * center_width}\n"
+            f"\nTransforms\n"
+            f"{'-' * max_width}\n"
+            f"{list(transforms_str)}\n"
+            f"\nTarget Labels = {self.target_labels}\n"
             f"{self.dataset_metadata}\n"
             f"\nBuilders"
             f"{'-' * max_width}\n"
@@ -231,12 +227,9 @@ class TorchSigIterableDataset(IterableDataset, Seedable):
         return iq_samples
 
 
-    def __generate_new_signal__(self) -> DatasetSignal:
+    def __generate_new_signal__(self) -> Signal:
         """Generates a new dataset signal/sample.
 
-        Args:
-            idx (int): The index for the new signal.
-
         Returns:
             DatasetSignal: A new generated dataset signal containing the data and metadata.
         """     
@@ -274,7 +267,8 @@ class TorchSigIterableDataset(IterableDataset, Seedable):
             new_signal = builder.build()
 
             # apply signal transforms
-            new_signal = self.dataset_metadata.impairments.signal_transforms(new_signal)
+            for component_transform in self.component_transforms:
+                new_signal = component_transform(new_signal)
 
             # frequency shift signal
             # after signal transforms applied at complex baseband
@@ -295,21 +289,19 @@ class TorchSigIterableDataset(IterableDataset, Seedable):
             has_overlap = self._check_if_overlap ( new_rectangle, signal_rectangle_list )
 
             # signal is used if there is no overlap OR with some random chance
-            if (has_overlap == False or self.random_generator.uniform(0,1) < self.dataset_metadata.cochannel_overlap_probability):
+            if (has_overlap is False or self.random_generator.uniform(0,1) < self.dataset_metadata.cochannel_overlap_probability):
+                num_signals_created += 1
                 # store the rectangle for future overlap checking
                 signal_rectangle_list.append( new_rectangle )
                 # place signal on iq sample cut
                 iq_samples[new_signal.metadata.start_in_samples:new_signal.metadata.stop_in_samples] += new_signal.data
                 # append the signal on the list
                 signals.append(new_signal)
-                # update signal created counter
-                num_signals_created += 1
             # else:
             #     loop back to top and attempt to recreate another signal
-
-
+        
         # form the sample (dataset object)
-        sample = DatasetSignal(data=iq_samples, signals=signals)
+        sample = Signal(data=iq_samples, component_signals=signals)
 
         return sample
 
@@ -342,7 +334,7 @@ class TorchSigIterableDataset(IterableDataset, Seedable):
         has_overlap = False
 
         # determine if overlap
-        if (len(signal_rectangle_list) > 0):
+        if len(signal_rectangle_list) > 0:
             # check to see if the current rectangle overlaps with any signals currently
             # in the spectrogram
             for reference_box in signal_rectangle_list:
@@ -353,18 +345,6 @@ class TorchSigIterableDataset(IterableDataset, Seedable):
 
         return has_overlap
 
-
-    # Read-Only properties
-
-    @property
-    def dataset_metadata(self):
-        """Returns the dataset metadata.
-
-        Returns:
-            DatasetMetadata: The dataset metadata.
-        """    
-        return self._dataset_metadata
-
     # Functions
 
     def _random_signal_class(self):     
@@ -379,66 +359,44 @@ class TorchSigIterableDataset(IterableDataset, Seedable):
 
 
 
-class StaticTorchSigDataset(Dataset):
+class StaticTorchSigDataset(Dataset, Seedable):
     """Static Dataset class, which loads pre-generated data from a directory.
-
-    This class assumes that the dataset has already been generated and saved to disk using a subclass of `NewTorchSigDataset`. 
-    It allows loading raw or processed data from disk for inference or analysis.
     
     Args:
         root (str): The root directory where the dataset is stored.
-        impairment_level (int): Defines impairment level 0, 1, 2.
         transforms (list, optional): Transforms to apply to the data (default: []).
-        target_transforms (list, optional): Target transforms to apply (default: []).
-        file_handler_class (TorchSigFileHandler, optional): Class used for reading the dataset (default: ZarrFileHandler).
+        file_handler_class (BaseFileHandler, optional): Class used for reading the dataset (default: HDF5FileHandler).
     """   
 
     def __init__(
         self,
         root: str,
-        impairment_level: int,
+        file_handler_class: BaseFileHandler = DEFAULT_READER,
         transforms: list = [],
-        target_transforms: list = [],
-        file_handler_class: TorchSigFileHandler = ZarrFileHandler,
-        train: bool = None,
-        # **kwargs
+        target_labels: list = None,
+        **kwargs
     ):
         self.root = Path(root)
-        self.impairment_level = impairment_level
-        self.transforms = transforms
-        self.target_transforms = target_transforms
-        self.file_handler = file_handler_class
-        self.train = train
-
-        # create filepath to saved dataset
-        # e.g., root/torchsig_narrowband_clean/
-        self.full_root = dataset_full_path(
-            impairment_level = self.impairment_level,
-            train = self.train
-        )
-        self.full_root = f"{self.root}/{self.full_root}"
-
-        # check dataset data type from writer_info.dataset_yaml_name
-        with open(f"{self.full_root}/{writer_yaml_name}", 'r') as f:
-            writer_info = yaml.load(f, Loader=yaml.FullLoader)
-            self.raw = writer_info['save_type'] == "raw"
+        self.reader = file_handler_class(root = self.root)
 
-        # need to create new dataset metadata from dataset_info.yaml
-        self.dataset_metadata = to_dataset_metadata(f"{self.full_root}/{dataset_yaml_name}")
+        Seedable.__init__(self, **kwargs)
+        self.transforms = transforms
+        for transform in self.transforms:
+            transform.add_parent(self)
+        self.target_labels = target_labels
 
         # dataset size
-        self.num_samples = self.file_handler.size(self.full_root)
+        self.dataset_length = len(self.reader)
+
+        self.dataset_metadata = self.reader.dataset_metadata
 
         self._verify()
 
     def _verify(self):
-        # Transforms
-        self.transforms = verify_transforms(self.transforms)
+        # check root
 
-        # Target Transforms
-        self.target_transforms = verify_target_transforms(self.target_transforms)
-        # print(self.target_transforms)
-        # print("verify")
+        if not self.root.exists():
+            raise ValueError(f"root does not exist: {self.root}")
 
 
     def __len__(self) -> int:
@@ -447,7 +405,7 @@ class StaticTorchSigDataset(Dataset):
         Returns:
             int: The number of samples in the dataset.
         """
-        return self.num_samples
+        return self.dataset_length
 
     def __getitem__(self, idx: int) -> Tuple[np.ndarray, Tuple]:
         """Retrieves a sample from the dataset by index.
@@ -456,94 +414,123 @@ class StaticTorchSigDataset(Dataset):
             idx (int): The index of the sample to retrieve.
 
         Returns:
-            Tuple[np.ndarray, Tuple]: The data and targets for the sample.
+            Tuple[np.ndarray, Tuple]file_handler: The data and targets for the sample.
 
         Raises:
             IndexError: If the index is out of bounds.
         """
-        if idx >= 0 and idx < self.__len__():
-            # load data and metadata
-            # data: np.ndarray
-            # signal_metadatas: List[dict]
-            if self.raw:
-                # loading in raw IQ data and signal metadata
-                data, signal_metadatas = self.file_handler.static_load(self.full_root, idx)
-
-                # convert to DatasetSignal
-                sample = DatasetSignal(
-                    data = data, 
-                    signals = signal_metadatas, 
-                    dataset_metadata = self.dataset_metadata,
-                )
-
-                # apply user transforms
-                for t in self.transforms:
-                    sample = t(sample)
-
-                # convert to DatasetDict
-                sample = DatasetDict(signal=sample)
-
-                # apply target transforms
-                targets = []
-                for target_transform in self.target_transforms:
-                    # apply transform to all metadatas
-                    sample.metadata = target_transform(sample.metadata)
-                    # get target outputs
-                    target_transform_output = []
-                    for signal_metadata in sample.metadata:
-                        # extract output from metadata
-                        # as required by TT target output field name
-                        signal_output = []
-                        for field in target_transform.targets_metadata:
-                            signal_output.append(signal_metadata[field])
-                        
-                        signal_output = tuple(signal_output)
-                        target_transform_output.append(signal_output)
-
-                    targets.append(target_transform_output)
-
-                # convert targets as a list of target transform output ordered by transform
-                # to ordered by signal
-                # e.g., [(transform 1 output for all signals), (transform 2 output for all signals), ... ] ->
-                # [signal 1 outputs, signal 2 outputs, ... ]
-                targets = list(zip(*targets))
-                    
-                if len(self.target_transforms) == 0:
-                    # no target transform applied
-                    targets = sample.metadata
-                elif self.dataset_metadata.num_signals_max == 1 and len(targets) == 1:
-                    # only one signal and only one target
-                    # unwrap targets
-                    targets = [item[0] if len(item) == 1 else item for row in targets for item in row]
-                    # unwrap any target transform output that produced a tuple
-                    targets = targets[0] if len(targets) == 1 else tuple(targets)
-                else:
-                    # multiple signals and/or multiple targets
-                    targets = [tuple([item[0] if len(item) == 1 else item for item in row]) for row in targets]
-                    # unwrap any target transform output that produced a tuple
-                    targets = [row[0] if len(row) == 1 else row for row in targets]
-                
-                return sample.data, targets
-            # else:
-            # loading in transformed data and targets from target transform
-            data, targets = self.file_handler.static_load(self.full_root, idx)
-
-            return data, targets
-
-        else:
-            raise IndexError(f"Index {idx} is out of bounds. Must be [0, {self.__len__()}]")
+        if 0 <= idx < len(self):
+            sample = self.reader.read(idx=idx)
+            return apply_transforms_and_labels_to_signal(sample, self.transforms, self.target_labels, num_signals_max=self.dataset_metadata.num_signals_max)
+        
+        raise IndexError(f"Index {idx} is out of bounds. Must be [0, {self.__len__() - 1}]")
     
     def __str__(self) -> str:
-        return f"{self.__class__.__name__}: {self.full_root}"
+        return f"{self.__class__.__name__}: {self.root}"
 
     def __repr__(self) -> str:
         return (
             f"{self.__class__.__name__}"
             f"(root={self.root}, "
-            f"impairment_level={self.impairment_level}, "
-            f"transforms={self.transforms.__repr__()}, "
-            f"target_transforms={self.target_transforms.__repr__()}, "
-            f"file_handler_class={self.file_handler}, "
-            f"train={self.train})"
+            f"file_handler_class={self.reader}"
         )
 
+
+
+
+
+class ExternalTorchSigDataset(Dataset):
+    """
+    Lightweight static dataset for importing external (not TorchSig generated) data and metadata from files.
+    
+    Args:
+        root (str): The root directory where the dataset is stored.
+        file_handler_class (ExternalFileHandler): Class used for reading dataset.
+        transforms (list, optional): Transforms to apply to the data (default: []).
+        target_transforms (list, optional): Target transforms to apply (default: []).        
+        
+    """
+    def __init__(
+        self, 
+        file_handler: ExternalFileHandler,
+        transforms: List[Transform] = [],  
+        target_labels: List[str] = []             
+    ):
+        self.transforms = transforms
+        self.target_labels = target_labels
+        self.file_handler = file_handler
+        self.dataset_length = self.file_handler.size()
+        self.dataset_metadata = self.file_handler.load_dataset_metadata()
+        self._verify()
+
+    
+    def _verify(self):
+        # Transforms
+        self.transforms = verify_transforms(self.transforms)   
+
+    
+    def __len__(self) -> int: 
+        return self.dataset_length
+            
+    def __getitem__(self, idx: int) -> Tuple[np.ndarray, Any]:
+        """
+        Retrieves a sample from the static dataset by index.
+
+        Args:
+            idx: sample index.
+
+        Returns:
+            Tuple[data, targets] returned data array and metadata.
+        """
+        if 0 <= idx < len(self):
+            data, signal_metadatas = self.file_handler.load(idx)
+            component_signals = []
+            for signal_metadata in signal_metadatas:
+                if not isinstance(signal_metadata, dict):
+                    raise ValueError(f"Signal metadata is not a dict: {type(signal_metadata)}.")
+                # create external signal metadata
+                esm = SignalMetadataExternal(
+                    self.dataset_metadata,
+                    **signal_metadata
+                )
+                # create component signal
+                component_signal = Signal(
+                    data = np.array([]),
+                    metadata = esm,
+                )
+                # add to component signals
+                component_signals.append(component_signal)
+            
+            # create Signal from component signals
+            sample = Signal(
+                data = data,
+                component_signals = component_signals
+            )
+
+            # apply user transforms
+            for transform in self.transforms:
+                sample = transform(sample)
+
+            # apply metadata transforms
+            # just return data if target_labels is None or empty list
+            if self.target_labels is None:
+                return sample
+            if len(self.target_labels) < 1:
+                return sample.data
+
+            metadatas = sample.get_full_metadata()
+            targets = []
+            if len(self.target_labels) == 1:
+                # just 1 target label
+                # set targets to single item
+                targets = [getattr(metadata, self.target_labels[0]) for metadata in metadatas]
+            else:
+                # multiple target labels
+                for metadata in metadatas:
+                    # for each signal metadata
+                    # apply all target labels
+                    targets += [[getattr(metadata, target_label) for target_label in self.target_labels]]
+
+            return sample.data, targets
+            
+        raise IndexError(f"Index {idx} is out of bounds. Must be [0, {self.__len__()}]")          
\ No newline at end of file
diff --git a/torchsig/datasets/default_configs/.ipynb_checkpoints/loader-checkpoint.py b/torchsig/datasets/default_configs/.ipynb_checkpoints/loader-checkpoint.py
new file mode 100644
index 000000000..be3c79e1e
--- /dev/null
+++ b/torchsig/datasets/default_configs/.ipynb_checkpoints/loader-checkpoint.py
@@ -0,0 +1,57 @@
+""" Loads default yaml configs
+"""
+
+# Built-In
+import yaml
+from pathlib import Path
+import sys
+
+sys.path.append(f"{Path(__file__).parent}")
+
+def get_default_yaml_config(
+    impairment_level: bool | int,
+    train: bool,
+    ret_config_path: bool = False
+) -> dict:
+    """Loads the default YAML configuration for a given dataset type, impairment level, and training/validation status.
+
+    This function constructs the path to the appropriate YAML configuration file based on the dataset type, impairment level, and whether the dataset is for training or validation. It then loads the YAML file and returns its contents as a dictionary. 
+
+    Args:
+        impairment_level (bool | int): The impairment level for the dataset:
+            - 0 or False for 'clean' data,
+            - 2 or True for 'impaired' data.
+        train (bool): Whether the dataset is for training (`True`) or validation (`False`).
+        ret_config_path (bool, optional): If `True`, the function also returns the path to the configuration file. Defaults to `False`.
+
+    Returns:
+        dict: The parsed dataset metadata from the YAML configuration file.
+        If `ret_config_path` is `True`, returns a tuple of the dataset metadata and the configuration file path.
+
+    Raises:
+        ValueError: If the impairment level is invalid or 1.
+    
+    Example:
+        # Load the default configuration for an impaired dataset for validation and get the config path
+        config, path = get_default_yaml_config(2, False, ret_config_path=True)
+    """
+
+    if impairment_level == 1:
+        raise ValueError("Default config does not exist for impairment level 1")
+    
+    impairment_level = "impaired" if impairment_level == 2 else "clean"
+
+    train = "train" if train else "val"
+
+    config_path = f"dataset_{impairment_level}_{train}.yaml"
+    full_config_path = f"{Path(__file__).parent}/{config_path}"
+
+    
+
+    with open(full_config_path, 'r') as f:
+        dataset_metadata = yaml.load(f, Loader=yaml.FullLoader)
+
+    if ret_config_path:
+        return dataset_metadata, config_path
+    # else:
+    return dataset_metadata
diff --git a/torchsig/datasets/default_configs/dataset_clean_train.yaml b/torchsig/datasets/default_configs/dataset_clean_train.yaml
index 8cceb9355..b988683b8 100644
--- a/torchsig/datasets/default_configs/dataset_clean_train.yaml
+++ b/torchsig/datasets/default_configs/dataset_clean_train.yaml
@@ -1,3 +1,5 @@
+# wideband 3-5 signals
+# clean, train
 required:
   num_iq_samples_dataset: 1048576 # 1024^2
   fft_size: 1024
diff --git a/torchsig/datasets/default_configs/dataset_impaired_train.yaml b/torchsig/datasets/default_configs/dataset_impaired_train.yaml
index b92335906..41fef85eb 100644
--- a/torchsig/datasets/default_configs/dataset_impaired_train.yaml
+++ b/torchsig/datasets/default_configs/dataset_impaired_train.yaml
@@ -1,3 +1,6 @@
+# wideband 3-5 signals
+# impaired level 2, train
+
 required:
   num_iq_samples_dataset: 1048576 # 1024^2
   fft_size: 1024
diff --git a/torchsig/datasets/default_configs/dataset_impaired_val.yaml b/torchsig/datasets/default_configs/dataset_impaired_val.yaml
index 1157cc023..24dbd99bb 100644
--- a/torchsig/datasets/default_configs/dataset_impaired_val.yaml
+++ b/torchsig/datasets/default_configs/dataset_impaired_val.yaml
@@ -1,3 +1,5 @@
+# wideband 3-5 signals
+# impaired level 2, train
 required:
   num_iq_samples_dataset: 1048576 # 1024^2
   fft_size: 1024
diff --git a/torchsig/datasets/default_configs/datasets_clean_val.yaml b/torchsig/datasets/default_configs/datasets_clean_val.yaml
index fdf53ff53..707e3ceea 100644
--- a/torchsig/datasets/default_configs/datasets_clean_val.yaml
+++ b/torchsig/datasets/default_configs/datasets_clean_val.yaml
@@ -1,3 +1,5 @@
+# wideband 3-5 signals
+# clean, train
 required:
   num_iq_samples_dataset: 1048576 # 1024^2
   fft_size: 1024
diff --git a/torchsig/datasets/default_configs/loader.py b/torchsig/datasets/default_configs/loader.py
index d5f665432..126be1d62 100644
--- a/torchsig/datasets/default_configs/loader.py
+++ b/torchsig/datasets/default_configs/loader.py
@@ -8,6 +8,8 @@ import sys
 
 sys.path.append(f"{Path(__file__).parent}")
 
+default_config_dir = Path(__file__).parent
+
 def get_default_yaml_config(
     impairment_level: bool | int,
     train: bool,
@@ -32,11 +34,8 @@ def get_default_yaml_config(
         ValueError: If the impairment level is invalid or 1.
     
     Example:
-        # Load the default configuration for a clean narrowband dataset for training
-        config = get_default_yaml_config('narrowband', 0, True)
-
         # Load the default configuration for an impaired dataset for validation and get the config path
-        config, path = get_default_yaml_config(2, False, ret_config_path=True)
+        config, path = get_default_yaml_config(impairment_level=2, train=False, ret_config_path=True)
     """
 
     if impairment_level == 1:
@@ -58,3 +57,23 @@ def get_default_yaml_config(
         return dataset_metadata, config_path
     # else:
     return dataset_metadata
+
+def get_yaml_filename(config_filename: str) -> dict:
+    """loads yaml file in default_configs
+
+    Args:
+        config_filename (str): config filename
+
+    Raises:
+        ValueError: Invalid config filename
+
+    Returns:
+        dict: yaml loaded as dict.
+    """    
+    full_config_path = f"{Path(__file__).parent}/{config_filename}"
+    try:
+        with open(full_config_path, 'r') as f:
+            dataset_metadata = yaml.load(f, Loader=yaml.FullLoader)
+        return dataset_metadata
+    except Exception as exc:
+        raise ValueError(f"No config found at {Path(__file__).parent}: {config_filename}") from exc
\ No newline at end of file
diff --git a/torchsig/datasets/default_configs/narrowband_defaults.yaml b/torchsig/datasets/default_configs/narrowband_defaults.yaml
new file mode 100644
index 000000000..dcbd1a5bf
--- /dev/null
+++ b/torchsig/datasets/default_configs/narrowband_defaults.yaml
@@ -0,0 +1,25 @@
+# narrowband defaults
+#  single signal channelized and time-aligned at complex baseband
+required:
+  num_iq_samples_dataset: 262144
+  fft_size: 512
+  num_signals_max: 1
+  impairment_level: 0
+
+overrides:
+  num_samples: 10
+  sample_rate: 10000000 # 10 MHz
+  num_signals_min: 1
+  num_signals_distribution: null
+  snr_db_min: 0.0
+  snr_db_max: 50.0
+  signal_duration_min: 0.0209         # 0.8*num_iq_samples_data/sample_rate = 0.0209 s
+  signal_duration_max: 0.0262         # 1.0*num_iq_samples_data/sample_rate = 0.0262 s
+  signal_bandwidth_min: 2500000       # sample_rate/4 = 2500 kHz
+  signal_bandwidth_max: 3333333       # sample_rate/3 = 3333 kHz
+  signal_center_freq_min: -2500000    # -sample_rate/4 = -10e6/4 = -2.5e6 = -2.5 MHz
+  signal_center_freq_max:  2499999    # sample_rate/4 -1 = 10e6/4 - 1 = 2.4999 MHz
+  # cochannel_overlap_probability: 0.1 # not relevant for narrowband
+  class_list: all
+  class_distribution: uniform
+  seed: 123456789
diff --git a/torchsig/datasets/default_configs/wideband_defaults.yaml b/torchsig/datasets/default_configs/wideband_defaults.yaml
new file mode 100644
index 000000000..4c790964a
--- /dev/null
+++ b/torchsig/datasets/default_configs/wideband_defaults.yaml
@@ -0,0 +1,25 @@
+# wideband defaults
+# multiple constant-wave (continuous) or bursty signals across a wide bandwidth
+required:
+  num_iq_samples_dataset: 262144
+  fft_size: 512
+  num_signals_max: 5
+  impairment_level: 0
+
+overrides:
+  num_samples: 10
+  sample_rate: 100000000 # 100 MHz
+  num_signals_min: 3
+  num_signals_distribution: null
+  snr_db_min: 0.0
+  snr_db_max: 50.0
+  signal_duration_min: 0.000131072 # 0.05*num_iq_samples_dataset/sample_rate = 0.13 ms
+  signal_duration_max: 0.000262144 # 0.10*num_iq_samples_dataset/sample_rate = 0.26 ms
+  signal_bandwidth_min:  5000000   # sample_rate/20 = 5 MHz
+  signal_bandwidth_max: 10000000   # sample_rate/10 = 10 MHz
+  signal_center_freq_min: -50000000 # sample_rate/2 = -50 MHz
+  signal_center_freq_max:  49999999 # sample_rate/2 -1 = 49.999999 MHz
+  cochannel_overlap_probability: 0.1
+  class_list: all
+  class_distribution: uniform
+  seed: 123456789
diff --git a/torchsig/image_datasets/datasets/file_loading_datasets.py b/torchsig/image_datasets/datasets/file_loading_datasets.py
index 14832b42c..30b85f2b8 100644
--- a/torchsig/image_datasets/datasets/file_loading_datasets.py
+++ b/torchsig/image_datasets/datasets/file_loading_datasets.py
@@ -32,8 +32,8 @@ def extract_bounding_boxes_from_image(img, isolate=True, filter_strength=None):
     # H, S, V
     # masking values hand tuned to ignore grayscale pixels
     # (aka low saturation and value)
-    lower = np.array([0, 70, 100]) # HARD CODED - TODO figure this out - no hard coding!
-    upper = np.array([179, 255, 255]) # HARD CODED - TODO figure this out - no hard coding!
+    lower = np.array([0, 70, 100]) # HARD CODED 
+    upper = np.array([179, 255, 255]) # HARD CODED 
 
     mask = cv2.inRange(img_hsv, lower, upper)
     
@@ -72,8 +72,8 @@ soi_image, assumed BGR colorspace
 def isolate_soi(soi_image, filter_strength=0):
     test_hsv = cv2.cvtColor(soi_image, cv2.COLOR_BGR2HSV)
     lower = np.array([0, 0, 0])
-    upper = np.array([360, 255, int(255/2)]) # hand tuned, HARD CODED # TODO hard coded considered harmful :(
-    upper = np.array([360, 255, int(255/2) - filter_strength]) # HARD CODED # TODO hard coded considered harmful :(
+    upper = np.array([360, 255, int(255/2)]) # hand tuned, HARD CODED 
+    upper = np.array([360, 255, int(255/2) - filter_strength]) # HARD CODED 
 
     mask = cv2.inRange(test_hsv, lower, upper)
     # plt.imshow(mask)
diff --git a/torchsig/image_datasets/generate_dataset.py b/torchsig/image_datasets/generate_dataset.py
index 7c25f16bc..9cc9e8dc3 100644
--- a/torchsig/image_datasets/generate_dataset.py
+++ b/torchsig/image_datasets/generate_dataset.py
@@ -16,8 +16,8 @@ from torchsig.image_datasets.dataset_generation import batched_write_yolo_synthe
 
 # constants/config stuff---------------------------------------------------------------------------------------------------------
 
-TRAINING_PATH = "./new_dataset_narrowband_imgs/training/"
-TESTING_PATH = "./new_dataset_narrowband_imgs/testing/"
+TRAINING_PATH = "./new_dataset_imgs/training/"
+TESTING_PATH = "./new_dataset_imgs/testing/"
 
 
 NUM_TRAINING_DATA = 250000
diff --git a/torchsig/image_datasets/transforms/denoising.py b/torchsig/image_datasets/transforms/denoising.py
index ab69eb35f..1672d68a2 100644
--- a/torchsig/image_datasets/transforms/denoising.py
+++ b/torchsig/image_datasets/transforms/denoising.py
@@ -26,8 +26,8 @@ def isolate_foreground_signal(image, filter_strength=0):
     '''
     test_hsv = cv2.cvtColor(cv2.cvtColor((image[0]*255).int().numpy().astype(np.uint8), cv2.COLOR_GRAY2BGR), cv2.COLOR_BGR2HSV)
     lower = np.array([0, 0, 0])
-    upper = np.array([360, 255, int(255/2)]) # hand tuned, HARD CODED # TODO hard coded considered harmful :(
-    upper = np.array([360, 255, int(255/2) - filter_strength]) # HARD CODED # TODO hard coded considered harmful :(
+    upper = np.array([360, 255, int(255/2)]) # hand tuned, HARD CODED 
+    upper = np.array([360, 255, int(255/2) - filter_strength]) # HARD CODED 
 
     mask = cv2.inRange(test_hsv, lower, upper)
 
diff --git a/torchsig/models/spectrogram_models/detr/criterion.py b/torchsig/models/spectrogram_models/detr/criterion.py
index 52284837f..b4c9cd78b 100755
--- a/torchsig/models/spectrogram_models/detr/criterion.py
+++ b/torchsig/models/spectrogram_models/detr/criterion.py
@@ -110,14 +110,12 @@ def is_dist_avail_and_initialized():
 
 
 def nested_tensor_from_tensor_list(tensor_list: List[Tensor]):
-    # TODO make this more general
     if tensor_list[0].ndim == 3:
         if torchvision._is_tracing():
             # nested_tensor_from_tensor_list() does not export well to ONNX
             # call _onnx_nested_tensor_from_tensor_list() instead
             return _onnx_nested_tensor_from_tensor_list(tensor_list)
 
-        # TODO make it support different-sized images
         max_size = _max_by_axis([list(img.shape) for img in tensor_list])
         # min_size = tuple(min(s) for s in zip(*[img.shape for img in tensor_list]))
         batch_shape = [len(tensor_list)] + max_size
@@ -333,7 +331,8 @@ class SetCriterion(nn.Module):
         src_masks = outputs["pred_masks"]
         src_masks = src_masks[src_idx]
         masks = [t["masks"] for t in targets]
-        # TODO use valid to mask invalid areas due to padding in loss
+        
+        # valid should be used to mask invalid areas due to padding in loss (currently unimplemented)
         target_masks, valid = nested_tensor_from_tensor_list(masks).decompose()
         target_masks = target_masks.to(src_masks)
         target_masks = target_masks[tgt_idx]
diff --git a/torchsig/models/spectrogram_models/detr/modules.py b/torchsig/models/spectrogram_models/detr/modules.py
index c3e816fb3..20e8d8b18 100755
--- a/torchsig/models/spectrogram_models/detr/modules.py
+++ b/torchsig/models/spectrogram_models/detr/modules.py
@@ -238,7 +238,7 @@ class SetCriterion(nn.Module):
         losses = {"loss_ce": loss_ce}
 
         if log:
-            # TODO this should probably be a separate loss, not hacked in this one here
+            # should probably be a separate loss, not hacked in this one here
             losses["class_error"] = 100 - accuracy(src_logits[idx], target_classes_o)[0]
         return losses
 
@@ -294,7 +294,7 @@ class SetCriterion(nn.Module):
         src_masks = outputs["pred_masks"]
         src_masks = src_masks[src_idx]
         masks = [t["masks"] for t in targets]
-        # TODO use valid to mask invalid areas due to padding in loss
+        # valid should be used to mask invalid areas due to padding in loss (currently unimplemented)
         target_masks, valid = nested_tensor_from_tensor_list(masks).decompose()
         target_masks = target_masks.to(src_masks)
         target_masks = target_masks[tgt_idx]
@@ -493,7 +493,6 @@ def create_detr(
     Function used to build a DETR network
 
     Args:
-        TODO
 
     Returns:
         torch.nn.Module
diff --git a/torchsig/signals/__init__.py b/torchsig/signals/__init__.py
index e7475569b..ceea04a0e 100644
--- a/torchsig/signals/__init__.py
+++ b/torchsig/signals/__init__.py
@@ -1 +1,10 @@
-from .signal_types import Signal, SignalMetadata, DatasetSignal, DatasetDict
\ No newline at end of file
+""" TorchSig Signals
+"""
+from .signal_types import Signal, SignalMetadata, SignalMetadataExternal
+from .signal_lists import TorchSigSignalLists
+
+__all__ = [
+    "SignalMetadata",
+    "SignalMetadataExternal",
+    "TorchSigSignalLists"
+]
\ No newline at end of file
diff --git a/torchsig/signals/builder.py b/torchsig/signals/builder.py
index ac3d5663c..c8b88e6e0 100644
--- a/torchsig/signals/builder.py
+++ b/torchsig/signals/builder.py
@@ -20,9 +20,10 @@ Examples
         >>> new_composite_signal = csb.build()
 """
 
+from __future__ import annotations
+
 # TorchSig
 from torchsig.signals.signal_types import Signal, SignalMetadata
-from torchsig.datasets.dataset_metadata import DatasetMetadata
 from torchsig.utils.random import Seedable
 from torchsig.utils.dsp import compute_spectrogram
 
@@ -33,8 +34,10 @@ import numpy as np
 from abc import ABC, abstractmethod
 from copy import copy
 import os
+from typing import TYPE_CHECKING
 
-DIR_PATH = os.path.dirname(os.path.realpath(__file__))
+if TYPE_CHECKING:
+    from torchsig.datasets.dataset_metadata import DatasetMetadata
 
 
 
@@ -48,6 +51,7 @@ class Builder(ABC):
         """Initialize builder, reset.
         """
         self.name = name
+        self._signal = None
 
     @abstractmethod
     def build(self) -> Signal:
@@ -91,12 +95,14 @@ class SignalBuilder(Builder, Seedable):
             ValueError: Signal builder does not support class_name signal.
         """
         self.class_name = class_name
+        self._signal = None
         Builder.__init__(self, name=f" {self.class_name} Signal Builder")
         
         Seedable.__init__(self, **kwargs)
         # retains dataset metadata info
         self.dataset_metadata = dataset_metadata
         
+        
 
         if not self.class_name in self.supported_classes:
             raise ValueError(f"{self.class_name} + ' not supported by {self.__class__.__name__}. List of supported waveforms: {self.supported_classes}")
diff --git a/torchsig/signals/builders/__init__.py b/torchsig/signals/builders/__init__.py
index 2d19bd929..2b3281ac8 100644
--- a/torchsig/signals/builders/__init__.py
+++ b/torchsig/signals/builders/__init__.py
@@ -1,3 +1,4 @@
+# pylint: disable=missing-module-docstring
 from .constellation import ConstellationSignalBuilder
 from .test import TestSignalBuilder
 from .tone import ToneSignalBuilder
diff --git a/torchsig/signals/builders/am.py b/torchsig/signals/builders/am.py
index 1aeceb73a..15e4aff92 100644
--- a/torchsig/signals/builders/am.py
+++ b/torchsig/signals/builders/am.py
@@ -9,7 +9,7 @@ from torchsig.utils.dsp import (
     convolve,
     frequency_shift,
     polyphase_decimator,
-    torchsig_complex_data_type
+    TorchSigComplexDataType
 )
 from torchsig.signals.signal_lists import TorchSigSignalLists
 
@@ -43,7 +43,7 @@ def am_modulator ( class_name:str, bandwidth:float, sample_rate:float, num_sampl
         num_samples_mod = num_samples
 
     # generate the random message, and make complex data type
-    message = rng.normal(0,1,num_samples_mod).astype(torchsig_complex_data_type)
+    message = rng.normal(0,1,num_samples_mod).astype(TorchSigComplexDataType)
     # scale to unit power
     message = message/np.sqrt(np.mean(np.abs(message)**2))
     # calculate filter cutoff
@@ -52,7 +52,7 @@ def am_modulator ( class_name:str, bandwidth:float, sample_rate:float, num_sampl
     # calculate maximum transition bandwidth
     max_transition_bandwidth = (sample_rate/2) - cutoff
     # derive actual transition bandwidth
-    transition_bandwidth = max_transition_bandwidth/2
+    transition_bandwidth = rng.uniform(0.05,0.25)*max_transition_bandwidth/2
 
     # generate bandwidth-limiting LPF
     lpf = low_pass_iterative_design(cutoff=cutoff, transition_bandwidth=transition_bandwidth, sample_rate=sample_rate)
@@ -95,7 +95,7 @@ def am_modulator ( class_name:str, bandwidth:float, sample_rate:float, num_sampl
         baseband_signal *= 2
 
     # convert to appropriate type
-    baseband_signal = baseband_signal.astype(torchsig_complex_data_type)
+    baseband_signal = baseband_signal.astype(TorchSigComplexDataType)
 
     return baseband_signal
 
diff --git a/torchsig/signals/builders/chirpss.py b/torchsig/signals/builders/chirpss.py
index cabdf24db..8ed040575 100644
--- a/torchsig/signals/builders/chirpss.py
+++ b/torchsig/signals/builders/chirpss.py
@@ -4,16 +4,16 @@
 # TorchSig
 from torchsig.signals.builder import SignalBuilder
 from torchsig.signals.builders.chirp import chirp
+from torchsig.signals.signal_utils import random_limiting_filter_design
+from torchsig.signals.signal_lists import TorchSigSignalLists
 from torchsig.datasets.dataset_metadata import DatasetMetadata
 from torchsig.utils.dsp import (
-    low_pass_iterative_design,
+    TorchSigComplexDataType,
     convolve,
-    torchsig_complex_data_type,
     multistage_polyphase_resampler,
     slice_head_tail_to_length,
     pad_head_tail_to_length,
 )
-from torchsig.signals.signal_lists import TorchSigSignalLists
 
 # Third Party
 import numpy as np
@@ -77,7 +77,7 @@ def chirpss_modulator_baseband ( class_name:str, max_num_samples:int, oversampli
     double_upchirp = np.concatenate((upchirp, upchirp), axis=0)
 
     # pre-allocate memory for the output modulated signal
-    modulated = np.zeros((max_num_samples,), dtype=torchsig_complex_data_type)
+    modulated = np.zeros((max_num_samples,), dtype=TorchSigComplexDataType)
 
     # create the modulated signal by selecting the appropriate symbol and inserting into the IQ array
     sym_start_index = 0
@@ -100,17 +100,10 @@ def chirpss_modulator_baseband ( class_name:str, max_num_samples:int, oversampli
         # increment the time next for next symbol
         sym_start_index = sym_start_index + samples_per_symbol
 
-    if rng.uniform(0,1) < 0.5: # 50% chance to turn on BW limiting filter
-        # randomize the cutoff
-        cutoff = rng.uniform(0.8*bandwidth/2,0.95*sample_rate/2)
-        # calculate maximum transition bandwidth
-        max_transition_bandwidth = sample_rate/2 - cutoff
-        # transition bandwidth is randomized value less than max transition bandwidth
-        transition_bandwidth = rng.uniform(0.5,1.5)*max_transition_bandwidth
-        # design bandwidth-limiting filter
-        lpf = low_pass_iterative_design(cutoff=cutoff,transition_bandwidth=transition_bandwidth,sample_rate=sample_rate)
-        # apply bandwidth-limiting LPF to reduce sidelobes
-        modulated = convolve(modulated,lpf)
+    # randomly (50%) chance of applying random coarse limiting filter
+    if rng.uniform(0,1) < 0.5: 
+        lpf = random_limiting_filter_design(bandwidth, sample_rate, rng)
+        modulated = convolve(modulated,lpf) # apply bandwidth-limiting LPF to reduce sidelobes
 
     return modulated
 
@@ -157,7 +150,7 @@ def chirpss_modulator ( class_name:str, bandwidth:float, sample_rate:float, num_
         chirpss_mod_correct_bw = pad_head_tail_to_length ( chirpss_mod_correct_bw, num_samples )
 
     # convert to appropriate type
-    chirpss_mod_correct_bw = chirpss_mod_correct_bw.astype(torchsig_complex_data_type)
+    chirpss_mod_correct_bw = chirpss_mod_correct_bw.astype(TorchSigComplexDataType)
 
     return chirpss_mod_correct_bw
 
diff --git a/torchsig/signals/builders/constellation.py b/torchsig/signals/builders/constellation.py
index 6efcea490..e4f0e3b3b 100644
--- a/torchsig/signals/builders/constellation.py
+++ b/torchsig/signals/builders/constellation.py
@@ -10,7 +10,7 @@ from torchsig.utils.dsp import (
     pad_head_tail_to_length,
     slice_head_tail_to_length,
     slice_tail_to_length,
-    torchsig_complex_data_type
+    TorchSigComplexDataType
 )
 from torchsig.signals.signal_lists import TorchSigSignalLists
 from torchsig.signals.builders.constellation_maps import all_symbol_maps
@@ -92,7 +92,7 @@ def constellation_modulator_baseband ( class_name:str, pulse_shape_name:str, max
     # create symbols. because OOK has symbols which are zeros this needs to run
     # a loop until 1 or more symbols are non-zero
     symbols = np.zeros(1)
-    while (np.sum(np.abs(symbols)) == 0):
+    while np.equal(np.sum(np.abs(symbols)), 0):
         # index into the symbol map
         map_index = rng.integers(low=0,high=len(symbol_map),size=num_symbols)
 
@@ -111,7 +111,7 @@ def constellation_modulator_baseband ( class_name:str, pulse_shape_name:str, max
     # else: signal correct length, do nothing
 
     # ensure proper data type
-    constellation_signal_baseband = constellation_signal_baseband.astype(torchsig_complex_data_type)
+    constellation_signal_baseband = constellation_signal_baseband.astype(TorchSigComplexDataType)
 
     return constellation_signal_baseband
 
@@ -177,7 +177,7 @@ def constellation_modulator ( class_name:str, pulse_shape_name:str, bandwidth:fl
         raise ValueError('constellation mod producing incorrect number of samples: ' + str(len(constellation_mod_signal)) + ' but requested: ' + str(num_samples))
 
     # convert to appropriate type
-    constellation_mod_signal = constellation_mod_signal.astype(torchsig_complex_data_type)
+    constellation_mod_signal = constellation_mod_signal.astype(TorchSigComplexDataType)
 
     return constellation_mod_signal
 
@@ -218,7 +218,7 @@ class ConstellationSignalBuilder(SignalBuilder):
         num_iq_samples_signal = self._signal.metadata.duration_in_samples
 
         # randomize pulse shape selection
-        if self.random_generator.integers(0,2) == 0:
+        if np.equal(self.random_generator.integers(0,2),0):
             pulse_shape_name = 'srrc'
             # randomize alpha_rolloff
             alpha_rolloff = self.random_generator.uniform(0.1,0.5)
diff --git a/torchsig/signals/builders/fm.py b/torchsig/signals/builders/fm.py
index cab667679..a1f04e464 100644
--- a/torchsig/signals/builders/fm.py
+++ b/torchsig/signals/builders/fm.py
@@ -7,7 +7,7 @@ from torchsig.datasets.dataset_metadata import DatasetMetadata
 from torchsig.utils.dsp import (
     low_pass_iterative_design,
     convolve,
-    torchsig_complex_data_type
+    TorchSigComplexDataType
 )
 from torchsig.signals.signal_lists import TorchSigSignalLists
 
@@ -45,7 +45,7 @@ def fm_modulator ( bandwidth:float, sample_rate:float, num_samples:int, rng=np.r
     # apply FM modulation
     modulated = np.exp(2j * np.pi * np.cumsum(source) * fdev/sample_rate)
     # convert to appropriate data type
-    modulated = modulated.astype(torchsig_complex_data_type)
+    modulated = modulated.astype(TorchSigComplexDataType)
     return modulated
 
 
diff --git a/torchsig/signals/builders/fsk.py b/torchsig/signals/builders/fsk.py
index 81bf465e5..5f5198aa1 100644
--- a/torchsig/signals/builders/fsk.py
+++ b/torchsig/signals/builders/fsk.py
@@ -9,7 +9,7 @@ from torchsig.utils.dsp import (
     pad_head_tail_to_length,
     slice_head_tail_to_length,
     slice_tail_to_length,
-    torchsig_complex_data_type
+    TorchSigComplexDataType
 )
 from torchsig.signals.signal_lists import TorchSigSignalLists
 
@@ -209,7 +209,7 @@ def fsk_modulator ( class_name:str, bandwidth:float, sample_rate:float, num_samp
     max_num_samples = int(np.floor(num_samples/resample_rate_ideal))
 
     # ensures a minimum number of samples
-    if (max_num_samples < oversampling_rate_nominal):
+    if max_num_samples < oversampling_rate_nominal:
         max_num_samples = copy(oversampling_rate_nominal)
 
     # modulate the baseband signal
@@ -228,7 +228,7 @@ def fsk_modulator ( class_name:str, bandwidth:float, sample_rate:float, num_samp
         fsk_correct_bw = pad_head_tail_to_length ( fsk_correct_bw, num_samples )
 
     # convert into the appropriate data type
-    fsk_correct_bw = fsk_correct_bw.astype(torchsig_complex_data_type)
+    fsk_correct_bw = fsk_correct_bw.astype(TorchSigComplexDataType)
 
     return fsk_correct_bw
 
diff --git a/torchsig/signals/builders/lfm.py b/torchsig/signals/builders/lfm.py
index 3a1833a66..8d367b8c5 100644
--- a/torchsig/signals/builders/lfm.py
+++ b/torchsig/signals/builders/lfm.py
@@ -1,25 +1,24 @@
 """LFM Signal Builder and Modulator
 """
-
 # TorchSig
 from torchsig.signals.builder import SignalBuilder
 from torchsig.signals.builders.chirp import chirp
+from torchsig.signals.signal_utils import random_limiting_filter_design
+from torchsig.signals.signal_lists import TorchSigSignalLists
+
 from torchsig.datasets.dataset_metadata import DatasetMetadata
 from torchsig.utils.dsp import (
-    low_pass_iterative_design,
+    TorchSigComplexDataType,
     convolve,
-    torchsig_complex_data_type,
     multistage_polyphase_resampler,
     slice_head_tail_to_length,
     pad_head_tail_to_length
 )
-from torchsig.signals.signal_lists import TorchSigSignalLists
 
 # Third Party
 import numpy as np
 
 # Built-In
-from copy import copy
 from collections import OrderedDict
 
 
@@ -84,7 +83,7 @@ def lfm_modulator_baseband ( class_name:str, max_num_samples:int, oversampling_r
     downchirp = chirp(f1,f0,samples_per_symbol)
 
     # pre-allocate memory for the output modulated signal
-    modulated = np.zeros((max_num_samples,), dtype=torchsig_complex_data_type)
+    modulated = np.zeros((max_num_samples,), dtype=TorchSigComplexDataType)
 
     # initialize time pointer to the first output index of each symbol
     sym_start_index = 0
@@ -112,17 +111,9 @@ def lfm_modulator_baseband ( class_name:str, max_num_samples:int, oversampling_r
         sym_start_index = sym_start_index + samples_per_symbol
 
 
-    if rng.uniform(0,1) < 0.5: # 50% chance to turn on BW limiting filter
-        # randomize the cutoff
-        cutoff = rng.uniform(0.8*bandwidth/2,0.95*sample_rate/2)
-        # calculate maximum transition bandwidth
-        max_transition_bandwidth = sample_rate/2 - cutoff
-        # transition bandwidth is randomized value less than max transition bandwidth
-        transition_bandwidth = rng.uniform(0.5,1.5)*max_transition_bandwidth
-        # design bandwidth-limiting filter
-        lpf = low_pass_iterative_design(cutoff=cutoff,transition_bandwidth=transition_bandwidth,sample_rate=sample_rate)
-        # apply bandwidth-limiting LPF to reduce sidelobes
-        modulated = convolve(modulated,lpf)
+    if rng.uniform(0,1) < 0.5: # 50% chance to enable BW limiting filter
+        filter_taps = random_limiting_filter_design(bandwidth, sample_rate, rng)
+        modulated = convolve(modulated, filter_taps)
 
     return modulated
 
@@ -156,8 +147,7 @@ def lfm_modulator ( class_name:str, bandwidth:float, sample_rate:float, num_samp
     # determine how many samples baseband modulator needs to implement.
     num_samples_baseband = int(np.ceil(num_samples/resample_rate_ideal))
 
-    if (num_samples_baseband < 1):
-        num_samples_baseband = 1
+    num_samples_baseband = max(num_samples_baseband, 1)
 
     # modulate at baseband
     lfm_signal_baseband = lfm_modulator_baseband ( class_name, num_samples_baseband, oversampling_rate_baseband, rng )
@@ -172,7 +162,7 @@ def lfm_modulator ( class_name:str, bandwidth:float, sample_rate:float, num_samp
         lfm_mod_correct_bw = pad_head_tail_to_length ( lfm_mod_correct_bw, num_samples )
 
     # convert to appropriate type
-    lfm_mod_correct_bw = lfm_mod_correct_bw.astype(torchsig_complex_data_type)
+    lfm_mod_correct_bw = lfm_mod_correct_bw.astype(TorchSigComplexDataType)
 
     return lfm_mod_correct_bw
 
diff --git a/torchsig/signals/builders/ofdm.py b/torchsig/signals/builders/ofdm.py
index 99a4950c5..f636731d4 100644
--- a/torchsig/signals/builders/ofdm.py
+++ b/torchsig/signals/builders/ofdm.py
@@ -8,7 +8,7 @@ from torchsig.utils.dsp import (
     pad_head_tail_to_length,
     slice_head_tail_to_length,
     slice_tail_to_length,
-    torchsig_complex_data_type
+    TorchSigComplexDataType
 )
 from torchsig.signals.signal_lists import TorchSigSignalLists
 from torchsig.signals.builders.constellation_maps import all_symbol_maps
@@ -79,7 +79,7 @@ def ofdm_modulator_baseband ( class_name:str, max_num_samples:int, oversampling_
     symbol_grid = symbol_map[map_index_grid]
 
     # create the full time/frequency grid
-    time_frequency_grid = np.zeros((ifft_size,num_ofdm_symbols),dtype=torchsig_complex_data_type)
+    time_frequency_grid = np.zeros((ifft_size,num_ofdm_symbols),dtype=TorchSigComplexDataType)
 
     # fill in the active subcarriers, ignoring index 0 in order to notch DC subcarrier
     half_num_subcarriers = int(num_subcarriers/2)
@@ -145,7 +145,7 @@ def ofdm_modulator ( class_name:str, bandwidth:float, sample_rate:float, num_sam
     # else: correct length, do nothing
 
     # convert to appropriate type
-    ofdm_signal_correct_bw = ofdm_signal_correct_bw.astype(torchsig_complex_data_type)
+    ofdm_signal_correct_bw = ofdm_signal_correct_bw.astype(TorchSigComplexDataType)
 
     return ofdm_signal_correct_bw
 
@@ -197,33 +197,29 @@ class OFDMSignalBuilder(SignalBuilder):
         Properly defines the minimum duration such that OFDM will
         generate at least 1 symbol.
         """
-
-        # split the class name to determine how many subcarriers
-        num_subcarriers = int(self._signal.metadata.class_name.split('-')[1])
-
-        # calculate final oversampling rate
+        num_subcarriers = int(self._signal.metadata.class_name.split('-')[1]) # split the class name to determine how many subcarriers
         oversampling_rate = self.dataset_metadata.sample_rate/self._signal.metadata.bandwidth
-
-        # calculate the minimum samples to generate
         minimum_duration_in_samples_for_ofdm = int(np.round(num_subcarriers*oversampling_rate))
-
-        # select the appropriate value against the signal minimum and the dataset minimum
         minimum_duration_in_samples = np.max((minimum_duration_in_samples_for_ofdm,self.dataset_metadata.signal_duration_in_samples_min))
 
-        if (minimum_duration_in_samples >= self.dataset_metadata.signal_duration_in_samples_max):
+        if minimum_duration_in_samples >= self.dataset_metadata.signal_duration_in_samples_max:
             # the estimated minimum is too large, use the max instead
             self._signal.metadata.duration_in_samples = copy(self.dataset_metadata.signal_duration_in_samples_max)
         else:
-            # randomize the duration
-            self._signal.metadata.duration_in_samples = self.random_generator.integers(low=minimum_duration_in_samples, high=self.dataset_metadata.signal_duration_in_samples_max,dtype=int)
-
-        # is start parameter to be randomized?
-        if self._signal.metadata.duration_in_samples == self.dataset_metadata.num_iq_samples_dataset:
-            # duration is equal to the total dataset length, therefore start must be zero
-            self._signal.metadata.start_in_samples = 0
-        else:
-            # given duration, start is randomly set from 0 to rightmost time that the duration still fits inside the dataset iq samples
-            self._signal.metadata.start_in_samples = self.random_generator.integers(low=0, high=self.dataset_metadata.num_iq_samples_dataset - self._signal.metadata.duration_in_samples,dtype=int)
+            self._signal.metadata.duration_in_samples = self.random_generator.integers(
+                low=minimum_duration_in_samples, 
+                high=self.dataset_metadata.signal_duration_in_samples_max,
+                dtype=int
+            )
+
+        if self._signal.metadata.duration_in_samples == self.dataset_metadata.num_iq_samples_dataset: # randomize start?
+            self._signal.metadata.start_in_samples = 0  # duration is equal to the total dataset length, therefore start must be zero
+        else:  # given duration, start is randomly set from 0 to rightmost time that the duration still fits inside the dataset iq samples
+            self._signal.metadata.start_in_samples = self.random_generator.integers(
+                low=0, 
+                high=self.dataset_metadata.num_iq_samples_dataset - self._signal.metadata.duration_in_samples,
+                dtype=int
+            )
 
 
 
diff --git a/torchsig/signals/builders/tone.py b/torchsig/signals/builders/tone.py
index f6452c6ee..e70f90473 100644
--- a/torchsig/signals/builders/tone.py
+++ b/torchsig/signals/builders/tone.py
@@ -4,7 +4,7 @@
 # TorchSig
 from torchsig.signals.builder import SignalBuilder
 from torchsig.datasets.dataset_metadata import DatasetMetadata
-from torchsig.utils.dsp import torchsig_complex_data_type
+from torchsig.utils.dsp import TorchSigComplexDataType
 from torchsig.signals.signal_lists import TorchSigSignalLists
 
 # Third Party
@@ -22,7 +22,7 @@ def tone_modulator ( num_samples:int ) -> np.ndarray:
         np.ndarray: Modulated tone IQ samples with proper center frequency.
     """
     # the tone at baseband is all ones
-    iq_samples = np.ones(num_samples,dtype=torchsig_complex_data_type)
+    iq_samples = np.ones(num_samples,dtype=TorchSigComplexDataType)
     return iq_samples
 
 
diff --git a/torchsig/signals/signal_types.py b/torchsig/signals/signal_types.py
index f09d0c084..6fa7b3301 100644
--- a/torchsig/signals/signal_types.py
+++ b/torchsig/signals/signal_types.py
@@ -19,26 +19,26 @@ from torchsig.utils.dsp import (
     upper_freq_from_center_freq_bandwidth,
     center_freq_from_lower_upper_freq,
     bandwidth_from_lower_upper_freq,
-    torchsig_complex_data_type
+    TorchSigComplexDataType
 )
 from torchsig.utils.verify import (
     verify_int,
     verify_float,
     verify_str,
     verify_numpy_array,
-    verify_dict
+    # verify_dict
 )
 
 # Third Party
 import numpy as np
 
 # Built-In
-from typing import List, TYPE_CHECKING, Dict, Any
+from typing import List, TYPE_CHECKING
 import copy
 
 # Imports for type checking
 if TYPE_CHECKING:
-    from torchsig.datasets.dataset_metadata import DatasetMetadata
+    from torchsig.datasets.dataset_metadata import DatasetMetadata, ExternalDatasetMetadata
 
 
 ### Signal Metadata Types
@@ -51,7 +51,6 @@ signal_metadata_dict_types = {
     'class_name':str,
     'class_index':int,
     'sample_rate':float,
-    'num_samples':int,
     'start':float,
     'stop':float,
     'duration':float,
@@ -85,6 +84,7 @@ class SignalMetadata():
         snr_db: float = None,
         class_name: str = None,
         class_index: int = None,
+        **kwargs
     ): 
         """Initializes the SignalMetadata object.
 
@@ -98,7 +98,7 @@ class SignalMetadata():
             class_name (str, optional): The class name of the signal. Defaults to "None".
             class_index (int, optional): The class index of the signal. Defaults to -1.
         """
-        self._dataset_metadata = dataset_metadata
+        self.dataset_metadata = dataset_metadata
         # Core SignalMetadata fields
         self.center_freq = center_freq # center freq (-sample_rate/2, sample_rate/2)
         self.bandwidth = bandwidth # bandwidth in Hz
@@ -107,7 +107,10 @@ class SignalMetadata():
         self.snr_db = snr_db # snr
         self.class_name = class_name # class modulation name
         self.class_index = class_index # class index wrt class list
-
+        self._lower_frequency = None # starts as null; if we can, we will update the lower and upper frequency from center frequency and bandwidth
+        self._upper_frequency = None
+        self._lower_frequency = self.lower_freq
+        self._upper_frequency = self.upper_freq
 
         # needed to enable/disable bounds checking for signal's center frequency.
         # since the center frequency will be set in TorchSigIterableDataset() after
@@ -116,14 +119,8 @@ class SignalMetadata():
 
         self.applied_transforms = []
 
-    @property
-    def dataset_metadata(self) -> DatasetMetadata:
-        """Returns the dataset metadata for the signal.
-
-        Returns:
-            DatasetMetadata: The dataset metadata.
-        """
-        return self._dataset_metadata
+        for key in kwargs.keys():
+            setattr(self, key, kwargs[key])
 
     @property
     def sample_rate(self) -> float:
@@ -132,16 +129,7 @@ class SignalMetadata():
         Returns:
             float: sample rate
         """
-        return self._dataset_metadata.sample_rate
-
-    @property
-    def num_samples(self) -> int:
-        """Signal number of IQ samples
-
-        Returns:
-            int: number of IQ samples
-        """        
-        return self.duration_in_samples
+        return self.dataset_metadata.sample_rate
 
     @property
     def start(self) -> float:
@@ -154,7 +142,7 @@ class SignalMetadata():
             float: signal start
         
         """
-        return self.start_in_samples/self._dataset_metadata.num_iq_samples_dataset
+        return self.start_in_samples/self.dataset_metadata.num_iq_samples_dataset
 
     @start.setter
     def start(self, new_start: float):
@@ -166,7 +154,7 @@ class SignalMetadata():
         Args:
             new_start (float): The starting location as a percentage from 0.0 to 1.0.
         """
-        self.start_in_samples = int(new_start * self._dataset_metadata.num_iq_samples_dataset)
+        self.start_in_samples = int(new_start * self.dataset_metadata.num_iq_samples_dataset)
 
     @property
     def stop(self) -> float:
@@ -179,7 +167,7 @@ class SignalMetadata():
             float: signal stop
         
         """
-        return self.stop_in_samples/self._dataset_metadata.num_iq_samples_dataset
+        return self.stop_in_samples/self.dataset_metadata.num_iq_samples_dataset
 
     @stop.setter
     def stop(self, new_stop: float):
@@ -191,7 +179,7 @@ class SignalMetadata():
         Args:
             new_stop (float): The stopping location as a percentage from 0.0 to 1.0.
         """
-        self.duration_in_samples = (new_stop * self._dataset_metadata.num_iq_samples_dataset) - self.start_in_samples
+        self.duration_in_samples = (new_stop * self.dataset_metadata.num_iq_samples_dataset) - self.start_in_samples
 
     @property
     def duration(self) -> float:
@@ -202,7 +190,7 @@ class SignalMetadata():
         Returns:
             float: signal duration
         """    
-        return self.duration_in_samples/self._dataset_metadata.num_iq_samples_dataset
+        return self.duration_in_samples/self.dataset_metadata.num_iq_samples_dataset
 
     @duration.setter
     def duration(self, new_duration: float):
@@ -211,7 +199,7 @@ class SignalMetadata():
         Args:
             new_duration (float): The new duration as a percentage of total time.
         """
-        self.duration_in_samples = new_duration * self._dataset_metadata.num_iq_samples_dataset
+        self.duration_in_samples = new_duration * self.dataset_metadata.num_iq_samples_dataset
 
     @property
     def stop_in_samples(self) -> int:
@@ -245,7 +233,11 @@ class SignalMetadata():
             float: upper frequency
         
         """
-        return upper_freq_from_center_freq_bandwidth(self.center_freq,self.bandwidth)
+        try:
+            self._upper_frequency = upper_freq_from_center_freq_bandwidth(self.center_freq,self.bandwidth)
+            return self._upper_frequency
+        except:
+            return self._upper_frequency
 
     @upper_freq.setter
     def upper_freq(self, new_upper_freq: float):
@@ -257,8 +249,10 @@ class SignalMetadata():
         Args:
             new_upper_freq (float): The new upper frequency value
         """
-        self.center_freq = center_freq_from_lower_upper_freq(new_upper_freq,self.lower_freq)
-        self.bandwidth = bandwidth_from_lower_upper_freq(new_upper_freq,self.lower_freq)
+        self._upper_frequency = new_upper_freq
+        if not self._lower_frequency == None:
+            self.bandwidth = bandwidth_from_lower_upper_freq(new_upper_freq,self.lower_freq)
+            self.center_freq = center_freq_from_lower_upper_freq(new_upper_freq,self.lower_freq)
 
     @property
     def lower_freq(self) -> float:
@@ -271,7 +265,11 @@ class SignalMetadata():
             float: lower frequency
         
         """
-        return lower_freq_from_center_freq_bandwidth(self.center_freq,self.bandwidth)
+        try:
+            self._lower_frequency = lower_freq_from_center_freq_bandwidth(self.center_freq,self.bandwidth)
+            return self._lower_frequency
+        except:
+            return self._lower_frequency
 
     @lower_freq.setter
     def lower_freq(self, new_lower_freq: float):
@@ -283,8 +281,10 @@ class SignalMetadata():
         Args:
             new_lower_freq (float): The new lower frequency value
         """        
-        self.center_freq = center_freq_from_lower_upper_freq(self.upper_freq,new_lower_freq)
-        self.bandwidth = bandwidth_from_lower_upper_freq(self.upper_freq,new_lower_freq)
+        self._lower_frequency = new_lower_freq
+        if not self._upper_frequency == None:
+            self.bandwidth = bandwidth_from_lower_upper_freq(self.upper_freq,new_lower_freq)
+            self.center_freq = center_freq_from_lower_upper_freq(self.upper_freq,new_lower_freq)
 
     @property
     def oversampling_rate(self) -> float:
@@ -301,26 +301,17 @@ class SignalMetadata():
 
 
     def to_dict(self) -> dict:
-        """Returns SignalMetadata as a full dictionary
+        """Returns SignalMetadataExternal as a full dictionary
         """
-        return {
-            'center_freq':self.center_freq,
-            'bandwidth':self.bandwidth,
-            'start_in_samples':self.start_in_samples,
-            'duration_in_samples':self.duration_in_samples,
-            'snr_db':self.snr_db,
-            'class_name':self.class_name,
-            'class_index':self.class_index,
-            'sample_rate':self.sample_rate,
-            'num_samples':self.num_samples,
-            'start':self.start,
-            'stop':self.stop,
-            'duration':self.duration,
-            'stop_in_samples':self.stop_in_samples,
-            'upper_freq':self.upper_freq,
-            'lower_freq':self.lower_freq,
-            'oversampling_rate':self.oversampling_rate,
-        }
+        attributes_original = self.__dict__.copy()  # Start with the instance variables
+
+        attributes = attributes_original.copy()
+
+        # exclude certain variables
+        for var in attributes_original:
+            if var in ["applied_transforms", "dataset_metadata", "_dataset_metadata", "_center_freq_set"]:
+                del attributes[var]
+        return attributes
 
     def deepcopy(self) -> SignalMetadata:
         """Returns a deep copy of itself
@@ -339,25 +330,25 @@ class SignalMetadata():
             InvalidSignalMetadata: Metadata invalid.
         """
 
-        if self._dataset_metadata is None:
+        if self.dataset_metadata is None:
             raise ValueError("dataset_metadata is None.")
 
         # only check the center frequency once it's been set. it is generated
         # at baseband (f=0) first and then later updated once it reaches
         # the dataset stage, when it can then be checked
-        if (self._center_freq_set):
+        if self._center_freq_set:
             self.center_freq = verify_float(
                 self.center_freq,
                 name = "center_freq",
-                low = self._dataset_metadata.signal_center_freq_min,
-                high = self._dataset_metadata.signal_center_freq_max
+                low = self.dataset_metadata.signal_center_freq_min,
+                high = self.dataset_metadata.signal_center_freq_max
             )
 
         self.bandwidth = verify_float(
             self.bandwidth,
             name = "bandwidth",
             low = 0.0,
-            high = self._dataset_metadata.sample_rate,
+            high = self.dataset_metadata.sample_rate,
             exclude_low = True
         )
 
@@ -365,7 +356,7 @@ class SignalMetadata():
             self.start_in_samples,
             name = "start_in_samples",
             low = 0,
-            high = self._dataset_metadata.num_iq_samples_dataset,
+            high = self.dataset_metadata.num_iq_samples_dataset,
             exclude_high = True
         )
 
@@ -373,7 +364,7 @@ class SignalMetadata():
             self.duration_in_samples,
             name = "duration_in_samples",
             low = 0,
-            high = self._dataset_metadata.num_iq_samples_dataset,
+            high = self.dataset_metadata.num_iq_samples_dataset,
             exclude_low = True
         )
 
@@ -395,93 +386,112 @@ class SignalMetadata():
         )
 
     def __repr__(self):
-        return f"{self.__class__.__name__}(center_freq={self.center_freq}, bandwidth={self.bandwidth}, start_in_samples={self.start_in_samples}, duration_in_samples={self.duration_in_samples}, snr_db={self.snr_db}, class_name={self.class_name}, class_index={self.class_index})"
+        class_dict = self.to_dict()
+        params = [f"{k}={v}" for k,v in class_dict.items()]
+        params_str = ",".join(params)
+        return f"{self.__class__.__name__}({params_str})"
+        #return f"{self.__class__.__name__}(center_freq={self.center_freq}, bandwidth={self.bandwidth}, start_in_samples={self.start_in_samples}, duration_in_samples={self.duration_in_samples}, snr_db={self.snr_db}, class_name={self.class_name}, class_index={self.class_index})"
+
+class SignalMetadataExternal():
+    """Modified SignalMetadata with fewer structural requirements, suitable for importing incomplete external datasets.
+    """
+    def __init__(
+        self,
+        dataset_metadata: ExternalDatasetMetadata | DatasetMetadata = None,
+        **kwargs
+    ): 
+        """
+        Args:
+            dataset_metadata (ExternalDatasetMetadata, optional): Global metadata related to the dataset. Defaults to None.
+        """
+        self.dataset_metadata = dataset_metadata
 
+        # all metadata fields
+        for key,value in kwargs.items():
+            # do not overwrite these fields
+            if key not in ["sample_rate"]:
+                setattr(self, key, value)
+        
 
+        self.applied_transforms = []
 
-### Signal
-class Signal():
-    """Initializes the Signal with data and metadata.
+    @property
+    def sample_rate(self) -> float:
+        """Signal sample rate
 
-        Args:
-            data (np.ndarray, optional): Signal IQ data. Defaults to np.array([]).
-            metadata (SignalMetadata, optional): Signal metadata. Defaults to an empty instance of SignalMetadata().
+        Returns:
+            float: sample rate
         """
-    def __init__(self, data: np.ndarray = np.array([]), metadata: SignalMetadata = None):
-        """Initializes the Signal with data and metadata.
+        return self.dataset_metadata.sample_rate
 
-        Args:
-            data (np.ndarray, optional): Signal IQ data. Defaults to np.array([]).
-            metadata (SignalMetadata, optional): Signal metadata. Defaults to an empty instance of SignalMetadata().
+    def to_dict(self) -> dict:
+        """Returns SignalMetadataExternal as a full dictionary
         """
-        self.data = data
-        self.metadata = metadata
+        attributes_original = self.__dict__.copy()  # Start with the instance variables
 
-    def verify(self):
-        """Verifies data and metadata are valid.
+        for prop_name in dir(self):
+            prop = getattr(self.__class__, prop_name, None)
+            if isinstance(prop, property):
+                attributes_original[prop_name] = getattr(self, prop_name)
+
+        attributes = attributes_original.copy()
+
+        # exclude certain variables
+        for var in attributes_original:
+            if var in ["applied_transforms", "dataset_metadata", "_dataset_metadata"]:
+                del attributes[var]
+
+        return attributes
+
+    def deepcopy(self) -> SignalMetadataExternal:
+        """Returns a deep copy of itself
+
+        Returns:
+            SignalMetadataExternal: Deep copy of SignalMetadataExternal
+        """        
+        return copy.deepcopy(self)
+
+
+    def verify(self) -> None:
+        """Verifies Signal metadata fields
 
         Raises:
-            ValueError: Data or metadata is invalid.
+            MissingSignalMetadataExternal: Metadata missing.
+            InvalidSignalMetadataExternal: Metadata invalid.
         """
-        # convert lists to array
-        self.data = verify_numpy_array(
-            self.data,
-            name = "IQ data",
-            exact_length=self.metadata.duration_in_samples,
-            data_type=torchsig_complex_data_type
-        )
 
-        self.metadata.verify()
+        if self.dataset_metadata is None:
+            raise ValueError("dataset_metadata is None.")
 
     def __repr__(self):
-        return f"{self.__class__.__name__}(data={self.data}, metadata={self.metadata})"
+        # return f"{self.__class__.__name__}(class_name={self.class_name}, class_index={self.class_index})"
+        return generate_repr_str(self, exclude_params=["_dataset_metadata"])
 
-## Dataset Signal Types
 
-class DatasetSignal():
-    """DatasetSignal class. Represents a signal within a dataset with metadata.
-
-    Attributes:
-        data (np.ndarray): The IQ data of the signal.
-        metadata (List[SignalMetadata]): The metadata associated with the signal.
+### Signal
+class Signal():
+    """Initializes the Signal with data and metadata.
 
-    Args:
-        data (np.ndarray, optional): The IQ data for the signal. Defaults to np.array([]).
-        signals (List[Signal] | Signal | List[SignalMetadata] | SignalMetadata | List[Dict[str, Any]], optional): The list of signals or metadata objects associated with the dataset signal.
-        dataset_metadata (DatasetMetadata, optional): The dataset metadata. Defaults to None.
-    """
+        Args:
+            data (np.ndarray, optional): Signal IQ data. Defaults to np.array([]).
+            metadata (SignalMetadata | SignalMetadataExternal, optional): Signal metadata. Defaults to an empty instance of SignalMetadata().
+        """
     def __init__(
         self, 
         data: np.ndarray = np.array([]), 
-        signals: List[Signal] | Signal | List[SignalMetadata] | SignalMetadata | List[Dict[str, Any]] = None,
-        dataset_metadata: DatasetMetadata = None
+        metadata: SignalMetadata | SignalMetadataExternal = None, 
+        component_signals: List[Signal] = []
     ):
+        """Initializes the Signal with data and metadata.
+
+        Args:
+            data (np.ndarray, optional): Signal IQ data. Defaults to np.array([]).
+            metadata (SignalMetadata | SignalMetadataExternal, optional): Signal metadata. Defaults to None.
+            component_signals (List[Signal], optional): individual components of the full signal, e.g. smaller individual signals collected together in a wideband signal. Defaults to [].
+        """
         self.data = data
-        self.metadata = []
-        
-        if isinstance(signals, (Signal, SignalMetadata)):
-            signals = [signals]
-
-        for s in signals:
-            if isinstance(s, Signal):
-                self.metadata.append(s.metadata)
-            elif isinstance(s, SignalMetadata):
-                self.metadata.append(s)
-            elif isinstance(s, dict):
-                if dataset_metadata is None:
-                    raise ValueError("dataset_metadata required if signals = list of dicts.")
-                self.metadata.append(SignalMetadata(
-                    dataset_metadata = dataset_metadata,
-                    center_freq = s['center_freq'],
-                    bandwidth = s['bandwidth'],
-                    start_in_samples = s['start_in_samples'],
-                    duration_in_samples = s['duration_in_samples'],
-                    snr_db = s['snr_db'],
-                    class_name = s['class_name'],
-                    class_index = s['class_index']
-                ))
-            else:
-                raise ValueError('Metadata type ' + str(type(s)) + ' not supported, metadata = ' + str(s))
+        self.metadata = metadata
+        self.component_signals = component_signals
 
     def verify(self):
         """Verifies data and metadata are valid.
@@ -489,56 +499,32 @@ class DatasetSignal():
         Raises:
             ValueError: Data or metadata is invalid.
         """
-        for m in self.metadata:
-            m.verify()
-
+        # convert lists to array
         self.data = verify_numpy_array(
             self.data,
-            name = "data",
-            exact_length = self.metadata[0].dataset_metadata.num_iq_samples_dataset,
+            name = "IQ data",
+            exact_length=self.metadata.duration_in_samples,
+            data_type=TorchSigComplexDataType
         )
-    
-    def __repr__(self):
-        return f"{self.__class__.__name__}(data={self.data}, metadata={self.metadata})"
-
-
-class DatasetDict():
-    """DatasetDict class. Represents a dictionary containing signal data and metadata.
-
-    Attributes:
-        data (np.ndarray): The IQ data of the signal.
-        metadata (List[dict]): The list of metadata dictionaries associated with the signal.
-        index (int, optional): The index of the signal in the dataset. Defaults to None.
 
-    Args:
-        signal (DatasetSignal): The DatasetSignal instance to extract data and metadata from.
-    """
-    def __init__(self, signal: DatasetSignal):
-        self.data: np.ndarray = signal.data
-        self.metadata: List[dict] = []
+        self.metadata.verify()
 
-        for m in signal.metadata:
-            self.metadata.append(m.to_dict())
-    
-    def verify(self):
-        """Verifies data and metadata are valid.
 
-        Raises:
-            ValueError: Data or metadata is invalid.
+    def get_full_metadata(self):
         """
-        self.data = verify_numpy_array(
-            self.data,
-            name = "data",
-        )
+        Returns a list of all top level metadata objects in the Signal. 
+        If no metadata is ddefined on a Signal, it's metadata is assumed to be the list of metadata of it's children.
+        This process is applied recursively until no more children without metadata can be found.
+        """
+        if not self.metadata is None:
+            return [self.metadata]
+        metadatas = []
+        for component_signal in self.component_signals:
+            component_metadata = component_signal.get_full_metadata()
+            metadatas += component_metadata
+        return metadatas
 
-        for i,m in enumerate(self.metadata):
-            m = verify_dict(
-                m,
-                name = f"metadata[{i}]",
-                required_keys = keys_types_list[0],
-                required_types = keys_types_list[1]
-            )
 
     def __repr__(self):
-        return f"{self.__class__.__name__}(data={self.data}, metadata={self.metadata})"
+        return f"{self.__class__.__name__}(metadata={self.metadata}, component_signals={self.component_signals})"
 
diff --git a/torchsig/signals/signal_utils.py b/torchsig/signals/signal_utils.py
index b57fa8fb2..18391f3d3 100644
--- a/torchsig/signals/signal_utils.py
+++ b/torchsig/signals/signal_utils.py
@@ -2,12 +2,14 @@
 Utility functions for dealing with the Signal type
 """
 
-from typing import List
+from torchsig.utils.dsp import low_pass_iterative_design
+
 
+from typing import List
+import numpy as np
 
 def check_signal_class(name: str, possible_names: List[str]) -> bool:
-    """
-    Check if the provided signal name matches any of the possible signal names.
+    """Check if the provided signal name matches any of the possible signal names.
 
     Args:
         name (str): The signal name to check.
@@ -18,4 +20,35 @@ def check_signal_class(name: str, possible_names: List[str]) -> bool:
     
     """
     is_type_signal = [n in name for n in possible_names]
-    return any(is_type_signal)
\ No newline at end of file
+    return any(is_type_signal)
+
+def random_limiting_filter_design(
+        bandwidth: float, 
+        sample_rate: float, 
+        rng: np.random.Generator = np.random.default_rng(seed=None)
+):
+    """Design a coarse bandwidth limiting filter with randomized parameters
+    using TorchSig's iterative designer function.
+    
+    Args:
+        bandwidth (float): Occupied bandwidth for signal (Hz).
+        sample_rate (float): Signal sampling rate (Hz).
+        rng (np.random.Generator, optional): Random number generator. Defaults to np.random.default_rng(seed=None).
+
+    Returns:
+        np.array: filter taps of designed low pass filter.
+    """
+
+    # randomize the cutoff
+    cutoff = rng.uniform(0.8*bandwidth/2,0.95*sample_rate/2)
+    
+    # calculate maximum transition bandwidth
+    max_transition_bandwidth = sample_rate/2 - cutoff
+    
+    # transition bandwidth is randomized value less than max transition bandwidth
+    transition_bandwidth = rng.uniform(0.5,1.5)*max_transition_bandwidth
+    
+    # design bandwidth-limiting filter
+    lpf = low_pass_iterative_design(cutoff=cutoff,transition_bandwidth=transition_bandwidth,sample_rate=sample_rate)
+    
+    return lpf
\ No newline at end of file
diff --git a/torchsig/transforms/base_transforms.py b/torchsig/transforms/base_transforms.py
index ecf628107..07bbe4504 100644
--- a/torchsig/transforms/base_transforms.py
+++ b/torchsig/transforms/base_transforms.py
@@ -1,4 +1,4 @@
-"""Base Transforms
+"""Base and Utility Transforms
 """
 
 from __future__ import annotations
@@ -14,55 +14,116 @@ __all__ = [
 
 # TorchSig
 import torchsig.transforms.functional as F
-from torchsig.signals.signal_types import Signal, DatasetSignal
+from torchsig.signals.signal_types import Signal, SignalMetadata, SignalMetadataExternal
 from torchsig.utils.random import Seedable
 from torchsig.utils.printing import generate_repr_str
 
 # Third Party
 from abc import ABC
-from typing import Callable, List, Literal, Optional, Union
+from typing import Callable, List, Literal, Optional
 
 
 class Transform(ABC, Seedable):
     """Transform abstract class.
     """
     def __init__(
-        self, 
-        measure=None,
+        self,
+        required_metadata: List[str] = [],
         **kwargs
     ):      
         """Transform initialization as Seedable.
         """
-        self.measure = measure  # optional measurement mode
+        # what metadata fields are requried for target transform to be applied
+        self.required_metadata = required_metadata
+
         Seedable.__init__(self, **kwargs)
 
-    def update(self, signal: Union[Signal, DatasetSignal]) -> None:   
-        """Update bookeeping for signals
+    def __validate__(
+        self, 
+        signal: Signal | SignalMetadata | SignalMetadataExternal
+    ) -> Signal | SignalMetadata | SignalMetadataExternal:
+        """Validates signal or metadata before applying transform
 
         Args:
-            signal (Signal | DatasetSignal): signal to update metadata.
+            signal (Signal | SignalMetadata): Signal to be validated.
 
         Raises:
-            NotImplementedError: Inherited classes must override this method.
-        """         
+            NotImplementedError: Subclasses must implement this method.
+
+        Returns:
+            Signal | SignalMetadata: Validated signal.
+        """        
         raise NotImplementedError
 
-    def __call__(self, signal: Union[Signal, DatasetSignal]) -> Union[Signal, DatasetSignal]:
-        """Performs transforms
+    def __update__(self, signal: Signal | SignalMetadata | SignalMetadataExternal) -> None:
+        """Updates bookeeping for signals
 
         Args:
-            signal (Any): Signal to be transformed.
+            signal (Signal | SignalMetadata): signal to update metadata.
+        """        
+       
+        if isinstance(signal, Signal):
+            # Signal object
+            if signal is None:
+                raise ValueError(f"Invalid signal object to update in transform {self.__class__.__name__}. Signal is None: {signal}")
+            #elif signal.metadata is None and len(signal.component_signals) > 1:
+            #    # signal has no metadata
+            #    raise ValueError(f"Invalid signal object to update in transform {self.__class__.__name__}. Signal has no metadata: {signal.metadata}, {signal.component_signals}")
+            
+            if signal.metadata is None:
+                # update component signals
+                for cs in signal.component_signals:
+                    cs.metadata.applied_transforms.append(self)
+            else:
+                # update signal metadata
+                signal.metadata.applied_transforms.append(self)
+
+            
+
+        elif isinstance(signal, (SignalMetadata, SignalMetadataExternal)):
+            # SignalMetadata or SignalMetadataExternal object
+            if signal is None:
+                raise ValueError(f"Invalid signal metadata object to update in transform {self.__class__.__name__}. Signal metadata is None: {signal}")
+            signal.applied_transforms.append(self)
+        else:
+            raise ValueError(f"Invalid signal metadata object to update in transform {self.__class__.__name__}. Must be Signal or SignalMetadata/SignalMetadataExternal, not {type(signal)}.")
+
+    def __apply__(
+        self, 
+        signal: Signal | SignalMetadata | SignalMetadataExternal
+    ) -> Signal | SignalMetadata | SignalMetadataExternal:  
+        """Performs transform
+
+        Args:
+            signal (Signal | SignalMetadata): Signal to be transformed.
+
+        Raises:
+            NotImplementedError: Subclasses must implement this method.
+
+        Returns:
+            Signal | SignalMetadata: Transformed signal.
+        """     
+        raise NotImplementedError
+
+    def __call__(
+        self, 
+        signal: Signal | SignalMetadata
+    ) -> Signal | SignalMetadata | SignalMetadataExternal:
+        """Validate signal, performs transform, update bookeeping
+
+        Args:
+            signal (Signal | SignalMetadata): Signal to be transformed.
 
         Raises:
             NotImplementedError: Inherited classes must override this method.
 
         Returns:
-            Any: Transformed Signal.
+            Signal | SignalMetadata: Transformed Signal.
             
         """
         raise NotImplementedError
 
-    def __str__(self) -> str:
+    def __str__(self) -> str:  
         return f"{self.__class__.__name__}"
 
     def __repr__(self) -> str:   
@@ -90,7 +151,7 @@ class Compose(Transform):
             if isinstance(t, Seedable):
                 t.add_parent(self)
 
-    def __call__(self, signal: Signal | DatasetSignal) -> Signal | DatasetSignal:
+    def __call__(self, signal: Signal) -> Signal:
         for t in self.transforms:
             signal = t(signal)
         return signal
@@ -116,7 +177,7 @@ class Lambda(Transform):
         super().__init__(**kwargs)
         self.func = func
 
-    def __call__(self, signal: Signal | DatasetSignal) -> Signal | DatasetSignal:
+    def __call__(self, signal: Signal) -> Signal:
         signal.data = self.func(signal.data)
         return signal
 
@@ -141,19 +202,13 @@ class Normalize(Transform):
         self,
         norm: Optional[int | float | Literal["fro", "nuc"]] = 2,
         flatten: bool = False,
-        seed: int = None,
         **kwargs
     ) -> None:
-        super().__init__(seed=seed, **kwargs)
+        super().__init__(**kwargs)
         self.norm = norm
         self.flatten = flatten
-    
-    # def __repr__(self) -> str:
-    #     r = super().__repr__()
-    #     r = r.replace("inf", "np.inf")
-    #     return r
 
-    def __call__(self, signal: Signal | DatasetSignal) -> Signal | DatasetSignal:
+    def __call__(self, signal: Signal) -> Signal:
         if self.flatten:
             signal.data = signal.data.reshape(signal.data.size)
         
@@ -185,7 +240,7 @@ class RandomApply(Transform):
         if isinstance(self.transform, Seedable):
             self.transform.add_parent(self)
 
-    def __call__(self, signal: Signal | DatasetSignal) -> Signal | DatasetSignal:
+    def __call__(self, signal: Signal) -> Signal:
         if self.random_generator.random() < self.probability:
             return self.transform(signal)
         return signal
@@ -207,10 +262,9 @@ class RandAugment(Transform):
         transforms: List[Transform], 
         choose: int = 2, 
         replace: bool = False,
-        seed:int = None,
         **kwargs
     ):
-        super().__init__(seed=seed, **kwargs)
+        super().__init__(**kwargs)
         self.transforms = transforms
         for transform in self.transforms:
             if isinstance(transform, Seedable):
@@ -218,7 +272,7 @@ class RandAugment(Transform):
         self.choose = choose
         self.replace = replace
 
-    def __call__(self, signal: Signal | DatasetSignal) -> Signal | DatasetSignal:
+    def __call__(self, signal: Signal) -> Signal:
         chosen_transforms_idx = self.random_generator.choice(
             len(self.transforms),
             size=self.choose,
diff --git a/torchsig/transforms/functional.py b/torchsig/transforms/functional.py
index 26cdd2393..43d2db0b2 100644
--- a/torchsig/transforms/functional.py
+++ b/torchsig/transforms/functional.py
@@ -1,19 +1,24 @@
-"""Functional transforms for reuse and custom fine-grained control
+"""Functional transforms for reuse and custom fine-grained control.
 """
-from typing import Literal, Optional, Tuple
+from typing import Literal, Optional
 
 # TorchSig
 import torchsig.utils.dsp as dsp
 from torchsig.utils.dsp import (
-    torchsig_complex_data_type,
-    torchsig_real_data_type
+    is_even,
+    multistage_polyphase_resampler,
+    prototype_polyphase_filter,
+    TorchSigComplexDataType,
+    TorchSigRealDataType
 )
 
+from torchsig.utils.rust_functions import sampling_clock_impairments
+
 # Third Party
-import scipy
-from scipy import signal as sp
 import numpy as np
-from scipy.constants import c
+from scipy import signal as sp
+from scipy.constants import c as speed_of_light
+from scipy.interpolate import interp1d as sp_interp1d
 import cv2
 from copy import copy
 
@@ -25,11 +30,12 @@ __all__ = [
     "carrier_frequency_drift",
     "carrier_phase_noise",
     "channel_swap",
+    "clock_jitter",
     "coarse_gain_change",
     "cochannel_interference",
     "complex_to_2d",
     "cut_out",
-    "digital_agc"    
+    "digital_agc",    
     "doppler",
     "drop_samples",
     "fading",
@@ -71,7 +77,7 @@ def add_slope(
     """  
     slope = np.diff(data)
     slope = np.insert(slope, 0, 0)
-    return (data + slope).astype(torchsig_complex_data_type)
+    return (data + slope).astype(TorchSigComplexDataType)
 
 
 def additive_noise(
@@ -94,9 +100,9 @@ def additive_noise(
         np.ndarray: Data with complex noise samples with specified power added.
     
     """
-    N = len(data)
-    noise_samples = dsp.noise_generator(N, power, color, continuous, rng)
-    return (data + noise_samples).astype(torchsig_complex_data_type)
+    n = len(data)
+    noise_samples = dsp.noise_generator(n, power, color, continuous, rng)
+    return (data + noise_samples).astype(TorchSigComplexDataType)
 
 
 def adjacent_channel_interference(
@@ -129,11 +135,11 @@ def adjacent_channel_interference(
         np.ndarray: Data with added adjacent interference.
     
     """
-    N = len(data)
-    t = np.arange(N) / sample_rate
+    n = len(data)
+    t = np.arange(n) / sample_rate
 
-    data_filtered = np.convolve(data, filter_weights)[-N:] # band limit original data (maintain data size)
-    phase_noise = rng.normal(0, phase_sigma, N)  # Gaussian phase noise
+    data_filtered = np.convolve(data, filter_weights)[-n:] # band limit original data (maintain data size)
+    phase_noise = rng.normal(0, phase_sigma, n)  # Gaussian phase noise
     interference = data_filtered * np.exp(1j*(2*np.pi*center_frequency*t + phase_noise)) # note: does not check aliasing
 
     time_shift = int(np.round(rng.normal(0, time_sigma, 1))[0]) # Gaussian block time shift for data (nearest sample)
@@ -148,7 +154,7 @@ def adjacent_channel_interference(
     est_power = np.sum(np.abs(interference)**2)/len(interference)
     interference = np.sqrt(power / est_power) * interference 
 
-    return (data + interference).astype(torchsig_complex_data_type)
+    return (data + interference).astype(TorchSigComplexDataType)
 
 
 def awgn(data: np.ndarray, 
@@ -177,7 +183,7 @@ def awgn(data: np.ndarray,
 
     real_noise = rng.standard_normal(*data.shape)
     imag_noise = rng.standard_normal(*data.shape)
-    return (data + (10.0 ** (noise_power_db / 20.0)) * (real_noise + 1j * imag_noise) / np.sqrt(2)).astype(torchsig_complex_data_type)
+    return (data + (10.0 ** (noise_power_db / 20.0)) * (real_noise + 1j * imag_noise) / np.sqrt(2)).astype(TorchSigComplexDataType)
 
 
 def channel_swap(
@@ -197,7 +203,148 @@ def channel_swap(
     new_data = np.empty(data.shape, dtype=data.dtype)
     new_data.real = imag_component
     new_data.imag = real_component
-    return new_data.astype(torchsig_complex_data_type)
+    return new_data.astype(TorchSigComplexDataType)
+
+
+def clock_drift(
+    data: np.ndarray,
+    drift_ppm: float = 10,
+    rng: np.random.Generator = np.random.default_rng(seed=None)
+) -> np.ndarray:
+    """Clock drift from a Local Oscillator (LO), modeled as accumulated gaussian random noise impacting the
+    sampling rate. The drift applies a randomness to the sampling rate, and by accumulating the gaussian RV 
+    over time it will slightly increase or decrease the sampling rate of the data, and thereby changing the
+    number of samples by a very small number.
+
+    Args:
+        data (np.ndarray): Complex valued IQ data samples.
+        drift_ppm(float): Clock drift in parts per million (ppm). Default 10.
+        rng (np.random.Generator): Random number generator. Defaults to np.random.default_rng(seed=None).
+
+    Returns:
+        np.ndarray: Data with LO drift applied.
+    
+    """
+    rng = rng if rng else np.random.default_rng()
+
+    # enforce data to be the correct complex type
+    data = data.astype(TorchSigComplexDataType)
+
+    # create a random seed for rust
+    rust_seed = rng.integers(low=0,high=2**32)
+
+    # define up/down rates
+    uprate=5000
+    downrate=copy(uprate)
+
+    # build the prototype filter
+    pfb_prototype_filter = prototype_polyphase_filter(num_branches=uprate)
+
+    # convert to real data type
+    pfb_prototype_filter = pfb_prototype_filter.astype(TorchSigRealDataType)
+
+    # call the impairment
+    data_with_drift = sampling_clock_impairments(h=pfb_prototype_filter,x=data,
+        uprate=uprate,drate=downrate,jitter_ppm=0,drift_ppm=drift_ppm,seed=rust_seed)
+
+    # discard extra samples from resampling process, or zero-pad if too short
+    num_samples_to_discard = len(data_with_drift)-len(data)
+
+    if (num_samples_to_discard > 0):
+        if (is_even(num_samples_to_discard)):
+            slice_front = num_samples_to_discard//2
+            slice_back = num_samples_to_discard//2
+        else:
+            slice_front = (num_samples_to_discard+1)//2
+            slice_back = num_samples_to_discard//2
+        data_with_drift = data_with_drift[slice_front:-slice_back]
+    else:
+        # calculate number of zeros to pad
+        num_samples_to_pad = len(data)-len(data_with_drift)
+        if (is_even(num_samples_to_pad)):
+            pad_front = num_samples_to_pad//2
+            pad_back = num_samples_to_pad//2
+        else:
+            pad_front = (num_samples_to_pad+1)//2
+            pad_back = num_samples_to_pad//2
+        data_with_drift = np.concatenate((np.zeros(pad_front),data_with_drift,np.zeros(pad_back)))
+
+    # ensure data type
+    data_with_drift = data_with_drift.astype(TorchSigComplexDataType)
+
+    return data_with_drift
+
+
+def clock_jitter(
+    data: np.ndarray,
+    jitter_ppm: float = 10,
+    rng: np.random.Generator = np.random.default_rng(seed=None)
+) -> np.ndarray:
+    """Clock jitter from a Local Oscillator (LO), modeled as gaussian random noise impacting the
+    sampling phase. The jitter applies a randomness to the sampling phase, applying a slight
+    increment or decrement to the sampling phase and therefore potentially changing the number of
+    samples by a very small number.
+
+    Args:
+        data (np.ndarray): Complex valued IQ data samples.
+        jitter_ppm(float): Jitter in parts per million (ppm). Default 10.
+        rng (np.random.Generator): Random number generator. Defaults to np.random.default_rng(seed=None).
+
+    Returns:
+        np.ndarray: Data with LO drift applied.
+    
+    """
+    rng = rng if rng else np.random.default_rng()
+
+    # enforce data to be the correct complex type
+    data = data.astype(TorchSigComplexDataType)
+
+    # create a random seed for rust
+    rust_seed = rng.integers(low=0,high=2**32)
+
+    # define up/down rates
+    uprate=5000
+    downrate=copy(uprate)
+
+    # build the prototype filter
+    pfb_prototype_filter = prototype_polyphase_filter(num_branches=uprate)
+
+    # convert to real data type
+    pfb_prototype_filter = pfb_prototype_filter.astype(TorchSigRealDataType)
+
+    # call the impairment
+    data_with_jitter = sampling_clock_impairments(h=pfb_prototype_filter,x=data,
+        uprate=uprate,drate=downrate,jitter_ppm=jitter_ppm,drift_ppm=0,seed=rust_seed)
+
+    # discard extra samples from resampling process, or zero-pad if too short
+    num_samples_to_discard = len(data_with_jitter)-len(data)
+
+    if (num_samples_to_discard > 0):
+        if (is_even(num_samples_to_discard)):
+            slice_front = num_samples_to_discard//2
+            slice_back = num_samples_to_discard//2
+        else:
+            slice_front = (num_samples_to_discard+1)//2
+            slice_back = num_samples_to_discard//2
+        data_with_jitter = data_with_jitter[slice_front:-slice_back]
+    else:
+        # calculate number of zeros to pad
+        num_samples_to_pad = len(data)-len(data_with_jitter)
+        if (is_even(num_samples_to_pad)):
+            pad_front = num_samples_to_pad//2
+            pad_back = num_samples_to_pad//2
+        else:
+            pad_front = (num_samples_to_pad+1)//2
+            pad_back = num_samples_to_pad//2
+        data_with_jitter = np.concatenate((np.zeros(pad_front),data_with_jitter,np.zeros(pad_back)))
+
+
+    # ensure data type
+    data_with_jitter = data_with_jitter.astype(TorchSigComplexDataType)
+
+    return data_with_jitter
+
+
 
 
 def cochannel_interference(
@@ -222,14 +369,14 @@ def cochannel_interference(
         np.ndarray: Data with added uncorrelated co-channel interference.
     
     """
-    N = len(data)
-    noise_samples = dsp.noise_generator(N, power, color, continuous, rng)
-    shaped_noise = np.convolve(noise_samples, filter_weights)[-N:]
+    n = len(data)
+    noise_samples = dsp.noise_generator(n, power, color, continuous, rng)
+    shaped_noise = np.convolve(noise_samples, filter_weights)[-n:]
     
     # correct shaped noise power (do not assume filter is prescaled)
     est_power = np.sum(np.abs(shaped_noise)**2)/len(shaped_noise)
     interference = np.sqrt(power / est_power) * shaped_noise 
-    return (data + interference).astype(torchsig_complex_data_type)
+    return (data + interference).astype(TorchSigComplexDataType)
 
 
 def coarse_gain_change(
@@ -255,7 +402,7 @@ def coarse_gain_change(
     output_data = copy(data)
     output_data[start_idx:] *= gain_change_linear
 
-    return output_data.astype(torchsig_complex_data_type)
+    return output_data.astype(TorchSigComplexDataType)
 
 
 def complex_to_2d(data: np.ndarray) -> np.ndarray:
@@ -334,7 +481,7 @@ def cut_out(
     # Insert cut mask into data
     data[cut_start : cut_start + cut_mask_length] = cut_mask
 
-    return data.astype(torchsig_complex_data_type)
+    return data.astype(TorchSigComplexDataType)
 
 def digital_agc(
     data: np.ndarray,
@@ -393,44 +540,37 @@ def digital_agc(
         gain_db += diff_db * alpha_adjust
         output[sample_idx] = data[sample_idx] * np.exp(gain_db)
 
-    return output.astype(torchsig_complex_data_type)
+    return output.astype(TorchSigComplexDataType)
 
 
 def doppler(
     data: np.ndarray,
     velocity: float = 1e1,
-    propagation_speed: float = c,
-    sampling_rate: float = 1.0
+    propagation_speed: float = speed_of_light
 ) -> np.ndarray:
-    """Applies Doppler effect through time scaling.
+    """Applies wideband Doppler effect through time scaling.
 
     Args:
         data (np.ndarray): Complex valued IQ data samples.
         velocity (float): Relative velocity in m/s (positive = approaching). Default 10 m/s.
-        propagation_speed (float): Wave speed in medium. Default 2.9979e8 m/s.
-        sampling_rate (float): Data sampling rate. Default 1.0.
+        propagation_speed (float): Wave speed in medium. Default 2.9979e8 m/s (speed_of_light).
 
     Returns:
-        np.ndarray: Data with Doppler.
+        np.ndarray: Data with wideband Doppler.
 
     """
-    N = data.size
+    n = data.size
     
     # time scaling factor
     alpha = propagation_speed / (propagation_speed - velocity)
 
-    # original and scaled signal sample times
-    t_orig = np.arange(N) / sampling_rate
-    t_new = t_orig * alpha
+    # if necessary, pad with zeros to maintain size
+    if alpha > 1.0:
+        num_zeros = int(np.ceil(n*(alpha - 1)) + 1)
+        data = np.concatenate((data, np.zeros(num_zeros)))
 
-    # prevent extrapolation beyond original signal duration
-    t_new = np.clip(t_new, 0, t_orig[-1])
-
-    # numpy default interpolator
-    interp_real = np.interp(t_new, t_orig, data.real)
-    interp_imag = np.interp(t_new, t_orig, data.imag)
-    data = interp_real + 1j*interp_imag
-    return (data).astype(torchsig_complex_data_type)
+    data = multistage_polyphase_resampler(data, 1/alpha)[:n]
+    return data.astype(TorchSigComplexDataType)
 
 
 def drop_samples(
@@ -491,7 +631,7 @@ def drop_samples(
         
         data[start:stop] = drop_region
 
-    return data.astype(torchsig_complex_data_type)
+    return data.astype(TorchSigComplexDataType)
 
 
 def fading(
@@ -535,8 +675,8 @@ def fading(
 
     # Linear interpolate taps by a factor of 100 -- so we can get accurate coherence bandwidths
     old_time = np.linspace(0, 1.0, num_taps, endpoint=True)
-    real_tap_function = scipy.interpolate.interp1d(old_time, rayleigh_taps.real)
-    imag_tap_function = scipy.interpolate.interp1d(old_time, rayleigh_taps.imag)
+    real_tap_function = sp_interp1d(old_time, rayleigh_taps.real)
+    imag_tap_function = sp_interp1d(old_time, rayleigh_taps.imag)
 
     new_time = np.linspace(0, 1.0, 100 * num_taps, endpoint=True)
     rayleigh_taps = real_tap_function(new_time) + 1j * imag_tap_function(new_time)
@@ -548,7 +688,7 @@ def fading(
     output_power = np.linalg.norm(data)
     data = np.multiply(input_power / output_power, data).astype(np.complex64)
 
-    return data.astype(torchsig_complex_data_type)
+    return data.astype(TorchSigComplexDataType)
 
 
 def intermodulation_products(
@@ -570,15 +710,15 @@ def intermodulation_products(
         np.ndarray: IQ data with local IMD products.
         
     """
-    if (coeffs.size == 0):
+    if np.equal(coeffs.size,0):
         raise IndexError('Coeffs has length zero.')
 
     model_order = coeffs.size
-    distorted_data = np.zeros(len(data),dtype=torchsig_complex_data_type)
+    distorted_data = np.zeros(len(data),dtype=TorchSigComplexDataType)
 
     # only odd-order distortion products are relevant local contributors
     for i in range(0, model_order, 1):
-        if (i > 0 and np.mod(i,2) == 1 and coeffs[i] != 0.0):
+        if i > 0 and np.equal(np.mod(i,2),1) and not np.equal(coeffs[i],0.0):
             raise ValueError('Even-order coefficients must be zero.')
 
         i_order_distortion = (np.abs(data) ** (i)) * data
@@ -591,7 +731,7 @@ def intermodulation_products(
     output_power = np.max(np.abs(np.fft.fft(distorted_data*win)))
     distorted_data *= input_power/output_power
     
-    return distorted_data.astype(torchsig_complex_data_type)
+    return distorted_data.astype(TorchSigComplexDataType)
 
 
 def iq_imbalance(
@@ -627,7 +767,7 @@ def iq_imbalance(
     data_fft_linear = np.abs(np.fft.fft(data))
     # apply smoothing
     avg_len = int(len(data_fft_linear)/8)
-    if (np.mod(avg_len,2) == 0):
+    if np.equal(np.mod(avg_len,2),0):
         avg_len += 1
     avg = np.ones(avg_len)/avg_len
     data_fft_linear = sp.convolve(data_fft_linear,avg)[avg_len:-avg_len]
@@ -648,7 +788,7 @@ def iq_imbalance(
     # add DC offset to signal
     data += dc_offset_tone
 
-    return data.astype(torchsig_complex_data_type)
+    return data.astype(TorchSigComplexDataType)
 
 def interleave_complex(
     data: np.ndarray, 
@@ -667,7 +807,7 @@ def interleave_complex(
     output = np.empty(len(data)*2)
     output[::2] = np.real(data)
     output[1::2] = np.imag(data)
-    return output.astype(torchsig_real_data_type)
+    return output.astype(TorchSigRealDataType)
 
 
 def carrier_frequency_drift(
@@ -687,13 +827,13 @@ def carrier_frequency_drift(
     
     """
     rng = rng if rng else np.random.default_rng()
-    N = data.size
+    n = data.size
 
     # convert drift PPM units
     drift = drift_ppm * 1e-6
 
     # randomize the instantaneous change in frequency
-    frequency_drift = rng.normal(0,drift,N)
+    frequency_drift = rng.normal(0,drift,n)
 
     # accumulate the changes into the frequency
     carrier_phase = np.cumsum(frequency_drift)
@@ -703,7 +843,7 @@ def carrier_frequency_drift(
 
     # apply frequency drift effect
     data = data * drift_effect
-    return data.astype(torchsig_complex_data_type)
+    return data.astype(TorchSigComplexDataType)
 
 
 def carrier_phase_noise(
@@ -723,10 +863,10 @@ def carrier_phase_noise(
     
     """
     rng = rng if rng else np.random.default_rng()
-    N = data.size
+    n = data.size
 
     # generate phase noise with given standard deviation
-    phase_noise_degrees_array = rng.normal(0,phase_noise_degrees,N)
+    phase_noise_degrees_array = rng.normal(0,phase_noise_degrees,n)
 
     # convert to radians
     phase_noise_radians_array = phase_noise_degrees_array * np.pi / 180
@@ -736,7 +876,7 @@ def carrier_phase_noise(
 
     # apply phase noise effect
     data = data * phase_noise_effect
-    return data.astype(torchsig_complex_data_type)
+    return data.astype(TorchSigComplexDataType)
 
 
 def nonlinear_amplifier(
@@ -767,7 +907,7 @@ def nonlinear_amplifier(
         np.ndarray: Nonlinearly distorted IQ data.
         
     """
-    N = len(data)
+    n = len(data)
     magnitude = np.abs(data)
     phase = np.angle(data)
     in_power = magnitude**2
@@ -786,7 +926,7 @@ def nonlinear_amplifier(
     # zero relative phase shift at low power input
     # and approaches phimax phase shift in saturation
     phi_shift = 0.0
-    if not (phi_max == 0.0) and not (phi_slope == 0.0):
+    if not np.equal(phi_max, 0.0) and not np.equal(phi_slope, 0.0):
         phi_slope = np.abs(phi_slope)
 
         # align AM and PM responses
@@ -803,19 +943,19 @@ def nonlinear_amplifier(
     # auto_scale: rescale output power to match full-scale input power
     # by estimating peaks for input and output power
     if auto_scale:
-        win = sp.windows.blackmanharris(N)
+        win = sp.windows.blackmanharris(n)
         input_power = np.max(np.abs(np.fft.fft(data*win)))
         output_power = np.max(np.abs(np.fft.fft(amp_data*win)))
         amp_data *= input_power/output_power
         
-    return amp_data.astype(torchsig_complex_data_type)
+    return amp_data.astype(TorchSigComplexDataType)
 
 
 def nonlinear_amplifier_table(
     data: np.ndarray,
-    Pin: np.ndarray =  10**((np.array([-100., -20., -10.,  0.,  5., 10. ]) / 10)),
-    Pout: np.ndarray = 10**((np.array([ -90., -10.,   0.,  9., 9.9, 10. ]) / 10)),
-    Phi: np.ndarray = np.deg2rad(np.array([0., -2.,  -4.,  7., 12., 23.])),
+    p_in: np.ndarray =  10**((np.array([-100., -20., -10.,  0.,  5., 10. ]) / 10)),
+    p_out: np.ndarray = 10**((np.array([ -90., -10.,   0.,  9., 9.9, 10. ]) / 10)),
+    phi: np.ndarray = np.deg2rad(np.array([0., -2.,  -4.,  7., 12., 23.])),
     auto_scale: bool = False
 ) -> np.ndarray:
     """A nonlinear amplifier (AM/AM, AM/PM) memoryless model that distorts an input
@@ -823,15 +963,15 @@ def nonlinear_amplifier_table(
     provided power input, power output, and phase change data points. 
 
         Default very small model parameters depict a 10 dB gain amplifier with P1dB = 9.0 dBW.
-            Pin =  10**((np.array([-100., -20., -10.,  0.,  5., 10. ]) / 10))
-            Pout = 10**((np.array([ -90., -10.,   0.,  9., 9.9, 10. ]) / 10))
-            Phi = np.deg2rad(np.array([0., -2., -4., 7., 12., 23.]))
+            p_in =  10**((np.array([-100., -20., -10.,  0.,  5., 10. ]) / 10))
+            p_out = 10**((np.array([ -90., -10.,   0.,  9., 9.9, 10. ]) / 10))
+            phi = np.deg2rad(np.array([0., -2., -4., 7., 12., 23.]))
 
     Args:
         data (np.ndarray): Complex valued IQ data samples.
-        Pin (np.ndarray): Model signal power input points. Assumes sorted ascending linear values (Watts).
-        Pout (np.ndarray): Model power out corresponding to Pin points (Watts).
-        Phi (np.ndarray): Model output phase shift values (radians) corresponding to Pin points.
+        p_in (np.ndarray): Model signal power input points. Assumes sorted ascending linear values (Watts).
+        p_out (np.ndarray): Model power out corresponding to p_in points (Watts).
+        phi (np.ndarray): Model output phase shift values (radians) corresponding to p_in points.
         auto_scale (bool): Automatically rescale output power to match full-scale peak 
             input power prior to transform, based on peak estimates. Default False.
 
@@ -842,7 +982,7 @@ def nonlinear_amplifier_table(
         np.ndarray: Nonlinearly distorted IQ data.
         
     """
-    if (len(Pin) != len(Pout)) or (len(Pin) != len(Phi)):
+    if (len(p_in) != len(p_out)) or (len(p_in) != len(phi)):
         raise ValueError('Model array arguments are not the same size.')
 
     magnitude = np.abs(data)
@@ -850,11 +990,11 @@ def nonlinear_amplifier_table(
     
     # amplitude-to-amplitude modulation (AM/AM)
     in_power = magnitude**2
-    out_power = np.interp(in_power, Pin, Pout)
+    out_power = np.interp(in_power, p_in, p_out)
     out_magnitude = out_power**0.5
     
     # amplitude-to-phase modulation (AM/PM)
-    out_phase_shift_rad = np.interp(in_power, Pin, Phi)
+    out_phase_shift_rad = np.interp(in_power, p_in, phi)
 
     amp_data = out_magnitude * np.exp(1j * (phase + out_phase_shift_rad))
     
@@ -866,7 +1006,7 @@ def nonlinear_amplifier_table(
         output_power = np.max(np.abs(np.fft.fft(amp_data*win)))
         amp_data *= input_power/output_power
 
-    return amp_data.astype(torchsig_complex_data_type)
+    return amp_data.astype(TorchSigComplexDataType)
      
 
 def normalize(
@@ -899,7 +1039,7 @@ def normalize(
         return np.multiply(data, 1.0 / norm)
 
     norm = np.linalg.norm(data, norm_order, keepdims=True)
-    return np.multiply(data, 1.0 / norm).astype(torchsig_complex_data_type)
+    return np.multiply(data, 1.0 / norm).astype(TorchSigComplexDataType)
 
 
 def passband_ripple(
@@ -945,13 +1085,13 @@ def passband_ripple(
         # increment counter
         counter += 1
 
-    if (counter >= max_counter):
+    if counter >= max_counter:
         raise ValueError('Passband ripple was unable to meet ripple specs.')
 
     # apply filter
     data = dsp.convolve(data,weights)
 
-    return data.astype(torchsig_complex_data_type)
+    return data.astype(TorchSigComplexDataType)
 
 
 def patch_shuffle(
@@ -988,7 +1128,7 @@ def patch_shuffle(
         rng.shuffle(patch)
         data[patch_start : patch_start + patch_size] = patch
 
-    return data.astype(torchsig_complex_data_type)
+    return data.astype(TorchSigComplexDataType)
 
 
 def phase_offset(
@@ -1006,7 +1146,7 @@ def phase_offset(
         np.ndarray: Data that has undergone a phase rotation.
 
     """
-    return (data * np.exp(1j * phase)).astype(torchsig_complex_data_type)
+    return (data * np.exp(1j * phase)).astype(TorchSigComplexDataType)
 
 def quantize(
     data: np.ndarray,
@@ -1034,7 +1174,7 @@ def quantize(
 
     """
 
-    if (not isinstance(num_bits,int)):
+    if not isinstance(num_bits,int):
         raise ValueError('quantize() num_bits must be an integer.')
 
     # calculate number of levels
@@ -1047,9 +1187,9 @@ def quantize(
     quant_level_distance = quant_levels[1]-quant_levels[0]
 
     # determine threshold levels
-    if (rounding_mode == 'floor'):
+    if rounding_mode == 'floor':
         threshold_levels = quant_levels + (quant_level_distance/2)
-    elif (rounding_mode == 'ceiling'):
+    elif rounding_mode == 'ceiling':
         threshold_levels = quant_levels - (quant_level_distance/2)
     else:
         raise ValueError(f'quantize() rounding mode is: {rounding_mode}, must be ceiling or floor')
@@ -1068,8 +1208,8 @@ def quantize(
     input_signal_scaled = data * ref_level_adjustment_linear / max_value_signal
 
     # quantize real and imag seperately
-    quant_signal_real = np.zeros(len(data),dtype=torchsig_real_data_type)
-    quant_signal_imag = np.zeros(len(data),dtype=torchsig_real_data_type)
+    quant_signal_real = np.zeros(len(data),dtype=TorchSigRealDataType)
+    quant_signal_imag = np.zeros(len(data),dtype=TorchSigRealDataType)
 
     input_signal_scaled_real = input_signal_scaled.real
     input_signal_scaled_imag = input_signal_scaled.imag
@@ -1106,7 +1246,7 @@ def quantize(
     # undo quantization-based scaling
     data_unscaled = quantized_data * max_value_signal / ref_level_adjustment_linear
 
-    return data_unscaled.astype(torchsig_complex_data_type)
+    return data_unscaled.astype(TorchSigComplexDataType)
 
 
 def shadowing(
@@ -1132,7 +1272,7 @@ def shadowing(
     rng = rng if rng else np.random.default_rng()
     power_db = rng.normal(mean_db, sigma_db) # normal distribution in log domain
     data = data * 10 ** (power_db / 20)
-    return data.astype(torchsig_complex_data_type)
+    return data.astype(TorchSigComplexDataType)
 
 
 def spectral_inversion(
@@ -1285,11 +1425,11 @@ def spectrogram_image(
     """
 
     # compute the spectrogram in dB
-    spectrogram_dB = spectrogram(data, fft_size=fft_size, fft_stride=fft_stride)
+    spectrogram_db = spectrogram(data, fft_size=fft_size, fft_stride=fft_stride)
 
     # convert to grey-scale image
-    img = np.zeros((spectrogram_dB.shape[0], spectrogram_dB.shape[1], 3), dtype=np.float32)
-    img = cv2.normalize(spectrogram_dB, img, 0, 255, cv2.NORM_MINMAX)
+    img = np.zeros((spectrogram_db.shape[0], spectrogram_db.shape[1], 3), dtype=np.float32)
+    img = cv2.normalize(spectrogram_db, img, 0, 255, cv2.NORM_MINMAX)
     img = cv2.cvtColor(img.astype(np.uint8), cv2.COLOR_GRAY2BGR)
     
     if black_hot:
@@ -1317,22 +1457,22 @@ def spurs(
     """
 
     # convert center_freqs and relative_power to arrays if received as scalars
-    if (np.isscalar(center_freqs)):
+    if np.isscalar(center_freqs):
         center_freqs_array = np.array([center_freqs])
     else:
         center_freqs_array = center_freqs
 
-    if (np.isscalar(relative_power_db)):
+    if np.isscalar(relative_power_db):
         relative_power_db_array = np.array([relative_power_db])
     else:
         relative_power_db_array = relative_power_db
 
     # error checking
-    if ((np.array(center_freqs_array) >= sample_rate/2).any()):
+    if (np.array(center_freqs_array) >= sample_rate/2).any():
         raise ValueError(f'center_freqs must be < sample rate / 2 = {sample_rate/2}')
-    elif ((np.array(center_freqs_array) <= -sample_rate/2).any()):
+    if (np.array(center_freqs_array) <= -sample_rate/2).any():
         raise ValueError(f'center_freqs must be >= -sample rate / 2 = {-sample_rate/2}')
-    elif (len(relative_power_db_array) != len(center_freqs_array)):
+    if len(relative_power_db_array) != len(center_freqs_array):
         raise ValueError(f'len(center_freqs) = {len(center_freqs_array)}, must be same length as len(relative_power_db) = {len(relative_power_db_array)}')
 
     # create copy of data since it will be modified
@@ -1342,7 +1482,7 @@ def spurs(
     data_fft_db = 20*np.log10(np.abs(np.fft.fft(data)))
     # apply smoothing
     avg_len = int(len(data_fft_db)/8)
-    if (np.mod(avg_len,2) == 0):
+    if np.equal(np.mod(avg_len,2),0):
         avg_len += 1
     avg = np.ones(avg_len)/avg_len
     data_fft_db = sp.convolve(data_fft_db,avg)[avg_len:-avg_len]
@@ -1351,12 +1491,11 @@ def spurs(
     noise_floor_db = np.min(data_fft_db)
 
     # generate spurs
-    for spur_index in range(len(center_freqs_array)):
+    for spur_index, center_freq in enumerate(center_freqs_array):
         # create the spur
-        spur = np.exp(2j*np.pi*(center_freqs_array[spur_index]/sample_rate)*np.arange(0,len(data)))
+        spur = np.exp(2j*np.pi*(center_freq/sample_rate)*np.arange(0,len(data)))
         # compute FFT of spur
         spur_fft_db = 20*np.log10(np.abs(np.fft.fft(spur)))
-        #ax.plot(spur_fft_db)
         # calculate peak value
         spur_max_db = np.max(spur_fft_db)
         # calculate change to set spur power properly
@@ -1367,8 +1506,7 @@ def spurs(
         # add spur to signal
         output += spur
 
-    return output.astype(torchsig_complex_data_type)
-
+    return output.astype(TorchSigComplexDataType)
 
 
 def time_reversal(
@@ -1383,7 +1521,7 @@ def time_reversal(
         np.ndarray: Time flipped IQ data.
 
     """    
-    return np.flip(data, axis=0).astype(torchsig_complex_data_type)
+    return np.flip(data, axis=0).astype(TorchSigComplexDataType)
 
 
 def time_varying_noise(
@@ -1439,7 +1577,7 @@ def time_varying_noise(
             start_power, stop_power, duration
         )
 
-    return ( data + (10.0 ** (noise_power / 20.0)) * (real_noise + 1j * imag_noise) / np.sqrt(2) ).astype(torchsig_complex_data_type)
+    return ( data + (10.0 ** (noise_power / 20.0)) * (real_noise + 1j * imag_noise) / np.sqrt(2) ).astype(TorchSigComplexDataType)
 
 
 
diff --git a/torchsig/transforms/impairments.py b/torchsig/transforms/impairments.py
index e40c5bb8c..4df9d5c89 100644
--- a/torchsig/transforms/impairments.py
+++ b/torchsig/transforms/impairments.py
@@ -1,41 +1,23 @@
 """Dataset Transform/Impairment class
 
 Impairments are transforms applied to Signal objects, after the Signal Builder generates an isolated signal.
-Transforms are applied to DatasetSignal objects, after isolated signals are placed on an IQ cut of noise.
-
-Example:
-    >>> impairments = Impairments(level = 2, dataset_metadata=dm)
-    >>> iq_samples = <random noise>
-    >>> metadatas = []
-    >>> for i in range(3): # 3 signals in wideband sample
-    >>>     sb = SignalBuilder(...)
-    >>>     new_signal = sb.build()
-    >>>     impaired_new_signal = impairments(new_signal)
-    >>>     iq_samples[start:stop] += new_signal.data
-    >>>     metadatas.append(impaired_new_signal.metadata)
-
-    >>> new_dataset_signal = DatasetSignal(data=iq_samples, metadata=metadatas)
-
-    >>> transforms = WidebandTransforms(level = 2, dataset_metadata=dm)
-    >>> transformed_dataset_signal = transforms(new_dataset_signal)
-
+Transforms are applied to Signal objects, after isolated signals are placed on an IQ cut of noise.
 """
 
 # TorchSig
 from torchsig.transforms.base_transforms import Compose, Transform
-from torchsig.transforms.transforms import SignalTransform
-
 from torchsig.transforms.base_transforms import (
     RandomApply,
     RandAugment
 )
-
 from torchsig.transforms.transforms import (
     AddSlope,
     CarrierFrequencyDrift,
     CarrierPhaseNoise,
     CarrierPhaseOffset,
     ChannelSwap,
+    ClockDrift,
+    ClockJitter,
     CoarseGainChange,
     DigitalAGC,
     Fading,
@@ -45,15 +27,12 @@ from torchsig.transforms.transforms import (
     PassbandRipple,
     Quantize,
     RandomDropSamples,
-    Spurs,
     SpectralInversion,
     Spurs,
-    TimeReversal,
+    TimeReversal
 )
 
-
 # Built-In
-from typing import List
 from copy import copy
 
 class Impairments(Transform):
@@ -90,31 +69,31 @@ class Impairments(Transform):
         # listing of transmit and receive HW impairments
         tx_hw_impairments = [
             RandomApply(Quantize(),0.75),
-            # RandomApply(,), # clock jitter
-            # RandomApply(,), # clock drift
+            RandomApply(ClockDrift(),0.75),
+            RandomApply(ClockJitter(),0.75),
+            RandomApply(PassbandRipple(),0.75),
+            RandomApply(IQImbalance(),0.25),
             RandomApply(CarrierPhaseNoise(),0.75),
             RandomApply(CarrierFrequencyDrift(),0.75),
             RandomApply(CarrierPhaseOffset(),1.0),
-            RandomApply(PassbandRipple(),0.75),
             RandomApply(IntermodulationProducts(),0.5),
-            RandomApply(IQImbalance(),0.25),
             RandomApply(NonlinearAmplifier(),0.75),
             RandomApply(Spurs(),0.75),
             RandomApply(SpectralInversion(),0.25),
         ]
 
         rx_hw_impairments = [
+            RandomApply(IntermodulationProducts(),0.5),
             RandomApply(NonlinearAmplifier(),0.75),
             RandomApply(CoarseGainChange(),0.25),
             RandomApply(Spurs(),0.75),
+            RandomApply(IQImbalance(),0.5),
             RandomApply(CarrierPhaseNoise(),0.75),
             RandomApply(CarrierFrequencyDrift(),0.75),
             RandomApply(CarrierPhaseOffset(),1.0),
-            RandomApply(IntermodulationProducts(),0.5),
-            RandomApply(IQImbalance(),0.5),
             RandomApply(PassbandRipple(),0.75),
-            # RandomApply(,), # clock jitter
-            # RandomApply(,), # clock drift
+            RandomApply(ClockDrift(),0.75),
+            RandomApply(ClockJitter(),0.75),
             RandomApply(Quantize(),0.75),
             RandomApply(DigitalAGC(),0.25),
         ]
@@ -143,29 +122,37 @@ class Impairments(Transform):
         ]
 
         # Signal (TX) Transforms
-        ST_level_0 = []                                # None
-        ST_level_1 = copy(tx_hw_impairments)           # TX impairments
-        ST_level_2 = copy(ST_level_1) + channel_models # TX impairments + channel models
-
-        ST_all_levels = [
-            ST_level_0,
-            ST_level_1,
-            ST_level_2
+        st_level_0 = []                                # None
+        st_level_1 = copy(tx_hw_impairments)           # TX impairments
+        st_level_2 = copy(st_level_1) + channel_models # TX impairments + channel models
+
+        st_all_levels = [
+            st_level_0,
+            st_level_1,
+            st_level_2
         ]
 
         # Dataset (RX) Transforms
-        DT_level_0 = copy(ml_transforms)            # ML Transforms
-        DT_level_1 = DT_level_0 + rx_hw_impairments # ML transforms + HW impairments
-        DT_level_2 = copy(DT_level_1)               # ML transforms + HW impairments
-
-        DT_all_levels = [
-            DT_level_0,
-            DT_level_1,
-            DT_level_2
+        dt_level_0 = copy(ml_transforms)            # ML Transforms
+        dt_level_1 = dt_level_0 + rx_hw_impairments # ML transforms + HW impairments
+        dt_level_2 = copy(dt_level_1)               # ML transforms + HW impairments
+
+        dt_all_levels = [
+            dt_level_0,
+            dt_level_1,
+            dt_level_2
         ]
 
-        self.signal_transforms = Compose(transforms = ST_all_levels[self.level])
+        self.signal_transforms = Compose(transforms = st_all_levels[self.level])
         self.signal_transforms.add_parent(self)
 
-        self.dataset_transforms = Compose(transforms = DT_all_levels[self.level])
+        self.dataset_transforms = Compose(transforms = dt_all_levels[self.level])
         self.dataset_transforms.add_parent(self)
+    
+    def get_signal_transforms(self):
+        """Get the signal transforms for this impairment level."""
+        return self.signal_transforms.transforms
+    
+    def get_dataset_transforms(self):
+        """Get the dataset transforms for this impairment level."""
+        return self.dataset_transforms.transforms
diff --git a/torchsig/transforms/metadata_transforms.py b/torchsig/transforms/metadata_transforms.py
new file mode 100755
index 000000000..bcdf2e73b
--- /dev/null
+++ b/torchsig/transforms/metadata_transforms.py
@@ -0,0 +1,225 @@
+"""Metadata Transforms
+"""
+
+__all__ = [
+    "MetadataTransform",
+    "FamilyName",
+    "FamilyIndex",
+    "CustomLabel",
+    "YOLOLabel"
+]
+
+# TorchSig
+from torchsig.signals.signal_types import SignalMetadata, Signal
+from torchsig.transforms.base_transforms import Transform
+from torchsig.signals.signal_lists import TorchSigSignalLists
+from torchsig.utils.printing import generate_repr_str
+
+# Built-In
+from typing import List, Optional, Dict
+
+
+## Base/Helper Classes
+class MetadataTransform(Transform):
+    """Metadata Transform base class
+
+    This class defines the basic structure of a metadata transform, which includes:
+    - The ability to validate metadata before applying the transform.
+    - A method for applying the transform on signal metadata.
+    - A callable interface to apply the transform to a list of signal metadata.
+
+    Attributes:
+        required_metadata (List[str]): List of metadata fields required for applying the target transform.
+
+    Methods:
+        __validate(metadata: Dict[str, Any]) -> Dict[str, Any]:
+            Validates the signal metadata before applying the transform.
+        
+        __apply(metadata: Dict[str, Any]) -> Dict[str, Any]:
+            Applies the target transform to the metadata. Should be overridden by subclasses.
+        
+        __call__(signal: Signal, enable_verify: bool = True)
+            Applies the transform to a list of signal metadata dictionaries.
+
+        __str__() -> str:
+            Returns the string representation of the transform.
+
+        __repr__() -> str:
+            Returns a detailed string representation of the transform object.
+    """
+    def __init__(
+        self,
+        required_metadata: List[str] = [],
+        **kwargs
+    ) -> None:
+        super().__init__(
+            required_metadata=required_metadata,
+            **kwargs
+        )
+
+    def __validate__(self, signal: SignalMetadata) -> SignalMetadata:
+        """Validate signal metadata before applying target transforms
+        makes sure a signal has all required metadata for a transform;
+        returns the original signal if it is valid; raises an exception otherwise 
+
+        Raises:
+            ValueError: If metadata is missing required metadata fields.
+        """        
+        if not isinstance(signal, SignalMetadata):
+            raise ValueError(f"metadata ({type(signal)}) is not a SignalMetadata object.")
+
+
+        for required_metadatum in self.required_metadata:
+            if not hasattr(signal, required_metadatum):
+                raise ValueError(f"key: {required_metadatum} is missing from signal metadata, but is required by {self.__class__.__name__}")
+            
+        return signal
+    
+    def __call__(
+        self, 
+        signal: Signal,
+        enable_verify = True
+    ):
+        """Applies the target transform to a list of signal metadata.
+        """
+        # apply metadata transform
+        metadatas = signal.get_full_metadata()
+        for metadata in metadatas:
+            # verify signal metadata is valid
+            if enable_verify:
+                metadata = self.__validate__(metadata)
+
+            # update dict with new metadata fields
+            metadata = self.__apply__(metadata)
+
+        return signal
+
+    def __apply__(self, signal: SignalMetadata):
+        """Applies the target transform to a single signal metadata.
+        
+        Args:
+            signal SignalMetadata: The metadata to transform.
+
+        Raises:
+            NotImplementedError: Subclasses must implement this method.
+        """
+        raise NotImplementedError
+    
+    def __repr__(self) -> str:   
+        return generate_repr_str(self, exclude_params = ['required_metadata'])
+
+
+class CustomLabel(MetadataTransform):
+    """Adds a 'label' field to the metadata, which contains a tuple of fields 
+    specified in the `label_fields` attribute.
+
+    Attributes:
+        label_fields (List[str]): The list of metadata fields to extract and place in the 'label' tuple.
+    """
+
+    def __init__(
+        self, 
+        label_fields: List[str], 
+        label_name: str = 'label', 
+        **kwargs
+    ):
+        super().__init__(
+            required_metadata=label_fields,
+            **kwargs
+        )
+        self.required_metadata = label_fields
+        self.label_name = label_name
+
+    def __apply__(self, signal: SignalMetadata) -> SignalMetadata:
+        setattr(signal, self.label_name, tuple(getattr(signal, field) for field in self.required_metadata))
+        return signal
+
+class FamilyName(MetadataTransform):
+    """
+    Adds a family_name to a signal's metadata based on it's class_name
+
+    Attributes:
+        class_family_dict (Optional[Dict[str, str]], optional): Class name to Family name dict (keys=class name, values= family name). Defaults to TorchSigSignalLists.family_dict.
+    """
+
+    def __init__(
+        self, 
+        class_family_dict: Optional[Dict[str, str]] = TorchSigSignalLists.family_dict, 
+        **kwargs
+    ):    
+        super().__init__(
+            required_metadata=["class_name"],
+            **kwargs
+        )
+        self.targets_metadata = ["family_name"]
+        self.class_family_dict = class_family_dict
+
+    
+    def __apply__(self, signal: SignalMetadata) -> SignalMetadata:    
+        setattr(signal, "family_name", self.class_family_dict[getattr(signal, "class_name")])
+        return signal
+        
+
+class FamilyIndex(MetadataTransform):
+    """
+    Adds a family_index to a signal's metadata based on it's class_name
+
+    Attributes:
+        class_family_dict (Optional[Dict[str, str]], optional): Class name to Family name dict (keys=class name, values= family name). Defaults to TorchSigSignalLists.family_dict.
+        family_list (Optional[List[str]], optional): Family list to index by. Defaults to alphabetical list of `class_family_dict` family names.
+    """
+
+    def __init__(
+        self, 
+        class_family_dict: Optional[Dict[str, str]] = TorchSigSignalLists.family_dict, 
+        family_list: Optional[List[str]] = None, 
+        **kwargs
+    ):    
+        super().__init__(
+            required_metadata=["class_name"],
+            **kwargs
+        )
+        self.targets_metadata = ["family_id"]
+        self.class_family_dict = class_family_dict
+        self.family_list = sorted(list(set(self.class_family_dict.values()))) if family_list is None else family_list
+
+    
+    def __apply__(self, signal: SignalMetadata) -> SignalMetadata: 
+
+        fam_name = self.class_family_dict[getattr(signal, "class_name")]
+        setattr(signal, "family_id", self.family_list.index(fam_name))
+        return signal
+
+class YOLOLabel(MetadataTransform):
+    """
+    Adds a YOLO_label to a signal, in the form of a list of tuples (cid, cx, cy, width, height)
+    """
+
+    def __init__(self, **kwargs):
+        super().__init__(
+            required_metadata=[
+                "class_index",
+                "start",
+                "bandwidth",
+                "center_freq",
+                "sample_rate"
+            ],
+            **kwargs
+        )
+        self.targets_metadata = ["yolo_label"]
+
+    
+    def __apply__(self, signal: SignalMetadata) -> SignalMetadata:
+        class_index = signal.class_index
+        # normalized to width of sample
+        width = signal.duration
+        # normalize bandwidth with sample rate
+        height = signal.bandwidth/signal.sample_rate
+        x_center = signal.start + (width / 2.0)
+        # normalize center frequency with sample rate
+        # subtract from 1 since (0,0) for YOLO is upper left, but we define (0,0) lower left
+        y_center = 1 - ((signal.sample_rate/2.0) + signal.center_freq) / signal.sample_rate
+        yolo_label = (class_index, x_center, y_center, width, height)
+        setattr(signal, "yolo_label", yolo_label)
+
+        return signal
diff --git a/torchsig/transforms/target_transforms.py b/torchsig/transforms/target_transforms.py
deleted file mode 100755
index 38dd1fb59..000000000
--- a/torchsig/transforms/target_transforms.py
+++ /dev/null
@@ -1,338 +0,0 @@
-"""Target Transforms
-"""
-
-__all__ = [
-    "TargetTransform",
-    "FamilyName",
-    "FamilyIndex",
-    "CustomLabel",
-    "YOLOLabel",
-]
-
-# TorchSig
-from torchsig.transforms.base_transforms import Transform
-from torchsig.signals.signal_lists import TorchSigSignalLists
-from torchsig.utils.printing import generate_repr_str
-
-# Built-In
-from typing import List, Any, Optional, Dict
-
-
-## Base/Helper Classes
-class TargetTransform(Transform):
-    """Target Transform base class
-
-    This class defines the basic structure of a target transform, which includes:
-    - The ability to validate metadata before applying the transform.
-    - A method for applying the transform on signal metadata.
-    - A callable interface to apply the transform to a list of signal metadata.
-
-    Attributes:
-        required_metadata (List[str]): List of metadata fields required for applying the target transform.
-        targets_metadata (List[str]): List of target metadata fields to be added to output of target transform.
-
-    Methods:
-        __validate(metadata: Dict[str, Any]) -> Dict[str, Any]:
-            Validates the signal metadata before applying the transform.
-        
-        __apply(metadata: Dict[str, Any]) -> Dict[str, Any]:
-            Applies the target transform to the metadata. Should be overridden by subclasses.
-        
-        __call__(metadatas: List[Dict[str, Any]], enable_verify: bool = True) -> List[Dict[str, Any]]:
-            Applies the transform to a list of signal metadata dictionaries.
-
-        __str__() -> str:
-            Returns the string representation of the transform.
-
-        __repr__() -> str:
-            Returns a detailed string representation of the transform object.
-    """
-    def __init__(self, **kwargs) -> None:
-        super().__init__(**kwargs)
-        # what metadata fields are requried for target transform to be applied
-        self.required_metadata = []
-        # when computing targets of target transform, what fields to use
-        self.targets_metadata = []
-
-    def __validate__(self, metadata: Dict[str, Any]) -> Dict[str, Any]:
-        """Validate signal metadata before applying target transforms
-        makes sure a signal has all required metadata for a transform;
-        returns the original signal if it is valid; raises an exception otherwise 
-
-        Raises:
-            ValueError: If metadata is not a dict or is missing required metadata fields.
-
-        Returns:
-            Dict[str, Any]: Validated signal metadata.
-        """        
-        if not isinstance(metadata, dict):
-            raise ValueError(f"metadata ({type(metadata)}) is not a list.")
-
-        for required_metadatum in self.required_metadata:
-            if not required_metadatum in metadata.keys():
-                raise ValueError(f"key: {required_metadatum} is missing from signal metadata, but is required by {self.__class__.__name__}")
-            
-        return metadata
-
-    def __apply__(self, metadata: Dict[str, Any]) -> Dict[str, Any]:
-        """Applies the target transform to a single signal metadata.
-        
-        Args:
-            metadata (Dict[str, Any]): The metadata to transform.
-
-        Raises:
-            NotImplementedError: Subclasses must implement this method.
-
-        Returns:
-            Dict[str, Any]: The transformed metadata.
-        """
-        raise NotImplementedError
-    
-    def __call__(
-        self, 
-        metadatas: List[Dict[str, Any]],
-        enable_verify = True
-    ) -> List[Any] | Dict[str, Any]:
-        """Applies the target transform to a list of signal metadata.
-
-        Args:
-            metadatas (List[Dict[str, Any]]): The list of metadata dictionaries to transform.
-            enable_verify (bool, optional): Whether to verify metadata before transforming. Defaults to True.
-
-        Returns:
-            List[Dict[str, Any]]: The transformed list of metadata dictionaries.
-        """
-        # apply target transform
-        for metadata in metadatas:
-            # verify signal metadata is valid
-            if enable_verify:
-                metadata = self.__validate__(metadata)
-
-            # update dict with new metadata fields
-            metadata = self.__apply__(metadata)
-
-        return metadatas
-
-    def __str__(self) -> str:
-        return f"{self.__class__.__name__}"
-    
-    def __repr__(self) -> str:   
-        return generate_repr_str(self, exclude_params = ['required_metadata', 'targets_metadata'])
-
-
-class CustomLabel(TargetTransform):
-    """Adds a 'label' field to the metadata, which contains a tuple of fields 
-    specified in the `label_fields` attribute.
-
-    Attributes:
-        label_fields (List[str]): The list of metadata fields to extract and place in the 'label' tuple.
-    """
-
-    def __init__(self, label_fields: List[str], label_name: str = 'label', **kwargs):
-        super().__init__(**kwargs)
-        self.required_metadata = label_fields
-        self.targets_metadata = [label_name]
-
-    
-    def __apply__(self, metadata):    
-        metadata[self.targets_metadata[0]] = tuple([metadata[field] for field in self.required_metadata])
-        return metadata
-
- 
-
-class PassThrough(TargetTransform):
-    """A helper class that does not alter the signal metadata but adds requested fields to the output.
-
-    This class is often used in combination with other transforms.
-    """  
-    def __init__(self, field: List[str] = [], **kwargs):
-        super().__init__(**kwargs)
-        self.required_metadata = field
-        self.targets_metadata = field
-    
-    def __apply__(self, metadata: dict):
-        return metadata
-
-
-### Built-In Target Transforms
-# These target transforms already have labels within the Signal class, 
-# which is turned into a dictionary inside the DatasetDict class. Thus,
-# they do not any further processig than grabbing the label
-###
-
-class CenterFreq(PassThrough):
-    """Adds `center_freq` from signal metadata
-    """ 
-    def __init__(self, **kwargs):
-        super().__init__(field = ['center_freq'])
-
-class Bandwidth(PassThrough):
-    """Adds `bandwidth` from signal metadata
-    """ 
-    def __init__(self, **kwargs):
-        super().__init__(field = ['bandwidth'])
-
-class StartInSamples(PassThrough):
-    """Adds `start_in_samples` from signal metadata
-    """ 
-    def __init__(self, **kwargs):
-        super().__init__(field = ['start_in_samples'])
-
-class DurationInSamples(PassThrough):
-    """Adds `duration_in_samples` from signal metadata
-    """ 
-    def __init__(self, **kwargs):
-        super().__init__(field = ['duration_in_samples'])
-
-class SNR(PassThrough):
-    """Adds `snr_db` from signal metadata
-    """ 
-    def __init__(self, **kwargs):
-        super().__init__(field = ['snr_db'])
-
-class ClassName(PassThrough):
-    """Adds `class_name` from signal metadata
-    """ 
-    def __init__(self, **kwargs):
-        super().__init__(field = ['class_name'])
-
-class ClassIndex(PassThrough):
-    """Adds `class_index` from signal metadata
-    """ 
-    def __init__(self, **kwargs):
-        super().__init__(field = ['class_index'])
-
-class SampleRate(PassThrough):
-    """Adds `sample_rate` from signal metadata
-    """ 
-    def __init__(self, **kwargs):
-        super().__init__(field = ['sample_rate'])
-
-class NumSamples(PassThrough):
-    """Adds `num_samples` from signal metadata
-    """ 
-    def __init__(self, **kwargs):
-        super().__init__(field = ['num_samples'])
-
-class Start(PassThrough):
-    """Adds `start` from signal metadata
-    """ 
-    def __init__(self, **kwargs):
-        super().__init__(field = ['start'])
-
-class Stop(PassThrough):
-    """Adds `stop` from signal metadata
-    """ 
-    def __init__(self, **kwargs):
-        super().__init__(field = ['stop'])
-
-class Duration(PassThrough):
-    """Adds `duration` from signal metadata
-    """ 
-    def __init__(self, **kwargs):
-        super().__init__(field = ['duration'])
-
-class StopInSamples(PassThrough):
-    """Adds `stop_in_samples` from signal metadata
-    """ 
-    def __init__(self, **kwargs):
-        super().__init__(field = ['stop_in_samples'])
-
-class UpperFreq(PassThrough):
-    """Adds `upper_freq` from signal metadata
-    """ 
-    def __init__(self, **kwargs):
-        super().__init__(field = ['upper_freq'])
-
-class LowerFreq(PassThrough):
-    """Adds `lower_freq` from signal metadata
-    """ 
-    def __init__(self, **kwargs):
-        super().__init__(field = ['lower_freq'])
-
-class OversamplingRate(PassThrough):
-    """Adds `oversampling_rate` from signal metadata
-    """ 
-    def __init__(self, **kwargs):
-        super().__init__(field = ['oversampling_rate'])
-
-
-# Special Target Transforms
-# Target Transforms that require calculation to generate.
-# They also need their metadata label field added to the metadata.
-
-class FamilyName(TargetTransform):
-    """
-    Adds a family_name to a signal's metadata based on it's class_name
-
-    Attributes:
-        class_family_dict (Optional[Dict[str, str]], optional): Class name to Family name dict (keys=class name, values= family name). Defaults to TorchSigSignalLists.family_dict.
-    """
-
-    def __init__(self, class_family_dict: Optional[Dict[str, str]] = TorchSigSignalLists.family_dict, **kwargs):    
-        super().__init__(**kwargs)
-        self.required_metadata = ["class_name"]
-        self.targets_metadata = ["family_name"]
-        self.class_family_dict = class_family_dict
-
-    
-    def __apply__(self, metadata):    
-        metadata["family_name"] = self.class_family_dict[metadata["class_name"]]
-        return metadata
-        
-
-class FamilyIndex(TargetTransform):
-    """
-    Adds a family_index to a signal's metadata based on it's class_name
-
-    Attributes:
-        class_family_dict (Optional[Dict[str, str]], optional): Class name to Family name dict (keys=class name, values= family name). Defaults to TorchSigSignalLists.family_dict.
-        family_list (Optional[List[str]], optional): Family list to index by. Defaults to alphabetical list of `class_family_dict` family names.
-    """
-
-    def __init__(self, class_family_dict: Optional[Dict[str, str]] = TorchSigSignalLists.family_dict, family_list: Optional[List[str]] = None, **kwargs):    
-        super().__init__(**kwargs)
-        self.required_metadata = ["class_name"]
-        self.targets_metadata = ["family_id"]
-        self.class_family_dict = class_family_dict
-        self.family_list = sorted(list(set(self.class_family_dict.values()))) if family_list is None else family_list
-
-    
-    def __apply__(self, metadata): 
-
-        fam_name = self.class_family_dict[metadata["class_name"]]
-        metadata["family_id"] = self.family_list.index(fam_name)
-        return metadata
-
-class YOLOLabel(TargetTransform):
-    """
-    Adds a YOLO_label to a signal, in the form of a list of tuples (cid, cx, cy, width, height)
-
-    Attributes:
-        output (str, optional): Structure to aggregate YOLO labels ("dict", "list"). Defaults to "list".
-    """
-
-    output_list = ["list", "dict"]
-
-    def __init__(self, **kwargs):
-        super().__init__(**kwargs)
-        self.required_metadata = ["class_index", "start", "bandwidth", "center_freq", "sample_rate"]
-        self.targets_metadata = ["yolo_label"]
-
-    
-    def __apply__(self, metadata):
-        class_index = metadata["class_index"]
-        # normalized to width of sample
-        width = metadata["duration"]
-        # normalize bandwidth with sample rate
-        height = metadata["bandwidth"] / metadata["sample_rate"]
-        x_center = metadata["start"] + (width / 2.0)
-        # normalize center frequency with sample rate
-        # subtract from 1 since (0,0) for YOLO is upper left, but we define (0,0) lower left
-        y_center = 1 - ((metadata["sample_rate"] / 2.0) + metadata["center_freq"]) / metadata["sample_rate"]
-        yolo_label = (class_index, x_center, y_center, width, height)
-        metadata["yolo_label"] = yolo_label
-
-        return metadata
-
-
diff --git a/torchsig/transforms/transforms.py b/torchsig/transforms/transforms.py
index d7a9f2ac4..38e169a37 100644
--- a/torchsig/transforms/transforms.py
+++ b/torchsig/transforms/transforms.py
@@ -1,4 +1,4 @@
-"""Transforms on Signal and DatasetSignal objects.
+"""Transforms on Signal objects.
 """
 
 __all__ = [
@@ -11,11 +11,13 @@ __all__ = [
     "CarrierPhaseNoise",
     "CarrierPhaseOffset",
     "ChannelSwap",
+    "ClockDrift",
+    "ClockJitter",
     "CoarseGainChange",
     "CochannelInterference",
     "ComplexTo2D",
     "CutOut",
-    "DigitalAGC"
+    "DigitalAGC",
     "Doppler",
     "Fading",
     "IntermodulationProducts",
@@ -38,21 +40,21 @@ __all__ = [
 
 # TorchSig
 from torchsig.transforms.base_transforms import Transform
-from torchsig.signals.signal_types import Signal, DatasetSignal, SignalMetadata
+from torchsig.signals.signal_types import Signal, SignalMetadata
 import torchsig.transforms.functional as F
 from torchsig.utils.dsp import (
-    torchsig_complex_data_type,
-    torchsig_real_data_type,
+    TorchSigComplexDataType,
+    TorchSigRealDataType,
     low_pass
 )
 
 # Third Party
 import numpy as np
-import scipy as sp
+import numpy.typing as npt
 from copy import copy
 
 # Built-In
-from typing import Tuple, List, Union
+from typing import Tuple, List
 
 
 
@@ -60,23 +62,91 @@ class SignalTransform(Transform):
     """SignalTransform parent class.
     """
 
-    def update(self, signal: Union[Signal, DatasetSignal]) -> None:
-        """Updates bookkeeping to Transforms metadata for Signals and DatsetSignals and checks signal valididty.
-        Inherited classes should always call self.update() after performing transform operation (inside __call__).
+    def __init__(
+        self,
+        required_metadata: List[str] = [],
+        data_dtype: npt.DTypeLike = None,
+        precise: bool = False,
+        **kwargs
+    ):
+        """Base class for performing transforms on data
+
+        These transforms primarily change or augment the data, and will sometimes update the metadata.
 
         Args:
-            signal (Union[Signal, DatasetSignal]): Transformed signal.
+            required_metadata (List[str], optional): Required signal metadata to perform transform. Defaults to [].
+            precise (bool, optional): Enable precise, but slower signal metadata updates. Defaults to False.
+        """        
+        super().__init__(
+            required_metadata=required_metadata,
+            **kwargs
+        )
+        # enforces data dtype after tranform
+        # set to None for no enforcement
+        self.data_dtype = data_dtype
 
-        """
-        if isinstance(signal, DatasetSignal):
-            for m in signal.metadata:
-                m.applied_transforms.append(self)
-        else:
-            signal.metadata.applied_transforms.append(self)
-        # signal.verify()
+        # enables accurate (but slower) metadata updates
+        # some transforms require computationally intensive metadata updates
+        # by default are disable in favor of speed, but if accurate metadata is desired, set to True
+        self.precise = precise
 
-    def __call__(self, signal: Union[Signal, DatasetSignal]) -> Union[Signal, DatasetSignal]:
-        """Performs transforms.
+    def __validate__(self, signal: Signal) -> Signal:
+        """Validates signal before transform is applied
+
+        Args:
+            signal (Signal): Signal to be transformed.
+
+        Raises:
+            ValueError: signal is not a Signal or missing required metadata to perform transform.
+        Returns:
+            Signal: Valid signal.
+        """        
+        if not isinstance(signal, Signal):
+            # not a Signal object
+            raise ValueError(f"Must be Signal class for transform {self.__class__.__name__}, signal is {type(signal)}.")
+
+        # check signal and all components have required metadata
+        signal_metadata = signal.get_full_metadata()
+
+        for sm in signal_metadata:
+            # for all signal metdatas
+            for rm in self.required_metadata:
+                # for each required metdata
+                # check signal metadata has required fields
+                if not hasattr(sm, rm):
+                    # throw error if not
+                    raise ValueError(f"Signal missing {rm} in metadata: {sm}.")
+
+        # signal has all required metadata
+        return signal
+
+    def __call__(self, signal: Signal) -> Signal:
+        """Validates signal, performs transform, updates bookeeping, (optionally) enforces data type
+
+        Args:
+            signal (Signal): Signal to be transformed.
+
+        Returns:
+            Signal: Transformed signal.
+        """        
+        # validate signal
+        signal = self.__validate__(signal)
+
+        # perform transform
+        signal = self.__apply__(signal)
+
+        # update bookeeping
+        self.__update__(signal)
+
+        # (optional) enforce data is dtype
+        if self.data_dtype is not None:
+            signal.data = signal.data.astype(self.data_dtype)
+
+        # return transformed signal
+        return signal
+
+    def __apply__(self, signal: Signal) -> Signal:
+        """Performs transform.
 
         Args:
             signal (Signal): Signal to be transformed.
@@ -96,51 +166,41 @@ class AWGN(SignalTransform):
 
     Attributes:
         noise_power_db (float): noise AWGN power in dB (absolute).
-        measure (bool): Measure and update SNR metadata. Default to False.
+        precise (bool): Measure and update SNR metadata. Default to False.
     
     """
     def __init__(
         self,
         noise_power_db: float,
-        measure: bool = False,
+        precise: bool = False,
         **kwargs
     ):
-        super().__init__(**kwargs)
+        super().__init__(
+            required_metadata=["snr_db"],
+            data_dtype = TorchSigComplexDataType,
+            **kwargs
+        )
         self.noise_power_db = noise_power_db
         self.noise_power_linear = 10**(self.noise_power_db / 10)
-        self.measure = measure
-
-    def __call__(self, signal: Union[Signal, DatasetSignal]) -> Union[Signal, DatasetSignal]:
-        if self.measure:
-            if isinstance(signal, DatasetSignal):
-                for i, m in enumerate(signal.metadata):
-                    start = m.start_in_samples
-                    duration = m.duration_in_samples
-                    stop = start + duration
-                    snr_linear = 10 ** (m.snr_db / 10) 
-                    
-                    # update SNR assuming independent noise
-                    total_power = np.sum(np.abs(signal.data[start:stop])**2)/duration
-                    sig_power = total_power / (1 + 1/snr_linear)
-                    noise_power = sig_power / snr_linear
-                    new_snr = sig_power / (noise_power + self.noise_power_linear)
-                    signal.metadata[i].snr_db = 10*np.log10(new_snr)
-            else:
-                # update SNR for full sampled band, assuming independent noise
-                snr_linear = 10 ** (signal.metadata.snr_db / 10)
-                total_power = np.sum(np.abs(signal.data)**2)/len(signal.data)
-                sig_power = total_power / (1 + 1/snr_linear)
-                noise_power = sig_power / snr_linear
-                new_snr = sig_power / (noise_power + self.noise_power_linear)
-                signal.metadata.snr_db = 10*np.log10(new_snr)                
+        self.precise = precise
+        
 
+    def __apply__(self, signal: Signal) -> Signal:
+        if self.precise:
+            # update SNR for full sampled band, assuming independent noise
+            snr_linear = 10 ** (signal.metadata.snr_db / 10)
+            total_power = np.sum(np.abs(signal.data)**2)/len(signal.data)
+            sig_power = total_power / (1 + 1/snr_linear)
+            noise_power = sig_power / snr_linear
+            new_snr = sig_power / (noise_power + self.noise_power_linear)
+            signal.metadata.snr_db = 10*np.log10(new_snr)     
+           
         signal.data = F.awgn(
             signal.data,
             noise_power_db = self.noise_power_db,
             rng = self.random_generator
         )
-        signal.data = signal.data.astype(torchsig_complex_data_type)
-        self.update(signal)
+        
         return signal
 
 
@@ -149,10 +209,19 @@ class AddSlope(SignalTransform):
     Creates a weak 0 Hz IF notch filtering effect.
 
     """
-    def __call__(self, signal: Union[Signal, DatasetSignal]) -> Union[Signal, DatasetSignal]:
+    def __init__(
+        self,
+        **kwargs
+    ):
+        super().__init__(
+            required_metadata=[],
+            data_dtype = TorchSigComplexDataType,
+            **kwargs
+        )
+
+    def __apply__(self, signal: Signal) -> Signal:
         signal.data = F.add_slope(signal.data) 
-        signal.data = signal.data.astype(torchsig_complex_data_type)
-        self.update(signal)
+        
         return signal
 
 
@@ -166,7 +235,7 @@ class AdditiveNoise(SignalTransform):
         color (str): Noise color, supports 'white', 'pink', or 'red' noise frequency spectrum types. 
             Defaults to 'white'.
         continuous (bool): Sets noise to continuous (True) or impulsive (False). Defaults to True.
-        measure (bool): Measure and update SNR metadata. Default to False.
+        precise (bool): Measure and update SNR metadata. Default to False.
     
     """
     def __init__(
@@ -174,41 +243,32 @@ class AdditiveNoise(SignalTransform):
         power_range: Tuple = (0.01, 10.0),
         color: str = 'white',
         continuous: bool = True,
-        measure: bool = False,
+        precise: bool = False,
         **kwargs
     ):  
-        super().__init__(**kwargs)
+        super().__init__(
+            required_metadata=["snr_db"],
+            data_dtype = TorchSigComplexDataType,
+            **kwargs
+        )
         self.power_range = power_range
         self.power_distribution = self.get_distribution(self.power_range)
         self.color = color
         self.continuous = continuous
-        self.measure = measure
+        self.precise = precise
+        
     
-    def __call__(self, signal: Union[Signal, DatasetSignal]) -> Union[Signal, DatasetSignal]:
+    def __apply__(self, signal: Signal) -> Signal:
         add_noise_power = self.power_distribution()
         
-        if self.measure:
-            if isinstance(signal, DatasetSignal):
-                for i, m in enumerate(signal.metadata):            
-                    start = m.start_in_samples
-                    duration = m.duration_in_samples
-                    stop = start + duration
-                    snr_linear = 10 ** (m.snr_db / 10) 
-                    
-                    # update SNR assuming independent noise
-                    total_power = np.sum(np.abs(signal.data[start:stop])**2)/duration
-                    sig_power = total_power / (1 + 1/snr_linear)
-                    noise_power = sig_power / snr_linear
-                    new_snr = sig_power / (noise_power + add_noise_power)
-                    signal.metadata[i].snr_db = 10*np.log10(new_snr)
-            else:
-                # update SNR for full sampled band, assuming independent noise
-                snr_linear = 10 ** (signal.metadata.snr_db / 10)
-                total_power = np.sum(np.abs(signal.data)**2)/len(signal.data)
-                sig_power = total_power / (1 + 1/snr_linear)
-                noise_power = sig_power / snr_linear
-                new_snr = sig_power / (noise_power + add_noise_power)
-                signal.metadata.snr_db = 10*np.log10(new_snr)           
+        if self.precise:
+            # update SNR for full sampled band, assuming independent noise
+            snr_linear = 10 ** (signal.metadata.snr_db / 10)
+            total_power = np.sum(np.abs(signal.data)**2)/len(signal.data)
+            sig_power = total_power / (1 + 1/snr_linear)
+            noise_power = sig_power / snr_linear
+            new_snr = sig_power / (noise_power + add_noise_power)
+            signal.metadata.snr_db = 10*np.log10(new_snr)           
             
         signal.data = F.additive_noise(
             data = signal.data,
@@ -217,8 +277,7 @@ class AdditiveNoise(SignalTransform):
             continuous = self.continuous,
             rng = self.random_generator
         )
-        signal.data = signal.data.astype(torchsig_complex_data_type)
-        self.update(signal)
+        
         return signal
 
 
@@ -253,7 +312,11 @@ class AdjacentChannelInterference(SignalTransform):
         filter_weights: np.ndarray = low_pass(0.125, 0.125, 1.0),
         **kwargs
     ):  
-        super().__init__(**kwargs)
+        super().__init__(
+            required_metadata=[],
+            data_dtype = TorchSigComplexDataType,
+            **kwargs
+        )
         self.sample_rate = sample_rate
         self.power_range = power_range
         self.power_distribution = self.get_distribution(self.power_range)
@@ -265,7 +328,7 @@ class AdjacentChannelInterference(SignalTransform):
         self.time_sigma_distribution = self.get_distribution(self.time_sigma_range)
         self.filter_weights = filter_weights # predefined, fixed filter     
     
-    def __call__(self, signal: Union[Signal, DatasetSignal]) -> Union[Signal, DatasetSignal]:
+    def __apply__(self, signal: Signal) -> Signal:
         signal.data = F.adjacent_channel_interference(
             data = signal.data,
             sample_rate = self.sample_rate,
@@ -275,9 +338,8 @@ class AdjacentChannelInterference(SignalTransform):
             time_sigma = self.time_sigma_distribution(),
             filter_weights = self.filter_weights,
             rng = self.random_generator
-        )        
-        signal.data = signal.data.astype(torchsig_complex_data_type)
-        self.update(signal)
+        )
+        
         return signal
 
 
@@ -294,20 +356,23 @@ class CarrierFrequencyDrift(SignalTransform):
         drift_ppm: Tuple[float, float] = (0.1, 10),
         **kwargs
     ):
-        super().__init__(**kwargs)
+        super().__init__(
+            required_metadata=[],
+            data_dtype = TorchSigComplexDataType,
+            **kwargs
+        )
         self.drift_ppm = drift_ppm
         self.drift_ppm_distribution = self.get_distribution(self.drift_ppm,'log10')
     
-    def __call__(self, signal: Union[Signal, DatasetSignal]) -> Union[Signal, DatasetSignal]:
+    def __apply__(self, signal: Signal) -> Signal:
         drift_ppm = self.drift_ppm_distribution()
 
         signal.data = F.carrier_frequency_drift(
             data = signal.data, 
             drift_ppm = drift_ppm, 
             rng = self.random_generator
-        )
-        signal.data = signal.data.astype(torchsig_complex_data_type)       
-        self.update(signal)
+        )   
+        
         return signal
 
 
@@ -324,11 +389,15 @@ class CarrierPhaseNoise(SignalTransform):
         phase_noise_degrees: Tuple[float, float] = (0.25, 1),
         **kwargs
     ):
-        super().__init__(**kwargs)
+        super().__init__(
+            required_metadata=[],
+            data_dtype = TorchSigComplexDataType,
+            **kwargs
+        )
         self.phase_noise_degrees = phase_noise_degrees
         self.phase_noise_degrees_distribution = self.get_distribution(self.phase_noise_degrees)
     
-    def __call__(self, signal: Union[Signal, DatasetSignal]) -> Union[Signal, DatasetSignal]:
+    def __apply__(self, signal: Signal) -> Signal:
         phase_noise_degrees = self.phase_noise_degrees_distribution()
 
         signal.data = F.carrier_phase_noise(
@@ -336,8 +405,7 @@ class CarrierPhaseNoise(SignalTransform):
             phase_noise_degrees = phase_noise_degrees,
             rng = self.random_generator
         )
-        signal.data = signal.data.astype(torchsig_complex_data_type)
-        self.update(signal)
+        
         return signal
 
 
@@ -362,17 +430,19 @@ class CarrierPhaseOffset(SignalTransform):
         phase_offset_range: Tuple[float, float] = (0, 2*np.pi),
         **kwargs
     ):
-        super().__init__(**kwargs)
+        super().__init__(
+            required_metadata=[],
+            data_dtype = TorchSigComplexDataType,
+            **kwargs
+        )
         self.phase_offset_range = phase_offset_range
         self.phase_offset_distribution = self.get_distribution(self.phase_offset_range)
     
-    def __call__(self, signal: Union[Signal, DatasetSignal]) -> Union[Signal, DatasetSignal]:
+    def __apply__(self, signal: Signal) -> Signal:
         phase_offset = self.phase_offset_distribution()
 
         signal.data = F.phase_offset(signal.data, phase_offset)
-
-        signal.data = signal.data.astype(torchsig_complex_data_type)
-        self.update(signal)
+        
         return signal
 
 
@@ -380,18 +450,84 @@ class ChannelSwap(SignalTransform):
     """Swaps the I and Q channels of complex input data.
     
     """
-    def __call__(self, signal: Union[Signal, DatasetSignal]) -> Union[Signal, DatasetSignal]:
+    def __init__(
+        self, 
+        **kwargs
+    ):
+        super().__init__(
+            required_metadata=[],
+            data_dtype = TorchSigComplexDataType,
+            **kwargs
+        )
+
+    def __apply__(self, signal: Signal) -> Signal:
         signal.data = F.channel_swap(signal.data)
-        signal.data = signal.data.astype(torchsig_complex_data_type)
 
         # metadata: swapping I/Q channels creates a frequency mirroring
-        if isinstance(signal, DatasetSignal):
-            for m in signal.metadata:
-                m.center_freq *= -1
-        else:
+        if signal.metadata and signal.metadata.center_freq:
             signal.metadata.center_freq *= -1
+        return signal
+
+
+class ClockDrift(SignalTransform):
+    """Simulates a clock drift effect, which applies a random error to
+    the sampling rate.
+    
+    """
 
-        self.update(signal)
+    def __init__(
+        self, 
+        drift_ppm: Tuple[float, float] = (1, 10),
+        **kwargs
+    ):
+        super().__init__(
+            required_metadata=[],
+            data_dtype = TorchSigComplexDataType,
+            **kwargs
+        )
+        self.drift_ppm = drift_ppm
+        self.drift_ppm_distribution = self.get_distribution(self.drift_ppm,'log10')
+    
+    def __apply__(self, signal: Signal) -> Signal:
+        drift_ppm = self.drift_ppm_distribution()
+
+        signal.data = F.clock_drift(
+            data = signal.data, 
+            drift_ppm = drift_ppm, 
+            rng = self.random_generator
+        )   
+        
+        return signal
+
+
+class ClockJitter(SignalTransform):
+    """Simulates a clock jitter effect, which applies a random error to
+    the sampling phase.
+    
+    """
+
+    def __init__(
+        self, 
+        jitter_ppm: Tuple[float, float] = (1, 10),
+        **kwargs
+    ):
+        super().__init__(
+            required_metadata=[],
+            data_dtype = TorchSigComplexDataType,
+            **kwargs
+        )
+        self.jitter_ppm = jitter_ppm
+        self.jitter_ppm_distribution = self.get_distribution(self.jitter_ppm,'log10')
+    
+    def __apply__(self, signal: Signal) -> Signal:
+        jitter_ppm = self.jitter_ppm_distribution()
+
+        signal.data = F.clock_jitter(
+            data = signal.data, 
+            jitter_ppm = jitter_ppm, 
+            rng = self.random_generator
+        )   
+        
         return signal
 
 
@@ -408,10 +544,14 @@ class CoarseGainChange(SignalTransform):
         gain_change_db: Tuple[float, float] = (-20, 20),
         **kwargs
     ):
-        super().__init__(**kwargs)
+        super().__init__(
+            required_metadata=[],
+            data_dtype = TorchSigComplexDataType,
+            **kwargs
+        )
         self.gain_change_db_distribution = self.get_distribution(gain_change_db)
         
-    def __call__(self, signal: Union[Signal, DatasetSignal]) -> Union[Signal, DatasetSignal]:
+    def __apply__(self, signal: Signal) -> Signal:
         # select a gain value change from distribution
         gain_change_db = self.gain_change_db_distribution()
         # determine which samples gain change will be applied to. minimum index is 1, and maximum
@@ -421,8 +561,7 @@ class CoarseGainChange(SignalTransform):
         start_index = self.random_generator.integers(1,len(signal.data)-1)
         
         signal.data = F.coarse_gain_change(signal.data, gain_change_db, start_index)
-        signal.data = signal.data.astype(torchsig_complex_data_type)
-        self.update(signal)
+        
         return signal
 
 
@@ -438,7 +577,7 @@ class CochannelInterference(SignalTransform):
         noise_color (str): Base noise color, supports 'white', 'pink', or 'red' noise 
             frequency spectrum types. Default 'white'.
         continuous (bool): Sets noise to continuous (True) or impulsive (False). Default True.
-        measure (bool): Measure and update SNR metadata. Default to False.
+        precise (bool): Measure and update SNR metadata. Default to False.
     
     """
     def __init__(
@@ -447,36 +586,31 @@ class CochannelInterference(SignalTransform):
         filter_weights: np.ndarray = low_pass(0.125, 0.125, 1.0),
         color: str = 'white',
         continuous: bool = True,
-        measure: bool = False,
+        precise: bool = False,
         **kwargs
     ):  
-        super().__init__(**kwargs)
+        super().__init__(
+            required_metadata=["snr_db"],
+            data_dtype = TorchSigComplexDataType,
+            **kwargs
+        )
         self.power_range = power_range
         self.power_distribution = self.get_distribution(self.power_range)
         self.filter_weights = filter_weights # predefined, fixed band limiting filter
         self.color = color
         self.continuous = continuous
-        self.measure = measure
+        
     
-    def __call__(self, signal: Union[Signal, DatasetSignal]) -> Union[Signal, DatasetSignal]:
+    def __apply__(self, signal: Signal) -> Signal:
         cochan_noise_power = self.power_distribution()
 
-        if self.measure:
-            if isinstance(signal, DatasetSignal):  
-                for i, m in enumerate(signal.metadata):
-                    snr_linear = 10 ** (m.snr_db / 10)
-                    total_power = np.sum(np.abs(signal.data)**2)/len(signal.data)
-                    sig_power = total_power / (1 + 1/snr_linear)
-                    noise_power = sig_power / snr_linear
-                    new_snr = sig_power / (noise_power + cochan_noise_power)
-                    signal.metadata[i].snr_db = 10*np.log10(new_snr)
-            else:
-                snr_linear = 10 ** (signal.metadata.snr_db / 10)
-                total_power = np.sum(np.abs(signal.data)**2)/len(signal.data)
-                sig_power = total_power / (1 + 1/snr_linear)
-                noise_power = sig_power / snr_linear
-                new_snr = sig_power / (noise_power + self.noise_power_linear)
-                signal.metadata.snr_db = 10*np.log10(new_snr)
+        if self.precise:
+            snr_linear = 10 ** (signal.metadata.snr_db / 10)
+            total_power = np.sum(np.abs(signal.data)**2)/len(signal.data)
+            sig_power = total_power / (1 + 1/snr_linear)
+            noise_power = sig_power / snr_linear
+            new_snr = sig_power / (noise_power + self.noise_power_linear)
+            signal.metadata.snr_db = 10*np.log10(new_snr)
        
         signal.data = F.cochannel_interference(
             data = signal.data,
@@ -485,19 +619,27 @@ class CochannelInterference(SignalTransform):
             color = self.color,
             continuous = self.continuous,
             rng = self.random_generator
-        )        
-        signal.data = signal.data.astype(torchsig_complex_data_type)
-        self.update(signal)
+        )
+        
         return signal
 
 
 class ComplexTo2D(SignalTransform):
     """Converts IQ data to two channels (real and imaginary parts).
     """
-    def __call__(self, signal: Union[Signal, DatasetSignal]) -> Union[Signal, DatasetSignal]:
+    def __init__(
+        self, 
+        **kwargs
+    ):
+        super().__init__(
+            required_metadata=[],
+            data_dtype = TorchSigRealDataType,
+            **kwargs
+        )
+
+    def __apply__(self, signal: Signal) -> Signal:
         signal.data = F.complex_to_2d(signal.data)
-        signal.data = signal.data.astype(torchsig_real_data_type)
-        self.update(signal)
+        
         return signal
 
 
@@ -537,7 +679,14 @@ class CutOut(SignalTransform):
         cut_type: List[str] = (["zeros", "ones", "low_noise", "avg_noise", "high_noise"]),
         **kwargs
     ):
-        super().__init__(**kwargs)
+        super().__init__(
+            required_metadata=[
+                "start",
+                "stop"
+            ],
+            data_dtype = TorchSigComplexDataType,
+            **kwargs
+        )
         self.duration = duration
         self.cut_type = cut_type
 
@@ -566,13 +715,12 @@ class CutOut(SignalTransform):
         # only remaining type
         return "outside"
 
-    def __call__(self, signal: DatasetSignal) -> DatasetSignal:
+    def __apply__(self, signal: Signal) -> Signal:
         cut_duration = self.duration_distribution()  
         cut_type = self.cut_type_distribution()
         cut_start = self.random_generator.uniform(low = 0.0, high = 1.0 - cut_duration)
 
         signal.data = F.cut_out(signal.data, cut_start, cut_duration, cut_type )
-        signal.data = signal.data.astype(torchsig_complex_data_type)
 
         # metadata 
         # CutOut can have complicated signal feature effects in practice.
@@ -581,44 +729,22 @@ class CutOut(SignalTransform):
         # update start, duration
         cut_stop = cut_start + cut_duration
 
-        if isinstance(signal, DatasetSignal):
-            new_metadata = []
-            for m in signal.metadata:
-                overlap = self._determine_overlap(m, cut_start, cut_duration)
-                if overlap == "left":
-                    m.stop = cut_start
-                elif overlap == "right":
-                    m.start = cut_stop
-                elif overlap == "split":
-                    # left half = update current metadata
-                    m.stop = cut_start
-                    # right half = create new metadata
-                    right_half_metadata = m.deepcopy()
-                    right_half_metadata.start = cut_stop
-                    new_metadata.append(right_half_metadata)
-                elif overlap == "inside":
-                    continue
-                # else: signal outside of cut region
-                new_metadata.append(m)
-            
-            signal.metadata = new_metadata
-        else:
-            overlap = self._determine_overlap(signal.metadata, cut_start, cut_duration)
-            if overlap == "left":
-                signal.metadata.stop = cut_start
-            elif overlap == "right":
-                signal.metadata.start = cut_stop
-            elif overlap == "split":
-                # left half = update current metadata
-                signal.metadata.stop = cut_start
-                # right half = create new metadata
-                right_half_metadata = signal.metadata.deepcopy()
-                right_half_metadata.start = cut_stop
-                signal.metadata.start = right_half_metadata.start
-            #elif overlap == "inside":
-            # else: signal outside of cut region
-
-        self.update(signal)
+        overlap = self._determine_overlap(signal.metadata, cut_start, cut_duration)
+        if overlap == "left":
+            signal.metadata.stop = cut_start
+        elif overlap == "right":
+            signal.metadata.start = cut_stop
+        elif overlap == "split":
+            # left half = update current metadata
+            signal.metadata.stop = cut_start
+            # right half = create new metadata
+            right_half_metadata = signal.metadata.deepcopy()
+            right_half_metadata.start = cut_stop
+            signal.metadata.start = right_half_metadata.start
+        #elif overlap == "inside":
+        # else: signal outside of cut region
+
+        
         return signal
 
 class DigitalAGC(SignalTransform):
@@ -643,7 +769,11 @@ class DigitalAGC(SignalTransform):
         track_range_db: Tuple[float] = (0.5, 2),
         **kwargs
     ):
-        super().__init__(**kwargs)
+        super().__init__(
+            required_metadata=[],
+            data_dtype = TorchSigComplexDataType,
+            **kwargs
+        )
         self.initial_gain_db = initial_gain_db
         self.alpha_smooth = alpha_smooth
         self.alpha_track = alpha_track
@@ -658,7 +788,7 @@ class DigitalAGC(SignalTransform):
         self.alpha_acquire_distribution = self.get_distribution(self.alpha_acquire,'log10')
         self.track_range_db_distribution = self.get_distribution(self.track_range_db)
 
-    def __call__(self, signal: DatasetSignal) -> DatasetSignal:
+    def __apply__(self, signal: Signal) -> Signal:
 
         initial_gain_db = self.initial_gain_db_distribution()
         alpha_smooth = self.alpha_smooth_distribution()
@@ -677,7 +807,7 @@ class DigitalAGC(SignalTransform):
         receive_signal_mag = np.abs(receive_signal)
 
         # find and replace all zeros
-        zero_sample_index = np.where(receive_signal_mag == 0)[0]
+        zero_sample_index = np.where(np.equal(receive_signal_mag,0))[0]
 
         # calculate all other values
         non_zero_sample_index = np.setdiff1d(np.arange(0,len(receive_signal)),zero_sample_index)
@@ -720,8 +850,7 @@ class DigitalAGC(SignalTransform):
             np.float64(low_level_db),
             np.float64(high_level_db)
         )
-        signal.data = signal.data.astype(torchsig_complex_data_type)
-        self.update(signal)
+        
         return signal
 
 
@@ -732,23 +861,23 @@ class Doppler(SignalTransform):
         velocity_range (Tuple[float, float]): Relative velocity bounds in m/s. Default (0.0, 10.0)
         velocity_distribution (Callable[[], float]): Random draw from velocity distribution.
         propagation_speed (float): Wave speed in medium. Default 2.9979e8 m/s.
-        sampling_rate (float): Data sampling rate. Default 1.0.
-        
     """
     def __init__(
         self, 
         velocity_range: Tuple[float, float] = (0.0, 10.0),
         propagation_speed: float = 2.9979e8,
-        sampling_rate: float = 1.0,
         **kwargs
     ):
-        super().__init__(**kwargs)
+        super().__init__(
+            required_metadata=[],
+            data_dtype = TorchSigComplexDataType,
+            **kwargs
+        )
         self.velocity_range = velocity_range
         self.velocity_distribution = self.get_distribution(self.velocity_range)
         self.propagation_speed = propagation_speed
-        self.sampling_rate = sampling_rate
     
-    def __call__(self, signal: Union[Signal, DatasetSignal]) -> Union[Signal, DatasetSignal]:
+    def __apply__(self, signal: Signal) -> Signal:
         velocity = self.velocity_distribution()
         alpha = self.propagation_speed / (self.propagation_speed - velocity) # scaling factor
 
@@ -756,20 +885,12 @@ class Doppler(SignalTransform):
             data = signal.data, 
             velocity = velocity, 
             propagation_speed = self.propagation_speed, 
-            sampling_rate = self.sampling_rate
         )
-        signal.data = signal.data.astype(torchsig_complex_data_type)
-        
-        # adjust metadata by scaling factor
-        if isinstance(signal, DatasetSignal):
-            for m in signal.metadata:
-                m.center_freq *= alpha
-                m.bandwidth *= alpha               
-        else:
+        if signal.metadata and signal.metadata.center_freq:
             signal.metadata.center_freq *= alpha
+        if signal.metadata and signal.metadata.bandwidth:
             signal.metadata.bandwidth *= alpha
-
-        self.update(signal)
+        
         return signal
 
 
@@ -799,12 +920,16 @@ class Fading(SignalTransform): # slow, fast, block fading
         power_delay_profile: Tuple | List | np.ndarray = (1, 1),
         **kwargs
     ):
-        super().__init__(**kwargs)
+        super().__init__(
+            required_metadata=[],
+            data_dtype = TorchSigComplexDataType,
+            **kwargs
+        )
         self.coherence_bandwidth = coherence_bandwidth
         self.power_delay_profile = np.asarray(power_delay_profile)
         self.coherence_bandwidth_distribution = self.get_distribution(self.coherence_bandwidth)
         
-    def __call__(self, signal: Union[Signal, DatasetSignal]) -> Union[Signal, DatasetSignal]:
+    def __apply__(self, signal: Signal) -> Signal:
         coherence_bandwidth = self.coherence_bandwidth_distribution()
 
         signal.data = F.fading(
@@ -813,8 +938,7 @@ class Fading(SignalTransform): # slow, fast, block fading
             power_delay_profile = self.power_delay_profile,
             rng = self.random_generator
         )
-        signal.data = signal.data.astype(torchsig_complex_data_type)
-        self.update(signal)
+        
         return signal
 
 
@@ -833,36 +957,40 @@ class IntermodulationProducts(SignalTransform):
         coeffs_range: Tuple[float, float] = (1e-4, 1e-1),
         **kwargs
     ):  
-        super().__init__(**kwargs)
+        super().__init__(
+            required_metadata=[],
+            data_dtype = TorchSigComplexDataType,
+            **kwargs
+        )
         self.model_order = model_order
         self.model_order_distribution = self.get_distribution(self.model_order)
         self.coeffs_range = coeffs_range
         self.coeffs_distribution = self.get_distribution(self.coeffs_range,'log10')
     
-    def __call__(self, signal: Union[Signal, DatasetSignal]) -> Union[Signal, DatasetSignal]:
+    def __apply__(self, signal: Signal) -> Signal:
         # get randomized choice for model order
         model_order = self.model_order_distribution()
 
         # determine how many non-zero coefficients
         num_coefficients = len(np.arange(0,model_order,2))
         # pre-allocate with all zeros
-        non_zero_coeffs = np.zeros(num_coefficients,dtype=torchsig_complex_data_type)
+        non_zero_coeffs = np.zeros(num_coefficients,dtype=TorchSigComplexDataType)
         # randomize each coefficient
         for index in range(num_coefficients):
-            if (index == 0):
+            if np.equal(index,0):
                 non_zero_coeffs[index] = 1
             else:
                 # calculate coefficient
                 non_zero_coeffs[index] = self.coeffs_distribution()
                 # run loop to ensure each coefficient must be smaller than the previous
-                while (non_zero_coeffs[index] > non_zero_coeffs[index-1]):
+                while non_zero_coeffs[index] > non_zero_coeffs[index-1]:
                     non_zero_coeffs[index] = self.coeffs_distribution()
 
         # form the coeff array with appropriate zero-based weights
-        coeffs = np.zeros(model_order,dtype=torchsig_complex_data_type)
+        coeffs = np.zeros(model_order,dtype=TorchSigComplexDataType)
         inner_index = 0
         for outer_index in range(model_order):
-            if (np.mod(outer_index,2) == 0):
+            if np.equal(np.mod(outer_index,2),0):
                 coeffs[outer_index] = non_zero_coeffs[inner_index]
                 inner_index += 1
 
@@ -870,8 +998,7 @@ class IntermodulationProducts(SignalTransform):
             data = signal.data,
             coeffs = coeffs      
         )
-        signal.data = signal.data.astype(torchsig_complex_data_type)
-        self.update(signal)
+        
         return signal
 
 
@@ -883,7 +1010,7 @@ class IQImbalance(SignalTransform):
         amplitude_imbalance_distribution (Callable[[], float]): Random draw from amplitude imbalance distribution.
         phase_imbalance (optional): Range bounds of IQ phase imbalance (radians).        
         phase_imbalance (Callable[[], float]): Random draw from phase imbalance distribution.
-        dc_offset_db (Tuple, optional): Range bounds for DC offset in relative power
+        dc_offset_db (Tuple, optional): Range bounds for DC offset in relative power.
         dc_offset_db_distribution (Callable[[], (float, float)]): Random draw from dc_offset_db distribution.
         dc_offset_phase_rads (Tuple, optional): Range bounds for phase of DC offset
         dc_offset_phase_rads_distribution (Callable[[], (float, float)]): Random draw from dc_offset_phase_rads distribution.
@@ -893,11 +1020,15 @@ class IQImbalance(SignalTransform):
         self,
         amplitude_imbalance = (-1., 1.),
         phase_imbalance = (-2.0 * np.pi / 180.0, 2.0 * np.pi / 180.0),
-        dc_offset_db = (0,30),
+        dc_offset_db = (0,3),
         dc_offset_rads = (0, 2*np.pi),
         **kwargs
     ):  
-        super().__init__(**kwargs)
+        super().__init__(
+            required_metadata=[],
+            data_dtype = TorchSigComplexDataType,
+            **kwargs
+        )
         self.amplitude_imbalance = amplitude_imbalance
         self.phase_imbalance = phase_imbalance
         self.dc_offset_db = dc_offset_db
@@ -908,7 +1039,7 @@ class IQImbalance(SignalTransform):
         self.dc_offset_db_distribution = self.get_distribution(self.dc_offset_db)
         self.dc_offset_phase_rads_distribution = self.get_distribution(self.dc_offset_rads)
 
-    def __call__(self, signal: Union[Signal, DatasetSignal]) -> Union[Signal, DatasetSignal]:
+    def __apply__(self, signal: Signal) -> Signal:
 
         amplitude_imbalance = self.amplitude_imbalance_distribution()
         phase_imbalance = self.phase_imbalance_distribution()
@@ -922,8 +1053,7 @@ class IQImbalance(SignalTransform):
             dc_offset_db,
             dc_offset_rads
         )
-        signal.data = signal.data.astype(torchsig_complex_data_type)
-        self.update(signal)
+        
         return signal
 
 
@@ -934,13 +1064,15 @@ class InterleaveComplex(SignalTransform):
         self,
         **kwargs
     ):  
-        super().__init__(**kwargs)
-
-    def __call__(self, signal: Union[Signal, DatasetSignal]) -> Union[Signal, DatasetSignal]:
+        super().__init__(
+            required_metadata=[],
+            data_dtype = TorchSigRealDataType,
+            **kwargs
+        )
 
+    def __apply__(self, signal: Signal) -> Signal:
         signal.data = F.interleave_complex(signal.data)
-        signal.data = signal.data.astype(torchsig_real_data_type)
-        self.update(signal)
+        
         return signal
 
 
@@ -972,7 +1104,11 @@ class NonlinearAmplifier(SignalTransform):
         auto_scale: bool = True,
         **kwargs
     ):  
-        super().__init__(**kwargs)
+        super().__init__(
+            required_metadata=[],
+            data_dtype = TorchSigComplexDataType,
+            **kwargs
+        )
         self.gain_range = gain_range
         self.gain_distribution = self.get_distribution(self.gain_range)
         self.psat_backoff_range = psat_backoff_range
@@ -983,7 +1119,7 @@ class NonlinearAmplifier(SignalTransform):
         self.phi_slope_distribution = self.get_distribution(self.phi_slope_range)
         self.auto_scale = auto_scale
     
-    def __call__(self, signal: Union[Signal, DatasetSignal]) -> Union[Signal, DatasetSignal]:
+    def __apply__(self, signal: Signal) -> Signal:
         gain = self.gain_distribution()
         psat_backoff = self.psat_backoff_distribution()
         phi_max = self.phi_max_distribution()
@@ -997,8 +1133,7 @@ class NonlinearAmplifier(SignalTransform):
             phi_slope = phi_slope,
             auto_scale = self.auto_scale
         )
-        signal.data = signal.data.astype(torchsig_complex_data_type)
-        self.update(signal)
+        
         return signal
 
 
@@ -1019,7 +1154,11 @@ class PassbandRipple(SignalTransform):
         **kwargs
     ):
 
-        super().__init__(**kwargs)
+        super().__init__(
+            required_metadata=[],
+            data_dtype = TorchSigComplexDataType,
+            **kwargs
+        )
         self.max_ripple_db = max_ripple_db
         self.max_ripple_db_distribution = self.get_distribution(self.max_ripple_db)
         self.num_taps = num_taps
@@ -1027,7 +1166,7 @@ class PassbandRipple(SignalTransform):
         self.coefficient_decay_rate = coefficient_decay_rate
         self.coefficient_decay_rate_distribution = self.get_distribution(coefficient_decay_rate)
 
-    def __call__(self, signal: Union[Signal, DatasetSignal]) -> Union[Signal, DatasetSignal]:
+    def __apply__(self, signal: Signal) -> Signal:
         max_ripple_db = self.max_ripple_db_distribution()
         num_taps = int(np.round(self.num_taps_distribution()))
         coefficient_decay_rate = self.coefficient_decay_rate_distribution()
@@ -1039,8 +1178,7 @@ class PassbandRipple(SignalTransform):
             coefficient_decay_rate = coefficient_decay_rate,
             rng = self.random_generator
         )
-        signal.data = signal.data.astype(torchsig_complex_data_type)
-        self.update(signal)
+        
         return signal
 
 
@@ -1073,13 +1211,17 @@ class PatchShuffle(SignalTransform):
         **kwargs
 
     ) -> None:
-        super().__init__(**kwargs)
+        super().__init__(
+            required_metadata=[],
+            data_dtype = TorchSigComplexDataType,
+            **kwargs
+        )
         self.patch_size = patch_size
         self.shuffle_ratio = shuffle_ratio
         self.patch_size_distribution = self.get_distribution(self.patch_size )
         self.shuffle_ratio_distribution = self.get_distribution(self.shuffle_ratio )
         
-    def __call__(self, signal: Union[Signal, DatasetSignal]) -> Union[Signal, DatasetSignal]:
+    def __apply__(self, signal: Signal) -> Signal:
         patch_size = self.patch_size_distribution()
         shuffle_ratio = self.shuffle_ratio_distribution()
 
@@ -1097,12 +1239,11 @@ class PatchShuffle(SignalTransform):
             patches_to_shuffle,
             self.random_generator
         )
-        signal.data = signal.data.astype(torchsig_complex_data_type)
 
         # PatchShuffle can have complicated signal feature effects in practice.
         # Any desired metadata updates should be made manually.
         
-        self.update(signal)
+        
         return signal
 
 
@@ -1124,7 +1265,11 @@ class Quantize(SignalTransform):
         rounding_mode: List[str] = ['floor', 'ceiling'],
         **kwargs
     ):
-        super().__init__(**kwargs)
+        super().__init__(
+            required_metadata=[],
+            data_dtype = TorchSigComplexDataType,
+            **kwargs
+        )
         self.num_bits = num_bits
         self.num_bits_distribution = self.get_distribution(self.num_bits)
         self.ref_level_adjustment_db = ref_level_adjustment_db
@@ -1132,7 +1277,7 @@ class Quantize(SignalTransform):
         self.rounding_mode = rounding_mode
         self.rounding_mode_distribution = self.get_distribution(self.rounding_mode)
         
-    def __call__(self, signal: Union[Signal, DatasetSignal]) -> Union[Signal, DatasetSignal]:
+    def __apply__(self, signal: Signal) -> Signal:
         num_bits = int(np.round(self.num_bits_distribution()))
         ref_level_adjustment_db = self.ref_level_adjustment_db_distribution()
         rounding_mode = self.rounding_mode_distribution()
@@ -1144,8 +1289,7 @@ class Quantize(SignalTransform):
             ref_level_adjustment_db = ref_level_adjustment_db,
             rounding_mode = rounding_mode,
         )
-        signal.data = signal.data.astype(torchsig_complex_data_type)
-        self.update(signal)
+        
         return signal
 
 
@@ -1187,7 +1331,11 @@ class RandomDropSamples(SignalTransform):
         fill: List[str] = (["ffill", "bfill", "mean", "zero"]),
         **kwargs
     ) -> None:
-        super().__init__(**kwargs)
+        super().__init__(
+            required_metadata=[],
+            data_dtype = TorchSigComplexDataType,
+            **kwargs
+        )
         self.drop_rate = drop_rate
         self.size = size
         self.fill = fill
@@ -1196,7 +1344,7 @@ class RandomDropSamples(SignalTransform):
         self.size_distribution = self.get_distribution(self.size )
         self.fill_distribution = self.get_distribution(self.fill )
         
-    def __call__(self, signal: Union[Signal, DatasetSignal]) -> Union[Signal, DatasetSignal]:
+    def __apply__(self, signal: Signal) -> Signal:
         drop_rate = self.drop_rate_distribution()
         fill = self.fill_distribution()
 
@@ -1210,8 +1358,7 @@ class RandomDropSamples(SignalTransform):
             drop_instances
         ).astype(int)
         signal.data = F.drop_samples(signal.data, drop_starts, drop_sizes, fill)
-        signal.data = signal.data.astype(torchsig_complex_data_type)
-        self.update(signal)
+        
         return signal
 
 
@@ -1231,13 +1378,17 @@ class Shadowing(SignalTransform):
         sigma_db_range: Tuple[float, float] = (2.0, 6.0),
         **kwargs
     ):
-        super().__init__(**kwargs)
+        super().__init__(
+            required_metadata=[],
+            data_dtype = TorchSigComplexDataType,
+            **kwargs
+        )
         self.mean_db_range = mean_db_range
         self.mean_db_distribution = self.get_distribution(self.mean_db_range)
         self.sigma_db_range = sigma_db_range
         self.sigma_db_distribution = self.get_distribution(self.sigma_db_range)
 
-    def __call__(self, signal: Union[Signal, DatasetSignal]) -> Union[Signal, DatasetSignal]:
+    def __apply__(self, signal: Signal) -> Signal:
         mean_db = self.mean_db_distribution()
         sigma_db = self.sigma_db_distribution()
 
@@ -1247,27 +1398,27 @@ class Shadowing(SignalTransform):
             sigma_db = sigma_db,
             rng = self.random_generator
         )
-        signal.data = signal.data.astype(torchsig_complex_data_type)
-        self.update(signal)
+        
         return signal
 
 
 class SpectralInversion(SignalTransform):
     """Inverts spectrum of complex signal data.
     """
-    def __call__(self, signal: Signal) -> Signal:
+    def __init__(
+        self, 
+        **kwargs
+    ):
+        super().__init__(
+            required_metadata=[],
+            data_dtype = TorchSigComplexDataType,
+            **kwargs
+        )
+    
+    def __apply__(self, signal: Signal) -> Signal:
         signal.data = F.spectral_inversion(signal.data)
-        signal.data = signal.data.astype(torchsig_complex_data_type)
-
-
-        # metadata
-        if isinstance(signal, DatasetSignal):
-            for m in signal.metadata:
-                m.center_freq *= -1
-        else:
+        if signal.metadata and signal.metadata.center_freq:
             signal.metadata.center_freq *= -1
-
-        self.update(signal)
         return signal
 
 
@@ -1283,19 +1434,22 @@ class Spectrogram(SignalTransform):
         fft_size: int,
         **kwargs
     ):
-        super().__init__(**kwargs)
+        super().__init__(
+            required_metadata=[],
+            data_dtype = TorchSigRealDataType,
+            **kwargs
+        )
         self.fft_size = fft_size
         # fft_stride is the number of data points to move or "hop" over when computing the next FF
         self.fft_stride = copy(fft_size)
 
-    def __call__(self, signal: Union[Signal, DatasetSignal]) -> Union[Signal, DatasetSignal]:
+    def __apply__(self, signal: Signal) -> Signal:
         signal.data = F.spectrogram(
             signal.data, 
             self.fft_size, 
             self.fft_stride, 
         )
-        signal.data = signal.data.astype(torchsig_real_data_type)
-        self.update(signal)
+        
         return signal
 
 
@@ -1343,7 +1497,11 @@ class SpectrogramDropSamples(SignalTransform):
         ),
         **kwargs
     ) -> None:
-        super().__init__(**kwargs)
+        super().__init__(
+            required_metadata=[],
+            data_dtype = TorchSigRealDataType,
+            **kwargs
+        )
         self.drop_rate = drop_rate
         self.size = size
         self.fill = fill
@@ -1352,7 +1510,7 @@ class SpectrogramDropSamples(SignalTransform):
         self.size_distribution = self.get_distribution(self.size )
         self.fill_distribution = self.get_distribution(self.fill )
         
-    def __call__(self, signal: Union[Signal, DatasetSignal]) -> Union[Signal, DatasetSignal]:
+    def __apply__(self, signal: Signal) -> Signal:
         drop_rate = self.drop_rate_distribution()
         fill = self.fill_distribution()
         drop_instances = int(signal.data.shape[0] * drop_rate)        
@@ -1372,12 +1530,11 @@ class SpectrogramDropSamples(SignalTransform):
                 drop_sizes,
                 fill,
             )
-            signal.data = signal.data.astype(torchsig_real_data_type)
             
             # SpectrogramDropSamples can have complicated signal feature effects in practice.
             # Any desired metadata updates should be made manually.
             
-            self.update(signal)
+            
         
         return signal
 
@@ -1392,19 +1549,23 @@ class SpectrogramImage(SignalTransform):
         black_hot: bool=True,
         **kwargs
     ) -> None:
-        super().__init__(**kwargs) 
+        super().__init__(
+            required_metadata=[],
+            data_dtype = TorchSigRealDataType,
+            **kwargs
+        ) 
         self.fft_size = fft_size
         self.fft_stride = fft_size #note: size = stride
         self.black_hot = black_hot
 
-    def __call__(self, signal: Union[Signal, DatasetSignal]) -> Union[Signal, DatasetSignal]:
+    def __apply__(self, signal: Signal) -> Signal:
         signal.data = F.spectrogram_image(
             data = signal.data,
             fft_size = self.fft_size,
             fft_stride = self.fft_stride,
             black_hot = self.black_hot
         )
-        self.update(signal)
+        
         return signal
 
 
@@ -1435,11 +1596,14 @@ class TimeReversal(SignalTransform):
         else:
             raise ValueError(f"Invalid type for allow_spectral_inversion {type(allow_spectral_inversion)}. Must be bool or float.")
 
-        super().__init__(**kwargs) 
+        super().__init__(
+            required_metadata=[],
+            data_dtype = TorchSigComplexDataType,
+            **kwargs
+        ) 
 
-    def __call__(self, signal: Union[Signal, DatasetSignal]) -> Union[Signal, DatasetSignal]:
+    def __apply__(self, signal: Signal) -> Signal:
         signal.data = F.time_reversal(signal.data)
-        signal.data = signal.data.astype(torchsig_complex_data_type)
 
         do_si = self.random_generator.random() > self.allow_spectral_inversion
         if do_si:
@@ -1447,19 +1611,12 @@ class TimeReversal(SignalTransform):
 
         # metadata
         num_data_samples = len(signal.data)
-        if isinstance(signal, DatasetSignal):
-            for i, m in enumerate(signal.metadata):
-                original_stop = m.stop_in_samples
-                signal.metadata[i].start_in_samples = num_data_samples - original_stop
-                if not do_si:
-                    signal.metadata[i].center_freq *= -1
-        else:
+        
+        if signal.metadata and signal.metadata.stop_in_samples:
             original_stop = signal.metadata.stop_in_samples
             signal.metadata.start_in_samples = num_data_samples - original_stop
-            if not do_si:
-                signal.metadata.center_freq *= -1
-        
-        self.update(signal)
+        if signal.metadata and signal.metadata.center_freq and not do_si:
+            signal.metadata.center_freq *= -1
         return signal
     
 
@@ -1485,7 +1642,11 @@ class TimeVaryingNoise(SignalTransform):
         random_regions: List | bool = True,
         **kwargs
     ):
-        super().__init__(**kwargs)
+        super().__init__(
+            required_metadata=[],
+            data_dtype = TorchSigComplexDataType,
+            **kwargs
+        )
         self.noise_power_low = noise_power_low
         self.noise_power_high = noise_power_high
         self.inflections = inflections
@@ -1496,7 +1657,7 @@ class TimeVaryingNoise(SignalTransform):
         self.inflections_distribution = self.get_distribution(self.inflections )
         self.random_regions_distribution = self.get_distribution(self.random_regions )
         
-    def __call__(self, signal: Union[Signal, DatasetSignal]) -> Union[Signal, DatasetSignal]:
+    def __apply__(self, signal: Signal) -> Signal:
         noise_power_low = self.noise_power_low_distribution()
         noise_power_high = self.noise_power_high_distribution()
         inflections = self.inflections_distribution()
@@ -1510,8 +1671,7 @@ class TimeVaryingNoise(SignalTransform):
             random_regions,
             rng = self.random_generator
         )
-        signal.data = signal.data.astype(torchsig_complex_data_type)
-        self.update(signal)
+        
         return signal
 
 
@@ -1531,14 +1691,18 @@ class Spurs(SignalTransform):
         relative_power_db: Tuple[float] = (0,30),
         **kwargs
     ):
-        super().__init__(**kwargs)
+        super().__init__(
+            required_metadata=[],
+            data_dtype = TorchSigComplexDataType,
+            **kwargs
+        )
         self.num_spurs = num_spurs
         self.num_spurs_distribution = self.get_distribution(self.num_spurs)
 
         self.relative_power_db = relative_power_db
         self.relative_power_db_distribution = self.get_distribution(self.relative_power_db)
         
-    def __call__(self, signal: DatasetSignal) -> DatasetSignal:
+    def __apply__(self, signal: Signal) -> Signal:
         num_spurs = int(np.round(self.num_spurs_distribution()))
 
         sample_rate = 1
@@ -1546,7 +1710,7 @@ class Spurs(SignalTransform):
         # randomize the parameters for each spur
         relative_power_db = []
         center_freqs = []
-        for index in range(num_spurs):
+        for _ in range(num_spurs):
             # randomize the relative power in dB
             relative_power_db.append(  self.relative_power_db_distribution() )
             # determine the corresponding center frequency
@@ -1561,7 +1725,6 @@ class Spurs(SignalTransform):
             center_freqs = center_freqs,
             relative_power_db = relative_power_db
         )
-        signal.data = signal.data.astype(torchsig_complex_data_type)
-        self.update(signal)
+        
         return signal
 
diff --git a/torchsig/utils/coordinate_system.py b/torchsig/utils/coordinate_system.py
index f2acb3b44..cdbad3645 100644
--- a/torchsig/utils/coordinate_system.py
+++ b/torchsig/utils/coordinate_system.py
@@ -1,97 +1,227 @@
+"""Library for overlap detection in spectrograms to control co-channel interference.
 
-# library for doing overlap detection in spectrograms so the amount of
-# co-channel interference can be controlled
+This module provides classes and functions to define 2D coordinates and axis-aligned
+rectangles, and to detect overlaps between rectangles using line-segment intersection
+and containment tests.
+"""
 
-# class object to contain (x,y) coordinates
+# class object to contain (x, y) coordinates
 class Coordinate:
-    def __init__( self, x, y):
-        self.x = x
-        self.y = y
-
-    def __str__( self ):
-        return f'x = {self.x}, y = {self.y}'
-
-# represents a rectangle shape with four vertices, with each vertex represented
-# using the Coordinate() class
-class Rectangle:
-    def __init__ ( self, lower_coord:Coordinate, upper_coord:Coordinate):
-        # build four verticies as coordinates
-        self.coord_lower_left = lower_coord
-        self.coord_upper_right = upper_coord
-
-        self.coord_upper_left = Coordinate(self.coord_lower_left.x,self.coord_upper_right.y)
-        self.coord_lower_right = Coordinate(self.coord_upper_right.x,self.coord_lower_left.y)
-
-
-# function used in determining if lines intersect
-# https://bryceboe.com/2006/10/23/line-segment-intersection-algorithm/
-def counter_clock_wise(A:Coordinate,B:Coordinate,C:Coordinate):
-    return (C.y-A.y)*(B.x-A.x) > (B.y-A.y)*(C.x-A.x)
+    """Represents a point in 2D space with x and y coordinates.
 
-# determine if two lines (AB and CD) intersect
-# https://bryceboe.com/2006/10/23/line-segment-intersection-algorithm/
-def line_intersection(A,B,C,D):
-    return counter_clock_wise(A,C,D) != counter_clock_wise(B,C,D) and counter_clock_wise(A,B,C) != counter_clock_wise(A,B,D)
+    Attributes:
+        x (float): X-coordinate of the point.
+        y (float): Y-coordinate of the point.
+    """
 
-# determine the input point is within the range of two points on a 1D line
-def is_within_range ( test_coord_x, rectangle_left_x, rectangle_right_x ):
-    linear_overlap_bool = rectangle_left_x <= test_coord_x and test_coord_x <= rectangle_right_x
-    return linear_overlap_bool
+    def __init__(self, x: float, y: float):
+        """Initialize a Coordinate.
 
-# determine if the corner point is within the boundary of the box
-def is_corner_in_rectangle ( corner_coord:Coordinate, reference_box:Rectangle ):
-
-    # check if x position is within boundary of box
-    corner_overlap_x = is_within_range( corner_coord.x, reference_box.coord_lower_left.x, reference_box.coord_lower_right.x )
-    # check if y position is within boundary of box
-    corner_overlap_y = is_within_range( corner_coord.y, reference_box.coord_lower_left.y, reference_box.coord_upper_left.y  )
-
-    corner_overlap_bool = corner_overlap_x and corner_overlap_y
-
-    return corner_overlap_bool
-
-# determine if a box is fully within the bounds of another box
-def is_rectangle_inside_rectangle( rectangle_a:Rectangle, rectangle_b:Rectangle ):
+        Args:
+            x (float): X-coordinate.
+            y (float): Y-coordinate.
+        """
+        self.x = x
+        self.y = y
 
-    # check if the four verices are within boundary
-    corner_overlap_bool_0 = is_corner_in_rectangle( rectangle_a.coord_lower_left,  rectangle_b )
-    corner_overlap_bool_1 = is_corner_in_rectangle( rectangle_a.coord_upper_left,  rectangle_b )
-    corner_overlap_bool_2 = is_corner_in_rectangle( rectangle_a.coord_upper_right, rectangle_b )
-    corner_overlap_bool_3 = is_corner_in_rectangle( rectangle_a.coord_lower_right, rectangle_b )
+    def __str__(self) -> str:
+        """Return a human-readable string representation of the coordinate.
 
-    rectangle_overlap_bool = corner_overlap_bool_0 and corner_overlap_bool_1 and corner_overlap_bool_2 and corner_overlap_bool_3
+        Returns:
+            str: Formatted as 'x = {x}, y = {y}'.
+        """
+        return f'x = {self.x}, y = {self.y}'
 
-    return rectangle_overlap_bool
 
-# determine if two boxes have any overlap. the conditions include:
-#  1. one (or more) of the sides intersect with one another
-#  2. one box is totally enclosed by another box
-def is_rectangle_overlap ( rectangle_a:Rectangle, rectangle_b:Rectangle ):
+# represents a rectangle shape with four vertices, each a Coordinate
+class Rectangle:
+    """Represents an axis-aligned rectangle defined by two opposite corners.
 
-    # check all combinations for the overlap of all sides
-    line_intersection_0  = line_intersection(rectangle_a.coord_lower_left,  rectangle_a.coord_lower_right, rectangle_b.coord_lower_left,  rectangle_b.coord_lower_right)
-    line_intersection_1  = line_intersection(rectangle_a.coord_lower_left,  rectangle_a.coord_lower_right, rectangle_b.coord_lower_left,  rectangle_b.coord_upper_left)
-    line_intersection_2  = line_intersection(rectangle_a.coord_lower_left,  rectangle_a.coord_lower_right, rectangle_b.coord_upper_left,  rectangle_b.coord_upper_right)
-    line_intersection_3  = line_intersection(rectangle_a.coord_lower_left,  rectangle_a.coord_lower_right, rectangle_b.coord_upper_right, rectangle_b.coord_lower_right)
+    The rectangle is built from a lower-left and an upper-right corner,
+    from which the other two corners are inferred.
 
-    line_intersection_4  = line_intersection(rectangle_a.coord_lower_left,  rectangle_a.coord_upper_left,  rectangle_b.coord_lower_left,  rectangle_b.coord_lower_right)
-    line_intersection_5  = line_intersection(rectangle_a.coord_lower_left,  rectangle_a.coord_upper_left,  rectangle_b.coord_lower_left,  rectangle_b.coord_upper_left)
-    line_intersection_6  = line_intersection(rectangle_a.coord_lower_left,  rectangle_a.coord_upper_left,  rectangle_b.coord_upper_left,  rectangle_b.coord_upper_right)
-    line_intersection_7  = line_intersection(rectangle_a.coord_lower_left,  rectangle_a.coord_upper_left,  rectangle_b.coord_upper_right, rectangle_b.coord_lower_right)
+    Attributes:
+        coord_lower_left (Coordinate): Lower-left corner.
+        coord_upper_right (Coordinate): Upper-right corner.
+        coord_upper_left (Coordinate): Upper-left corner.
+        coord_lower_right (Coordinate): Lower-right corner.
+    """
 
-    line_intersection_8  = line_intersection(rectangle_a.coord_upper_left,  rectangle_a.coord_upper_right, rectangle_b.coord_lower_left,  rectangle_b.coord_lower_right)
-    line_intersection_9  = line_intersection(rectangle_a.coord_upper_left,  rectangle_a.coord_upper_right, rectangle_b.coord_lower_left,  rectangle_b.coord_upper_left)
-    line_intersection_10 = line_intersection(rectangle_a.coord_upper_left,  rectangle_a.coord_upper_right, rectangle_b.coord_upper_left,  rectangle_b.coord_upper_right)
-    line_intersection_11 = line_intersection(rectangle_a.coord_upper_left,  rectangle_a.coord_upper_right, rectangle_b.coord_upper_right, rectangle_b.coord_lower_right)
+    def __init__(self, lower_coord: Coordinate, upper_coord: Coordinate):
+        """Initialize a Rectangle from two corner coordinates.
 
-    line_intersection_12 = line_intersection(rectangle_a.coord_upper_right, rectangle_a.coord_lower_right, rectangle_b.coord_lower_left,  rectangle_b.coord_lower_right)
-    line_intersection_13 = line_intersection(rectangle_a.coord_upper_right, rectangle_a.coord_lower_right, rectangle_b.coord_lower_left,  rectangle_b.coord_upper_left)
-    line_intersection_14 = line_intersection(rectangle_a.coord_upper_right, rectangle_a.coord_lower_right, rectangle_b.coord_upper_left,  rectangle_b.coord_upper_right)
-    line_intersection_15 = line_intersection(rectangle_a.coord_upper_right, rectangle_a.coord_lower_right, rectangle_b.coord_upper_right, rectangle_b.coord_lower_right)
+        Args:
+            lower_coord (Coordinate): Lower-left corner of the rectangle.
+            upper_coord (Coordinate): Upper-right corner of the rectangle.
+        """
+        self.coord_lower_left = lower_coord
+        self.coord_upper_right = upper_coord
 
-    # determine if one box is within another box
-    rectangle_overlap_0 = is_rectangle_inside_rectangle( rectangle_a, rectangle_b )
-    rectangle_overlap_1 = is_rectangle_inside_rectangle( rectangle_b, rectangle_a )
+        self.coord_upper_left = Coordinate(
+            self.coord_lower_left.x,
+            self.coord_upper_right.y
+        )
+        self.coord_lower_right = Coordinate(
+            self.coord_upper_right.x,
+            self.coord_lower_left.y
+        )
 
-    return line_intersection_0 or line_intersection_1 or line_intersection_2 or line_intersection_3 or line_intersection_4 or line_intersection_5 or line_intersection_6 or line_intersection_7 or line_intersection_8 or line_intersection_9 or line_intersection_10 or line_intersection_11 or line_intersection_12 or line_intersection_13 or line_intersection_14 or line_intersection_15 or rectangle_overlap_0 or rectangle_overlap_1
 
+# function used in determining if lines intersect
+# based on the counter-clockwise test algorithm
+def counter_clock_wise(a: Coordinate, b: Coordinate, c: Coordinate) -> bool:
+    """Determine if three points a, b, c are in counter-clockwise order.
+
+    Args:
+        a (Coordinate): First point.
+        b (Coordinate): Second point.
+        c (Coordinate): Third point.
+
+    Returns:
+        bool: True if the sequence (a → b → c) is counter-clockwise.
+    """
+    return (c.y - a.y) * (b.x - a.x) > (b.y - a.y) * (c.x - a.x)
+
+
+# determine if two line segments (AB and CD) intersect
+def line_intersection(
+    a: Coordinate,
+    b: Coordinate,
+    c: Coordinate,
+    d: Coordinate
+) -> bool:
+    """Check if the line segments AB and CD intersect.
+
+    Uses the counter-clockwise orientation test.
+
+    Args:
+        a (Coordinate): First endpoint of segment AB.
+        b (Coordinate): Second endpoint of segment AB.
+        c (Coordinate): First endpoint of segment CD.
+        d (Coordinate): Second endpoint of segment CD.
+
+    Returns:
+        bool: True if segments AB and CD intersect.
+    """
+    return (
+        counter_clock_wise(a, c, d) != counter_clock_wise(b, c, d) and
+        counter_clock_wise(a, b, c) != counter_clock_wise(a, b, d)
+    )
+
+
+# determine if a point lies within the 1D interval [left, right]
+def is_within_range(
+    test_coord_x: float,
+    rectangle_left_x: float,
+    rectangle_right_x: float
+) -> bool:
+    """Check if a coordinate lies within a closed interval on the x-axis.
+
+    Args:
+        test_coord_x (float): The x-value to test.
+        rectangle_left_x (float): Lower bound of the interval.
+        rectangle_right_x (float): Upper bound of the interval.
+
+    Returns:
+        bool: True if rectangle_left_x <= test_coord_x <= rectangle_right_x.
+    """
+    return rectangle_left_x <= test_coord_x <= rectangle_right_x
+
+
+# determine if a rectangle corner lies inside another rectangle
+def is_corner_in_rectangle(
+    corner_coord: Coordinate,
+    reference_box: Rectangle
+) -> bool:
+    """Check if a corner point is within the bounds of a reference rectangle.
+
+    Args:
+        corner_coord (Coordinate): The corner to test.
+        reference_box (Rectangle): The rectangle in which to test containment.
+
+    Returns:
+        bool: True if the corner is inside reference_box (including edges).
+    """
+    x_inside = is_within_range(
+        corner_coord.x,
+        reference_box.coord_lower_left.x,
+        reference_box.coord_lower_right.x
+    )
+    y_inside = is_within_range(
+        corner_coord.y,
+        reference_box.coord_lower_left.y,
+        reference_box.coord_upper_left.y
+    )
+    return x_inside and y_inside
+
+
+# determine if one rectangle is entirely within another
+def is_rectangle_inside_rectangle(
+    rectangle_1: Rectangle,
+    rectangle_2: Rectangle
+) -> bool:
+    """Check if rectangle_1 is completely inside rectangle_2.
+
+    Tests whether all four corners of rectangle_1 lie within rectangle_2.
+
+    Args:
+        rectangle_1 (Rectangle): The inner rectangle to test.
+        rectangle_2 (Rectangle): The outer rectangle to test against.
+
+    Returns:
+        bool: True if rectangle_1 is fully contained in rectangle_2.
+    """
+    corners = [
+        rectangle_1.coord_lower_left,
+        rectangle_1.coord_upper_left,
+        rectangle_1.coord_upper_right,
+        rectangle_1.coord_lower_right
+    ]
+    return all(is_corner_in_rectangle(c, rectangle_2) for c in corners)
+
+
+# determine if two rectangles have any overlap
+def is_rectangle_overlap(
+    rectangle_a: Rectangle,
+    rectangle_b: Rectangle
+) -> bool:
+    """Check if two rectangles overlap by intersection or containment.
+
+    Overlap occurs if:
+        1. Any side of rectangle_a intersects any side of rectangle_b.
+        2. One rectangle is fully contained within the other.
+
+    Args:
+        rectangle_a (Rectangle): First rectangle.
+        rectangle_b (Rectangle): Second rectangle.
+
+    Returns:
+        bool: True if the rectangles overlap.
+    """
+    # all side-pairs of rectangle a and b
+    a_sides = [
+        (rectangle_a.coord_lower_left, rectangle_a.coord_lower_right),
+        (rectangle_a.coord_lower_left, rectangle_a.coord_upper_left),
+        (rectangle_a.coord_upper_left, rectangle_a.coord_upper_right),
+        (rectangle_a.coord_upper_right, rectangle_a.coord_lower_right)
+    ]
+    b_sides = [
+        (rectangle_b.coord_lower_left, rectangle_b.coord_lower_right),
+        (rectangle_b.coord_lower_left, rectangle_b.coord_upper_left),
+        (rectangle_b.coord_upper_left, rectangle_b.coord_upper_right),
+        (rectangle_b.coord_upper_right, rectangle_b.coord_lower_right)
+    ]
+
+    # check for any side intersection
+    for (a1, a2) in a_sides:
+        for (b1, b2) in b_sides:
+            if line_intersection(a1, a2, b1, b2):
+                return True
+
+    # check for full containment either way
+    if is_rectangle_inside_rectangle(rectangle_a, rectangle_b):
+        return True
+    if is_rectangle_inside_rectangle(rectangle_b, rectangle_a):
+        return True
+
+    return False
\ No newline at end of file
diff --git a/torchsig/utils/data_loading.py b/torchsig/utils/data_loading.py
index ac17b3515..f3b8cb9f9 100644
--- a/torchsig/utils/data_loading.py
+++ b/torchsig/utils/data_loading.py
@@ -1,76 +1,137 @@
+"""Collate function and DataLoader with worker seeding for TorchSig.
 
-from torch import tensor
-import warnings
-import numpy as np
+Provides:
+    - metadata_padding_collate_fn: pads variable-length metadata in each batch.
+    - WorkerSeedingDataLoader: seeds each worker process differently for reproducibility.
+"""
 
-from torch.utils.data import DataLoader
 from torchsig.utils.random import Seedable
 
+import torch
+from torch.utils.data import DataLoader
+import numpy as np
+
+import warnings
+
+
 def metadata_padding_collate_fn(batch):
+    """Collate a batch of (data, metadata_list) pairs, padding metadata to equal lengths.
+
+    Metadata for each sample is a list of dicts. This function:
+        1. Finds the maximum metadata-list length in the batch.
+        2. Pads shorter metadata lists with default values.
+        3. Stacks data tensors and metadata fields into batched tensors.
+
+    Args:
+        batch (List[Tuple[Any, List[Dict[str, Any]]]]):
+            A list where each element is a tuple of:
+                - x: any object convertible to a NumPy array (e.g., tensor, array).
+                - y: a list of metadata dicts, where each dict shares the same set of keys.
+
+    Returns:
+        Tuple[torch.Tensor, Dict[str, torch.Tensor]]:
+            - data_tensor: stacked torch.Tensor of all x values, shape (batch_size, ...).
+            - metadata_tensors: dict mapping each metadata key to a Tensor of shape
+                (batch_size, max_sequence_length).
 
+    Raises:
+        ValueError: if any element in `batch` is not a tuple of length 2.
+    """
     default_y_value = 0
 
     batch_max_len = 0
     iqs = []
     y_tensor_obj = {}
+
     for data_pair in batch:
         if not isinstance(data_pair, tuple) or len(data_pair) != 2:
-            raise ValueError(str(data_pair) + " is not a valid (x, y) pair; this collate function expects datasets to return tuples of (x, y)")
-        if batch_max_len < len(data_pair[1]):
-            batch_max_len = len(data_pair[1])
-        for metadata_obj in data_pair[1]:
+            raise ValueError(
+                f"{data_pair} is not a valid (x, y) pair; this collate function "
+                "expects datasets to return tuples of (x, y)"
+            )
+
+        _, metadata_list = data_pair
+        batch_max_len = max(batch_max_len, len(metadata_list))
+
+        for metadata_obj in metadata_list:
             for key in metadata_obj.keys():
-                if not key in y_tensor_obj.keys():
+                if key not in y_tensor_obj:
                     y_tensor_obj[key] = []
-        iqs += [data_pair[0]]
+
+        iqs.append(data_pair[0])
 
     if batch_max_len < 1:
-        return tensor(np.array(iqs)), y_tensor_obj
-    
-    for key in y_tensor_obj.keys():
-        y_tensor_obj[key] = [[]]*batch_max_len
-        
-    for data_pair in batch:
+        # No metadata to pad, return raw list for metadata
+        return torch.Tensor(np.array(iqs)), y_tensor_obj
+
+    # Initialize per-key lists for each time step
+    for key in y_tensor_obj:
+        y_tensor_obj[key] = [[] for _ in range(batch_max_len)]
+
+    # Fill in metadata values or default where missing
+    for _, metadata_list in batch:
         for i in range(batch_max_len):
-            if len(data_pair[1]) > i:
-                #add the record from the metadata
-                metadata_obj = data_pair[1][i]
-                for key in y_tensor_obj.keys():
-                    if key in metadata_obj.keys():
-                        y_tensor_obj[key][i] += [metadata_obj[key]]
-                    else:
-                        y_tensor_obj[key][i] += [default_y_value]
+            if i < len(metadata_list):
+                metadata_obj = metadata_list[i]
+                # Use .items() here to iterate key-value pairs in y_tensor_obj
+                for key, value_lists in y_tensor_obj.items():
+                    # Use .get() with default_y_value
+                    value_lists[i].append(metadata_obj.get(key, default_y_value))
             else:
-                #add a record consisting entirely of default values  
-                for key in y_tensor_obj.keys():
-                    y_tensor_obj[key][i] += [default_y_value]
-    
+                for key, value_lists in y_tensor_obj.items():
+                    value_lists[i].append(default_y_value)
+
+    # Convert lists to tensors, dropping invalid keys
     final_tensor_obj = {}
-    for key in y_tensor_obj:
+    for key, sequences in y_tensor_obj.items():
         try:
-            final_tensor_obj[key] = tensor(np.array(y_tensor_obj[key]))
-        except:
-            warnings.warn("Dropping key value: '"+key+"' because it contained invalid tensor values")
+            final_tensor_obj[key] = torch.Tensor(np.array(sequences))
+        except (ValueError, TypeError, MemoryError) as e:
+            warnings.warn(
+                f"Dropping key value: '{key}' because it contained invalid tensor values: {type(e).__name__}"
+            )
+
+    return torch.Tensor(np.array(iqs)), final_tensor_obj
 
-    return tensor(np.array(iqs)), final_tensor_obj
 
 class WorkerSeedingDataLoader(DataLoader, Seedable):
+    """DataLoader that seeds each worker process differently using a shared seed.
+
+    This loader prohibits external `worker_init_fn` definitions and sets its own
+    init function to ensure reproducible randomness in multi-worker pipelines.
     """
-    A Custom DataLoader for torchsig that seeds workers differently on worker init based on a shared initial seed;
-    """
 
-    def __init__(self, dataset, collate_fn=metadata_padding_collate_fn, **kwargs):
-        DataLoader.__init__(self, dataset, collate_fn=collate_fn, **kwargs)
+    def __init__(self, dataset, **kwargs):
+        """Initialize DataLoader and Seedable, then assign custom worker init.
+
+        Args:
+            dataset (Dataset): The dataset to load.
+            **kwargs: Passed to both `DataLoader` and `Seedable` initializers.
+
+        Raises:
+            ValueError: if `worker_init_fn` is provided in kwargs.
+        """
+        DataLoader.__init__(self, dataset, **kwargs)
         Seedable.__init__(self, **kwargs)
+
         if self.worker_init_fn:
-            raise ValueError("No worker_init_fn should be given to WorkerSeedingDataLoader; it will set it's own worker_init_fn.")
+            raise ValueError(
+                "No worker_init_fn should be given to WorkerSeedingDataLoader; "
+                "it will set its own worker_init_fn."
+            )
+
         self.worker_init_fn = self.init_worker_seed
 
     def init_worker_seed(self, worker_id):
-        from torch.utils.data import get_worker_info
-        get_worker_info().dataset.seed(int(self.random_generator.random()*100 + 1) * (worker_id + 1))
+        """Set a unique random seed for each worker process.
 
-    def __len__(self):
-        return self.dataset.dataset_metadata.num_samples
+        Uses the shared `random_generator` from the `Seedable` mixin to derive
+        a new seed per `worker_id`.
 
+        Args:
+            worker_id (int): The integer ID of the worker process.
+        """
+        from torch.utils.data import get_worker_info
 
+        seed = int(self.random_generator.random() * 100 + 1) * (worker_id + 1)
+        get_worker_info().dataset.seed(seed)
diff --git a/torchsig/utils/defaults.py b/torchsig/utils/defaults.py
new file mode 100644
index 000000000..e20847667
--- /dev/null
+++ b/torchsig/utils/defaults.py
@@ -0,0 +1,37 @@
+from torchsig.datasets.dataset_metadata import DatasetMetadata
+from torchsig.datasets.datasets import TorchSigIterableDataset
+from torchsig.transforms.impairments import Impairments
+from torchsig.utils.writer import default_collate_fn
+from torchsig.utils.data_loading import WorkerSeedingDataLoader
+
+def default_dataset(num_signals_min=1, num_signals_max=1, num_iq_samples_dataset=4096, fft_size=64, impairment_level=None, target_labels=None, transforms=[], component_transforms=[], **kwargs):
+    dataset_metadata = DatasetMetadata(
+        num_iq_samples_dataset = num_iq_samples_dataset,
+        fft_size = fft_size,
+        num_signals_max = num_signals_max,
+        num_signals_min = num_signals_min,
+        num_samples = None
+    )
+    if impairment_level != None:
+        impairments = Impairments(impairment_level)
+        burst_impairments = impairments.signal_transforms
+        signal_impairments = impairments.dataset_transforms
+        new_transforms=[signal_impairments] + transforms
+        new_component_transforms=[burst_impairments] + component_transforms
+    else:
+        new_transforms = transforms
+        new_component_transforms = component_transforms
+    return TorchSigIterableDataset(
+        dataset_metadata = dataset_metadata,
+        target_labels=target_labels,
+        transforms=new_transforms,
+        component_transforms=new_component_transforms,
+        **kwargs
+    )
+
+def default_dataloader(seed=False, collate_fn=default_collate_fn, batch_size=1, num_workers=1, **kwargs):
+    dataset = default_dataset(**kwargs)
+    dataloader = WorkerSeedingDataLoader(dataset, collate_fn=collate_fn, batch_size=batch_size, num_workers=num_workers)
+    if seed:
+        dataloader.seed(seed)
+    return dataloader
\ No newline at end of file
diff --git a/torchsig/utils/dsp.py b/torchsig/utils/dsp.py
index 9091d06a4..d70e92bfd 100755
--- a/torchsig/utils/dsp.py
+++ b/torchsig/utils/dsp.py
@@ -10,14 +10,12 @@ import torch
 from pathlib import Path
 import pickle
 
-# common reference for the complex data type to allow for
-# standardization across the different algorithms
-torchsig_complex_data_type = np.complex64
+from typing import Any
 
-# common reference for the float data type to allow for
-# standardization across the different algorithms
-torchsig_real_data_type = np.float32
 
+# data types to be used internally within torchsig
+TorchSigComplexDataType = np.complex64
+TorchSigRealDataType = np.float32
 
 def slice_tail_to_length(input_signal:np.ndarray, num_samples:int) -> np.ndarray:
     """Slices the tail of a signal
@@ -201,7 +199,7 @@ def upconversion_anti_aliasing_filter(input_signal:np.ndarray, center_freq:float
     output = convolve(input_signal,bpf_weights)
 
     # convert data type
-    output = output.astype(torchsig_complex_data_type)
+    output = output.astype(TorchSigComplexDataType)
 
     return output, box_center_freq, box_bandwidth
 
@@ -217,7 +215,7 @@ def is_even(number):
     Returns:
         bool: Returns true if number is even, false if number is odd
     """
-    return np.mod(number,2) == 0
+    return not np.mod(number,2)
 
 def is_odd(number):
     """Is the number odd?
@@ -339,7 +337,7 @@ def design_half_band_filter(stage_number:int=0, passband_percentage:float=0.8, a
     cutoff = sample_rate/4
     fpass = cutoff * passband_percentage / (2**stage_number)
     transition_bandwidth = 2*(cutoff - fpass)
-    fstop = fpass + transition_bandwidth
+    #fstop = fpass + transition_bandwidth
   
     # initial filter length estimation 
     filter_length_estim = estimate_filter_length(transition_bandwidth,attenuation_db,sample_rate)
@@ -568,11 +566,21 @@ def prototype_polyphase_filter (num_branches:int, attenuation_db:float=120) -> n
     cutoff = sample_rate/(2*num_branches)
     transition_bandwidth = sample_rate/(2*num_branches)
 
+    # sub-directory name for pfb filter weights
+    pfb_weights_directory_name = "pfb_weights"
+
+    # set up path to pfb filter weights
+    pfb_weights_directory_path = Path(__file__).parent.absolute().joinpath(pfb_weights_directory_name)
+
+    # does the sub-directory exist? if not, create it
+    if not pfb_weights_directory_path.exists():
+        pfb_weights_directory_path.mkdir(parents=True, exist_ok=True)
+
     # formating for the weights filename
     pfb_weights_filename = f'torchsig_{torchsig_version}_pfb_weights_num_branches_{num_branches}_attenuation_db_{attenuation_db:0.0f}.pkl'
 
     # create path to weights file
-    path_to_file = Path(__file__).parent.absolute().joinpath(pfb_weights_filename)
+    path_to_file = pfb_weights_directory_path.joinpath(pfb_weights_filename)
 
     # does weights file exist?
     weights_exist_boolean = path_to_file.is_file()
@@ -580,16 +588,11 @@ def prototype_polyphase_filter (num_branches:int, attenuation_db:float=120) -> n
     # can the weights be loaded? possibility of corrupted file
     # if CTRL+C exit during write, or other misc file corruption.
     design_weights_boolean = True
-    if (weights_exist_boolean):
-        try:
-            # read from file
-            filter_weights = read_pickle ( path_to_file )
-            # overwrite the default value of boolean, no need to recompute
-            design_weights_boolean = False
-        except:
-            # do nothing here. design_weights_boolean already has the correct
-            # value and will be acted upon in next if() statement
-            pass
+    if weights_exist_boolean:
+        # read from file
+        filter_weights = read_pickle ( path_to_file )
+        # overwrite the default value of boolean, no need to recompute
+        design_weights_boolean = False       
 
     # design and save new weights if the file does not exist OR the file read failed
     if (not weights_exist_boolean or design_weights_boolean):
@@ -600,12 +603,38 @@ def prototype_polyphase_filter (num_branches:int, attenuation_db:float=120) -> n
 
     return filter_weights
 
-def read_pickle ( path_to_file ):
+def read_pickle (path_to_file: str) -> Any:
+    """
+    Reads an object from a pickle file.
+
+    Args:
+        path_to_file (str): The path to the pickle file to be read.
+
+    Returns:
+        Any: The object loaded from the pickle file.
+
+    Raises:
+        FileNotFoundError: If the specified file does not exist.
+        pickle.UnpicklingError: If there is an error during the unpickling process.
+    """
     with open(path_to_file, 'rb') as handle:
         obj = pickle.load(handle)
     return obj
 
-def write_pickle ( obj, path_to_file ):
+def write_pickle (obj: Any, path_to_file: str) -> None:
+    """
+    Writes an object to a pickle file.
+
+    Args:
+        obj (Any): The object to be pickled and written to the file.
+        path_to_file (str): The path where the pickle file will be saved.
+
+    Returns:
+        None: This function does not return any value.
+
+    Raises:
+        IOError: If there is an error writing to the file.
+    """
     with open(path_to_file, 'wb') as handle:
         pickle.dump(obj, handle, protocol=pickle.HIGHEST_PROTOCOL)
 
@@ -830,7 +859,7 @@ def frequency_shift(signal:np.ndarray, frequency:float, sample_rate:float) -> np
         np.ndarray: The frequency shifted signal
     """
     # build mixer
-    mixer = np.exp(2j*np.pi*(frequency/sample_rate)*np.arange(0,len(signal))).astype(torchsig_complex_data_type)
+    mixer = np.exp(2j*np.pi*(frequency/sample_rate)*np.arange(0,len(signal))).astype(TorchSigComplexDataType)
     return signal*mixer
 
 def compute_spectrogram(
@@ -864,7 +893,7 @@ def compute_spectrogram(
         # number of zeros to be padded
         num_zeros = fft_size-len(iq_samples)
         # form the zero array
-        zero_padding = np.zeros(num_zeros,dtype=torchsig_complex_data_type)
+        zero_padding = np.zeros(num_zeros,dtype=TorchSigComplexDataType)
         # put zeros at the end
         iq_samples_formatted = np.concatenate((iq_samples,zero_padding))
     else:
@@ -887,7 +916,7 @@ def compute_spectrogram(
     epsilon = np.max(np.max(np.abs(spectrogram_linear_numpy)))*np.sqrt(1e-20)
 
     # find the zero locations, and replace them with tiny values
-    zero_ind_rows, zero_ind_cols = np.where(spectrogram_linear_numpy == 0)
+    zero_ind_rows, zero_ind_cols = np.where(np.equal(spectrogram_linear_numpy,0))
     spectrogram_linear_numpy[zero_ind_rows,zero_ind_cols] = epsilon
 
     # convert to dB
@@ -929,14 +958,15 @@ def convolve(signal: np.ndarray, taps: np.ndarray) -> np.ndarray:
     """
 
     filtered = sp.convolve(signal, taps, mode='full')
-    if (len(taps) == 2):
+    if len(taps) == 2:
         return filtered[1:]
-    elif is_even(len(taps)): # even-length filter
+    if is_even(len(taps)): # even-length filter
         slice_length = int(len(taps)/2)
         return filtered[slice_length:-slice_length+1]
-    else: # odd-length filter
-        slice_length = int((len(taps)-1)/2)
-        return filtered[slice_length:-slice_length]
+    
+    # odd-length filter
+    slice_length = int((len(taps)-1)/2)
+    return filtered[slice_length:-slice_length]
 
 def low_pass(cutoff: float, transition_bandwidth: float, sample_rate:float, attenuation_db:float=120) -> np.ndarray:
     """Low-pass filter design
@@ -981,7 +1011,7 @@ def estimate_filter_length(transition_bandwidth: float, attenuation_db:float, sa
     filter_length = int(np.round((sample_rate / transition_bandwidth) * (attenuation_db / 22)))
 
     # odd-length filters are desirable because they do not introduce a half-sample delay
-    if np.mod(filter_length, 2) == 0:
+    if np.equal(np.mod(filter_length, 2),0):
         filter_length += 1
 
     return filter_length
@@ -1046,7 +1076,33 @@ def gaussian_taps(samples_per_symbol: int, bt: float = 0.35) -> np.ndarray:
 
 
 def low_pass_iterative_design(cutoff:float, transition_bandwidth:float, sample_rate:float, desired_attenuation_db:float=120)-> np.ndarray:
+    """
+    Iteratively designs a low-pass filter using the window method, adjusting the filter length 
+    to meet the desired stopband attenuation.
+
+    The filter design process starts with an initial filter design, and then iteratively increases 
+    the filter length based on the measured stopband attenuation. This process continues until 
+    the desired stopband attenuation is achieved or the maximum number of iterations is reached.
 
+    Args:
+        cutoff (float): The cutoff frequency of the low-pass filter (in Hz).
+        transition_bandwidth (float): The transition bandwidth of the filter (in Hz).
+        sample_rate (float): The sample rate of the system (in Hz).
+        desired_attenuation_db (float, optional): The desired stopband attenuation in decibels (dB). 
+                                                  Defaults to 120 dB.
+
+    Returns:
+        np.ndarray: The designed low-pass filter coefficients.
+
+    Raises:
+        Warning: If the filter design process exceeds the maximum number of iterations, 
+                a warning is raised and the initial filter design is returned.
+
+    Notes:
+        The iterative design process adjusts the filter length based on the ratio of 
+        desired and measured stopband attenuation. If the process doesn't converge 
+        within a reasonable number of iterations, the initial design is returned.
+    """
     # estimate the filter length
     filter_length = estimate_filter_length( transition_bandwidth, desired_attenuation_db, sample_rate)
     #print('filter length = ' + str(filter_length))
@@ -1068,14 +1124,14 @@ def low_pass_iterative_design(cutoff:float, transition_bandwidth:float, sample_r
             fs=sample_rate,
         )
 
-        # hold onto the initial filter design in case the design
-        if iterations == 0:
-            lpf_init = copy(lpf)
+        # # hold onto the initial filter design in case the design
+        # if not iterations:
+        #     lpf_init = copy(lpf)
 
         # get FFT of filter from 0 to fs/2
         fft_size = 4096
         fft_linear = np.abs(np.fft.fftshift(np.fft.fft(lpf,fft_size*2)))
-        fft_linear[np.where(fft_linear == 0)[0]] = 1e-15 # replace all zeros with tiny value
+        fft_linear[np.where(np.equal(fft_linear,0))[0]] = 1e-15 # replace all zeros with tiny value
         fft_db = 20*np.log10(fft_linear)
         fft_db = fft_db[fft_size:]
         f = np.linspace(0,0.5,fft_size)*sample_rate
@@ -1085,7 +1141,7 @@ def low_pass_iterative_design(cutoff:float, transition_bandwidth:float, sample_r
         
         # find the closest bin matching the stopband edge
         stopband_bin = np.argmin(np.abs(stopband_freq_init - f)) 
-        stopband_freq = f[stopband_bin]
+        #stopband_freq = f[stopband_bin]
 
         # get the maximum sidelobe level from stopband to fs/2
         measured_attenuation_db = np.abs(np.max(fft_db[stopband_bin:]))
@@ -1093,7 +1149,7 @@ def low_pass_iterative_design(cutoff:float, transition_bandwidth:float, sample_r
         if iterations > max_iterations:
             # hit too many iterations, exit to avoid infinite loop
             raise Warning('low_pass_iterative_design has trouble converging, using initial design.')
-            return lpf_init
+            #return lpf_init
  
         if desired_attenuation_db  > measured_attenuation_db:
             # the filter is below speed and needs an increase to filter length
@@ -1130,7 +1186,7 @@ def low_pass_iterative_design(cutoff:float, transition_bandwidth:float, sample_r
 
 
 def noise_generator(
-    N: int = 1024,
+    num_samples: int = 1024,
     power: float = 1.0,
     color: str = 'white',
     continuous: bool = True,
@@ -1139,6 +1195,7 @@ def noise_generator(
     """Generates additive complex noise of specified power and type.
 
     Args:
+        num_samples (int): number of noise samples to generate. Default to 1024
         power (float): Desired noise power (linear, positive). Defaults to 1.0 W (0 dBW).
         color (str): Noise color, supports 'white', 'pink', or 'red' noise frequency spectrum types. Defaults to 'white'.
         continuous (bool): Sets noise to continuous (True) or impulsive (False). Defaults to True.
@@ -1152,36 +1209,36 @@ def noise_generator(
         np.ndarray: Complex noise samples with specified power.
     
     """
-    if not power >= 0.:
-         raise ValueError(f"Noise power must be greater than or equal to 0.")
+    if power < 0.:
+        raise ValueError("Noise power must be greater than or equal to 0.")
 
     if continuous:
-        noise_source = (   rng.standard_normal((N,), dtype=torchsig_real_data_type) + 
-                        1j*rng.standard_normal((N,), dtype=torchsig_real_data_type)) / np.sqrt(2) # continous white noise (1.0 W)
+        noise_source = (   rng.standard_normal((num_samples,), dtype=TorchSigRealDataType) + 
+                        1j*rng.standard_normal((num_samples,), dtype=TorchSigRealDataType)) / np.sqrt(2) # continous white noise (1.0 W)
     else: # impulsive
-        noise_source = np.zeros((N,), dtype=torchsig_complex_data_type)
-        impulse_ind = rng.integers(0,N,dtype=int)   # random impulse location
+        noise_source = np.zeros((num_samples,), dtype=TorchSigComplexDataType)
+        impulse_ind = rng.integers(0,num_samples,dtype=int)   # random impulse location
         noise_source[impulse_ind] = (1 + 1j) / np.sqrt(2) # impulse 1.0 W
 
-    X_white = np.fft.fft(noise_source, norm="ortho") # frequency domain noise 1.0 W
+    x_white = np.fft.fft(noise_source, norm="ortho") # frequency domain noise 1.0 W
 
     # frequency domain shaping filter
-    freqs = np.fft.fftfreq(N) # sample frequencies 
+    freqs = np.fft.fftfreq(num_samples) # sample frequencies 
     if color == 'white': # flat frequency spectrum
-        S = 1
-        #S = np.ones((N,))
-        #S = S / np.sqrt(np.mean(S**2)) 
+        s = 1
+        #s = np.ones((N,))
+        #s = s / np.sqrt(np.mean(s**2)) 
     elif color == 'pink': # 1/f (flicker noise), -10 db/decade frequency power spectrum
-        S = 1/np.where(freqs == 0, float('inf'), np.sqrt(np.abs(freqs))) # zero-mean (DC=0) 
-        S = S / np.sqrt(np.mean(S**2)) # RMS normalize shaping filter (estimated)
+        s = 1/np.where(np.equal(freqs,0), float('inf'), np.sqrt(np.abs(freqs))) # zero-mean (DC=0) 
+        s = s / np.sqrt(np.mean(s**2)) # RMS normalize shaping filter (estimated)
     elif color == 'red': # 1/f**2 (brownian noise), -20 dB/decade frequency power spectrum
-        S = 1/np.where(freqs == 0, float('inf'), np.abs(freqs)) # zero-mean (DC=0)
-        S = S / np.sqrt(np.mean(S**2)) # RMS normalize shaping filter (estimated)
+        s = 1/np.where(np.equal(freqs,0), float('inf'), np.abs(freqs)) # zero-mean (DC=0)
+        s = s / np.sqrt(np.mean(s**2)) # RMS normalize shaping filter (estimated)
     else:
         raise ValueError(f"Invalid noise type {type}. Must be 'white', 'pink', or 'red'.")
     
-    X_shaped = S * X_white 
-    noise = np.fft.ifft(X_shaped, norm="ortho")
+    x_shaped = s * x_white 
+    noise = np.fft.ifft(x_shaped, norm="ortho")
     est_power = np.sum(np.abs(noise)**2)/len(noise)
     noise = np.sqrt(power / est_power) * noise 
     return noise
diff --git a/torchsig/utils/file_handlers/__init__.py b/torchsig/utils/file_handlers/__init__.py
index e69de29bb..ae9064404 100644
--- a/torchsig/utils/file_handlers/__init__.py
+++ b/torchsig/utils/file_handlers/__init__.py
@@ -0,0 +1,12 @@
+"""TorchSig File Handlers
+"""
+from .base_handler import BaseFileHandler, FileReader, FileWriter
+from .external import ExternalFileHandler
+
+__all__ = [
+    "BaseFileHandler",
+    "TorchSigFileHandler",
+    "HDF5FileHandler",
+    "FileReader",
+    "FileWriter"
+]
\ No newline at end of file
diff --git a/torchsig/utils/file_handlers/base_handler.py b/torchsig/utils/file_handlers/base_handler.py
index 5307d5a19..38cab4933 100644
--- a/torchsig/utils/file_handlers/base_handler.py
+++ b/torchsig/utils/file_handlers/base_handler.py
@@ -1,77 +1,79 @@
-"""File Handlers for writing and reading datasets to/from disk
-
-Only write one item from a TorchSigDataset's `__getitem__` method
+"""File Handler Base and Utility Classes for reading and writing datasets to/from disk.
 """
 
-from __future__ import annotations
-
 # TorchSig
-from torchsig.datasets.dataset_metadata import DatasetMetadata
-from torchsig.datasets.dataset_utils import dataset_full_path, writer_yaml_name
 from torchsig.utils.printing import generate_repr_str
 
 # Third Party
-import numpy as np
 
 # Built-In
-from typing import Any, Tuple, List, Dict, TYPE_CHECKING
-import os
+import pathlib
 import shutil
-import yaml
-
-# Imports for type checking
-if TYPE_CHECKING:
-    from torchsig.datasets.datasets import NewTorchSigDataset
+from typing import Any
 
+def reset_folder(path: str) -> None:
+    folder_path = pathlib.Path(path)
 
-class BaseFileHandler():
-    def __init__(
-        self,
-        root: str
-    ):
-        self.root = root
-
-    def _reset_folder(self, filepath: str) -> None:
-        if os.path.exists(filepath):
-            shutil.rmtree(filepath)
-        os.makedirs(filepath, exist_ok=True)
+    if folder_path.exists():
+        if folder_path.is_dir():
+            # To delete non-empty folder, use shutil.rmtree
+            shutil.rmtree(folder_path)
+            print(f"Deleted folder: {folder_path}")
+        else:
+            # folder is not a directory
+            raise ValueError(f"Path is not a directory: {path}")
     
+    # folder does not exists / is deleted
+
+    # Recreate the folder
+    folder_path.mkdir(parents=True, exist_ok=True)  # 'parents=True' allows creation of intermediate dirs if needed
+
+
+class FileWriter():
+
+    def __init__(self, root: str, **kwargs):
+        self.root: pathlib.Path = pathlib.Path(root)
+
     def _setup(self) -> None:
-        pass
+        """Hook for subclasses to perform setup after folder reset."""
 
     def setup(self) -> None:
-        # Prepares any necessary resources or configurations before writing.
-        # dataset either does not exist or we want to overwrite it
-        # ensures we have empty directory
-        self._reset_folder(self.root)
+        """Prepare resources before writing begins.
 
+        This resets the root folder and then calls the subclass `_setup`.
+        """
+        reset_folder(self.root)
         self._setup()
-        
+
     def teardown(self) -> None:
-        # cleans up resources after writing
-        pass
+        """Hook for cleaning up resources after writing is complete."""
 
-    def exists(self) -> bool:
-        # check whether dataset already exists on disk
-        if os.path.exists(self.root):
-            return True
-        else:
-            return False
+    def write(self, batch_idx: int, data: Any) -> None:
+        """Write a single batch to disk.
 
-    def write(self, batch_idx: int, batch: Any) -> None:
-        # writes a batch from dataset's __getitem__
-        raise NotImplementedError
+        Args:
+            batch_idx (int): Index of the batch being written.
+            data (Any): Data to be written.
 
-    def load(self, idx: int) -> Any:
-        # loads sample `idx` from disk into memory
+        Raises:
+            NotImplementedError: Must be implemented in subclasses.
+        """
         raise NotImplementedError
 
-    @staticmethod
-    def static_load(filename:str, idx: int) -> Any:
-        # loads sample `idx` from `filename` into memory
-        # method can be used without instantiating class
-        # used for just reading
-        raise NotImplementedError
+    def exists(self) -> bool:
+        """Check if the dataset directory already exists.
+
+        Returns:
+            bool: True if `self.root` exists on disk, False otherwise.
+        """
+        return self.root.exists()
+
+    def __del__(self):
+        """Destructor to ensure clean resource cleanup"""
+        try:
+            self.teardown()
+        except:
+            pass  # Ignore errors during cleanup
 
     def __str__(self) -> str:
         return f"{self.__class__.__name__}"
@@ -79,40 +81,28 @@ class BaseFileHandler():
     def __repr__(self) -> str:
         return generate_repr_str(self)
 
-class TorchSigFileHandler(BaseFileHandler):
-    
-    def __init__(
-        self,
-        root: str,
-        batch_size: int = 1
-    ):
-        super().__init__(
-            root = root,
-        )
-
-        self.batch_size = batch_size
-
-    def write(self, batch_idx: int, batch: Any) -> None:
-        # writes a batch from dataset's __getitem__
+    def __len__(self) -> int:
         raise NotImplementedError
 
-    @staticmethod
-    def size(dataset_path: str) -> int:
-        # given path to dataset on disk
-        # return dataset size
-        raise NotImplementedError
+    def __enter__(self):
+        self.setup()
+        return self
+    def __exit__(self, exc_type, exc_value, traceback):
+        self.teardown()
+        return False
 
-    @staticmethod
-    def static_load(filename:str, idx: int) -> Tuple[np.ndarray, List[Dict[str, Any]]]:
-        # loads sample `idx` from `filename` into memory
-        # method can be used without instantiating class
-        # used for just reading
+class FileReader():
+
+    def __init__(self, root: str, **kwargs):
+        self.root = pathlib.Path(root)
+        self.dataset_info_filepath = self.root.joinpath("dataset_info.yaml")
+        
+
+    def read(self, idx: int) -> Any:
         raise NotImplementedError
 
-    def load(self, idx: int) -> Tuple[np.ndarray, List[Dict[str, Any]]]:
-        # loads sample `idx` from disk into memory
-        # uses instantiated class
-        return self.static_load(self.root, idx)
+    def size(self) -> int:
+        raise NotImplementedError
 
     def __str__(self) -> str:
         return f"{self.__class__.__name__}"
@@ -120,13 +110,26 @@ class TorchSigFileHandler(BaseFileHandler):
     def __repr__(self) -> str:
         return generate_repr_str(self)
 
+    def __len__(self) -> int:
+        raise NotImplementedError
+
+class BaseFileHandler():
+
+    reader_class: FileReader = FileReader
+    writer_class: FileWriter = FileWriter
+
+    
     @staticmethod
-    def _calculate_batch_size(root: str) -> int:
+    def create_handler(mode: str, root: str, **kwargs) -> FileWriter | FileReader:
+        if mode == "r":
+            return BaseFileHandler.reader_class(root, **kwargs)
+        elif mode == "w":
+            return BaseFileHandler.writer_class(root, **kwargs)
+        else:
+            raise ValueError(f"Invalid File Handler mode: {mode}")
 
-        writer_yaml = f"{root}/{writer_yaml_name}"
-        with open(writer_yaml, 'r') as f:
-            writer_dict = yaml.load(f, Loader=yaml.FullLoader)
-            # extract batch size
-            batch_size = writer_dict['batch_size']
+    def __str__(self) -> str:
+        return f"{self.__class__.__name__}"
 
-        return batch_size
+    def __repr__(self) -> str:
+        return generate_repr_str(self)
\ No newline at end of file
diff --git a/torchsig/utils/file_handlers/external.py b/torchsig/utils/file_handlers/external.py
new file mode 100644
index 000000000..5cfca1839
--- /dev/null
+++ b/torchsig/utils/file_handlers/external.py
@@ -0,0 +1,66 @@
+"""External File Handler base class for user imported data
+"""
+
+from __future__ import annotations
+
+# Third Party
+import numpy as np
+
+# Built-In
+from typing import TYPE_CHECKING, Tuple, List
+
+if TYPE_CHECKING:
+    from torchsig.datasets.dataset_metadata import ExternalDatasetMetadata
+
+
+class ExternalFileHandler:
+    """Abstract base for user-provided file handlers in ExternalTorchSigDataset.
+
+    Users should subclass this and implement `size`, `load_dataset_metadata`,
+    and `load` to adapt external datasets into the TorchSig pipeline.
+    """   
+    def __init__(
+        self,
+        root: str,
+    ):
+        """Initialize with the external dataset root directory.
+
+        Args:
+            root (str): Path to the external dataset.
+        """
+        self.root = root
+
+    def size(self) -> int:
+        """Compute the number of samples in the external dataset.
+
+        Returns:
+            int: Total number of samples.
+
+        Raises:
+            NotImplementedError: Subclasses must implement this method.
+        """   
+        raise NotImplementedError
+
+    def load_dataset_metadata(self) -> ExternalDatasetMetadata:
+        """Load in dataset information into a `ExternalDatasetMetadata`.
+        Raises:
+            NotImplementedError: Subclasses must implement this method.
+
+        Returns:
+            ExternalDatasetMetadata: Dataset metadata.
+        """        
+        raise NotImplementedError
+
+    def load(self, idx: int) -> Tuple[np.ndarray, List[Any]]:
+        """Load a single sample from dataset on disk
+
+        Args:
+            idx (int): index of sample to load.
+
+        Raises:
+            NotImplementedError: Subclasses must implement this method.
+
+        Returns:
+            Tuple[np.ndarray, List[Any]]: data, targets
+        """        
+        raise NotImplementedError
\ No newline at end of file
diff --git a/torchsig/utils/file_handlers/hdf5.py b/torchsig/utils/file_handlers/hdf5.py
new file mode 100644
index 000000000..419ee3341
--- /dev/null
+++ b/torchsig/utils/file_handlers/hdf5.py
@@ -0,0 +1,355 @@
+""" HDF5 File Handler for TorchSig datasets.
+
+High-performance HDF5 storage with optimized compression and chunking.
+"""
+
+from __future__ import annotations
+
+# TorchSig
+from torchsig.datasets.dataset_metadata import load_dataset_metadata
+from torchsig.signals.signal_types import (Signal, SignalMetadata)
+from torchsig import __version__ as torchsig_version
+from torchsig.utils.file_handlers import (
+    FileWriter,
+    FileReader,
+    BaseFileHandler
+)
+
+# Third Party
+import numpy as np
+import h5py
+
+# Built-In
+import threading
+
+
+
+def populate_hdf5_group_with_signal(group, sig):
+    """Inserts a Signal object's data and metadata into the HDF5 group.
+
+    Args:
+        group (h5py.Group): The HDF5 group to add the Signal to.
+        sig (Signal): The Signal object.
+    """
+    group.create_dataset("data", data=sig.data)
+    metadata_group = group.create_group("metadata")
+    metadatas = sig.get_full_metadata()
+    counter = -1
+    for metadata in metadatas:
+        counter += 1
+        if metadata is not None:
+            index_group = metadata_group.create_group(str(counter))
+            metadata_dict = metadata.to_dict()
+            for key in metadata_dict.keys():
+                if metadata_dict[key] is not None:
+                    if isinstance(metadata_dict[key], str) or np.isscalar(metadata_dict[key]):
+                        index_group.create_dataset(key, data=metadata_dict[key])
+                    else:
+                        try:
+                            index_group.create_dataset(key, data=np.array(metadata_dict[key]))
+                        except:
+                            index_group.create_dataset(key, data=metadata_dict[key])
+
+def populate_hdf5_group_with_signals(group, sigs):
+    """Inserts a list of Signal objects into the HDF5 group.
+
+    Args:
+        group (h5py.Group): The HDF5 group to add the Signals to.
+        sigs (List[Signal]): The list of Signal objects.
+    """
+    for i in range(len(sigs)):
+        signal_group = group.create_group(str(len(group)))
+        populate_hdf5_group_with_signal(signal_group, sigs[i])
+
+class HDF5Writer(FileWriter):
+    """Handles writing Signal data to HDF5 files with specified compression and buffering."""
+
+    def __init__(  # noqa: D107
+        self,
+        root,
+        compression: str = "gzip",
+        compression_opts: int = 6,
+        shuffle: bool = True,
+        fletcher32: bool = True,
+        chunk_cache_size: int = 1024 * 1024 * 10,  # 10MB cache
+        max_batches_in_memory: int = 4,
+    ):
+        """Initializes the HDF5FileHandler.
+
+        Args:
+            root (str): Where to write dataset on disk.
+            compression (str, optional): Compression algorithm ('gzip', 'szip', 'lzf'). Defaults to 'gzip'.
+            compression_opts (int, optional): Compression level (0-9 for gzip). Defaults to 6.
+            shuffle (bool, optional): Enable shuffle filter for better compression. Defaults to True.
+            fletcher32 (bool, optional): Enable Fletcher32 checksum filter. Defaults to True.
+            chunk_cache_size (int, optional): HDF5 chunk cache size in bytes. Defaults to 10MB.
+            max_batches_in_memory (int, optional): Maximum batches to keep in memory before flushing. Defaults to 4.
+        """
+        # compression
+        self.compression = compression
+        self.compression_opts = compression_opts
+        self.shuffle = shuffle
+        self.fletcher32 = fletcher32
+        self.chunk_cache_size = chunk_cache_size
+        self.max_batches_in_memory = max_batches_in_memory
+
+        # Internal state
+        self._file = None
+        self._data_group = None
+        self._batch_buffer: List[Tuple[int, Any]] = []
+        
+        self._current_sample_index = 0
+        super().__init__(root=root)
+        self.datapath = self.root.joinpath("data.h5")
+        # Thread safety
+        self._lock = threading.Lock()
+
+    def _setup(self) -> None:
+        """Set up HDF5 file and initial structure."""
+        # Create HDF5 file with optimized settings
+        self._file = h5py.File(
+            self.datapath, 
+            'w',
+            libver='latest',  # Use latest HDF5 format for better performance
+            swmr=False,  # Single writer mode for dataset creation
+            rdcc_nbytes=self.chunk_cache_size,  # Chunk cache size
+            rdcc_w0=0.75,  # Chunk cache policy
+        )
+        
+        # Set global attributes
+        self._file.attrs['torchsig_version'] = torchsig_version
+        self._file.attrs['compression'] = self.compression
+        self._file.attrs['created_by'] = 'TorchSig HDF5FileHandler'
+
+    def teardown(self) -> None:
+        """Clean up resources and close HDF5 file."""
+        # Flush any remaining data if buffer exists
+        if hasattr(self, '_batch_buffer') and self._batch_buffer:
+            self._flush_buffer()
+        # Close file
+        if hasattr(self, '_file') and self._file is not None:
+            try:
+                self._file.flush()
+                self._file.close()
+            except Exception:
+                pass  # File might already be closed
+            del self._file
+
+    def _write_batch_to_hdf5(self, data) -> None:
+        """Writes a batch of signals (as List[Signal]) to the file.
+
+        Args:
+            data (List[Signal]): The list of signals to write to the HDF5 file.
+        """
+        populate_hdf5_group_with_signals(self._file, data)
+
+    def _flush_buffer(self) -> None:
+        """Flush buffered batches to HDF5 file."""
+        if not self._batch_buffer:
+            return
+            
+        # Ensure file is open for writing
+        if not self._file:
+            self._setup()
+            
+        if not hasattr(self, '_lock'):
+            self._lock = threading.Lock()
+            
+        with self._lock:
+            # Sort buffer by batch index to maintain order
+            self._batch_buffer.sort(key=lambda x: x[0])
+            
+            # Process all batches in buffer
+            for batch_idx, data in self._batch_buffer:
+                # breakpoint()
+                self._write_batch_to_hdf5(data)
+            
+            # Clear buffer
+            self._batch_buffer.clear()
+            
+            # Force flush to disk
+            if self._file:
+                self._file.flush()
+
+    def write(self, batch_idx: int, data) -> None:
+        """Write a batch of data to HDF5 file.
+        
+        Args:
+            batch_idx (int): Index of the batch being written.
+            data (Any): Signal data to write.
+        """
+        # Add to buffer
+        self._batch_buffer.append((batch_idx, data))
+        
+        # Flush buffer if it's getting too large
+        if len(self._batch_buffer) >= self.max_batches_in_memory:
+            self._flush_buffer()
+            
+    def __len__(self) -> int:
+        """Returns the total number of samples in the dataset."""
+        return len(self._file)
+
+def pop_nullable_dict_field(dic, field) -> Any:
+    """Removes a field from a dictionary and returns its value, handling byte strings.
+
+    Args:
+        dic (dict): The dictionary to pop the field from.
+        field (Any): The field to pop.
+
+    Returns:
+        Any: The value associated with the field, or None if the field is not present.
+    """
+    if field in dic.keys():
+        value = dic[field]
+        del dic[field]
+        return handle_bytes_as_string(value)
+    return None
+
+def handle_bytes_as_string(bts) -> Any:
+    """Converts byte strings to standard strings.
+
+    Args:
+        bts (Any): The input, which can be a byte string.
+
+    Returns:
+        str: The standard string if input was a byte string, otherwise returns the input as is.
+    """
+    if isinstance(bts, bytes):
+        return str(bts.decode())
+    return bts
+
+def dict_to_signal_metadata(dic) -> SignalMetadata:
+    """Converts a dictionary to a SignalMetadata object.
+
+    Args:
+        dic (dict): The dictionary to convert.
+
+    Returns:
+        SignalMetadata: The generated SignalMetadata object.
+    """
+    dataset_metadata = pop_nullable_dict_field(dic, "dataset_metadata")
+    center_freq = pop_nullable_dict_field(dic, "center_freq")
+    bandwidth = pop_nullable_dict_field(dic, "bandwidth")
+    start_in_samples = pop_nullable_dict_field(dic, "start_in_samples")
+    duration_in_samples = pop_nullable_dict_field(dic, "duration_in_samples")
+    snr_db = pop_nullable_dict_field(dic, "snr_db")
+    class_name = pop_nullable_dict_field(dic, "class_name")
+    class_index = pop_nullable_dict_field(dic, "class_index")
+
+    new_metadata = SignalMetadata(
+        dataset_metadata=dataset_metadata,
+        center_freq=center_freq,
+        bandwidth=bandwidth,
+        start_in_samples=start_in_samples,
+        duration_in_samples=duration_in_samples,
+        snr_db=snr_db,
+        class_name=class_name,
+        class_index=class_index,
+    )
+    for field in dic.keys():
+        setattr(new_metadata, field, handle_bytes_as_string(dic[field]))
+    return new_metadata
+
+def hdf5_group_to_dict(group) -> dict:
+    """Converts an HDF5 group to a dictionary.
+
+    Args:
+        group (h5py.Group): The HDF5 group to convert.
+
+    Returns:
+        dict: The resulting dictionary.
+    """
+    new_dict = {}
+    for key in group.keys():
+        new_dict[key] = group[key][()]
+    return new_dict
+
+def hdf5_group_to_signal(group) -> Signal:
+    """Converts an HDF5 group to a Signal object.
+
+    Args:
+        group (h5py.Group): The HDF5 group to convert.
+
+    Returns:
+        Signal: The generated Signal object.
+    """
+    metadatas = [dict_to_signal_metadata(hdf5_group_to_dict(group['metadata'][key])) for key in group['metadata'].keys()]
+    metadata = None
+    if len(metadatas) == 1:
+        metadata = metadatas[0]
+    component_signals = []
+    if len(metadatas) > 1:
+        component_signals = [Signal(data=None, metadata=component_metadata, component_signals=[]) for component_metadata in metadatas]
+    data = group['data'][()]
+    return Signal(data=data, metadata=metadata, component_signals=component_signals)
+
+class HDF5Reader(FileReader):
+    """Handles reading Signal data from HDF5 files."""
+
+    def __init__(self, root) -> None:
+        """Initializes the HDF5Reader.
+
+        Args:
+            root (str): The root directory containing the HDF5 file.
+        """
+        super().__init__(root=root)
+        self.datapath = self.root.joinpath("data.h5")
+        self._file = h5py.File(self.datapath, 'r')
+        self.dataset_metadata = load_dataset_metadata(self.dataset_info_filepath)
+
+    def read(self, idx: int) -> Signal:
+        """Reads a single sample and its corresponding targets from the HDF5 file.
+
+        Args:
+            idx (int): The index of the sample to read.
+
+        Returns:
+            Signal: The sample as a Signal object.
+        """
+        new_signal = hdf5_group_to_signal(self._file[str(idx)])
+        new_signal.dataset_metadata = self.dataset_metadata
+        for metadata in new_signal.get_full_metadata():
+            metadata.dataset_metadata = self.dataset_metadata
+        return new_signal
+
+    def __len__(self) -> int:
+        """Returns the total number of samples in the dataset.
+
+        Returns:
+            int: The number of samples in the dataset.
+        """
+        return len(self._file)
+
+    def teardown(self) -> None:
+        """Closes the HDF5 file handle."""
+        if self._file:
+            self._file.close()
+            self._file = None
+
+class HDF5FileHandler(BaseFileHandler):
+    """HDF5FileHandler creates a reader or writer for HDF5 files."""
+
+    reader_class: FileReader = HDF5Reader
+    writer_class: FileWriter = HDF5Writer
+
+    @staticmethod
+    def create_handler(mode: str, root: str, **kwargs) -> HDF5Writer | HDF5Reader:
+        """Creates an instance of HDF5Reader or HDF5Writer based on the mode.
+
+        Args:
+            mode (str): The mode, either "r" for read or "w" for write.
+            root (str): The root directory for the file handler.
+            **kwargs: Additional arguments for the file handler.
+
+        Returns:
+            HDF5Writer | HDF5Reader: The created file handler.
+
+        Raises:
+            ValueError: If the mode is invalid.
+        """
+        if mode == "r":
+            return HDF5FileHandler.reader_class(root, **kwargs)
+        elif mode == "w":
+            return HDF5FileHandler.writer_class(root, **kwargs)
+        else:
+            raise ValueError(f"Invalid File Handler mode: {mode}")
\ No newline at end of file
diff --git a/torchsig/utils/file_handlers/zarr.py b/torchsig/utils/file_handlers/zarr.py
deleted file mode 100644
index 6ff7c2c7e..000000000
--- a/torchsig/utils/file_handlers/zarr.py
+++ /dev/null
@@ -1,195 +0,0 @@
-
-"""
-zarr==2.18.3
-"""
-from __future__ import annotations
-
-# TorchSig
-from torchsig.utils.file_handlers.base_handler import TorchSigFileHandler
-from torchsig.datasets.dataset_metadata import DatasetMetadata
-from torchsig.datasets.dataset_utils import writer_yaml_name
-
-# Third Party
-import zarr
-import numpy as np
-
-# Built-In
-from typing import TYPE_CHECKING, Tuple, List, Dict, Any
-import os
-import pickle
-import yaml
-
-class ZarrFileHandler(TorchSigFileHandler):
-    """Handler for reading and writing data to/from a Zarr file format.
-
-    This class extends the `TorchSigFileHandler` and provides functionality to handle 
-    reading, writing, and managing Zarr-based storage for dataset samples.
-
-    Attributes:
-        datapath_filename (str): The name of the folder used to store the data in Zarr format.
-    """
-
-    datapath_filename_base = "data"
-
-    def __init__(
-        self,
-        root: str,
-        batch_size: int = 1,
-    ):
-        """Initializes the ZarrFileHandler
-
-        Args:
-            root (str): Where to write dataset on disk.
-            batch_size (int, optional): Size fo each batch write. Defaults to 1.
-        """        
-        super().__init__(
-            root = root,
-            batch_size = batch_size
-        )
-
-        self.datapath = f"{self.root}/{ZarrFileHandler.datapath_filename_base}"
-
-        # compressor
-        self.compressor = zarr.Blosc(
-            cname = 'zstd', # type
-            clevel = 4, # compression level
-            shuffle = 2 # use bit shuffle
-        )
-
-    def exists(self) -> bool:
-        """Checks if the Zarr file exists at the specified path.
-
-        Returns:
-            bool: True if the Zarr file exists, otherwise False.
-        """
-        if os.path.exists(self.datapath):
-            return True
-        else:
-            return False
-
-    def write(self, batch_idx: int, batch: Any) -> None:
-        """Writes a sample (data and targets) to the Zarr file at the specified index.
-
-        Args:
-            idx (int): The index at which to store the data in the Zarr file.
-            data (np.ndarray): The data to write to the Zarr file.
-            targets (Any): The corresponding targets to write as metadata for the sample.
-        
-        Notes:
-            If the index is greater than the current size of the array, the array is 
-            expanded to accommodate the new sample.
-        """
-
-        start_idx = batch_idx * self.batch_size
-        stop_idx = start_idx + len(batch[0])
-
-        data, targets = batch
-
-        
-        # write batch of data into file
-        zarr_array = zarr.open(
-            # filenames will have 10 digits
-            # might need to change if you have more than 1 billion batches 
-            f"{self.datapath}/{batch_idx:010}.zarr",
-            mode = 'w', # create or overwrite if exists
-            # array will be shape (num samples, num iq samples)
-            shape = (len(data),) + data[0].shape,
-            # Data type
-            dtype = data[0].dtype,
-            # compression
-            compressor = self.compressor
-        )
-        zarr_array[:] = np.array(data)
-
-        # add targets to zarr array attributes
-        attrs_dict = {str(start_idx + tidx): target for tidx, target in enumerate(targets)}
-
-        zarr_array.attrs.update(attrs_dict) 
-
-
-
-    @staticmethod
-    def size(dataset_path: str) -> int:
-        """Return size of dataset
-
-        Args:
-            dataset_path (str): path to dataset on disk
-
-        Returns:
-            int: size of dataset
-        """        
-        # find batch size
-        batch_size = TorchSigFileHandler._calculate_batch_size(dataset_path)
-        
-        # count number of files
-        all_zarr_arrays = sorted(os.listdir(f"{dataset_path}/{ZarrFileHandler.datapath_filename_base}"))
-        num_zarr_files = len(all_zarr_arrays)
-
-        # num files * batch size
-        size = batch_size * (num_zarr_files - 1)
-
-        # check last file, since it might have less than batch_size data points
-        last_array = zarr.open(f"{dataset_path}/{ZarrFileHandler.datapath_filename_base}/{all_zarr_arrays[-1]}", mode = 'r')
-        last_batch_size = last_array.shape[0]
-
-        # add size of last batch file
-        size += last_batch_size
-
-        return size
-
-    @staticmethod
-    def static_load(filename:str, idx: int) -> Tuple[np.ndarray, List[Dict[str, Any]]]:
-        """Loads a sample from the Zarr file at the specified index (without instantiating a ZarrFileHandler)
-
-        Args:
-            filename (str): Path to the directory containing the Zarr file.
-            idx (int): The index of the sample to load.
-
-        Returns:
-            Tuple[np.ndarray, List[Dict[str, Any]]]: The data and the associated metadata for the sample.
-        
-        Raises:
-            IndexError: If the index is out of bounds.
-        """
-
-        # calculate batch size
-        batch_size = TorchSigFileHandler._calculate_batch_size(filename)
-        batch_idx = idx // batch_size
-        batch_file_idx = idx % batch_size 
-
-        # find correct file
-        batch_filename = f"{batch_idx:010}.zarr"
-
-        # load in
-        # root/data/batch filename.zarr
-        zarr_arr = zarr.open(f"{filename}/{ZarrFileHandler.datapath_filename_base}/{batch_filename}", mode = 'r')
-
-        data = zarr_arr[batch_file_idx]
-        
-        targets = zarr_arr.attrs[str(idx)]
-
-        # print(f"load: {targets}")
-        # print(data)
-        # breakpoint()
-
-        if isinstance(targets, tuple) or isinstance(targets, list):
-            # empty list
-            if (len(targets) == 0):
-                pass # do nothing
-            # target has multiple outputs
-            elif isinstance(targets[0], list):
-                # convert targets (2D list) to a list of tuples
-                # also convert any nested lists into tuples
-                targets = list(
-                    tuple(item if not isinstance(item, list) else tuple(item) for item in target)
-                    for target in targets
-                )
-            else:
-                # convert narrowband targets (1D list) to a tuple
-                targets = tuple(targets)
-        # else:
-            # narrowband target (single item), return itself
-
-        # print(f"post load: {targets}")
-
-        return data, targets
diff --git a/torchsig/utils/generate.py b/torchsig/utils/generate.py
index 06cbd8c8d..3c8370b89 100644
--- a/torchsig/utils/generate.py
+++ b/torchsig/utils/generate.py
@@ -1,4 +1,4 @@
-"""TorchSig Dataset generation code for command line
+"""TorchSig Dataset generation code for command line.
 """
 
 # TorchSig
@@ -7,15 +7,16 @@ from torchsig.datasets.datasets import TorchSigIterableDataset
 from torchsig.utils.writer import DatasetCreator
 
 # Third Party
+from torch.utils.data import DataLoader
 
-# Built-In
-
-# generates a dataset, writes to disk
 def generate(
     root: str,
     dataset_metadata: DatasetMetadata,
     batch_size: int,
     num_workers: int,
+    transforms: list = [],
+    target_labels: list = None,
+    
 ):
     """Generates and saves a dataset to disk.
 
@@ -35,14 +36,22 @@ def generate(
         ValueError: If the dataset type is unknown or invalid.
     """
     
-    create_dataset = TorchSigIterableDataset(dataset_metadata=dataset_metadata)
+    create_dataset = TorchSigIterableDataset(
+        dataset_metadata=dataset_metadata,
+        transforms=transforms,
+        target_labels=target_labels
+    )
+
+    create_loader = DataLoader(
+        dataset = create_dataset,
+        batch_size=batch_size,
+        num_workers=num_workers
+    )
 
     creator = DatasetCreator(
-        dataset=create_dataset,
+        dataloader=create_loader,
         root = root,
         overwrite = True,
-        batch_size=batch_size,
-        num_workers=num_workers
     )
     creator.create()
 
diff --git a/torchsig/utils/printing.py b/torchsig/utils/printing.py
index 62caa9b0d..31daf43d0 100644
--- a/torchsig/utils/printing.py
+++ b/torchsig/utils/printing.py
@@ -55,7 +55,8 @@ def generate_repr_str(class_object: Any, exclude_params: List[str] = []) -> str:
     
     # remove any exclude params
     for r in exclude_params:
-        class_dict.pop(r)
+        if r in class_dict:
+            class_dict.pop(r)
 
     if isinstance(class_object, Seedable):
         # remove Seedable params
@@ -105,9 +106,7 @@ def dataset_metadata_str(
         ```
         MyClass
         ----------------------------------------------------------------------------------------------------
-        num_iq_samples_dataset            1000       
-        num_samples                       5000       
-        impairment_level                  0.8       
+        num_iq_samples_dataset            1000        
         fft_size                          512       
         sample_rate                       1000.0    
         num_signals_min                   1         
@@ -120,9 +119,7 @@ def dataset_metadata_str(
         signal_bandwidth_min              10
         signal_bandwidth_max              100
         signal_center_freq_min            -10
-        signal_center_freq_max            10
-        transforms                        [TransformA, TransformB]   
-        target_transforms                 [TargetTransform1]       
+        signal_center_freq_max            10    
         class_list                        [Class1, Class2, Class3]    
         class_distribution                [0.3, 0.4, 0.3]       
         seed                               42         
@@ -153,26 +150,10 @@ def dataset_metadata_str(
         subsequent_indent= f"{' ' * array_width_indent}",
     )[first_col_width:]
 
-    transform_str = textwrap.fill(
-        f"{dataset_metadata.transforms}",
-        width = max_width,
-        initial_indent= f"{' ' * first_col_width}",
-        subsequent_indent= f"{' ' * array_width_indent}",
-    )[first_col_width:]
-
-    target_transform_str = textwrap.fill(
-        f"{dataset_metadata.target_transforms}",
-        width = max_width,
-        initial_indent= f"{' ' * first_col_width}",
-        subsequent_indent= f"{' ' * array_width_indent}",
-    )[first_col_width:]
-
     return (
         f"\n{dataset_metadata.__class__.__name__}\n"
         f"{'-' * max_width}\n"
         f"{'num_iq_samples_dataset':<29} {dataset_metadata.num_iq_samples_dataset:<10}\n"
-        f"{'num_samples':<29} {dataset_metadata.num_samples}\n" 
-        f"{'impairment_level':<29} {dataset_metadata.impairment_level}\n" 
         f"{'fft_size':<29} {dataset_metadata.fft_size}\n"
         f"{'sample_rate':<29} {dataset_metadata.sample_rate}\n" 
         f"{'num_signals_min':<29} {dataset_metadata.num_signals_min}\n"
@@ -185,9 +166,7 @@ def dataset_metadata_str(
         f"{'signal_bandwidth_min':<29} {dataset_metadata.signal_bandwidth_min}\n" 
         f"{'signal_bandwidth_max':<29} {dataset_metadata.signal_bandwidth_max}\n" 
         f"{'signal_center_freq_min':<29} {dataset_metadata.signal_center_freq_min}\n" 
-        f"{'signal_center_freq_max':<29} {dataset_metadata.signal_center_freq_max}\n" 
-        f"{'transforms':<29} {transform_str}\n" 
-        f"{'target_transforms':<29} {target_transform_str}\n" 
+        f"{'signal_center_freq_max':<29} {dataset_metadata.signal_center_freq_max}\n"
         f"{'class_list':<29} {class_list_str}\n" 
         f"{'class_distribution':<29} {class_distribution_str}\n" 
         ####f"{'seed':<29} {dataset_metadata.rng_seed}\n"   
@@ -229,12 +208,7 @@ def dataset_metadata_repr(
             f"signal_bandwidth_max={dataset_metadata.signal_bandwidth_max}," 
             f"signal_center_freq_min={dataset_metadata.signal_center_freq_min}," 
             f"signal_center_freq_max={dataset_metadata.signal_center_freq_max}," 
-            f"transforms={dataset_metadata.transforms}," 
-            f"target_transforms={dataset_metadata.target_transforms}," 
-            f"impairment_level={dataset_metadata.impairment_level}," 
             f"class_list={dataset_metadata.class_list}," 
-            f"class_distribution={None if dataset_metadata.class_distribution is None else dataset_metadata.class_distribution.tolist()}," 
-            f"num_samples={dataset_metadata.num_samples}," 
-            f"dataset_type={dataset_metadata.dataset_type}," 
+            f"class_distribution={None if dataset_metadata.class_distribution is None else dataset_metadata.class_distribution.tolist()}"
         f")"
     )
diff --git a/torchsig/utils/random.py b/torchsig/utils/random.py
index 5e8c81784..1879f08d9 100644
--- a/torchsig/utils/random.py
+++ b/torchsig/utils/random.py
@@ -8,6 +8,7 @@ import numpy as np
 # Built-In
 import secrets
 
+from typing import Any, Tuple
 
 
 class Seedable():
@@ -27,10 +28,22 @@ class Seedable():
         """
         self.children = []
         self.parent = None
+        self.rng_seed = None
+        self.np_rng = None
+        self.torch_rng = None
+        self.random_generator = None
+        self.kwargs = kwargs
+
         if not seed:
+            # choose random seed
             seed = secrets.randbits(64)
+
+        # seed itself
         self.seed(seed)
+
         if parent:
+            # has parent Seedable objects
+            # add parents
             self.add_parent(parent)
     
     def add_parent(self, parent) -> None:
@@ -82,80 +95,124 @@ class Seedable():
             child.update_from_parent()
 
     def __repr__(self) -> str:
+        """Printable representaiton with seed and parent.
+        """
         return (
             f"{self.__class__.__name__}(seed={self.rng_seed}, parent={self.parent})"
         )
 
-    def get_distribution(self, params, scaling:str='linear'):
+    def get_distribution(self, params: list | tuple | int | float, scaling:str='linear') -> "Distribution":
+        """create distribution function with proper seeding
+
+        Args:
+            params (list | tuple | int | float): parameters for distribution.
+            scaling (str, optional): scaling param for distribution. Defaults to 'linear'.
+
+        Returns:
+            Distribution: distribution function, seeded.
+        """          
         new_distribution = make_distribution(params,scaling)
         new_distribution.add_parent(self)
         return new_distribution
 
 
-def make_distribution(params,scaling:str='linear'):
+def make_distribution(params: list | tuple | int | float ,scaling:str='linear') -> "Distribution":
+    """creates distribution given params
+
+    Args:
+        params (list | tuple | int | float): params for distribution
+        scaling (str, optional): scaling param for distribution. Defaults to 'linear'.
+
+    Raises:
+        NotImplementedError: params is unimplamented type.
+        ValueError: undefined distribution.
+
+    Returns:
+        Distribution: distribution function from params.
+    """    
     if callable(params):
         # custom distribution function
         raise NotImplementedError
-    elif isinstance(params, list):
+    if isinstance(params, list):
         # draw samples from uniform distribution from list values
         return ChoiceDistribution(params)
-    elif isinstance(params, tuple) and scaling == 'linear':
+    if isinstance(params, tuple) and scaling == 'linear':
         # draw samples from uniform distribution from [params[0], params[1]]
         return UniformRangeDistribution(params)
-    elif isinstance(params, tuple) and scaling == 'log10':
+    if isinstance(params, tuple) and scaling == 'log10':
         # draw samples from log10-weighted uniform distribution from [params[0], params[1]]
         return Log10UniformRangeDistribution(params)
-    elif (isinstance(params, int) or isinstance(params, float)) and scaling == 'linear':
+    if isinstance(params, (int, float)) and scaling == 'linear':
         # draw samples from evenly spaced values within [0, params)
         return UniformDistribution(params)
-    else:
-        raise ValueError(f'Undefined conditions in make_distribution(). params = {params}, scaling = {scaling}')
+    
+    # undefined distribution
+    raise ValueError(f'Undefined conditions in make_distribution(). params = {params}, scaling = {scaling}')
 
 
 class Distribution(Seedable):
     """A class for representing random distributions; created by calling get_distribution(params) on a Seedable object
     distributions are callable, such that some_seedable.get_distribution(params)() should return a random number from the distribution
     """
-    def __init__(self, params, **kwargs):
+    def __init__(self, params: Any, **kwargs):
         Seedable.__init__(self, **kwargs)
         self.params = params
             
     def __repr__(self) -> str:
-         return (
-             f"{self.__class__.__name__}(params={self.params}, seed={self.rng_seed}, parent={self.parent})"
-         )
+        return (
+            f"{self.__class__.__name__}(params={self.params}, seed={self.rng_seed}, parent={self.parent})"
+        )
         
-    def get_value(self):
+    def get_value(self) -> Any:
+        """samples from distribution function, returns a value
+
+        Raises:
+            NotImplementedError: Subclasses must implement this method.
+
+        Returns:
+            Any: Value(s) from distribution.
+        """             
         raise NotImplementedError("The Distribution class does not specify a distribution by itself. This must be specified by a subclass.")
         
-    def __call__(self, size=None):
-        if size == None:
+    def __call__(self, size: int = None) -> Any | np.ndarray:
+        """disttribution can return single value or np array of values sampled.
+
+        Args:
+            size (int, optional): number of values to return. Defaults to None.
+
+        Returns:
+            Any | np.ndarray: Value(s) sampled from distribution.
+        """        
+        if size is None:
             return self.get_value()
         return np.array([self.get_value() for i in range(size)])
 
 class ChoiceDistribution(Distribution):
     """A class for handling random choices from lists"""
-    def __init__(self, params, **kwargs):
+    def __init__(self, params: list | np.ndarray | int, **kwargs):
         Distribution.__init__(self, params, **kwargs)
+
     def get_value(self):
         return self.random_generator.choice(self.params)
 
 class UniformRangeDistribution(Distribution):
     """A class for handling random uniform ranges"""
-    def __init__(self, params, **kwargs):
+    def __init__(self, params: Tuple[float, float], **kwargs):
         Distribution.__init__(self, params, **kwargs)
+
     def get_value(self):
         return self.random_generator.uniform(low=self.params[0], high=self.params[1])
 
 class Log10UniformRangeDistribution(Distribution):
     """A class for handling log10-weighted random uniform ranges"""
-    def __init__(self, params, **kwargs):
+    def __init__(self, params: Tuple[float, float], **kwargs):
         Distribution.__init__(self, params, **kwargs)
+
     def get_value(self):
-        if (self.params[0] == 0 or self.params[1] == 0):
+        if (np.equal(self.params[0],0) or np.equal(self.params[1],0)):
             raise ValueError(f'Cannot compute log10(0). params = {self.params}')
-        elif (self.params[0] < 0 or self.params[1] < 0):
-            raise ValueError(f'Cannot compute log10 of negative number. params = {params}')
+        if (self.params[0] < 0 or self.params[1] < 0):
+            raise ValueError(f'Cannot compute log10 of negative number. params = {self.params}')
 
         low_log10 = np.log10(self.params[0])
         high_log10 = np.log10(self.params[1])
@@ -165,8 +222,9 @@ class Log10UniformRangeDistribution(Distribution):
 
 class UniformDistribution(Distribution):
     """A class for handling uniform random variables"""
-    def __init__(self, params, **kwargs):
+    def __init__(self, params: int | float, **kwargs):
         Distribution.__init__(self, params, **kwargs)
+
     def get_value(self):
         return self.random_generator.uniform(high=self.params)
 
diff --git a/torchsig/utils/verify.py b/torchsig/utils/verify.py
index 0099d854b..4c682d355 100644
--- a/torchsig/utils/verify.py
+++ b/torchsig/utils/verify.py
@@ -11,12 +11,10 @@ __all__ = [
     "verify_list",
     "verify_numpy_array",
     "verify_transforms",
-    "verify_target_transforms",
+    "verify_metadata_transforms",
     "verify_dict"
 ]
 
-# TorchSig
-
 # Third Party
 import numpy as np
 
@@ -26,7 +24,7 @@ from collections import Counter
 
 if TYPE_CHECKING:
     from torchsig.transforms.base_transforms import Transform
-    from torchsig.transforms.target_transforms import TargetTransform
+    from torchsig.transforms.target_transforms import MetadataTransform
 
 def verify_bounds(
     a: float | int,
@@ -332,14 +330,14 @@ def verify_numpy_array(
     if data_type is not None:
         item = n[0]
         if not isinstance(item, data_type):
-            raise ValueError(f"{name}[{i}] is not correct dtype {data_type}: {type(item)}")
+            raise ValueError(f"{name}[0] is not correct dtype {data_type}: {type(item)}")
 
     # check for np.nan's
-    if (np.isnan(n).any()):
+    if np.isnan(n).any():
         raise ValueError('Data contains one or more NaN np.nan values.')
 
     # check for np.inf's
-    if (np.isinf(n).any()):
+    if np.isinf(n).any():
         raise ValueError('Data contains one or more np.inf values.')
 
     return n
@@ -411,27 +409,26 @@ def verify_transforms(
     
     return t
 
-def verify_target_transforms(
-    tt: TargetTransform
-) -> List[TargetTransform | Callable]:
+def verify_metadata_transforms(
+    tt: MetadataTransform
+) -> List[MetadataTransform | Callable]:
     """
     Verifies that the value `tt` is a valid target transform, which can be a single target transform or a list of transforms.
 
     Args:
-        tt (TargetTransform): The target transform(s) to be checked.
+        tt (MetadataTransform): The target transform(s) to be checked.
 
     Raises:
         ValueError: If `tt` is not a valid target transform.
 
     Returns:
-        List[TargetTransform | Callable]: The verified list of target transforms.
+        List[MetadataTransform | Callable]: The verified list of target transforms.
     """
-    from torchsig.transforms.target_transforms import TargetTransform
-
+    from torchsig.transforms.metadata_transforms import MetadataTransform
     if tt is None:
         return []
     # convert target transforms to list
-    if isinstance(tt, TargetTransform):
+    if isinstance(tt, MetadataTransform):
         tt = [tt]
     elif not isinstance(tt, list):
         raise ValueError(f"target transforms is not a list: {type(tt)}")
diff --git a/torchsig/utils/writer.py b/torchsig/utils/writer.py
index 974bb9b59..9db13a37c 100644
--- a/torchsig/utils/writer.py
+++ b/torchsig/utils/writer.py
@@ -4,15 +4,11 @@
 from __future__ import annotations
 
 # TorchSig
-from torchsig.datasets.datasets import TorchSigIterableDataset
-from torchsig.datasets.dataset_utils import dataset_full_path, dataset_yaml_name, writer_yaml_name
-from torchsig.utils.file_handlers.base_handler import TorchSigFileHandler
-from torchsig.utils.file_handlers.zarr import ZarrFileHandler
-
-from torchsig.datasets.dataset_utils import save_type
+from torchsig.datasets.dataset_utils import dataset_yaml_name, writer_yaml_name
+from torchsig.utils.file_handlers.base_handler import FileWriter as TorchSigFileHandler
+from torchsig.utils.file_handlers.hdf5 import HDF5Writer as DEFAULT_FILE_HANDLER
 from torchsig.utils.yaml import write_dict_to_yaml
-
-from torchsig.datasets.dataset_utils import collate_fn as default_collate_fn
+from torchsig.signals.signal_types import Signal, SignalMetadata
 
 # Third Party
 from tqdm.auto import tqdm
@@ -20,16 +16,76 @@ import yaml
 import numpy as np
 from time import time
 from torch import Tensor
+from torch.utils.data import DataLoader
 
 # Built-In
-from typing import Callable, Dict, Any, List, Tuple
+from typing import Dict, Any, List, Tuple
 from pathlib import Path
 import os
 from shutil import disk_usage
 import concurrent.futures
 import threading
 
-from torchsig.utils.data_loading import WorkerSeedingDataLoader
+def default_collate_fn(batch):
+    """Collates a batch by zipping its elements together.
+
+    Args:
+        batch (tuple): A batch from the dataloader.
+
+    Returns:
+        tuple: A tuple of zipped elements, where each element corresponds to a single batch item.
+    """
+    return tuple(zip(*batch))
+
+def handle_non_numpy_datatypes(data):
+        if isinstance(data, Tensor):
+            data = data.numpy()
+        return data
+
+def targets_as_metadata(targets, target_labels, dataset_metadata):
+    """utility function for reading target labels as signal metadata objects; returns a new SignalMetadata"""
+    signal_metadata = SignalMetadata(dataset_metadata=dataset_metadata)
+    if not isinstance(targets,list):
+        targets = [targets]
+    for i in range(len(target_labels)):
+        setattr(signal_metadata, target_labels[i], targets[i])
+    return signal_metadata
+
+def batch_as_signal_list(batch, target_labels = None, dataset_metadata = None):
+    signal_list = []
+    if isinstance(batch, tuple) and len(batch) == 2:
+        datas, batch_targets = batch[0], batch[1]
+        for i in range(len(datas)):
+            data = handle_non_numpy_datatypes(datas[i])
+            metadata = None
+            component_signals=[]
+            targets = batch_targets[i]
+            if dataset_metadata.num_signals_max == 1:
+                #do make on a single signal with no comonents
+                metadata = targets_as_metadata(targets, target_labels, dataset_metadata)
+            else:
+                #many a single signal with multiple components containing the given targets
+                for component_targets in targets:
+                    component_metadata = targets_as_metadata(component_targets, target_labels, dataset_metadata)
+                    component_signals += [Signal(data=None, metadata=component_metadata, component_signals=[])]
+
+            signal_list += [Signal(data=data, metadata=metadata, component_signals=component_signals)]
+        return signal_list
+    elif isinstance(batch, np.ndarray):
+        if len(batch.shape) < 2:
+            batch = batch.reshape(1,-1)
+        for row in batch:
+            signal_list += [Signal(data=handle_non_numpy_datatypes(row), metadata=None, component_signals=[])]
+        return signal_list
+    elif isinstance(batch, list):
+        for s in batch:
+            if isinstance(s,Signal):
+                signal_list += [s]
+            else:
+                raise ValueError("could not parse batch input as signals")
+        return signal_list
+    raise ValueError("could not parse batch input as signals")
+
 
 class DatasetCreator():
     """Class for creating a dataset and saving it to disk in batches.
@@ -40,93 +96,53 @@ class DatasetCreator():
     batch size, and number of worker threads.
 
     Attributes:
+        dataloader (DataLoader): The DataLoader used to load data in batches.
         root (Path): The root directory where the dataset will be saved.
         overwrite (bool): Flag indicating whether to overwrite an existing dataset.
-        batch_size (int): The number of samples in each batch.
-        num_workers (int): The number of worker threads to use for data loading.
-        save_type (str): The type of dataset being saved ("raw" or "processed").
         tqdm_desc (str): A description for the progress bar.
-        writer (TorchSigFileHandler): The file handler used for saving the dataset.
-        dataloader (DataLoader): The DataLoader used to load data in batches.
+        file_handler (TorchSigFileHandler): The file handler used for saving the dataset.
     """
     def __init__(
         self,
-        dataset: TorchSigIterableDataset,
-        root: str,
-        overwrite: bool = False, # will overwrite any existing dataset on disk
-        batch_size: int = 1,
-        num_workers: int = 1,
-        collate_fn: Callable = default_collate_fn,
+        dataloader: DataLoader = None,
+        dataset_length : int = None,
+        root: str = '.',
+        overwrite: bool = True, # will overwrite any existing dataset on disk
         tqdm_desc: str = None,
-        file_handler: TorchSigFileHandler = ZarrFileHandler,
-        train: bool = None,
+        file_handler: TorchSigFileHandler = DEFAULT_FILE_HANDLER,
         multithreading: bool = True,
-        seed = None,
         **kwargs # any additional file handler args
     ):
         """Initializes the DatasetCreator.
 
         Args:
-            dataset (NewTorchSigDataset): The dataset to be written to disk.
-            root (str): The root directory where the dataset will be saved.
-            overwrite (bool): Whether to overwrite an existing dataset (default: False).
-            batch_size (int): The number of samples per batch (default: 1).
-            num_workers (int): The number of workers for loading data (default: 1).
-            collate_fn (Callable): Function to merge a list of samples into a batch (default: default_collate_fn).
-            tqdm_desc (str): Description for the tqdm progress bar (optional).
-            file_handler (TorchSigFileHandler): File handler for saving the dataset (default: ZarrFileHandler).
-            train (bool): Whether the dataset is for training (optional).
-        
-        Raises:
-            ValueError: If the dataset does not specify `num_samples`.
+            dataloader (DataLoader): The DataLoader used to load data in batches.
+            dataset_length (int): The number of samples to draw from a dataset.
+            root (Path): The root directory where the dataset will be saved.
+            overwrite (bool): Flag indicating whether to overwrite an existing dataset.
+            tqdm_desc (str): A description for the progress bar.
+            file_handler (TorchSigFileHandler): The file handler used for saving the dataset.
         """
         self.root = Path(root)
+        self.dataset_info_filepath = self.root.joinpath("dataset_info.yaml")
+        self.writer_info_filepath = self.root.joinpath("writer_info.yaml")
+        self.dataset_length = dataset_length
         self.overwrite = overwrite
-        self.batch_size = batch_size
-        self.num_workers = num_workers
-        self.batch_size = batch_size
+        self.batch_size = dataloader.batch_size
+        self.num_workers = dataloader.num_workers
         self.multithreading = multithreading
+        self.num_batches = self.dataset_length//self.batch_size
+        if not np.equal(self.dataset_length % self.batch_size,0):
+            self.num_batches += 1 #include the partial batch at the end if it can't be evenly batched
 
-        if dataset.dataset_metadata.num_samples is None:
-            raise ValueError("Must specify num_samples as an integer number. Cannot write infinite dataset to disk.")
-
-        self.dataloader = WorkerSeedingDataLoader(
-            dataset = dataset,
-            num_workers = num_workers,
-            batch_size = batch_size,
-            collate_fn = collate_fn,
-            persistent_workers = False,  # Don't keep workers alive between epochs
-            pin_memory = False,  # Disable pin_memory to reduce memory usage
-            prefetch_factor = 2 if num_workers > 0 else 2  # Reduce prefetch buffer
-        )
-        if seed:
-            self.dataloader.seed(seed)
-
-        # e.g., root/torchsig_narrowband_clean
-        full_root = dataset_full_path(
-            impairment_level = dataset.dataset_metadata.impairment_level,
-            train = train,
-        )
-        self.full_root = f"{root}/{full_root}"
-
-        self.writer = file_handler(
-            root = self.full_root,
-            batch_size = self.batch_size,
-            **kwargs
-        )
-        # save_type (str): What kind of data was written to disk.
-        # * "raw" means data and metadata after impairments are applied, but no other transforms and target transforms.
-        #     * When loaded back in, users can choose what transforms or target transforms to apply.
-        #     * Choose this option if you want to create a dataset that you (or multiple people) can later choose their own transforms and target transforms.
-        # * "processed" means data and targets after all transforms and target transforms are applied.
-        #     * When loaded back in, users cannot change the transforms or target transform already applied to data.
-        #     * Choose this option if you want to lock in the transforms and target transform applied, or if you want maximum speed and/or minimal disk space used.
-        self.save_type = "raw" if save_type( 
-            dataset.dataset_metadata.transforms,
-            dataset.dataset_metadata.target_transforms
-        ) else "processed"
-
-        self.tqdm_desc = f"Generating Dataset:" if tqdm_desc is None else tqdm_desc
+
+        self.dataloader = dataloader
+        self.file_handler = file_handler
+
+        # get reference to tqdm progress bar object
+        self.pbar = tqdm()
+
+        self.tqdm_desc = "Generating Dataset:" if tqdm_desc is None else tqdm_desc
 
         # limit in gigabytes for remaining space on disk for which writer stops writing
         self.minimum_remaining_disk_gigabytes = 1
@@ -134,6 +150,8 @@ class DatasetCreator():
         # Thread lock for updating tqdm message to avoid race conditions
         self._tqdm_lock = threading.Lock()
 
+        self._msg_timer = None
+
     
     def get_writing_info_dict(self) -> Dict[str, Any]:
         """Returns a dictionary with information about the dataset being written.
@@ -147,12 +165,9 @@ class DatasetCreator():
         """
         return {
             'root':str(self.root),
-            'full_root': self.writer.root,
             'overwrite': self.overwrite,
             'batch_size': self.batch_size,
             'num_workers': self.num_workers,
-            'file_handler': self.writer.__class__.__name__,
-            'save_type': self.save_type,
             'complete': False,
         }
 
@@ -167,17 +182,15 @@ class DatasetCreator():
         """
         to_write_dataset_metadata = self.dataloader.dataset.dataset_metadata.to_dict()
 
-        writer_yaml = f"{self.writer.root}/{writer_yaml_name}"
         complete = False
-        with open(writer_yaml, 'r') as f:
+        with open(self.writer_info_filepath, 'r') as f:
             writer_dict = yaml.load(f, Loader=yaml.FullLoader)
             # check if dataset finished writing
             complete = writer_dict['complete']
         
-        dataset_yaml = f"{self.writer.root}/{dataset_yaml_name}"
         different_params = []
 
-        if os.path.exists(dataset_yaml):
+        if os.path.exists(self.dataset_info_filepath):
             with open(dataset_yaml, 'r') as f:
                 dataset_metadata_yaml = yaml.load(f, Loader=yaml.FullLoader)
 
@@ -193,18 +206,15 @@ class DatasetCreator():
 
         return complete, different_params
 
-    def _write_batch(self, batch_idx: int, batch: Any, pbar):
+    def _write_batch(self, writer, batch_idx: int, batch: Any):
         """Multi-threaded writer batch
         Args:
             batch_idx (int): batch index
             batch (Any): batch
-            pbar (_type_): tqdm bar to update
         """        
         try:
             # write to disk
-            self.writer.write(batch_idx, batch)
-            # update progress bar message
-            self._update_tqdm_message(pbar,batch_idx)
+            writer.write(batch_idx, batch)
         finally:
             # Clear batch reference to help garbage collection
             del batch
@@ -220,134 +230,123 @@ class DatasetCreator():
         Raises:
             ValueError: If the dataset is already generated and `overwrite` is set to False.
         """
-        if self.writer.exists() and not self.overwrite:
-            complete, different_params = self.check_yamls()
-            if len(different_params) == 0 and complete:
-                print(f"Dataset already exists in {self.writer.root}. Not regenerating.")
+        with self.file_handler(root = self.root) as writer:
+            if writer.exists() and not self.overwrite:
+                complete, different_params = self.check_yamls()
+                if np.equal(len(different_params),0) and complete:
+                    print(f"Dataset already exists in {self.root}. Not regenerating.")
+                    return
+    
+                if not complete:
+                    # dataset on disk is corrupted
+                    # dataset was not fully written to disk
+                    raise RuntimeError(f"Dataset only partially exists in {self.root} (writing dataset to disk was cancelled early). Regenerate the dataset by setting overwrite = True for DatasetCreator")
+                # else:
+                # dataset exists on disk with different params
+                # use dataset on disk instead
+                # warn users that params are different
+                print(f"Dataset exists at {self.root} but is different than current dataset.")
+                print("Differences:")
+                for row in different_params:
+                    key, disk_value, current_value = row
+                    print(f"\t{key} = {current_value} ({disk_value} found)")
+                print("If you want to overwrite dataset on disk, set overwrite = True for the DatasetCreator.")
+                print("Not regenerating. Using dataset on disk.")
                 return
-
-            if not complete:
-                # dataset on disk is corrupted
-                # dataset was not fully written to disk
-                raise RuntimeError(f"Dataset only partially exists in {self.writer.root} (writing dataset to disk was cancelled early). Regenerate the dataset by setting overwrite = True for DatasetCreator")
-            # else:
-            # dataset exists on disk with different params
-            # use dataset on disk instead
-            # warn users that params are different
-            print(f"Dataset exists at {self.writer.root} but is different than current dataset.")
-            print("Differences:")
-            for row in different_params:
-                key, disk_value, current_value = row
-                print(f"\t{key} = {current_value} ({disk_value} found)")
-            print("If you want to overwrite dataset on disk, set overwrite = True for the DatasetCreator.")
-            print("Not regenerating. Using dataset on disk.")
-            return
-
-        # set up writer
-        self.writer.setup()
-
-        # generate info yamls
-        write_dict_to_yaml(f"{self.writer.root}/{dataset_yaml_name}", self.dataloader.dataset.dataset_metadata.to_dict())
-        write_dict_to_yaml(f"{self.writer.root}/{writer_yaml_name}", self.get_writing_info_dict())
-
-        # get reference to tqdm progress bar object
-        pbar = tqdm()
-
-        # store start time
-        self._msg_timer = time()
-
-        # update progress bar message
-        self._update_tqdm_message(pbar)
-
-        # write dataset
-        if self.multithreading:
-            # write each batch as its own thread
-            # num_threads defaults to: min(32, os.cpu_count() + 4)
-            with concurrent.futures.ThreadPoolExecutor() as executor:
-
-                # Process batches in chunks to avoid memory buildup
-                batch_chunk_size = min(100, len(self.dataloader) // 10)  # Process in smaller chunks
-                if batch_chunk_size == 0:
-                    batch_chunk_size = 1
-
-                batch_iter = enumerate(self.dataloader)
-                processed_batches = 0
-                total_batches = len(self.dataloader)
-
-                # Process in chunks to manage memory
-                while processed_batches < total_batches:
-                    # Get next chunk of batches
-                    chunk_futures = []
-                    chunk_size = 0
-
-                    for _ in range(min(batch_chunk_size, total_batches - processed_batches)):
-                        try:
-                            batch_idx, batch = next(batch_iter)
-                            future = executor.submit(self._write_batch, batch_idx, batch, pbar)
-                            chunk_futures.append(future)
-                            chunk_size += 1
-                        except StopIteration:
+    
+            # generate info yamls
+            write_dict_to_yaml(self.dataset_info_filepath, self.dataloader.dataset.dataset_metadata.to_dict())
+            write_dict_to_yaml(self.writer_info_filepath, self.get_writing_info_dict())
+    
+            # store start time
+            self._msg_timer = time()
+    
+            # write dataset
+            if self.multithreading:
+                # write each batch as its own thread
+                # num_threads defaults to: min(32, os.cpu_count() + 4)
+                with concurrent.futures.ThreadPoolExecutor() as executor:
+    
+                    # Process batches in chunks to avoid memory buildup
+                    batch_chunk_size = max(1, min(100, self.num_batches) // 10) # Process in smaller chunks
+    
+                    batch_iter = enumerate(self.dataloader)
+                    processed_batches = 0
+                    total_batches = self.num_batches
+    
+                    # Process in chunks to manage memory
+                    while processed_batches < total_batches:
+                        # Get next chunk of batches
+                        chunk_futures = []
+                        chunk_size = 0
+    
+                        for _ in range(min(batch_chunk_size, total_batches - processed_batches)):
+                            try:
+                                batch_idx, batch = next(batch_iter)
+                                batch = batch_as_signal_list(batch, self.dataloader.dataset.target_labels, self.dataloader.dataset.dataset_metadata)
+    
+                                if batch_idx == self.num_batches - 1 and not np.equal(self.dataset_length % self.batch_size,0):
+                                    batch = batch[:self.dataset_length%self.batch_size]
+    
+                                future = executor.submit(self._write_batch, writer, batch_idx, batch)
+                                chunk_futures.append(future)
+                                chunk_size += 1
+                            except StopIteration:
+                                break
+    
+                        # Only process if we have futures to process
+                        if chunk_futures:
+                            # Wait for chunk to complete before processing next chunk
+                            concurrent.futures.wait(chunk_futures)
+    
+                            # Clear references to help garbage collection
+                            for future in chunk_futures:
+                                future.result()  # Ensure completion
+                            del chunk_futures
+    
+                            processed_batches += chunk_size
+    
+                            # Force garbage collection between chunks
+                            import gc
+                            gc.collect()
+    
+                        else:
+                            # No more batches to process
                             break
-
-                    # Only process if we have futures to process
-                    if chunk_futures:
-                        # Wait for chunk to complete before processing next chunk
-                        concurrent.futures.wait(chunk_futures)
-
-                        # Clear references to help garbage collection
-                        for future in chunk_futures:
-                            future.result()  # Ensure completion
-                        del chunk_futures
-
-                        processed_batches += chunk_size
-
-                        # Force garbage collection between chunks
-                        import gc
-                        gc.collect()
-
-                    else:
-                        # No more batches to process
-                        break
-
-        else:
-            # single threaded writing
-            itr = iter(self.dataloader)
-            for batch_idx in tqdm(range(len(self.dataloader)), total = len(self.dataloader)):
-
-                batch = next(itr)
-
-                try:
-                    # write to disk
-                    self.writer.write(batch_idx, batch)
-
-                    # update progress bar message
-                    self._update_tqdm_message(pbar,batch_idx)
-
-                finally:
-                    # Clear batch reference to help garbage collection
-                    del batch
-
-                    # Force garbage collection every 10 batches
-                    if batch_idx % 10 == 0:
-                        import gc
-
-                        gc.collect()
-
-        # update writer yaml
-        # indicate writing dataset to disk was successful
-        updated_writer_yaml = self.get_writing_info_dict()
-        updated_writer_yaml['complete'] = True
-        write_dict_to_yaml(f"{self.writer.root}/{writer_yaml_name}", updated_writer_yaml)
-
-    def _handle_batch_datatypes(self, batch):
-        bx, by = batch
-        if isinstance(bx, Tensor):
-            bx = bx.numpy()
-        if isinstance(by, Tensor):
-            by = by.numpy()
-        return (bx,by)
-
-    def _update_tqdm_message( self, pbar=tqdm(), batch_idx:int = 0 ):
+    
+            else:
+                # single threaded writing
+                itr = iter(self.dataloader)
+    
+                for batch_idx in tqdm(range(self.num_batches), total = self.num_batches):
+                    batch = next(itr)
+                    batch = batch_as_signal_list(batch, self.dataloader.dataset.target_labels, self.dataloader.dataset.dataset_metadata)
+                    
+                    if batch_idx == self.num_batches - 1 and not np.equal(self.dataset_length % self.batch_size,0):
+                        batch = batch[:self.dataset_length%self.batch_size]
+
+                    try:
+                        # write to disk
+                        self._write_batch(writer,batch_idx,batch)
+    
+                        # update progress bar message
+                        self._update_tqdm_message(batch_idx)
+    
+                    finally:
+                        # Clear batch reference to help garbage collection
+                        del batch
+    
+                        # Force garbage collection every 10 batches
+                        if np.equal(batch_idx % 10,0):
+                            import gc
+                            gc.collect()
+            # update writer yaml
+            # indicate writing dataset to disk was successful
+            updated_writer_yaml = self.get_writing_info_dict()
+            updated_writer_yaml['complete'] = True
+            write_dict_to_yaml(self.writer_info_filepath, updated_writer_yaml)
+
+    def _update_tqdm_message(self, batch_idx:int ):
 
         """Updates the tqdm progress bar with remaining disk space
 
@@ -364,42 +363,39 @@ class DatasetCreator():
             # compute elapsed time since last run
             elapsed_time = time() - self._msg_timer
 
-            # run every second
-            if (batch_idx == 0 or elapsed_time > 1):
-
-                # update timer
-                self._msg_timer = time()
+            # run every second, but wait until 20 iterations have
+            # passed in order to create a more realiable estimate
+            if (not batch_idx or elapsed_time > 1):
 
                 # get the amount of disk space remaining
-                disk_size_available_bytes = disk_usage(self.writer.root)[2]
+                disk_size_available_bytes = disk_usage(self.root)[2]
                 # convert to GB and round to two decimal places
-                disk_size_available_gigabytes = np.round(disk_size_available_bytes/(1024**3),2)
-
+                disk_size_available_gigabytes = np.round(disk_size_available_bytes/(1000**3),2)
                 # get size of dataset written so far
-                dataset_size_current_gigabytes = self._get_directory_size_gigabytes(self.writer.root)
+                dataset_size_current_gigabytes = self._get_directory_size_gigabytes(self.root)
+                # num samples processed and remaining
+                num_samples_written = (batch_idx+1)*self.batch_size
+                num_samples_remaining = self.dataset_length - num_samples_written
                 # estimate size per sample
-                dataset_size_per_sample_gigabytes = dataset_size_current_gigabytes/(batch_idx+1)
-                # number of samples left
-                num_samples_remaining = len(self.dataloader)-(batch_idx+1)
-                # project estimated size
+                dataset_size_per_sample_gigabytes = dataset_size_current_gigabytes/num_samples_written
+                # predict estimated size
                 dataset_size_remaining_gigabytes = np.round(dataset_size_per_sample_gigabytes*num_samples_remaining,2)
+                # estimate total dataset size
+                dataset_size_total_gigabytes = np.round(dataset_size_per_sample_gigabytes*self.dataset_length,2)
 
                 # concatenate disk size for progress bar message
-                updated_tqdm_desc = f'{self.tqdm_desc} dataset remaining to create = {dataset_size_remaining_gigabytes} GB, remaining disk = {disk_size_available_gigabytes} GB'
+                updated_tqdm_desc = f'{self.tqdm_desc} estimated dataset size = {dataset_size_total_gigabytes} GB, dataset remaining = {dataset_size_remaining_gigabytes} GB, remaining disk = {disk_size_available_gigabytes} GB'
 
-                # set the progress bar message
-                pbar.set_description(updated_tqdm_desc)
+                # avoid crashing by stopping write process
+                if disk_size_available_gigabytes < self.minimum_remaining_disk_gigabytes:
+                    # remaining disk size is below a hard cutoff value to avoid crashing operating system
+                    raise ValueError(f'Disk nearly full! Remaining space is {disk_size_available_gigabytes} GB. Please make space before continuing.')
+                if dataset_size_remaining_gigabytes > disk_size_available_gigabytes:
+                    # projected size of dataset too large for available disk space
+                    raise ValueError(f'Not enough disk space. Projected dataset size is {dataset_size_remaining_gigabytes} GB. Remaining space is {disk_size_available_gigabytes} GB. Please reduce dataset size or make space before continuing.')
 
-                # wait for 20 batches to be produced to get an accurate
-                # estimate of dataset size to be produced
-                if (batch_idx > 20):
-                    # avoid crashing by stopping write process
-                    if disk_size_available_gigabytes < self.minimum_remaining_disk_gigabytes:
-                        # remaining disk size is below a hard cutoff value to avoid crashing operating system
-                        raise ValueError(f'Disk nearly full! Remaining space is {disk_size_available_gigabytes} GB. Please make space before continuing.')
-                    elif dataset_size_remaining_gigabytes > disk_size_available_gigabytes:
-                        # projected size of dataset too large for available disk space
-                        raise ValueError(f'Not enough disk space. Projected dataset size is {dataset_size_remaining_gigabytes} GB. Remaining space is {disk_size_available_gigabytes} GB. Please reduce dataset size or make space before continuing.')
+                # set the progress bar message
+                self.pbar.set_description(updated_tqdm_desc)
 
 
     def _get_directory_size_gigabytes ( self, start_path ):
@@ -407,7 +403,7 @@ class DatasetCreator():
         Returns total size of a directory (including subdirs) in gigabytes
         """
         total_size = 0
-        for path, dirs, files in os.walk(start_path):
+        for path, _, files in os.walk(start_path):
             for f in files:
                 fp = os.path.join(path, f)
                 #total_size += os.path.getsize(fp)
@@ -418,7 +414,5 @@ class DatasetCreator():
                     # skip it and continue
                     continue
         
-        total_size_GB = total_size/(1024**3)
-        return total_size_GB
-
-
+        total_size_gb = total_size/(1000**3)
+        return total_size_gb
diff --git a/torchsig/utils/yaml.py b/torchsig/utils/yaml.py
index 6fe235e8d..83acadfa8 100644
--- a/torchsig/utils/yaml.py
+++ b/torchsig/utils/yaml.py
@@ -2,6 +2,8 @@
 """
 
 import yaml
+from torchsig.datasets.dataset_metadata import DatasetMetadata
+from torchsig.datasets.datasets import TorchSigIterableDataset
 
 
 def custom_representer(dumper, value):
@@ -36,4 +38,86 @@ def write_dict_to_yaml(filename: str, info_dict: dict) -> None:
     yaml.add_representer(list, custom_representer)
 
     with open(filename, 'w+') as file:
-        yaml.dump(info_dict, file, default_flow_style=False, sort_keys=False, width=200)
\ No newline at end of file
+        yaml.dump(info_dict, file, default_flow_style=False, sort_keys=False, width=200)
+
+def dataset_metadata_from_yaml_dict(yaml_dict):
+    """
+    passes data from the yaml_dict as needed into the DatasetMetadata constructor, and returns a new DatasetMetadata
+    """
+    return DatasetMetadata(
+        num_iq_samples_dataset = yaml_dict["num_iq_samples_dataset"], 
+        fft_size = yaml_dict["fft_size"],
+        num_signals_min = yaml_dict["num_signals_min"],
+        num_signals_max = yaml_dict["num_signals_max"],
+        sample_rate = yaml_dict["sample_rate"],
+        num_signals_distribution = yaml_dict["num_signals_distribution"],
+        snr_db_min = yaml_dict["snr_db_min"],
+        snr_db_max = yaml_dict["snr_db_max"],
+        signal_duration_min = yaml_dict["signal_duration_min"],
+        signal_duration_max = yaml_dict["signal_duration_max"],
+        signal_bandwidth_min = yaml_dict["signal_bandwidth_min"],
+        signal_bandwidth_max = yaml_dict["signal_bandwidth_max"],
+        signal_center_freq_min = yaml_dict["signal_center_freq_min"],
+        signal_center_freq_max = yaml_dict["signal_center_freq_max"],
+        cochannel_overlap_probability = yaml_dict["cochannel_overlap_probability"],
+        class_list = yaml_dict["class_list"],
+        class_distribution = yaml_dict["class_distribution"],
+    )
+
+def dataset_from_yaml_dict(yaml_dict):
+    """
+    passes data from the yaml_dict as needed into the TorchSigIterableDataset constructor, and returns a new TorchSigIterableDataset
+    """
+    dataset_metadata = dataset_metadata_from_yaml_dict(yaml_dict["dataset_metadata"])
+    return TorchSigIterableDataset(
+        dataset_metadata = dataset_metadata,
+        transforms = [],
+        component_transforms = [],
+        target_labels = yaml_dict["target_labels"],
+        seed = yaml_dict["seed"],
+    )
+
+def load_dataset_yaml(filepath):
+    """
+    loads YAML data from specified filepath and uses it to construct and return a new TorchSigIterableDataset
+    """
+    loaded_dict = {}
+    with open(filepath, 'r') as yaml_file:
+        loaded_dict = yaml.safe_load(yaml_file)
+    return dataset_from_yaml_dict(loaded_dict)
+
+def save_dataset_yaml(filepath, dataset):
+    """
+    saves YAML data to specified filepath to represent the input TorchSigIterableDataset
+    """
+    yaml_dict = {}
+    yaml_dict["seed"] = dataset.rng_seed
+    yaml_dict["target_labels"] = dataset.target_labels
+    yaml_dict["dataset_metadata"] = dataset_metadata_to_yaml_dict(dataset.dataset_metadata)
+    write_dict_to_yaml(filepath, yaml_dict)
+
+def dataset_metadata_to_yaml_dict(dataset_metadata):
+    """
+    returns a dictionary representation of a DatasetMetadata object for storing as YAML
+    """
+    yaml_dict = {}
+    yaml_dict["num_iq_samples_dataset"] = dataset_metadata.num_iq_samples_dataset
+    yaml_dict["fft_size"] = dataset_metadata.fft_size
+    yaml_dict["num_signals_min"] = dataset_metadata.num_signals_min
+    yaml_dict["num_signals_max"] = dataset_metadata.num_signals_max
+    yaml_dict["sample_rate"] = dataset_metadata.sample_rate
+    yaml_dict["num_signals_distribution"] = dataset_metadata.num_signals_distribution
+    yaml_dict["snr_db_min"] = dataset_metadata.snr_db_min
+    yaml_dict["snr_db_max"] = dataset_metadata.snr_db_max
+    yaml_dict["signal_duration_min"] = dataset_metadata.signal_duration_min
+    yaml_dict["signal_duration_max"] = dataset_metadata.signal_duration_max
+    yaml_dict["signal_bandwidth_min"] = dataset_metadata.signal_bandwidth_min
+    yaml_dict["signal_bandwidth_max"] = dataset_metadata.signal_bandwidth_max
+    yaml_dict["signal_center_freq_min"] = dataset_metadata.signal_center_freq_min
+    yaml_dict["signal_center_freq_max"] = dataset_metadata.signal_center_freq_max
+    yaml_dict["cochannel_overlap_probability"] = dataset_metadata.cochannel_overlap_probability
+    yaml_dict["class_list"] = dataset_metadata.class_list
+    yaml_dict["class_distribution"] = dataset_metadata.class_distribution
+    return yaml_dict
+
+        
\ No newline at end of file
